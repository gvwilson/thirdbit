---
title: "I Don't Know What to Think About AI"
date: 2023-08-13
---

I had a conversation last week with someone who has been working hard for years
to get more students from marginalized groups into tech jobs.
Their organization is about to invest heavily in AI for coding;
when I mentioned that I have concerns about both the ethics and the efficacy of that,
their response was (a) students are going to use these tools anyway
and (b) these kids can't afford to be fussy about ethics—they need jobs.

I've been chewing over the conversation ever since.
On the one hand,
I believe that AI tools are going to change programming just as much as Stack Overflow did.
As Jon Udell has said,
AI is the next great democratizer:
with its help,
millions of people will be able to make computers do things
that they can't feasibly make them do today.
On the other hand,
today's models encode and perpetuate the biases of the data they're trained on,
and the environmental and [human cost][guardian-ai] of that training is high
(and is mostly *not* borne by the people who benefit from them).

But then I remember another conversation that I overheard many years ago.
The woman beside me kept saying that
poor kids would be better off if they ate a balanced diet and organic produce.
Eventually the woman sitting opposite her
(who taught at a middle school in a low-income neighborhood)
lost her temper and said,
"It would take two hours each way for my kids' parents
to get to the grocery store in your neighborhood.
Even if they went they couldn't afford to buy what's there,
so who are you in your hundred-dollar t-shirt to tell them what to eat?"

I believe that most of the present furore over AI is Silicon Valley hype
and that it would be reckless to deploy anything in classrooms today
when so many technical, ethical, and regulatory aspects
are going to change in the coming months or even weeks.
I also believe that my social and economic privilege allow me to be squeamish
in ways that many other people can't afford.
We've paid off our mortgage and I'm just a few years away from retirement;
who the hell am I with my top-of-the-line MacBook to tell anyone how to code?

The best analogy I've been able to come up with so far is opioids.
My [younger brother's final months][jeff] would have been literally unbearable without them,
but they have also destroyed hundreds of thousands of lives.
That didn't have to happen,
but billionaires have undermined regulatory agencies and the popular will to enforce regulations
so successfully
that the Sackler family and the doctors who lined their own pockets by "over-prescribing"
are all still walking around free.
I'd sleep a lot easier
if I believed that we would somehow magically find enough shared backbone
to hold companies liable for the harm AI is going to do,
but again,
who the hell am I to make that decision for a 21-year-old Indigenous college student
for whom a job as a web developer might literally be live-saving?

So as the title says,
I don't know what to think about AI.
People I trust believe in its potential;
other people whom I also trust are terrified of the ways in which it is going to be mis-used.
What I *want* to do is spend a year watching people experiment with these tools
in the way that they experimented with the web in the 1990s
and *then* form an opinion:
to paraphrase William Gibson,
the classroom finds its own uses for things,
and I think we'd all be better off if we gave the courageous and the curious
a year to figure out what AI is actually good for
before we start placing our bets.
But I fear the train has already left the station…

[guardian-ai]: https://www.theguardian.com/technology/2023/aug/02/ai-chatbot-training-human-toll-content-moderator-meta-openai
[jeff]: @root/2018/03/20/goodbye-jeff/
