---
date: 2019-07-07
title: "A Veteran of a Thousand Language Wars"
---

> You see me now a veteran of a thousand psychic wars<br>
> I've been living on the edge so long, where the winds of limbo roar…<br>
> —Blue Oyster Cult

There's been some more discussion on the interwebs about base R versus tidyverse.
As someone who once had strong beliefs about Fortran 90 versus FORTRAN 77
(and yes, I did capitalize them that way thirty-odd years ago),
I'd like to ask you to tell me
what empirical study could be done that would convince you that you're wrong
about whatever belief you hold.
Do you think that people who've never programmed before
can reach a certain level of statistical proficiency more quickly with the tidyverse than with base R?
Great:
show me the assessments you will use to determine if they've reached that level
and tell me the threshold at which you would say, "Gosh—OK, I guess I ought to change my mind."
Or if [you believe](https://github.com/matloff/TidyverseSkeptic)
that R users who learned the tidyverse first will,
"…be biased against non-Tidyverse job seekers,
non-Tidyverse CRAN packages,
and academics who submit non-Tidyverse data science research papers and grant proposals,"
tell me what data you would accept as refutation.
We know how to study bias in hiring practices and journal reviews;
what *p* value would convince you that bias *doesn't* exist in this case<sup><a href="#p-value">1</a></sup>?

I'm not asking anyone to actually run these studies before having an opinion
(but watch this space—I hope to be able to share some news soon).
What I'm asking for is evidence that people are willing to change their minds,
because if they're not,
we're arguing about faith,
not science,
and I think that's a pretty poor example for those of us with "scientist" in their job titles to set.

<a id="p-value">[1]</a> Which will no doubt trigger endless arguments about *p* values…
