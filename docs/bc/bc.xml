<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book
  PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN" "http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">
<book id="I_book_tt2" fpi="9780596510046"><title>Beautiful Code</title><bookinfo><isbn>9780596510046</isbn><!--Published by--><publisher><publishername>O’Reilly Media, Inc.</publishername><address format="linespecific"><street>1005 Gravenstein Highway North</street><city>Sebastopol</city><state>CA</state><postcode>95472</postcode></address></publisher></bookinfo><preface id="beautiful_code" role="copyrightpg"><title>Beautiful Code</title><para>Edited by Andy Oram and Greg Wilson</para><para>Copyright © 2007 O'Reilly Media, Inc. All rights reserved. Printed in the United States of America.</para><para>Published by O'Reilly Media, Inc. 1005 Gravenstein Highway North, Sebastopol, CA 95472</para><para>O'Reilly books may be purchased for educational, business, or sales promotional use. Online editions are also available for most titles (<ulink url="http://safari.oreilly.com">safari.oreilly.com</ulink>). For more information, contact our corporate/institutional sales department: (800) 998-9938 or <email>corporate@oreilly.com</email>.</para><informaltable><tgroup cols="2"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><thead><row><entry><para><emphasis role="strong">Production Editor</emphasis>: Marlowe Shaeffer</para></entry><entry><para><emphasis role="strong">Cover Designer</emphasis>: Randy Comer</para></entry></row></thead><tbody><row><entry><para><emphasis role="strong">Production Editor</emphasis>: Marlowe Shaeffer</para></entry><entry><para><emphasis role="strong">Cover Designer</emphasis>: Randy Comer</para></entry></row><row><entry><para><emphasis role="strong">Copyeditor</emphasis>: Sanders Kleinfeld</para></entry><entry><para><emphasis role="strong">Interior Designer</emphasis>: Marcia Friedman</para></entry></row><row><entry><para><emphasis role="strong">Proofreader</emphasis>: Sohaila Abdulali</para></entry><entry><para><emphasis role="strong">Illustrator</emphasis>: Jessamyn Read</para></entry></row><row><entry><para><emphasis role="strong">Indexer</emphasis>: Ellen Troutman Zaig</para></entry><entry><para/></entry></row></tbody></tgroup></informaltable><informaltable><tgroup cols="2"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><thead><row><entry><para>Printing History:</para></entry><entry><para/></entry></row></thead><tbody><row><entry><para>June 2007:</para></entry><entry><para>First Edition.</para></entry></row></tbody></tgroup></informaltable><para>The O'Reilly logo is a registered trademark of O'Reilly Media, Inc. <emphasis>Beautiful Code</emphasis> and related trade dress are trademarks of O'Reilly Media, Inc. Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and O'Reilly Media, Inc. was aware of a trademark claim, the designations have been printed in caps or initial caps.</para><para>While every precaution has been taken in the preparation of this book, the publisher and authors assume no responsibility for errors or omissions, or for damages resulting from the use of the information contained herein.</para><para>ISBN-10: 0-596-51004-7</para><para>ISBN-13: 978-0-596-51004-6</para><para>[C]</para></preface><dedication id="dedication"><title>Dedication</title><para>All royalties from this book will be donated to Amnesty International.</para></dedication><preface id="foreword" role=""><title>Foreword</title><para><emphasis>Greg Wilson</emphasis></para><para><emphasis>I got my first job as a programmer in the summer of 1982</emphasis>. Two weeks after I started, one of the system administrators loaned me Kernighan and Plauger's <emphasis>The Elements of Programming Style</emphasis> (McGraw-Hill) and Wirth's <emphasis>Algorithms + Data Structures = Programs</emphasis> (Prentice Hall). They were a revelation—for the first time, I saw that programs could be more than just instructions for computers. They could be as elegant as well-made kitchen cabinets, as graceful as a suspension bridge, or as eloquent as one of George Orwell's essays.</para><para>Time and again since that summer, I have heard people bemoan the fact that our profession doesn't teach students to see this. Architects are taught to look at buildings, and com-posers study one another's scores, but programmers—they look at each other's work only when there's a bug to fix; even then, they try to look at as little as possible. We tell students to use sensible variable names, introduce them to some basic design patterns, and then wonder why so much of what they write is so ugly.</para><para>This book is our attempt to fix this. In May 2006, I asked some well-known (and not so well-known) software designers to dissect and discuss the most beautiful piece of code they knew. As this book shows, they have found beauty in many different places. For some, it lives in the small details of elegantly crafted software. Others find beauty in the big picture—in how a program's structure allows it to evolve gracefully over time, or in the techniques used to build it.</para><para>Wherever they find it, I am grateful to our contributors for taking time to give us a tour. I hope that you enjoy reading this book as much as Andy and I have enjoyed editing it, and that it inspires you to create something beautiful, too.</para></preface><preface id="preface" role=""><title>Preface</title><para><emphasis role="smaller">Beautiful code was conceived by greg wilson in 2006</emphasis> as a way to elicit insights from leading software developers and computer scientists. Together, he and his co-editor, Andy Oram, approached experts with diverse backgrounds from all over the world. They received a flood of responses, partly because royalties from the book are being donated to Amnesty International. The results of the project appear in this volume.</para><para>As wide-ranging as this book is, it represents just a small fraction of what is happening in this most exciting of fields. Thousand of other projects, equally interesting and educational, are being moved forward every day by other programmers whom we did not contact. Furthermore, many excellent practitioners who were asked for chapters do not appear in this book because they were too busy at the time, preferred not to contribute to Amnesty International, or had conflicting obligations. To benefit from the insights of all these people, we hope to do further books along similar lines in the future.</para><sect1 id="how_this_book_is_organized"><title>How This Book Is Organized</title><para><xref linkend="a_regular_expression_matcher"/>, <emphasis>A Regular Expression Matcher</emphasis>, by Brian Kernighan, shows how deep insight into a language and a problem can lead to a concise and elegant solution.</para><para><xref linkend="subversions_delta_editor_interface_as_ontology"/>, <emphasis>Subversion's Delta Editor: Interface As Ontology</emphasis>, by Karl Fogel, starts with a well-chosen abstraction and demonstrates its unifying effects on the system's further development.</para><para><xref linkend="the_most_beautiful_code_i_never_wrote"/>, <emphasis>The Most Beautiful Code I Never Wrote</emphasis>, by Jon Bentley, suggests how to measure a procedure without actually executing it.</para><para><xref linkend="finding_things"/>, <emphasis>Finding Things</emphasis>, by Tim Bray, draws together many strands in Computer Science in an exploration of a problem that is fundamental to many computing tasks.</para><para><xref linkend="correct_beautiful_fast_in_that_order_lessons_from_designing_xml"/>, <emphasis>Correct, Beautiful, Fast (in That Order): Lessons from Designing XML Verifiers</emphasis>, by Elliotte Rusty Harold, reconciles the often conflicting goals of thoroughness and good performance.</para><para><xref linkend="framework_for_integrated_test_beauty_through_fragility"/>, <emphasis>Framework for Integrated Test: Beauty Through Fragility</emphasis>, by Michael Feathers, presents an example that breaks the rules and achieves its own elegant solution.</para><para><xref linkend="beautiful_tests"/>, <emphasis>Beautiful Tests</emphasis>, by Alberto Savoia, shows how a broad, creative approach to testing can not only eliminate bugs but turn you into a better programmer.</para><para><xref linkend="on-the-fly_code_generation_for_image_processing"/>, <emphasis>On-the-Fly Code Generation for Image Processing</emphasis>, by Charles Petzold, drops down a level to improve performance while maintaining portability.</para><para><xref linkend="top_down_operator_precedence"/>, <emphasis>Top Down Operator Precedence</emphasis>, by Douglas Crockford, revives an almost forgotten parsing technique and shows its new relevance to the popular JavaScript language.</para><para><xref linkend="the_quest_for_an_accelerated_population_count"/>, <emphasis>The Quest for an Accelerated Population Count</emphasis>, by Henry S. Warren, Jr., reveals the impact that some clever algorithms can have on even a seemingly simple problem.</para><para><xref linkend="secure_communication_the_technology_of_freedom"/>, <emphasis>Secure Communication: The Technology Of Freedom</emphasis>, by Ashish Gulhati, discusses the directed evolution of a secure messaging application that was designed to make sophisticated but often confusing cryptographic technology intuitively accessible to users.</para><para><xref linkend="growing_beautiful_code_in_bioperl"/>, <emphasis>Growing Beautiful Code in BioPerl</emphasis>, by Lincoln Stein, shows how the combination of a flexible language and a custom-designed module can make it easy for people with modest programming skills to create powerful visualizations for their data.</para><para><xref linkend="the_design_of_the_gene_sorte"/>, <emphasis>The Design of the Gene Sorter</emphasis>, by Jim Kent, combines simple building blocks to produce a robust and valuable tool for gene researchers.</para><para><xref linkend="how_elegant_code_evolves_with_hardware_the_case_of_gaussian_eli"/>, <emphasis>How Elegant Code Evolves with Hardware: The Case of Gaussian Elimination</emphasis>, by Jack Dongarra and Piotr Luszczek, surveys the history of LINPACK and related major software packages to show how assumptions must constantly be re-evaluated in the face of new computing architectures.</para><para><xref linkend="the_long-term_benefits_of_beautiful_design"/>, <emphasis>The Long-Term Benefits of Beautiful Design</emphasis>, by Adam Kolawa, explains how attention to good design principles many decades ago helped CERN's widely used mathematical library (the predecessor of LINPACK) stand the test of time.</para><para><xref linkend="the_linux_kernel_driver_model_the_benefits_of_working_together"/>, <emphasis>The Linux Kernel Driver Model: The Benefits of Working Together</emphasis>, by Greg Kroah-Hartman, explains how many efforts by different collaborators to solve different problems led to the successful evolution of a complex, multithreaded system.</para><para><xref linkend="another_level_of_indirection"/>, <emphasis>Another Level of Indirection</emphasis>, by Diomidis Spinellis, shows how the flexibility and maintainability of the FreeBSD kernel is promoted by abstracting operations done in common by many drivers and filesystem modules.</para><para><xref linkend="pythons_dictionary_implementation_being_all_things_to_all_peopl"/>, <emphasis>Python's Dictionary Implementation: Being All Things to All People</emphasis>, by Andrew Kuchling, explains how a careful design combined with accommodations for a few special cases allows a language feature to support many different uses.</para><para><xref linkend="multidimensional_iterators_in_numpy"/>, <emphasis>Multidimensional Iterators in NumPy</emphasis>, by Travis E. Oliphant, takes you through the design steps that succeed in hiding complexity under a simple interface.</para><para><xref linkend="a_highly_reliable_enterprise_system_for_nasas_mars_rover_missio"/>, <emphasis>A Highly Reliable Enterprise System for NASA's Mars Rover Mission</emphasis>, by Ronald Mak, uses industry standards, best practices, and Java technologies to meet the requirements of a NASA expedition where reliability cannot be in doubt.</para><para><xref linkend="erp5_designing_for_maximum_adaptability"/>, <emphasis>ERP5: Designing for Maximum Adaptability</emphasis>, by Rogerio Atem de Carvalho and Rafael Monnerat, shows how a powerful ERP system can be developed with free software tools and a flexible architecture.</para><para><xref linkend="a_spoonful_of_sewage"/>, <emphasis>A Spoonful of Sewage</emphasis>, by Bryan Cantrill, lets the reader accompany the author through a hair-raising bug scare and a clever solution that violated expectations.</para><para><xref linkend="distributed_programming_with_mapReduce"/>, <emphasis>Distributed Programming with MapReduce</emphasis>, by Jeff Dean and Sanjay Ghemawat, describes a system that provides an easy-to-use programming abstraction for large-scale distributed data processing at Google that automatically handles many difficult aspects of distributed computation, including automatic parallelization, load balancing, and failure handling.</para><para><xref linkend="beautiful_concurrency"/>, <emphasis>Beautiful Concurrency</emphasis>, by Simon Peyton Jones, removes much of the difficulty of parallel programs through Software Transactional Memory, demonstrated here using Haskell.</para><para><xref linkend="syntactic_abstraction_the_syntax-case_expander"/>, <emphasis>Syntactic Abstraction: The syntax-case Expander</emphasis>, by R. Kent Dybvig, shows how macros—a key feature of many languages and systems—can be protected in Scheme from producing erroneous output.</para><para><xref linkend="labor-saving_architecture_an_object-oriented_framework_for_netw"/>, <emphasis>Labor-Saving Architecture: An Object-Oriented Framework for Networked Software</emphasis>, by William R. Otte and Douglas C. Schmidt, applies a range of standard object-oriented design techniques, such as patterns and frameworks, to distributed logging to keep the system flexible and modular.</para><para><xref linkend="integrating_business_partners_the_restful_way"/>, <emphasis>Integrating Business Partners the RESTful Way</emphasis>, by Andrew Patzer, demonstrates a designer's respect for his programmers by matching the design of a B2B web service to its requirements.</para><para><xref linkend="beautiful_debugging"/>, <emphasis>Beautiful Debugging</emphasis>, by Andreas Zeller, shows how a disciplined approach to validating code can reduce the time it takes to track down errors.</para><para><xref linkend="treating_code_as_an_essay"/>, <emphasis>Treating Code As an Essay</emphasis>, by Yukihiro Matsumoto, lays out some challenging principles that drove his design of the Ruby programming language, and that, by extension, will help produce better software in general.</para><para><xref linkend="when_a_button_is_all_that_connects_you_to_the_world"/>, <emphasis>When a Button Is All That Connects You to the World</emphasis>, by Arun Mehta, takes you on a tour through the astounding interface design choices involved in a text-editing system that allows people with severe motor disabilities, like Professor Stephen Hawking, to communicate via a computer.</para><para><xref linkend="emacspeak_the_complete_audio_desktop"/>, <emphasis>Emacspeak: The Complete Audio Desktop</emphasis>, by T. V. Raman, shows how Lisp's advice facility can be used with Emacs to address a general need—generating rich spoken output—that cuts across all aspects of the Emacs environment, without modifying the underlying source code of a large software system.</para><para><xref linkend="code_in_motion"/>, <emphasis>Code in Motion</emphasis>, by Laura Wingerd and Christopher Seiwald, lists some simple rules that have unexpectedly strong impacts on programming accuracy.</para><para><xref linkend="writing_programs_for_the_book"/>, <emphasis>Writing Programs for "The Book"</emphasis>, by Brian Hayes, explores the frustrations of solving a seemingly simple problem in computational geometry, and its surprising resolution.</para></sect1><sect1 id="conventions_used_in_this_book"><title>Conventions Used in This Book</title><para>The following typographical conventions are used in this book:</para><variablelist><varlistentry><term><emphasis>Italic</emphasis></term><listitem><para>Indicates new terms, mathematical variables, URLs, file and directory names, and commands.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">Constant width</literal></term><listitem><para>Indicates elements of program code, the contents of files, and text output displayed on a computer console.</para></listitem></varlistentry><varlistentry><term><userinput moreinfo="none">Constant width bold</userinput></term><listitem><para>Shows commands or other text typed literally by the user.</para></listitem></varlistentry><varlistentry><term><replaceable>Constant width italic</replaceable></term><listitem><para>Shows text replaced with user-supplied values.</para></listitem></varlistentry></variablelist></sect1><sect1 id="using_code_examples"><title>Using Code Examples</title><para>This book is here to help you get your job done. In general, you may use the code in this book in your programs and documentation. You do not need to contact us for permission unless you're reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing a CD-ROM of examples from O'Reilly books <emphasis>does</emphasis> require permission.</para><para>Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product's documentation <emphasis>does</emphasis> require permission.</para><para>We appreciate, but do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: "<emphasis>Beautiful Code</emphasis>, edited by Andy Oram and Greg Wilson. Copyright 2007 O'Reilly Media, Inc., 978-0-596-51004-6."</para><para>If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at <email>permissions@oreilly.com</email>.</para></sect1><sect1 id="how_to_contact_us"><title>How to Contact Us</title><para>Please address comments and questions concerning this book to the publisher:</para><simplelist type="vert"><member>O'Reilly Media, Inc.</member><member>1005 Gravenstein Highway North</member><member>Sebastopol, CA 95472</member><member>800-998-9938 (in the United States or Canada)</member><member>707-829-0515 (international or local)</member><member>707-829-0104 (fax)</member></simplelist><para>We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at:</para><para><ulink url="http://www.oreilly.com/catalog/9780596510046"/></para><para>To comment or ask technical questions about this book, send email to:</para><para><email>bookquestions@oreilly.com</email></para><para>For more information about our books, conferences, Resource Centers, and the O'Reilly Network, see our web site at:</para><para><ulink url="http://www.oreilly.com"/></para></sect1><sect1 id="safarireg_enabled"><title>Safari® Enabled</title><para>
<mediaobject id="I_mediaobject_tt3"><imageobject role="print"><imagedata fileref="figs/print/beauty_0002.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0002.png" format="PNG"/></imageobject></mediaobject>
When you see a Safari® Enabled icon on the cover of your favorite technology book, that means the book is available online through the O'Reilly Network Safari Bookshelf.</para><para>Safari offers a solution that's better than e-books. It's a virtual library that lets you easily search thousands of top tech books, cut and paste code samples, download chapters, and find quick answers when you need the most accurate, current information. Try it for free at <ulink url="http://safari.oreilly.com"/>.</para></sect1></preface><chapter id="a_regular_expression_matcher" label="1" role=""><title>A Regular Expression Matcher</title><para><emphasis>Brian Kernighan</emphasis><indexterm id="idx-CHP-1-0001" significance="normal"><primary>wildcards</primary><secondary>in regular expressions</secondary></indexterm><indexterm id="idx-CHP-1-0002" significance="normal"><primary>Kernighan</primary></indexterm></para><para><emphasis>Regular expressions are notations for describing patterns of text</emphasis> and, in effect, make up a special-purpose language for pattern matching. Although there are myriad variants, all share the idea that most characters in a pattern match literal occurrences of themselves, but some <emphasis>metacharacters</emphasis> have special meaning, such as * to indicate some kind of repetition or […] to mean any one character from the set within the brackets.<indexterm id="idx-CHP-1-0003" significance="normal"><primary>regular expressions</primary></indexterm><indexterm id="idx-CHP-1-0004" significance="normal"><primary>metacharacters (regular expressions)</primary></indexterm></para><para>In practice, most searches in programs such as text editors are for literal words, so the regular expressions are often literal strings like <literal moreinfo="none">print</literal>, which will match <literal moreinfo="none">printf</literal> or <literal moreinfo="none">sprint</literal> or <literal moreinfo="none">printer paper</literal> anywhere. In so-called <emphasis>wildcards</emphasis> used to specify filenames in Unix and Windows, a * matches any number of characters, so the pattern <literal moreinfo="none">*.c</literal> matches all filenames that end in <literal moreinfo="none">.c.</literal> There are many, many variants of regular expressions, even in contexts where one would expect them to be the same. Jeffrey Friedl's <emphasis>Mastering Regular Expressions</emphasis> (O'Reilly) is an exhaustive study of the topic.</para><para>Stephen <indexterm id="idx-CHP-1-0005" significance="normal"><primary>Kleene</primary></indexterm>Kleene invented regular expressions in the mid-1950s as a notation for finite automata; in fact, they are equivalent to finite automata in what they represent. They first appeared in a program setting in Ken <indexterm id="idx-CHP-1-0006" significance="normal"><primary>Thompson</primary></indexterm>Thompson's version of the QED text editor in the mid-1960s. In 1967, Thompson applied for a patent on a mechanism for rapid text matching based on regular expressions. The patent was granted in 1971, one of the very first software patents [U.S. Patent 3,568,156, Text Matching Algorithm, March 2, 1971].</para><para><indexterm id="idx-CHP-1-0007" significance="normal"><primary>regular expressions</primary></indexterm>Regular expressions moved from QED to the Unix editor <emphasis>ed</emphasis>, and then to the quintessential Unix tool <emphasis>grep</emphasis>, which Thompson created by performing radical surgery on <emphasis>ed</emphasis>. These widely used programs helped regular expressions become familiar throughout the early Unix community.</para><para>Thompson's original matcher was very fast because it combined two independent ideas. One was to generate machine instructions on the fly during matching so that it ran at machine speed rather than by interpretation. The other was to carry forward all possible matches at each stage, so it did not have to backtrack to look for alternative potential matches. In later text editors that Thompson wrote, such as <emphasis>ed</emphasis>, the matching code used a simpler algorithm that backtracked when necessary. In theory, this is slower, but the patterns found in practice rarely involved backtracking, so the <emphasis>ed</emphasis> and <emphasis>grep</emphasis> algorithm and code were good enough for most purposes.</para><para>Subsequent regular expression matchers like <emphasis>egrep</emphasis> and <emphasis>fgrep</emphasis> added richer classes of regular expressions, and focused on fast execution no matter what the pattern. Ever-fancier regular expressions became popular and were included not only in C-based libraries, but also as part of the syntax of scripting languages such as Awk and Perl.<indexterm id="idx-CHP-1-0008" significance="normal"><primary>egrep</primary></indexterm><indexterm id="idx-CHP-1-0009" significance="normal"><primary>fgrep</primary></indexterm></para><sect1 id="the_practice_of_programming" label="1.1"><title>The Practice of Programming</title><para>In 1998, Rob Pike and I were writing <emphasis>The Practice of Programming</emphasis> (Addison-Wesley). The last chapter of the book, "<indexterm id="idx-CHP-1-0010" significance="normal"><primary>notation</primary></indexterm>Notation," collected a number of examples where good <indexterm id="idx-CHP-1-0011" significance="normal"><primary>regular expressions</primary><secondary>notation</secondary></indexterm>notation led to better programs and better programming. This included the use of simple data specifications (<literal moreinfo="none">printf</literal>, for instance), and the generation of code from tables.<indexterm id="idx-CHP-1-0012" significance="normal"><primary>Practice of Programming</primary></indexterm></para><para>Because of our Unix backgrounds and nearly 30 years of experience with tools based on regular expression notation, we naturally wanted to include a discussion of regular expressions, and it seemed mandatory to include an implementation as well. Given our emphasis on tools, it also seemed best to focus on the class of regular expressions found in <emphasis>grep</emphasis>—rather than, say, those from shell wildcards—since we could also then talk about the design of <emphasis>grep</emphasis> itself.</para><para>The problem was that any existing regular expression package was far too big. The local <emphasis>grep</emphasis> was over 500 lines long (about 10 book pages) and encrusted with barnacles. Open source regular expression packages tended to be huge—roughly the size of the entire book—because they were engineered for generality, flexibility, and speed; none were remotely suitable for pedagogy.</para><para>I suggested to Rob that we find the smallest regular expression package that would illustrate the basic ideas while still recognizing a useful and nontrivial class of patterns. Ideally, the code would fit on a single page.</para><para>Rob disappeared into his office. As I remember it now, he emerged in no more than an hour or two with the 30 lines of C code that subsequently appeared in <xref linkend="top_down_operator_precedence"/> of <emphasis>The Practice of Programming</emphasis>. That code implements a regular expression matcher that handles the following constructs.</para><informaltable><tgroup cols="2"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><thead><row><entry><para><indexterm id="idx-CHP-1-0013" significance="normal"><primary>c (character)</primary></indexterm>Character</para></entry><entry><para>Meaning</para></entry></row></thead><tbody><row><entry><para><emphasis>c</emphasis></para></entry><entry><para>Matches any literal character <emphasis>c</emphasis>.</para></entry></row><row><entry><para>. (period)</para></entry><entry><para>Matches any single character.</para></entry></row><row><entry><para><indexterm id="idx-CHP-1-0014" significance="normal"><primary>^ (caret)</primary></indexterm>^</para></entry><entry><para>Matches the beginning of the input string.</para></entry></row><row><entry><para>$</para></entry><entry><para>Matches the <indexterm id="idx-CHP-1-0015" significance="normal"><primary>$ (dollar sign)</primary><secondary>end of line matching in regular expressions</secondary></indexterm>end of the input string.</para></entry></row><row><entry><para>*</para></entry><entry><para>Matches zero or more occurrences of the previous character.</para></entry></row></tbody></tgroup></informaltable><para>This is quite a useful class; in my own experience of using <indexterm id="idx-CHP-1-0016" significance="normal"><primary>regular expressions</primary></indexterm>regular expressions on a day-to-day basis, it easily accounts for 95 percent of all instances. In many situations, solving the right problem is a big step toward creating a beautiful program. Rob deserves great credit for choosing a very small yet important, well-defined, and extensible set of features from among a wide set of options.</para><para>Rob's <indexterm id="idx-CHP-1-0017" significance="normal"><primary>regular expression matcher</primary><secondary>implementation</secondary></indexterm>implementation itself is a superb example of beautiful code: compact, elegant, efficient, and useful. It's one of the best examples of recursion that I have ever seen, and it shows the power of C pointers. Although at the time we were most interested in conveying the important role of good notation in making a program easier to use (and perhaps easier to write as well), the regular expression code has also been an excellent way to illustrate algorithms, data structures, testing, performance enhancement, and other important topics.</para></sect1><sect1 id="implementation" label="1.2"><title>Implementation</title><para>In <emphasis>The Practice of Programming</emphasis>, the regular expression matcher is part of a standalone program that mimics <emphasis>grep</emphasis>, but the regular expression code is completely separable from its surroundings. The main program is not interesting here; like many Unix tools, it reads either its standard input or a sequence of files, and prints those lines that contain a match of the regular expression.</para><para>This is the <indexterm id="idx-CHP-1-0018" significance="normal"><primary>matching any single character in regular expressions</primary></indexterm>matching code:</para><programlisting id="I_programlisting1_tt4" format="linespecific">
	/* match: search for regexp anywhere in text */
	int match(char *regexp, char *text)
	{
	    if (regexp[0] == '^')
	        return matchhere(regexp+1, text);
	    do {    /* must look even if string is empty */
	        if (matchhere(regexp, text))
	            return 1;
	    } while (*text++ != '\0');
	    return 0;
	}

	/* matchhere: search for regexp at beginning of text */
	int matchhere(char *regexp, char *text)
	{
	   if (regexp[0] == '\0')
	       return 1;
	   if (regexp[1] == '*')
	       return matchstar(regexp[0], regexp+2, text);

	   if (regexp[0] == '$' &amp;&amp; regexp[1] == '\0')
	       return *text == '\0';
	   if (*text!='\0' &amp;&amp; (regexp[0]=='.' || regexp[0]==*text))
	       return <indexterm id="idx-CHP-1-0019" significance="normal"><primary>match function</primary></indexterm>matchhere(regexp+1, text+1);
	   return 0;
	}

	/* matchstar: search for c*regexp at beginning of text */
	int matchstar(int c, char *regexp, char *text)
	{
	   do {   /* a * matches zero or more instances */
	       if (<indexterm id="idx-CHP-1-0020" significance="normal"><primary>matchhere function</primary></indexterm>matchhere(regexp, text))
	           return 1;
	   } while (*text != '\0' &amp;&amp; (*text++ == c || c == '.'));
	   return 0;
	}
</programlisting></sect1><sect1 id="discussion" label="1.3"><title>Discussion</title><para>The function <literal moreinfo="none">match(regexp, text</literal>) tests whether there is an occurrence of the <indexterm id="idx-CHP-1-0021" significance="normal"><primary>regular expressions</primary></indexterm>regular expression anywhere within the text; it returns 1 if a match is found and 0 if not. If there is more than one match, it finds the leftmost and shortest.</para><para>The basic operation of <literal moreinfo="none">match</literal> is straightforward. If the first character of the regular expression is ^ (an anchored match), any possible match must occur at the beginning of the string. That is, if the regular expression is <literal moreinfo="none">^xyz</literal>, it matches <literal moreinfo="none">xyz</literal> only if <literal moreinfo="none">xyz</literal> occurs at the beginning of the text, not somewhere in the middle. This is tested by <indexterm id="idx-CHP-1-0022" significance="normal"><primary>* (asterisk)</primary><secondary>matching zero or more occurrences in regular expressions</secondary></indexterm>matching the rest of the regular expression against the text starting at the beginning and nowhere else. Otherwise, the regular expression might match anywhere within the string. This is tested by matching the pattern against each character position of the text in turn. If there are multiple matches, only the first (leftmost) one will be identified. That is, if the regular expression is <literal moreinfo="none">xyz</literal>, it will match the first occurrence of <literal moreinfo="none">xyz</literal> regardless of where it occurs.</para><para>Notice that advancing over the input string is done with a <literal moreinfo="none">do-while</literal> loop, a comparatively unusual construct in C programs. The occurrence of a <literal moreinfo="none">do-while</literal> instead of a <literal moreinfo="none">while</literal> should always raise a question: why isn't the loop termination condition being tested at the beginning of the loop, before it's too late, rather than at the end after something has been done? But the test is correct here: since the * operator permits zero-length matches, we first have to check whether a <indexterm id="idx-CHP-1-0023" significance="normal"><primary>null match</primary></indexterm>null match is possible.<indexterm id="idx-CHP-1-0024" significance="normal"><primary>do-while loop</primary></indexterm></para><para>The bulk of the work is done in the function <literal moreinfo="none">matchhere(regexp, text</literal>), which tests whether the regular expression matches the text that begins right here. The function <literal moreinfo="none">matchhere</literal> operates by attempting to match the first character of the regular expression with the first character of the text. If the match fails, there can be no match at this text position and <literal moreinfo="none">matchhere</literal> returns 0. If the match succeeds, however, it's possible to advance to the next character of the regular expression and the next character of the text. This is done by calling <literal moreinfo="none">matchhere</literal> recursively.</para><para>The situation is a bit more complicated because of some special cases, and of course the need to stop the recursion. The easiest case is that if the <indexterm id="idx-CHP-1-0025" significance="normal"><primary>regular expressions</primary></indexterm>regular expression is at its end (<literal moreinfo="none">regexp[0]=='\0'</literal>), all previous tests have succeeded, and thus the regular expression matches the text.</para><para>If the regular expression is a character followed by a <literal moreinfo="none">*, matchstar</literal> is called to see whether the closure matches. The function <literal moreinfo="none">matchstar(c, regexp, text</literal>) tries to match repetitions of the text character <literal moreinfo="none">c</literal>, beginning with zero repetitions and counting up, until it either finds a match of the rest of the text, or it fails and thus concludes that there is no match. This algorithm identifies a "<indexterm id="idx-CHP-1-0026" significance="normal"><primary>shortest match</primary></indexterm>shortest match," which is fine for simple pattern matching as in <emphasis>grep</emphasis>, where all that matters is finding a match as quickly as possible. A "<indexterm id="idx-CHP-1-0027" significance="normal"><primary>longest match</primary></indexterm>longest match" is more intuitive and almost certain to be better for a text editor where the matched text will be replaced. Most modern regular expression libraries provide both alternatives, and <emphasis>The Practice of Programming</emphasis> presents a simple variant of <literal moreinfo="none">matchstar</literal> for this case, shown below.<indexterm id="idx-CHP-1-0028" significance="normal"><primary>matchstar function</primary></indexterm></para><para>If the regular expression consists of a $ at the <indexterm id="idx-CHP-1-0029" significance="normal"><primary>$ (dollar sign)</primary><secondary>end of line matching in regular expressions</secondary></indexterm>end of the expression, the text matches only if it too is at its end:</para><programlisting id="I_programlisting1_tt5" format="linespecific">
	if (regexp[0] == '$' &amp;&amp; regexp[1] == '\0')
	    return *text == '\0';
</programlisting><para>Otherwise, if we are not at the end of the text string (that is, <literal moreinfo="none">*text!='\0'</literal>), and if the first character of the text string matches the first character of the regular expression, so far so good; we go on to test whether the next character of the regular expression matches the next character of the text by making a recursive call to <literal moreinfo="none">matchhere</literal>. This recursive call is the heart of the algorithm and the reason why the code is so compact and clean.</para><para>If all of these attempts to match fail, there can be no match at this point between the regular expression and the text, so <literal moreinfo="none">matchhere</literal> returns 0.</para><para>This code uses C <indexterm id="idx-CHP-1-0030" significance="normal"><primary>pointers</primary></indexterm>pointers intensively. At each stage of the recursion, if something matches, the recursive call that follows uses pointer arithmetic (e.g., <literal moreinfo="none">regexp+1</literal> and <literal moreinfo="none">text+1</literal>) so that the subsequent function is called with the next character of the regular expression and of the text. The depth of recursion is no more than the length of the pattern, which in normal use is quite short, so there is no danger of running out of space.</para></sect1><sect1 id="alternatives" label="1.4"><title>Alternatives</title><para>This is a very elegant and well-written piece of code, but it's not perfect. What might we do differently? I might rearrange <literal moreinfo="none">matchhere</literal> to deal with $ before *. Although it makes no difference here, it feels a bit more natural, and a good rule is to do easy cases before difficult ones.</para><para>In general, however, the order of tests is critical. For instance, in this test from <literal moreinfo="none">matchstar:</literal></para><programlisting id="I_programlisting1_tt6" format="linespecific">
	} while (*text != '\0' &amp;&amp; (*text++ == c || c == '.'));
</programlisting><para>we must advance over one more character of the text string no matter what, so the increment in <literal moreinfo="none">text++</literal> must always be performed.</para><para>This code is careful about <indexterm id="idx-CHP-1-0031" significance="normal"><primary>termination conditions (regular expression matcher)</primary></indexterm>termination conditions. Generally, the success of a match is determined by whether the <indexterm id="idx-CHP-1-0032" significance="normal"><primary>regular expressions</primary></indexterm>regular expression runs out at the same time as the text does. If they do run out together, that indicates a match; if one runs out before the other, there is no match. This is perhaps most obvious in a line like:</para><programlisting id="I_programlisting1_tt7" format="linespecific">
	if (regexp[0] == '$' &amp;&amp; regexp[1] == '\0')
	    return *text == '\0';
</programlisting><para>but subtle <indexterm id="idx-CHP-1-0033" significance="normal"><primary>regular expression matcher</primary><secondary>termination conditions</secondary></indexterm>termination conditions show up in other cases as well.</para><para>The version of <literal moreinfo="none">matchstar</literal> that implements <indexterm id="idx-CHP-1-0034" significance="normal"><primary>longest match</primary><secondary>leftmost longest matching</secondary></indexterm>leftmost longest matching begins by identifying a maximal sequence of occurrences of the input character <literal moreinfo="none">c</literal>. Then it uses <literal moreinfo="none">matchhere</literal> to try to extend the match to the rest of the pattern and the rest of the text. Each failure reduces the number of <literal moreinfo="none">c</literal>s by one and tries again, including the case of zero occurrences:</para><programlisting id="I_programlisting1_tt8" format="linespecific">
	/* matchstar: leftmost longest search for c*regexp */
	int matchstar(int c, char *regexp, char *text)
	{

	    char *t;

	    for (t = text; *t != '\0' &amp;&amp; (*t == c || c == '.'); t++)
	        ;
	    do { /* * matches zero or more */
	        if (matchhere(regexp, t))
	            return 1;
	    } while (t-- &gt; text);
	    return 0;
	}
</programlisting><para>Consider the regular expression (.*), which matches arbitrary text within parentheses. Given the target text:</para><programlisting id="I_programlisting1_tt9" format="linespecific">
	for (t = text; *t != '\0' &amp;&amp; (*t == c || c == '.'); t++)
</programlisting><para>a longest match from the beginning will identify the entire parenthesized expression, while a shortest match will stop at the first right parenthesis. (Of course a longest match beginning from the second left parenthesis will extend to the end of the text.)</para></sect1><sect1 id="building_on_it" label="1.5"><title>Building on It</title><para>The purpose of <emphasis>The Practice of Programming</emphasis> was to teach good programming. At the time the book was written, Rob and I were still at Bell Labs, so we did not have firsthand experience of how the book would be best used in a classroom. It has been gratifying to discover that some of the material does work well in classes. I have used this code since 2000 as a vehicle for teaching important points about programming.</para><para>First, it shows how <indexterm id="idx-CHP-1-0035" significance="normal"><primary>recursion</primary></indexterm>recursion is useful and leads to clean code in a novel setting; it's not yet another version of Quicksort (or factorial!), nor is it some kind of tree walk.</para><para>It's also a good example for performance experiments. Its performance is not very different from the system versions of <emphasis>grep</emphasis>, which shows that the recursive technique is not too costly and that it's not worth trying to tune the code.</para><para>On the other hand, it is also a fine illustration of the importance of a good algorithm. If a pattern includes several .* sequences, the straightforward implementation requires a lot of backtracking, and, in some cases, will run very slowly indeed.</para><para>The standard Unix <emphasis>grep</emphasis> has the same backtracking properties. For example, the command:</para><programlisting id="I_programlisting1_tt10" format="linespecific">
	grep 'a.*a.*a.*a.a'
</programlisting><para>takes about 20 seconds to process a 4 MB text file on a typical machine.</para><para>An implementation based on converting a nondeterministic finite automaton to a deterministic automaton, as in <emphasis>egrep</emphasis>, will have much better performance on hard cases; it can process the same pattern and the same input in less than one-tenth of a second, and running time in general is independent of the pattern.</para><para>Extensions to the regular expression class can form the basis of a variety of assignments. For example:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Add other <indexterm id="idx-CHP-1-0036" significance="normal"><primary>metacharacters (regular expressions)</primary></indexterm>metacharacters, such as + for one or more occurrences of the previous character, or ? for zero or one matches. Add some way to quote metacharacters, such as \$ to stand for a literal occurrence of $.</para></listitem><listitem><para>Separate regular expression processing into a <emphasis>compilation</emphasis> phase and an <emphasis>execution</emphasis> phase. Compilation converts the regular expression into an internal form that makes the matching code simpler or allows the subsequent matching to run faster. This separation is not necessary for the simple class of <indexterm id="idx-CHP-1-0037" significance="normal"><primary>regular expressions</primary></indexterm>regular expressions in the original design, but it makes sense in <emphasis>grep</emphasis>-like applications where the class is richer and the same regular expression is used for a large number of input lines.<indexterm id="idx-CHP-1-0038" significance="normal"><primary>compilation phase</primary></indexterm><indexterm id="idx-CHP-1-0039" significance="normal"><primary>execution phase</primary></indexterm></para></listitem><listitem><para>Add <indexterm id="idx-CHP-1-0040" significance="normal"><primary>character classes (in regular expressions)</primary></indexterm>character classes such as [<literal moreinfo="none">abc</literal>] and [<literal moreinfo="none">0-9</literal>], which in conventional <emphasis>grep</emphasis> notation match <literal moreinfo="none">a</literal> or <literal moreinfo="none">b</literal> or <literal moreinfo="none">c</literal> and a digit, respectively. This can be done in several ways, the most natural of which seems to be replacing the <literal moreinfo="none">char*</literal> variables of the original code with a structure:</para><programlisting id="I_programlisting1_tt11" format="linespecific">
	typedef struct RE {
	        int     type;   /* CHAR, STAR, etc. */ 
	        int     ch;     /* the character itself */ 
	        char    *ccl;   /* for [...] instead */
	        int     nccl;   /* true if class is negated [^...] */
	} RE;
</programlisting><para>and modifying the basic code to handle an array of these instead of an array of characters. It's not strictly necessary to separate compilation from execution for this situation, but it turns out to be a lot easier. Students who follow the advice to pre-compile into such a structure invariably do better than those who try to interpret some complicated pattern data structure on the fly.</para><para>Writing clear and unambiguous specifications for character classes is tough, and implementing them perfectly is worse, requiring a lot of tedious and uninstructive coding. I have simplified this assignment over time, and today most often ask for Perl-like shorthands such as <literal moreinfo="none">\d</literal> for digit and <literal moreinfo="none">\D</literal> for nondigit instead of the original bracketed ranges.</para></listitem><listitem><para>Use an opaque type to hide the RE structure and all the implementation details. This is a good way to show <indexterm id="idx-CHP-1-0041" significance="normal"><primary>C language</primary><secondary>object-oriented programming and</secondary></indexterm>object-oriented programming in C, which doesn't support much beyond this. In effect, this creates a regular expression class that uses function names like <literal moreinfo="none">RE_new()</literal> and <literal moreinfo="none">RE_match()</literal> for the methods instead <indexterm id="idx-CHP-1-0042" significance="normal"><primary>Java</primary><secondary>conversion of regular expression matcher to</secondary></indexterm>of the syntactic sugar of an object-oriented language.</para></listitem><listitem><para>Modify the class of <indexterm id="idx-CHP-1-0043" significance="normal"><primary>regular expressions</primary></indexterm>regular expressions to be like the wildcards in various <indexterm id="idx-CHP-1-0044" significance="normal"><primary>wildcards</primary><secondary>shell</secondary></indexterm>shells: matches are implicitly anchored at both ends, * matches any number of characters, and ? matches any single character. One can modify the algorithm or map the input into the existing algorithm.</para></listitem><listitem><para>Convert the code to Java. The original code uses C pointers very well, and it's good practice to figure out the alternatives in a different language. Java versions use either <literal moreinfo="none">String.charAt</literal> (indexing instead of pointers) or <literal moreinfo="none">String.substring</literal> (closer to the pointer version). Neither seems as clear as the C code, and neither is as compact. Although performance isn't really part of this exercise, it is interesting to see that the Java implementation runs roughly six or seven times slower than the C versions.</para></listitem><listitem><para>Write a wrapper class that converts from this class's regular expressions to Java's <indexterm id="idx-CHP-1-0045" significance="normal"><primary>Pattern and Matcher classes (Java)</primary></indexterm>Pattern and Matcher classes, which separate the compilation and matching in a quite different way. This is a good example of the <indexterm id="idx-CHP-1-0046" significance="normal"><primary>Adapter or Facade pattern</primary></indexterm>Adapter or Facade pattern, which puts a different face on an existing class or set of functions.</para></listitem></orderedlist><para>I've also used this code extensively to explore testing techniques. Regular expressions are rich enough that testing is far from trivial, but small enough that one can quickly write down a substantial collection of tests to be performed mechanically. For extensions like those just listed, I ask students to write a large number of tests in a compact language (yet another example of "notation") and use those tests on their own code; naturally, I use their tests on other students' code as well.</para></sect1><sect1 id="conclusion" label="1.6"><title>Conclusion</title><para>I was amazed by how compact and elegant this code was when Rob Pike first wrote it—it was much smaller and more powerful than I had thought possible. In hindsight, one can see a number of <indexterm id="idx-CHP-1-0047" significance="normal"><primary>regular expression matcher</primary><secondary>reasons for compactness of code</secondary></indexterm>reasons why the code is so small.</para><para>First, the features are well chosen to be the most useful and to give the most insight into implementation, without any frills. For example, the implementation of the anchored patterns ^ and $ requires only three or four lines, but it shows how to deal with special cases cleanly before handling the general cases uniformly. The closure operation * must be present because it is a fundamental notion in regular expressions and provides the only way to handle patterns of unspecified lengths. But it would add no insight to also provide + and ?, so those are left as exercises.</para><para>Second, recursion is a win. This fundamental programming technique almost always leads to smaller, cleaner, and more elegant code than the equivalent written with explicit loops, and that is the case here. The idea of peeling off one matching character from the front of the regular expression and from the text, then recursing for the rest, echoes the recursive structure of the traditional factorial or string length examples, but in a much more interesting and useful setting.</para><para>Third, this code really uses the underlying language to good effect. Pointers can be misused, of course, but here they are used to create compact expressions that naturally express the extracting of individual characters and advancing to the next character. Array indexing or substrings can achieve the same effect, but in this code, pointers do a better job, especially when coupled with C idioms for autoincrement and implicit conversion of truth values.</para><para>I don't know of another piece of code that does so much in so few lines while providing such a rich source of insight and further ideas.</para></sect1></chapter><chapter id="subversions_delta_editor_interface_as_ontology" label="2" role=""><title>Subversion's Delta Editor: Interface As Ontology</title><para><emphasis>Karl Fogel</emphasis><indexterm id="idx-CHP-2-0048" significance="normal"><primary>Subversion</primary></indexterm><indexterm class="startofrange" id="idx-CHP-2-0049" significance="normal"><primary>delta editor (Subversion)</primary></indexterm><indexterm id="idx-CHP-2-0050" significance="normal"><primary>Fogel</primary></indexterm></para><para><emphasis>Examples of beautiful code tend to be local solutions</emphasis> to well-bounded, easily comprehensible problems, such as <indexterm id="idx-CHP-2-0051" significance="normal"><primary>Duff's Device</primary></indexterm>Duff's Device (<ulink url="http://en.wikipedia.org/wiki/Duff's_device"/>) or <emphasis>rsync's</emphasis> rolling checksum algorithm (<ulink url="http://en.wikipedia.org/wiki/Rsync#Algorithm"/>). This is not because small, simple solutions are the only beautiful kind, but because appreciating complex code requires more context than can be given on the back of a napkin.<indexterm id="idx-CHP-2-0052" significance="normal"><primary>rsync's rolling checksum algorithm</primary></indexterm></para><para>Here, with the luxury of several pages to work in, I'd like to talk about a larger sort of beauty—not necessarily the kind that would strike a passing reader immediately, but the kind that programmers who work with the code on a regular basis would come to appreciate as they accumulate experience with the problem domain. My example is not an algorithm, but an interface: the programming interface used by the open source version control system Subversion (<ulink url="http://subversion.tigris.org"/>) to express the difference between two directory trees, which is also the interface used to transform one tree into the other. In Subversion, its formal name is the C type <literal moreinfo="none">svn_delta_editor_t</literal>, but it is known colloquially as the <emphasis>delta editor</emphasis>.</para><para><indexterm id="idx-CHP-2-0053" significance="normal"><primary>Subversion</primary></indexterm>Subversion's <indexterm id="idx-CHP-2-0054" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta editor demonstrates the properties that programmers look for in good design. It breaks down the problem along boundaries so natural that anyone designing a new feature for Subversion can easily tell when to call each function, and for what purpose. It presents the programmer with uncontrived opportunities to maximize efficiency (such as by eliminating unnecessary data transfers over the network) and allows for easy integration of auxiliary tasks (such as progress reporting). Perhaps most important, the design has proved very resilient during enhancements and updates.</para><para>And as if to confirm suspicions about the origins of good design, the delta editor was created by a single person over the course of a few hours (although that person was very familiar with the problem and the code base).</para><para>To understand what makes the delta editor beautiful, we must start by examining the problem it solves.</para><sect1 id="version_control_and_tree_transformation" label="2.1"><title>Version Control and Tree Transformation</title><para>Very early in the Subversion project, the team realized we had a general task that would be performed over and over: that of minimally expressing the difference between two similar (usually related) directory trees. As a version control system, one of Subversion's goals is to track revisions to directory structures as well as individual file contents. In fact, Subversion's server-side repository is fundamentally designed around directory versioning. A repository is simply a series of snapshots of a directory tree as that tree transforms over time. For each changeset committed to the repository, a new tree is created, differing from the preceding tree exactly where the changes are located and nowhere else. The unchanged portions of the new tree share storage with the preceding tree, and so on back into time. Each successive version of the tree is labeled with a monotonically increasing integer; this unique identifier is called a <emphasis>revision number</emphasis>.<indexterm class="startofrange" id="idx-CHP-2-0055" significance="normal"><primary>directory trees</primary><secondary>version control and tree transformation</secondary></indexterm><indexterm id="idx-CHP-2-0056" significance="normal"><primary>tree transformation</primary></indexterm><indexterm id="idx-CHP-2-0057" significance="normal"><primary>revision number</primary></indexterm></para><para>Think of the repository as an array of revision numbers, stretching off into infinity. By convention, revision 0 is always an empty directory. In <xref linkend="conceptual_view_of_revision_numbers"/>, revision 1 has a tree hanging off it (typically the initial import of content into the repository), and no other revisions have been committed yet. The boxes represent nodes in this virtual filesystem: each node is either a directory (labeled DIR in the upper-right corner) or a file (labeled FILE).</para><para>What happens when we modify <emphasis>tuna?</emphasis> First, we make a new file node, containing the latest text. The new node is not connected to anything yet. As <xref linkend="new_node_when_just_created"/> shows, it's just hanging out there in space, with no name.</para><para>Next, we create a new revision of its parent directory. As <xref linkend="creation_of_new_parent_directory"/> shows, the subgraph is still not connected to the revision array.</para><figure id="conceptual_view_of_revision_numbers" label="2-1" float="0"><title>Conceptual view of revision numbers</title><mediaobject id="I_mediaobject2_tt12"><imageobject role="print"><imagedata fileref="figs/print/beauty_0201.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0201.png" format="PNG"/></imageobject></mediaobject></figure><figure id="new_node_when_just_created" label="2-2" float="0"><title>New node when just created</title><mediaobject id="I_mediaobject2_tt13"><imageobject role="print"><imagedata fileref="figs/print/beauty_0202.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0202.png" format="PNG"/></imageobject></mediaobject></figure><figure id="creation_of_new_parent_directory" label="2-3" float="0"><title>Creation of new parent directory</title><mediaobject id="I_mediaobject2_tt14"><imageobject role="print"><imagedata fileref="figs/print/beauty_0203.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0203.png" format="PNG"/></imageobject></mediaobject></figure><para>We continue up the line, creating a new revision of the next parent directory (<xref linkend="continuing_to_move_up_creating_parent_directories"/>).</para><para>At the top, we create a new revision of the root directory, as shown in <xref linkend="complete_new_directory_tree"/><indexterm id="idx-CHP-2-0058" significance="normal"><primary>tree transformation</primary></indexterm>. This new directory needs an entry to point to the "new" directory A, but since directory B hasn't changed at all, the new root directory also has an entry still pointing to the <emphasis>old</emphasis> directory B's node.</para><figure id="continuing_to_move_up_creating_parent_directories" label="2-4" float="0"><title>Continuing to move up, creating parent directories</title><mediaobject id="I_mediaobject2_tt15"><imageobject role="print"><imagedata fileref="figs/print/beauty_0204.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0204.png" format="PNG"/></imageobject></mediaobject></figure><figure id="complete_new_directory_tree" label="2-5" float="0"><title>Complete new directory tree</title><mediaobject id="I_mediaobject2_tt16"><imageobject role="print"><imagedata fileref="figs/print/beauty_0205.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0205.png" format="PNG"/></imageobject></mediaobject></figure><para>Now that all the new nodes are written, we finish the "bubble up" process by linking the new tree to the next available revision in the history array, thus making it visible to repository users (<xref linkend="finished_revision_link_to_new_tree"/>). In this case, the new tree becomes revision 2.</para><para>Thus each revision in the repository points to the root node of a unique tree, and the difference between that tree and the preceding one is the change that was committed in the new revision. To trace the changes, a program walks down both trees simultaneously, noting where entries point to different places. (For brevity, I've left out some details, such as saving storage space by compressing older nodes as differences against their newer <indexterm id="idx-CHP-2-0059" significance="normal"><primary>directory trees</primary><secondary>version control and tree transformation</secondary></indexterm>versions.)</para><figure id="finished_revision_link_to_new_tree" label="2-6" float="0"><title>Finished revision: link to new tree</title><mediaobject id="I_mediaobject2_tt17"><imageobject role="print"><imagedata fileref="figs/print/beauty_0206.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0206.png" format="PNG"/></imageobject></mediaobject></figure><para>Although this tree-<indexterm id="idx-CHP-2-0060" significance="normal"><primary>directory trees</primary><secondary>version control and tree transformation</secondary></indexterm>versioning model is all background to the main point of this chapter (the <indexterm id="idx-CHP-2-0061" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta editor, which we'll come to soon), it has such nice properties that I considered making it the subject of its own chapter, as an example of beautiful code. Some of its attractive features are:</para><variablelist><varlistentry><term><emphasis>Easy reads</emphasis></term><listitem><para>To locate revision <emphasis>n</emphasis> of file <emphasis>/path/to/foo.txt</emphasis>, one jumps to revision <emphasis>n</emphasis>, then walks down the tree to <literal moreinfo="none">/path/to/foo.txt.</literal></para></listitem></varlistentry><varlistentry><term><emphasis>Writers don't interfere with readers</emphasis></term><listitem><para>As writers create new nodes, bubbling their way up to the top, concurrent readers cannot see the work in progress. A new tree becomes visible to readers only after the writer makes its final "link" to a revision number in the repository.</para></listitem></varlistentry><varlistentry><term><emphasis>Tree structure is versioned</emphasis></term><listitem><para>The very structure of each tree is being saved from revision to revision. File and directory renames, additions, and deletions become an intrinsic part of the repository's history.</para></listitem></varlistentry></variablelist><para>If <indexterm id="idx-CHP-2-0062" significance="normal"><primary>Subversion</primary></indexterm>Subversion were only a repository, this would be the end of the story. However, there's a client side, too: the <emphasis>working copy</emphasis>, which is a user's checked-out copy of some revision tree plus whatever local edits the user has made but not yet committed. (Actually, working copies do not always reflect a single revision tree; they often contain mixtures of nodes from different revisions. This turns out not to make much of a difference as far as <indexterm id="idx-CHP-2-0063" significance="normal"><primary>tree transformation</primary></indexterm>tree transformation is concerned. So, for the purposes of this chapter, just assume that a working copy represents some revision tree, though not necessarily that of the latest revision.)<indexterm id="idx-CHP-2-0064" significance="normal"><primary>working copy (Subversion)</primary></indexterm><indexterm id="I_indexterm2_tt18" class="endofrange" startref="idx-CHP-2-0055" significance="normal"><primary>directory trees</primary><secondary>version control and tree transformation</secondary></indexterm></para></sect1><sect1 id="expressing_tree_differences" label="2.2"><title>Expressing Tree Differences</title><para>The most common action in <indexterm id="idx-CHP-2-0065" significance="normal"><primary>Subversion</primary></indexterm>Subversion is to transmit changes between the two sides: from the repository to the working copy when doing an update to receive others' changes, and from the working copy to the repository when committing one's own changes. Expressing the difference between two trees is also key to many other common operations—e.g., diffing, switching to a branch, merging changes from one branch to another, and so on.<indexterm id="idx-CHP-2-0066" significance="normal"><primary>directory trees</primary><secondary>differences</secondary></indexterm></para><para>Clearly it would be silly to have two different interfaces, one for server → client and another for client → server. The underlying task is the same in both cases. A tree difference is a tree difference, regardless of which direction it's traveling over the network or what its consumer intends to do with it. But finding a natural way to express tree differences proved surprisingly challenging. Complicating matters further, Subversion supports multiple network protocols and multiple backend storage mechanisms; we needed an interface that would look the same across all of those.</para><para>Our initial attempts to come up with an interface ranged from unsatisfying to downright awkward. I won't describe them all here, but what they had in common was that they tended to leave open questions for which there were no persuasive answers.</para><para>For example, many of the solutions involved transmitting the changed paths as strings, either as full paths or path components. Well, what order should the paths be transmitted in? Depth first? Breadth first? Random order? Alphabetical? Should there be different commands for directories than for files? Most importantly, how would each individual command expressing a difference know that it was part of a larger operation grouping all the changes into a unified set? In Subversion, the concept of the overall tree operation is quite user-visible, and if the programmatic interface didn't intrinsically match that concept, we'd surely need to write lots of brittle glue code to compensate.</para><para>In frustration, I drove with another developer, Ben Collins-Sussman, from Chicago down to Bloomington, Indiana, to seek the advice of Jim <indexterm id="idx-CHP-2-0067" significance="normal"><primary>Blandy</primary></indexterm>Blandy, who had invented Subversion's repository model in the first place, and who has, shall we say, strong opinions about design. Jim listened quietly as we described the various avenues we'd explored for transmitting tree differences, his expression growing grimmer and grimmer as we talked. When we reached the end of the list, he sat for a moment and then politely asked us to scram for a while so he could think. I put on my jogging shoes and went running; Ben stayed behind and read a book in another room or something. So much for collaborative development.</para><para>After I returned from my run and showered, Ben and I went back into Jim's den, and he showed us what he'd come up with. It is essentially what's in Subversion today; there have been various changes over the years, but none to its fundamental structure.</para></sect1><sect1 id="the_delta_editor_interface" label="2.3"><title>The Delta Editor Interface</title><para>Following is a mildly abridged version of the delta editor interface. I've left out the parts that deal with copying and renaming, the parts related to <indexterm id="idx-CHP-2-0068" significance="normal"><primary>Subversion</primary></indexterm>Subversion properties (properties are versioned metadata, and are not important here), and parts that handle some other Subversion-specific bookkeeping. However, you can always see the latest version of the delta editor by visiting <ulink url="http://svn.collab.net/repos/svn/trunk/subversion/include/svn_delta.h"/>. This chapter is based on r21731 (that is, revision 21731) at <ulink url="http://svn.collab.net/viewvc/svn/trunk/subversion/include/svn_delta.h?revision=21731"/>.<indexterm id="idx-CHP-2-0069" significance="normal"><primary>delta editor (Subversion)</primary></indexterm><indexterm class="startofrange" id="idx-CHP-2-0070" significance="normal"><primary>delta editor (Subversion)</primary><secondary>interface</secondary></indexterm><indexterm id="idx-CHP-2-0071" significance="normal"><primary>delta editor (Subversion)</primary></indexterm></para><para>To understand the interface, even in its abridged form, you'll need to know some Subversion jargon:</para><variablelist><varlistentry><term><emphasis>pools</emphasis></term><listitem><para>The <literal moreinfo="none">pool</literal> arguments are memory pools—allocation buffers that allow a large number of objects to be freed simultaneously.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">svn_error_t</literal></term><listitem><para>The return type <literal moreinfo="none">svn_error_t</literal> simply means that the function returns a pointer to a Subversion error object; a successful call returns a null pointer.<indexterm id="idx-CHP-2-0072" significance="normal"><primary>svn_error_t (Subversion error type)</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>text delta</emphasis></term><listitem><para>A text delta is the difference between two different versions of a file; you can apply a text delta as a patch to one version of the file to produce the other version. In Subversion, the "text" of a file is considered binary data—it doesn't matter whether the file is plain text, audio data, an image, or something else. Text deltas are expressed as streams of fixed-sized windows, each window containing a chunk of binary diff data. This way, peak memory usage is proportional to the size of a single window, rather than to the total size of the patch (which might be quite large in the case of, say, an image file).<indexterm id="idx-CHP-2-0073" significance="normal"><primary>text delta (Subversion)</primary></indexterm><indexterm id="idx-CHP-2-0074" significance="normal"><primary>window handler (Subversion)</primary></indexterm></para></listitem></varlistentry><varlistentry><term>window handler</term><listitem><para>This is the function prototype for applying one window of text-delta data to a target file.</para></listitem></varlistentry><varlistentry><term><emphasis>baton</emphasis></term><listitem><para>This is a <literal moreinfo="none">void *</literal> data structure that provides context to a callback function. In other APIs, these are sometimes called <literal moreinfo="none">void *ctx, void *userdata</literal>, or <literal moreinfo="none">void *closure</literal>. Subversion calls them "batons" because they're passed around a lot, like batons in a relay race.<indexterm id="idx-CHP-2-0075" significance="normal"><primary>baton (Subversion)</primary></indexterm></para></listitem></varlistentry></variablelist><para>The interface starts with an introduction, to put a reader of the code in the right frame of mind. This text is almost unchanged since Jim <indexterm id="idx-CHP-2-0076" significance="normal"><primary>Blandy</primary></indexterm>Blandy wrote it in August of 2000, so the general concept has clearly weathered well:</para><programlisting id="I_programlisting2_tt19" format="linespecific">
	/** Traversing tree deltas.
	 *
	 * In Subversion, we've got various producers and consumers of tree
	 * deltas.
	 *
	 * In processing a `commit' command:
	 * - The client examines its working copy data, and produces a tree
	 *   <indexterm id="idx-CHP-2-0077" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta describing the changes to be committed.
	 * - The client networking library consumes that delta, and sends them
	 *   across the wire as an equivalent series of network requests.
	 * - The server receives those requests and produces a tree delta --
	 *   hopefully equivalent to the one the client produced above.
	 * - The <indexterm id="idx-CHP-2-0078" significance="normal"><primary>Subversion</primary></indexterm>Subversion server module consumes that delta and commits an
	 *   appropriate transaction to the filesystem.
	 *
	 * In processing an `update' command, the process is reversed:
	 * - The Subversion server module talks to the filesystem and produces
	 *   a tree delta describing the changes necessary to bring the
	 *   client's working copy up to date.
	 * - The server consumes this delta, and assembles a reply
	 *   representing the appropriate changes.
	 * - The client networking library receives that reply, and produces a
	 *   tree delta --- hopefully equivalent to the one the Subversion
	 *   server produced above.
	 * - The working copy library consumes that delta, and makes the
	 *   appropriate changes to the working copy.
	 *
	 * The simplest approach would be to represent tree deltas using the
	 * obvious data structure. To do an update, the server would
	 * construct a delta structure, and the working copy library would
	 * apply that structure to the working copy; the network layer's job
	 * would simply be to get the structure across the net intact.
	 *
	 * However, we expect that these deltas will occasionally be too large
	 * to fit in a typical workstation's swap area. For example, in
	 * checking out a 200Mb source tree, the entire source tree is
	 * represented by a single tree delta. So it's important to handle
	 * deltas that are too large to fit in swap all at once.
	 *
	 * So instead of representing the tree delta explicitly, we define a
	 * standard way for a consumer to process each piece of a tree delta
	 * as soon as the producer creates it. The <userinput moreinfo="none">svn_delta_editor_t</userinput>
	 * structure is a set of callback functions to be defined by a delta
	 * consumer, and invoked by a delta producer. Each invocation of a
	 * callback function describes a piece of the delta --- a file's
	 * contents changing, something being renamed, etc.
	 */
</programlisting><para>Then comes a long, formal documentation comment, followed by the <indexterm id="idx-CHP-2-0079" significance="normal"><primary>delta editor (Subversion)</primary><secondary>interface</secondary></indexterm>interface itself, which is a callback table whose invocation order is partially constrained:<indexterm id="I_indexterm2_tt20" class="endofrange" startref="idx-CHP-2-0070" significance="normal"><primary>delta editor (Subversion)</primary><secondary>interface</secondary></indexterm></para><programlisting id="I_programlisting2_tt21" format="linespecific">
	/** A structure full of callback functions the delta source will invoke
	 * as it produces the delta.
	 *
	 * Function Usage
	 * ============== 
	 *
	 * Here's how to use these functions to express a tree delta.
	 *
	 * The delta consumer implements the callback functions described in
	 * this structure, and the <indexterm id="idx-CHP-2-0080" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta producer invokes them. So the
	 * caller (producer) is pushing tree delta data at the callee
	 * (consumer).
	 *
	 * At the start of traversal, the consumer provides <userinput moreinfo="none">edit_baton</userinput>, a
	 * baton global to the entire delta edit. 
	 *
	 * Next, if there are any tree deltas to express, the producer should
	 * pass the <userinput moreinfo="none">edit_baton</userinput> to the <userinput moreinfo="none">open_root</userinput> function, to get a baton
	 * representing root of the tree being edited.
	 *
	 * Most of the callbacks work in the obvious way:
	 *
	 * <userinput moreinfo="none">delete_entry</userinput>
	 * <userinput moreinfo="none"> add_file</userinput>
	 * <userinput moreinfo="none">add_directory</userinput>
	 * <userinput moreinfo="none">open_file</userinput> 
	 * <userinput moreinfo="none">open_directory</userinput>
	 *
	 * Each of these takes a directory baton, indicating the directory
	 * in which the change takes place, and a <userinput moreinfo="none">path</userinput> argument, giving the
	 * path (relative to the root of the edit) of the file,
	 * subdirectory, or directory entry to change. Editors will usually
	 * want to join this relative path with some base stored in the edit
	 * baton (e.g. a URL, a location in the OS filesystem). 
	 *
	 * Since every call requires a parent directory baton, including
	 * <userinput moreinfo="none">add_directory</userinput> and <userinput moreinfo="none">open_directory</userinput>, where do we ever get our
	 * initial directory baton, to get things started? The <userinput moreinfo="none">open_root</userinput>
	 * function returns a baton for the top directory of the change. In
	 * general, the producer needs to invoke the editor's <userinput moreinfo="none">open_root</userinput>
	 * function before it can get anything of interest done.
	 *
	 * While <userinput moreinfo="none">open_root</userinput> provides a directory baton for the root of
	 * the tree being changed, the <userinput moreinfo="none">add_directory</userinput> and <userinput moreinfo="none">open_directory</userinput>
	 * callbacks provide batons for other directories. Like the
	 * callbacks above, they take a <userinput moreinfo="none">parent_baton</userinput> and a relative path
	 * <userinput moreinfo="none">path</userinput>, and then return a new baton for the subdirectory being
	 * created / modified --- <userinput moreinfo="none">child_baton</userinput>. The producer can then use
	 * <userinput moreinfo="none">child_baton</userinput> to make further changes in that subdirectory. 
	 *
	 * So, if we already have subdirectories named `foo' and `foo/bar',
	 * then the producer can create a new file named `foo/bar/baz.c' by
	 * calling:
	 *
	 *     - <userinput moreinfo="none">open_root</userinput> () --- yielding a baton <userinput moreinfo="none">root</userinput> for the top directory
	 *
	 *     - <userinput moreinfo="none">open_directory</userinput> (root, "foo")
	 *
	 *     - <userinput moreinfo="none">open_directory</userinput> (f, "foo/bar") --- yielding a baton b for `foo/bar' 
	 *
	 *     - <userinput moreinfo="none">add_file</userinput> (b, "foo/bar/baz.c")
	 *
	 * When the producer is finished making changes to a directory, it
	 * should call <userinput moreinfo="none">close_directory</userinput>. This lets the consumer do any
	 * necessary cleanup, and free the baton's storage.
	 *
	 * <userinput moreinfo="none">The add_file</userinput> and <userinput moreinfo="none">open_file</userinput> callbacks each ret urn a baton
	 * for the file being created or changed. This baton can then be
	 * passed to <userinput moreinfo="none">apply_textdelta</userinput><indexterm id="idx-CHP-2-0081" significance="normal"><primary>delta editor (Subversion)</primary></indexterm> to change the file's contents.
	 * When the producer is finished making changes to a file, it should
	 * call <userinput moreinfo="none">close_file</userinput>, to let the consumer clean up and free the baton. 
	 *
	 * Function Call Ordering
	 * ======================
	 *
	 * There are five restrictions on the order in which the producer
	 * may use the batons: 
	 *
	 * 1. The producer may call <userinput moreinfo="none">open_directory, add_directory</userinput>,
	 *    <userinput moreinfo="none">open_file, add_file</userinput> at most once on any given directory
	 *	  entry. <userinput moreinfo="none">delete_entry</userinput> may be called at most once on any given
	 *    directory entry and may later be followed by <userinput moreinfo="none">add_directory</userinput> or
	 *	 <userinput moreinfo="none">add_file</userinput> on the same directory entry. <userinput moreinfo="none">delete_entry</userinput> may
	 *    not be called on any directory entry after <userinput moreinfo="none">open_directory</userinput>,
	 *   <userinput moreinfo="none">add_directory,open_file</userinput> or <userinput moreinfo="none">add_file</userinput> has been called on
	 *    that directory entry.
	 *
	 * 2. The producer may not close a directory baton until it has
	 *    closed all batons for its subdirectories. 
	 *
	 * 3. When a producer calls <userinput moreinfo="none">open_directory</userinput> or <userinput moreinfo="none">add_directory</userinput>,
	 *    it must specify the most recently opened of the currently open
	 *    directory batons. Put another way, the producer cannot have
	 *    two sibling directory batons open at the same time.
	 *
	 * 4. When the producer calls <userinput moreinfo="none">open_file</userinput> or <userinput moreinfo="none">add_file</userinput>, it must
	 *    follow with any changes to the file (using <userinput moreinfo="none">apply_textdelta</userinput>),
	 *    followed by a <userinput moreinfo="none">close_file</userinput> call, before issuing any other
	 *    file or directory calls.
	 *
	 * 5. When the producer calls <userinput moreinfo="none">apply_textdelta</userinput>, it must make all of
	 *    the window handler calls (including the <userinput moreinfo="none">NULL</userinput> window at the
	 *    end) before issuing any other <userinput moreinfo="none">svn_delta_editor_t</userinput> calls. 
	 *
	 * So, the producer needs to use directory and file batons as if it
	 * is doing a single depth-first traversal of the tree. 
	 *
	 * Pool Usage
	 * ==========
	 *
	 * Many editor functions are invoked multiple times, in a sequence
	 * determined by the editor "driver". The driver is responsible for
	 * creating a pool for use on each iteration of the editor function,
	 * and clearing that pool between each iteration. The driver passes
	 * the appropriate pool on each function invocation. 
	 *
	 * Based on the requirement of calling the editor functions in a
	 * depth-first style, it is usually customary for the driver to similarly
	 * nest the pools. However, this is only a safety feature to ensure
	 * that pools associated with deeper items are always cleared when the
	 * top-level items are also cleared. The <indexterm id="idx-CHP-2-0082" significance="normal"><primary>delta editor (Subversion)</primary><secondary>interface</secondary></indexterm>interface does not assume, nor
	 * require, any particular organization of the pools passed to these
	 * functions.
	 */
	typedef struct svn_<indexterm id="idx-CHP-2-0083" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta_editor_t 
	{
	  /** Set <userinput moreinfo="none">*root_baton</userinput> to a baton for the top directory of the change.
	   * (This is the top of the subtree being changed, not necessarily
	   * the root of the filesystem.) Like any other directory baton, the
	   * producer should call <userinput moreinfo="none">close_directory</userinput> on <userinput moreinfo="none">root_baton</userinput> when they're
	   * done. 
	   */
	  svn_error_t *(*open_root)(void *edit_baton,
	                            apr_pool_t *dir_pool,
	                            void **root_baton);



	  /** Remove the directory entry named <userinput moreinfo="none">path</userinput>, a child of the directory
	   * represented by <userinput moreinfo="none">parent_baton</userinput>.
	   */
	  svn_error_t *(*delete_entry)(const char *path,
	                               void *parent_baton,
	                               apr_pool_t *pool);



	  /** We are going to add a new subdirectory named <userinput moreinfo="none">path</userinput>. We will use
	   * the value this callback stores in <userinput moreinfo="none">*child_baton</userinput> as the
	   * <userinput moreinfo="none">parent_baton</userinput> for further changes in the new subdirectory.
	   */
	  svn_error_t *(*add_directory)(const char *path,
	                                void *parent_baton,
	                                apr_pool_t *dir_pool,
	                                void **child_baton);

	  /** We are going to make changes in a subdirectory (of the directory
	   * identified by <userinput moreinfo="none">parent_baton</userinput>). The subdirectory is specified by
	   * <userinput moreinfo="none">path</userinput>. The callback must store a value in <userinput moreinfo="none">*child_baton</userinput> that
	   * should be used as the <userinput moreinfo="none">parent_baton</userinput> for subsequent changes in this
	   * subdirectory.
	   */
	  svn_error_t *(*open_directory)(const char *path,
	                                 void *parent_baton,
	                                 apr_pool_t *dir_pool,
	                                 void **child_baton);

	  /** We are done processing a subdirectory, whose baton is <userinput moreinfo="none">dir_baton</userinput>
	   * (set by <userinput moreinfo="none">add_directory</userinput> or <userinput moreinfo="none">open_directory</userinput>). We won't be using
	   * the baton any more, so whatever resources it refers to may now be
	   * freed.
	   */
	  svn_error_t *(*close_directory)(void *dir_baton,
	                                  apr_pool_t *pool);
	  /** We are going to add a new file named <userinput moreinfo="none">path</userinput>. The callback can
	   * store a baton for this new file in <userinput moreinfo="none">**file_baton;</userinput> whatever value
	   * it stores there should be passed through to <userinput moreinfo="none">apply_textdelta</userinput><indexterm id="idx-CHP-2-0084" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>.
	   */
	  svn_error_t *(*add_file)(const char *path,
	                           void *parent_baton,
	                           apr_pool_t *file_pool,
	                           void **file_baton);

	  /** We are going to make change to a file named <userinput moreinfo="none">path</userinput>, which resides
	   * in the directory identified by <userinput moreinfo="none">parent_baton.</userinput>
	   *
	   * The callback can store a baton for this new file in <userinput moreinfo="none">**file_baton;</userinput>
	   * whatever value it stores there should be passed through to
	   * <userinput moreinfo="none">apply_textdelta</userinput>.
	   */
	  svn_error_t *(*open_file)(const char *path,
	                            void *parent_baton,
	                            apr_pool_t *file_pool,
	                             void **file_baton);

	  /** Apply a text delta, yielding the new revision of a file. 
	   *
	   * <userinput moreinfo="none">file_baton</userinput> indicates the file we're creating or updating, and the
	   * ancestor file on which it is based; it is the baton set by some
	   * prior <userinput moreinfo="none">add_file</userinput> or <userinput moreinfo="none">open_file</userinput> callback.
	   *
	   * The callback should set <userinput moreinfo="none">*handle</userinput> to a text delta window
	   * handler; we will then call <userinput moreinfo="none">*handle</userinput> on successive text
	   * delta windows as we receive them. The callback should set
	   * * <userinput moreinfo="none">handler_baton</userinput> to the value we should pass as the <userinput moreinfo="none">baton</userinput>
	   * argument to <userinput moreinfo="none">*handler.</userinput>
	   */
	  svn_error_t *(*apply_textdelta)(void *file_baton,
	                                  apr_pool_t *pool,
	                                  svn_txdelta_window_handler_t *handler,
	                                  void **handler_baton);

	  /** We are done processing a file, whose baton is <userinput moreinfo="none">file_baton</userinput> (set by
	   * <userinput moreinfo="none">add_file</userinput> or <userinput moreinfo="none">open_file</userinput>). We won't be using the baton any
	   * more, so whatever resources it refers to may now be freed.
	   */
	  svn_error_t *(*close_file)(void *file_baton,
	                             apr_pool_t *pool)

	  /** All delta processing is done. Call this, with the <userinput moreinfo="none">edit_baton</userinput> for
	   * the entire edit.
	   */
	  svn_error_t *(*close_edit)(void *edit_baton,
	                             apr_pool_t *pool);]

	  /** The editor-driver has decided to bail out. Allow the editor to
	   * gracefully clean up things if it needs to.
	   */
	  svn_error_t *(*abort_edit)(void *edit_baton,
	                             apr_pool_t *pool);
	} svn_delta_editor_t;
</programlisting></sect1><sect1 id="but_is_it_art" label="2.4"><title>But Is It Art?</title><para>I cannot claim that the beauty of this interface was immediately obvious to me. I'm not sure it was obvious to Jim either; he was probably just trying to get Ben and me out of his house. But he'd been pondering the problem for a long time, too, and he followed his instincts about how tree structures behave.</para><para>The first thing that strikes one about the <indexterm id="idx-CHP-2-0085" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta editor is that it <emphasis>chooses</emphasis> constraint: even though there is no philosophical requirement that tree edits be done in depth-first order (or indeed in any order at all), the interface enforces depth-firstness anyway, by means of the baton relationships. This makes the interface's usage and behavior more predictable.</para><para>The second thing is that an entire edit operation unobtrusively carries its context with it, again by means of the batons. A file baton can contain a pointer to its parent directory baton, a directory baton can contain a pointer to <emphasis>its</emphasis> parent directory baton (with a null parent for the root of the edit), and everyone can contain a pointer to the global edit baton. Although an individual baton may be a disposable object—for example, when a file is closed, its baton is destroyed—any given baton allows access to the global edit context, which may contain, for example, the revision number the client side is being updated to. Thus, batons are overloaded: they provide scope (i.e., lifetime, because a baton only lasts as long as the pool in which it is allocated) to portions of the edit, but they also carry global context.</para><para>The third important feature is that the interface provides clear boundaries between the various suboperations involved in expressing a tree change. For example, opening a file merely indicates that something changed in that file between the two trees, but doesn't give details; calling <literal moreinfo="none">apply_textdelta</literal> gives the details, but you don't have to call <literal moreinfo="none">apply_ textdelta</literal> if you don't want to. Similarly, opening a directory indicates that something changed in or under that directory, but if you don't need to say any more than that, you can just close the directory and move on. These boundaries are a consequence of the interface's dedication to <emphasis>streaminess</emphasis>, as expressed in its introductory comment: "…<emphasis>instead of representing the tree delta explicitly, we define a standard way for a consumer to process each piece of a tree delta as soon as the producer creates it</emphasis>." It would have been tempting to stream only the largest data chunks (that is, the file diffs), but the delta editor interface goes the whole way and streams the entire tree delta, thus giving both producer and consumer fine-grained control over memory usage, progress reporting, and interruptibility.<indexterm id="idx-CHP-2-0086" significance="normal"><primary>streamer service (CIP)</primary><secondary>streaminess (Subversion interface)</secondary></indexterm><indexterm id="idx-CHP-2-0087" significance="normal"><primary>tree delta (Subversion editor)</primary></indexterm></para><para>It was only after we began throwing the new delta editor at various problems that these features began to show their value. For example, one thing we wanted to implement was change summarization: a way to show an overview of the difference between two trees without giving the details. This is useful when someone wants to know which files in her working copy have changed in the repository since she checked them out, but doesn't need to know exactly what the changes were.</para><para>Here's a slightly simplified version of how it works: the client tells the server what revision tree the working copy is based on, and then the server tells the client the difference between that revision tree and the latest one, using the <indexterm id="idx-CHP-2-0088" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta editor. The server is the producer, the client is the consumer.</para><para>Using the repository from earlier in the chapter, in which we built up a change to <emphasis>/A/fish/tuna</emphasis> to create revision 2, let's see how this would look as a series of editor calls, sent by the server to a client whose tree is still at revision 1. The if block about two-thirds of the way through is where we decide whether this is a summarization edit or a "give me everything" edit:</para><programlisting id="I_programlisting2_tt22" format="linespecific">
	svn_delta_editor_t *editor
	void *edit_baton;

	/* In real life, this would be a passed-in parameter, of course. */
	int summarize_only = TRUE;

	/* In real life, these variables would be declared in subroutines,
	   so that their lifetimes would be bound to the stack frame just
	   as the objects they point to are bound by the tree edit frame. */
	void *root_baton;
	void *dir_baton;
	void *subdir_baton;
	void *file_baton;

	/* Similarly, there would be subpools, not just one top-level pool. */
	apr_pool_t *pool = svn_pool_create();

	/* Each use of the delta editor interface starts by requesting the 
	   particular editor that implements whatever you need, e.g.,
	   streaming the edit across the network, applying it to a working
	   copy, etc. */
	Get_Update_Editor(&amp;editor, &amp;eb,
	                some_repository,
	                1, /* source revision number */
	                2, /* target revision number */
	                pool);

	/* Now we drive the editor. In real life, this sequence of calls
	   would be dynamically generated, by code that walks the two
	   repository trees and invokes editor-&gt;foo() as appropriate. */

	editor-&gt;open_root(edit_baton, pool, &amp;root_baton);
	editor-&gt;open_directory("A", root_baton, pool, &amp;dir_baton);
	editor-&gt;open_directory("A/fish", dir_baton,pool, &amp;subdir_baton);
	editor-&gt;open_file("A/fish/tuna", subdir_baton, pool, &amp;file_baton);

	if (! summarize_only)
	  {
	    svn_txdelta_window_handler_t window_handler;
	    void *window_handler_baton;
	    svn_txdelta_window_t *window;

	    editor-&gt;apply_textdelta(file_baton, pool
	                               apr_pool_t *pool,
	                               &amp;window_handler,
	                               &amp;window_handler_baton);
	   do {
	     window = Get_Next_TextDelta_Window(...);
	     window_handler(window, window_handler_baton);
	   } while (window);
	 }

	 editor-&gt;close_file(file_baton, pool);
	 editor-&gt;close_directory(subdir_baton, pool);
	 editor-&gt;close_directory(dir_baton, pool);
	 editor-&gt;close_directory(root_baton, pool);
	 editor-&gt;close_edit(edit_baton, pool);
</programlisting><para>As this example shows, the distinction between a summary of a change and the full version of the change falls naturally along the boundaries of the <indexterm id="idx-CHP-2-0089" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta editor interface, allowing us to use the same code path for both purposes. While it happens that the two revision trees in this example were adjacent (revision 1 and revision 2), they didn't have to be. The same method would work for any two trees, even with many revisions between them, as is the case when a working copy hasn't been updated for a long time. And it would work when the two trees are in reverse order—that is, with the newer revision first. This is useful for reverting a change.</para></sect1><sect1 id="abstraction_as_a_spectator_sport" label="2.5"><title>Abstraction As a Spectator Sport</title><para>Our next indication of the delta editor's flexibility came when we needed to do two or more distinct things in the same tree edit. One of the earliest such situations was the need to handle <indexterm id="idx-CHP-2-0090" significance="normal"><primary>cancellations</primary></indexterm>cancellations. When the user interrupted an update, a signal handler trapped the request and set a flag; then at various points during the operation, we checked the flag and exited cleanly if it was set. It turned out that in most cases, the safest place to exit the operation was simply the next entry or exit boundary of an editor function call. This was trivially true for operations that performed no I/O on the client side (such as change summarizations and diffs), but it was also true of many operations that did touch files. After all, most of the work in an update is simply writing out the data, and even if the user interrupts the overall update, it usually still makes sense to either finish writing or cleanly cancel whatever file was in progress when the interrupt was detected.</para><para>But where to implement the flag checks? We could hardcode them into the delta editor, the one returned (by reference) from <literal moreinfo="none">Get_Update_Editor()</literal>. But that's obviously a poor choice: the delta editor is a library function that might be called from code that wants a totally different style of cancellation checking, or none at all.</para><para>A slightly better solution would be to pass a cancellation-checking callback function and associated baton to <literal moreinfo="none">Get_Update_Editor()</literal>. The returned editor would periodically invoke the callback on the baton and, depending on the return value, either continue as normal or return early (if the callback is null, it is never invoked). But that arrangement isn't ideal either. Checking cancellation is really a parasitic goal: you might want to do it when updating, or you might not, but in any case it has no effect on the way the update process itself works. Ideally, the two shouldn't be tangled together in the code, especially as we had concluded that, for the most part, operations didn't need fine-grained control over cancellation checking, anyway—the editor call boundaries would do just fine.</para><para>Cancellation is just one example of an auxiliary task associated with tree <indexterm id="idx-CHP-2-0091" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta edits. We faced, or thought we faced, similar problems in keeping track of committed targets while transmitting changes from the client to the server, in reporting update or commit progress to the user, and in various other situations. Naturally, we looked for a way to abstract out these adjunct behaviors, so the core code wouldn't be cluttered with them. In fact, we looked so hard that we initially <emphasis>over</emphasis>-abstracted:</para><programlisting id="I_programlisting2_tt23" format="linespecific">
	/** Compose <userinput moreinfo="none">editor_1</userinput> and its baton with <userinput moreinfo="none">editor_2</userinput> and its baton. 
	 *
	 * Return a new editor in <userinput moreinfo="none">new_editor</userinput> (allocated in <userinput moreinfo="none">pool</userinput>), in which
	 * each function <userinput moreinfo="none">fun</userinput> calls <userinput moreinfo="none">editor_1-&gt;fun</userinput> and then <userinput moreinfo="none">editor_2-&gt;fun</userinput>,
	 * with the corresponding batons. 
	 *
	 * If <userinput moreinfo="none">editor_1-&gt;fun</userinput> returns error, that error is returned from
	 * <userinput moreinfo="none">new_editor-&gt;fun</userinput> and <userinput moreinfo="none">editor_2-&gt;fun</userinput> is never called; otherwise
	 * <userinput moreinfo="none">new_editor-&gt;fun</userinput>'s return value is the same as <userinput moreinfo="none">editor_2-&gt;fun</userinput>'s.
	 *
	 * If an editor function is null, it is simply never called, and this
	 * is not an error.
	 */
	void
	svn_delta_compose_editors(const svn_delta_editor_t **new_editor,
	                          void **new_edit_baton,
	                          const svn_delta_editor_t *editor_1,
	                          void *edit_baton_1,
	                          const svn_delta_editor_t *editor_2,
	                          void *edit_baton_2,
	                          apr_pool_t *pool);
</programlisting><para>Although this turned out to go a bit too far—we'll look at why in a moment—I still find it a testament to the beauty of the editor interface. The composed editors behaved predictably, they kept the code clean (because no individual editor function had to worry about the details of some parallel editor invoked before or after it), and they passed the associativity test: you could take an editor that was itself the result of a composition and compose it with other editors, and everything would <emphasis>just work</emphasis>. It worked because the editors all agreed on the basic shape of the operation they were performing, even though they might do totally different things with the data.</para><para>As you can tell, I still miss editor composition for its sheer elegance. But in the end it was more abstraction than we needed. Much of the functionality that we initially implemented using composed editors, we later rewrote to use custom callbacks passed to the editor-creation routines. Although the adjunct behaviors did usually line up with editor call boundaries, they often weren't appropriate at <emphasis>all</emphasis> call boundaries, or even at most of them. The result was an overly high infrastructure-to-work ratio: by setting up an entire parallel editor, we were misleadingly implying to readers of the code that the adjunct behaviors would be invoked more often than they actually were.</para><para>Having gone as far as we could with editor composition and then retreated, we were still free to implement it by hand when we really wanted it, however. Today in <indexterm id="idx-CHP-2-0092" significance="normal"><primary>Subversion</primary></indexterm>Subversion, cancellation is done with manual composition. The cancellation-checking editor's constructor takes another editor—the core operation editor—as a parameter:</para><programlisting id="I_programlisting2_tt24" format="linespecific">
	/** Set <userinput moreinfo="none">*editor</userinput> and <userinput moreinfo="none">*edit_baton</userinput> to a cancellation editor that
	 * wraps <userinput moreinfo="none">wrapped_editor</userinput> and <userinput moreinfo="none">wrapped_baton</userinput>.
	 *
	 * The <userinput moreinfo="none">editor</userinput> will call <userinput moreinfo="none">cancel_func</userinput> with <userinput moreinfo="none">cancel_baton</userinput> when each <indexterm id="idx-CHP-2-0093" significance="normal"><primary>delta editor (Subversion)</primary><secondary>benefits of</secondary></indexterm>of
	 * its functions is called, continuing on to call the corresponding wrapped
	 * function if <userinput moreinfo="none">cancel_func</userinput> returns <userinput moreinfo="none">SVN_NO_ERROR.</userinput>
	 *
	 * If <userinput moreinfo="none">cancel_func</userinput> is <userinput moreinfo="none">NULL</userinput>, set <userinput moreinfo="none">*editor</userinput> to <userinput moreinfo="none">wrapped_editor</userinput> and
	 * <userinput moreinfo="none">*edit_baton</userinput> to <userinput moreinfo="none">wrapped_baton.</userinput>
	 */
	svn_error_t *
	svn_delta_get_cancellation_editor(svn_cancel_func_t cancel_func,
	                                  void *cancel_baton,
	                                  const svn_delta_editor_t *wrapped_editor,
	                                  void *wrapped_baton,
	                                  const svn_delta_editor_t **editor,
	                                  void **edit_baton,
	                                  apr_pool_t *pool);
</programlisting><para>We also implement some conditional debugging traces using a similar process of manual composition. The other adjunct behaviors—primarily progress reporting, event notification, and target counting—are implemented via callbacks that are passed to the editor constructors and (if nonnull) invoked by the editor at the few places where they are needed.</para><para>The editor interface continues to provide a strong unifying force across Subversion's code. It may seem strange to praise an API that first tempted its users into over-abstraction, but that temptation was mainly a side effect of suiting the problem of streamy tree delta transmission exceptionally well—it made the problem look so tractable that we wanted other problems to become that problem! When they didn't fit, we backed off, but the editor constructors still provided a canonical place to inject callbacks, and the editor's internal operation boundaries helped guide our thinking about when to invoke those callbacks.</para></sect1><sect1 id="conclusions" label="2.6"><title>Conclusions</title><para>The real strength of this API, and, I suspect, of any good API, is that it guides one's thinking. All operations involving tree modification in Subversion are now shaped roughly the same way. This not only reduces the amount of time newcomers must spend learning existing code, it gives new code a clear model to follow, and developers have taken the hint. For example, the <emphasis>svnsync</emphasis> feature, which mirrors one repository's activity directly into another repository—and was added to Subversion in 2006, six years after the advent of the <indexterm id="idx-CHP-2-0094" significance="normal"><primary>delta editor (Subversion)</primary></indexterm>delta editor—uses the delta editor interface to transmit the activity. The developer of that feature was not only spared the need to design a change-transmission mechanism, he was spared the need to even <emphasis>consider</emphasis> whether he needed to design a change-transmission mechanism. And others who now hack on the new code find it feels mostly familiar the first time they see it.<indexterm id="idx-CHP-2-0095" significance="normal"><primary>svnsync functionality (Subversion)</primary></indexterm></para><para>These are significant benefits. Not only does having the right API reduce learning time, it also relieves the development community of the need to have certain debates: design discussions that would have spawned long and contentious mailing list threads simply do not come up. That may not be quite the same thing as pure technical or aesthetic beauty, but in a project with many participants and a constant turnover rate, it's a beauty you can use.<indexterm id="I_indexterm2_tt25" class="endofrange" startref="idx-CHP-2-0049" significance="normal"><primary>delta editor (Subversion)</primary></indexterm></para></sect1></chapter><chapter id="the_most_beautiful_code_i_never_wrote" label="3" role=""><title>The Most Beautiful Code I Never Wrote</title><para><emphasis>Jon Bentley</emphasis><indexterm id="idx-CHP-3-0096" significance="normal"><primary>Bentley</primary></indexterm></para><para><emphasis>I once heard a master programmer praised with the phrase</emphasis>, "He adds function by deleting code." Antoine de Saint-Exupéry, the French writer and aviator, expressed this sentiment more generally when he said, "A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away." In software, the most beautiful code, the most beautiful functions, and the most beautiful programs are sometimes not there at all.</para><para>It is, of course, difficult to talk about things that aren't there. This chapter attempts this daunting task by presenting a novel analysis of the runtime of the classic <indexterm class="startofrange" id="idx-CHP-3-0097" significance="normal"><primary>Quicksort program</primary></indexterm>Quicksort program. The first section sets the stage by reviewing Quicksort from a personal perspective. The subsequent section is the meat of this chapter. We'll start by adding one counter to the program, then manipulate the code to make it smaller and smaller and yet more and more powerful until just a few lines of code completely capture its average runtime. The third section summarizes the techniques, and presents a particularly succinct analysis of the cost of binary search trees. The final two sections draw insights from the chapter to help you write more elegant programs.</para><sect1 id="the_most_beautiful_code_i_ever_wrote" label="3.1"><title>The Most Beautiful Code I Ever Wrote</title><para>When Greg Wilson first described the idea of this book, I asked myself what was the most beautiful code I had ever written. After this delicious question rolled around my brain for the better part of a day, I realized that the answer was easy: <indexterm id="idx-CHP-3-0098" significance="normal"><primary>Quicksort program</primary></indexterm>Quicksort. Unfortunately, the one question has three different answers, depending on precisely how it is phrased.</para><para>I wrote my thesis on divide-and-conquer algorithms, and found that C.A.R. <indexterm id="idx-CHP-3-0099" significance="normal"><primary>Hoare</primary></indexterm>Hoare's Quicksort ("Quicksort," <emphasis>Computer Journal</emphasis> 5) is undeniably the granddaddy of them all. It is a beautiful algorithm for a fundamental problem that can be implemented in elegant code. I loved the algorithm, but I always tiptoed around its innermost loop. I once spent two days debugging a complex program that was based on that loop, and for years I carefully copied that code whenever I needed to perform a similar task. It solved my problems, but I didn't <emphasis>really</emphasis> understand it.</para><para>I eventually learned an elegant partitioning scheme from Nico Lomuto, and was finally able to write a Quicksort that I could understand and even prove correct. William Strunk Jr.'s observation that "vigorous writing is concise" applies to code as well as to English, so I followed his admonition to "omit needless words" (The <emphasis>Elements of Style</emphasis>). I finally reduced approximately 40 lines of code to an even dozen. So if the question is, "What is the most beautiful small piece of code that you've ever written?" my answer is the Quicksort from my book <emphasis>Programming Pearls</emphasis>, Second Edition (Addison-Wesley). This Quicksort function, implemented in C, is shown in <xref linkend="quicksort_function"/>. We'll further study and refine this example in the next section.<indexterm id="idx-CHP-3-0100" significance="normal"><primary>Programming Pearls</primary></indexterm></para><example id="quicksort_function" label="3-1"><title>Quicksort function</title><programlisting format="linespecific">
void <indexterm id="idx-CHP-3-0101" significance="normal"><primary>Quicksort program</primary><secondary>quicksort( ) function</secondary></indexterm>quicksort(int l, int u)
{   int i, m;
    if (l &gt;= u) return;
    swap(l, randint(l, u));
    m = l;
    for (i = l+1; i &lt;= u; i++)
        if (x[i] &lt; x[l])
            swap(++m, i);
    swap(l, m);
    quicksort(l, m-1);
    quicksort(m+1, u);
}
</programlisting></example><para>This code sorts a global array <literal moreinfo="none">x[n]</literal> when called with the arguments <literal moreinfo="none">quicksort(0, n-1)</literal>. The two parameters of the function are the indexes of the subarray to be sorted: <literal moreinfo="none">l</literal> for lower and <literal moreinfo="none">u</literal> for upper. The call <literal moreinfo="none">swap(i, j)</literal> exchanges the contents of <literal moreinfo="none">x[i]</literal> and <literal moreinfo="none">x[j]</literal>. The first swap randomly chooses a partitioning element uniformly selected between <literal moreinfo="none">l</literal> and <literal moreinfo="none">u</literal>.</para><para><emphasis>Programming Pearls</emphasis> contains a detailed derivation and proof of correctness for the <literal moreinfo="none">quicksort</literal> function. Throughout the rest of this chapter, I'll assume that the reader is familiar with Quicksort to the level presented in that description and in most elementary algorithms textbooks.</para><para>If you change the question to, "What is the most beautiful piece of code that you've written that was widely used?" my answer is again a <indexterm id="idx-CHP-3-0102" significance="normal"><primary>Quicksort program</primary></indexterm>Quicksort. An article I wrote with M. D. McIlroy ("Engineering a <indexterm id="idx-CHP-3-0103" significance="normal"><primary>sorting</primary><secondary>sort function</secondary></indexterm>sort function," <emphasis>Software–Practice and Experience</emphasis>, Vol. 23, No. 11) describes a serious performance bug in the venerable Unix <literal moreinfo="none">qsort</literal> <indexterm id="idx-CHP-3-0104" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>function</tertiary></indexterm>function. We set out to build a new C library <literal moreinfo="none">sort</literal> function, and considered many different algorithms for the task, including Merge Sort and Heap Sort. After comparing several possible implementations, we settled on a version of the Quicksort algorithm. That paper describes how we engineered a new function that was clearer, faster, and more robust than its competitors—partly because it was smaller. Gordon <indexterm id="idx-CHP-3-0105" significance="normal"><primary>Bell</primary></indexterm>Bell's sage advice proved true: "The cheapest, fastest, and most reliable components of a computer system are those that aren't there." That function has now been widely used for over a decade with no reports of failure.</para><para>Considering the gains that could be achieved by reducing code size, I finally asked myself a third variant of the question that began this chapter. "What is the most beautiful code that you <emphasis>never</emphasis> wrote?" How was I able to accomplish a great deal with very little? The answer was once again related to Quicksort, specifically, the analysis of its performance. The next section tells that tale.</para></sect1><sect1 id="more_and_more_with_less_and_less" label="3.2"><title>More and More with Less and Less</title><para>Quicksort is an elegant algorithm that lends itself to subtle analysis. Around 1980, I had a wonderful discussion with Tony <indexterm id="idx-CHP-3-0106" significance="normal"><primary>Hoare</primary></indexterm>Hoare about the history of his algorithm. He told me that when he first developed Quicksort, he thought it was too simple to publish, and only wrote his classic "Quicksort" paper after he was able to analyze its expected runtime.</para><para>It is easy to see that in the worst case, Quicksort might take about <emphasis>n<superscript>2</superscript></emphasis> time to sort an array of <emphasis>n</emphasis> elements. In the best case, it chooses the median value as a partitioning element, and therefore sorts an array in about <emphasis>n</emphasis> lg <emphasis>n</emphasis> comparisons. So, how many comparisons does it use on the average for a random array of <emphasis>n</emphasis> distinct values?</para><para>Hoare's analysis of this question is beautiful, but unfortunately over the mathematical heads of many programmers. When I taught Quicksort to undergraduates, I was frustrated that many just didn't "get" the proof, even after sincere effort. We'll now attack that problem experimentally. We'll start with Hoare's program, and eventually end up with an analysis close to his.</para><para>Our task is to modify <xref linkend="quicksort_function"/> of the randomizing Quicksort code to analyze the average number of <indexterm id="idx-CHP-3-0107" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>counting comparisons used in array sort</tertiary></indexterm>comparisons used to sort an array of distinct inputs. We will also attempt to gain maximum insight with minimal code, runtime, and space.</para><para>To determine the average number of comparisons, we first augment the program to count them. To do this, we increment the variable <literal moreinfo="none">comps</literal> before the comparison in the inner loop (<xref linkend="quicksort_inner_loop_instrumented_to_count_comparisons"/>).</para><example id="quicksort_inner_loop_instrumented_to_count_comparisons" label="3-2"><title>Quicksort inner loop instrumented to count comparisons</title><programlisting format="linespecific">
for (i = l+1; i &lt;= u; i++) {
    comps++;
    if (x[i] &lt; x[l])
        swap(++m, i);
}
</programlisting></example><para>If we run the program for one value of <emphasis>n</emphasis>, we'll see how many comparisons that particular run takes. If we repeat that for many runs over many values of <emphasis>n</emphasis>, and analyze the results statistically, we'll observe that, on average, Quicksort takes about 1.4 <emphasis>n</emphasis> lg <emphasis>n</emphasis> comparisons to sort <emphasis>n</emphasis> elements.<indexterm id="idx-CHP-3-0108" significance="normal"><primary>Quicksort program</primary></indexterm></para><para>That isn't a bad way to gain insight into the behavior of a program. Thirteen lines of code and a few experiments can reveal a lot. A famous quote attributed to writers such as Blaise Pascal and T. S. Eliot states that, "If I had more time, I would have written you a shorter letter." We have the time, so let's experiment with the code to attempt to create a shorter (and better) program.</para><para>We'll play the game of speeding up that experiment, trying to increase statistical accuracy and programming insight. Because the inner loop always makes precisely <emphasis>u</emphasis><literal moreinfo="none">-l</literal> comparisons, we can make the program a tiny bit faster by counting those comparisons in a single operation outside the loop. This change yields the Quicksort shown in <xref linkend="quicksort_inner_loop_with_increment_moved_out_of_loop"/>.</para><example id="quicksort_inner_loop_with_increment_moved_out_of_loop" label="3-3"><title>Quicksort inner loop with increment moved out of loop</title><programlisting format="linespecific">
comps += u-l;
for (i = l+1; i &lt;= u; i++)
    if (x[i] &lt; x[l])
        swap(++m, i);
</programlisting></example><para>This program sorts an array and counts the number of comparisons used while doing so. However, if our goal is only to count the comparisons, we don't really need to sort the array. <xref linkend="quicksort_skeleton_reduced_to_counting"/> removes the "real work" of sorting the elements, and keeps only the "skeleton" of the various calls made by the program.<indexterm id="idx-CHP-3-0109" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>increment moved out of loop</tertiary></indexterm></para><example id="quicksort_skeleton_reduced_to_counting" label="3-4"><title>Quicksort skeleton reduced to counting</title><programlisting format="linespecific">
void quickcount(int l, int u)
{   int m;
    if (l &gt;= u) return;
    m = randint(l, u);
    comps += u-l;
    quickcount(l, m-1);
    quickcount(m+1, u);
}
</programlisting></example><para>This program works because of the "randomizing" way in which Quicksort chooses its partitioning element, and because all of the elements are assumed to be distinct. This new program now runs in time proportional to <emphasis>n</emphasis>, and while <xref linkend="quicksort_inner_loop_with_increment_moved_out_of_loop"/> required space proportional to <emphasis>n</emphasis>, the space is now reduced to the recursion stack, which on average is proportional to lg <emphasis>n</emphasis>.<indexterm id="idx-CHP-3-0110" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>skeleton reduced to counting</tertiary></indexterm></para><para>While the indexes (l and <replaceable>u</replaceable>) of the array are critical in an actual program, they don't matter in this skeleton version. We can replace these two indexes with a single integer (<literal moreinfo="none">n</literal>) that specifies the size of the subarray to be sorted <indexterm id="idx-CHP-3-0111" significance="normal"><primary>Quicksort program</primary></indexterm>(see <xref linkend="quicksort_skeleton_with_single_size_argument"/>).</para><example id="quicksort_skeleton_with_single_size_argument" label="3-5"><title>Quicksort skeleton with single size argument</title><programlisting format="linespecific">
void qc(int n)
{   int m;
    if (n &lt;= 1) return;
    m = randint(1, n);
    comps += n-1;
    qc(m-1);
    qc(n-m);
}
</programlisting></example><para>It is now more natural to rephrase this procedure as a <emphasis>comparison count</emphasis> <indexterm id="idx-CHP-3-0112" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>function</tertiary></indexterm>function that returns the number of comparisons used by one random Quicksort run. This function is shown in <xref linkend="quicksort_skeleton_implemented_as_a_function"/>.<indexterm id="idx-CHP-3-0113" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>skeleton with single size argument</tertiary></indexterm><indexterm id="idx-CHP-3-0114" significance="normal"><primary>comparison count function (Quicksort)</primary></indexterm></para><example id="quicksort_skeleton_implemented_as_a_function" label="3-6"><title>Quicksort skeleton implemented as a function</title><programlisting format="linespecific">
int cc(int n)
{   int m;
    if (n &lt;= 1) return 0;
    m = randint(1, n);
   return n-1 + cc(m-1) + cc(n-m);
}
</programlisting></example><para><xref linkend="quicksort_skeleton_reduced_to_counting"/>, <xref linkend="quicksort_skeleton_with_single_size_argument"/>, and <xref linkend="quicksort_skeleton_implemented_as_a_function"/> all solve the same basic problem, and they do so with the same runtime and memory usage. Each successor improves the form of the function and is thereby clearer and a bit more succinct than its predecessor.<indexterm id="idx-CHP-3-0115" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>skeleton implemented as a function</tertiary></indexterm></para><para>In defining the <emphasis>inventor's paradox</emphasis> (<emphasis>How To Solve It</emphasis>, Princeton University Press), George Pólya says that "the more ambitious plan may have more chances of success." We will now try to exploit that paradox in the analysis of Quicksort. So far we have asked, "How many comparisons does Quicksort make on one run of size <replaceable>n</replaceable>?" We will now ask the more ambitious question, "How many comparisons does Quicksort make, on average, for a random array of size <replaceable>n</replaceable>?" We can extend <xref linkend="quicksort_skeleton_implemented_as_a_function"/> to yield the pseudocode in <xref linkend="quicksort_average_comparisons_as_pseudocode"/>.<indexterm id="idx-CHP-3-0116" significance="normal"><primary>inventor's paradox</primary></indexterm></para><example id="quicksort_average_comparisons_as_pseudocode" label="3-7"><title>Quicksort average comparisons as pseudocode</title><programlisting format="linespecific">
float c(int n)
    if (n &lt;= 1) return 0
    sum = 0
    for (m = 1; m &lt;= n; m++)
        sum += n-1 + c(m-1) + c(n-m)
    return sum/n
</programlisting></example><para>If the input has a maximum of one element, Quicksort uses no comparisons, just as in <xref linkend="quicksort_skeleton_implemented_as_a_function"/>. For larger <replaceable>n</replaceable>, this code considers each partition value <replaceable>m</replaceable> (from the first element to the last, each equally likely) and determines the cost of partitioning there. The code then calculates the sum of these values (thereby solving recursively one problem of size <literal moreinfo="none">m-1</literal> and one problem of size (<replaceable>n</replaceable>-<replaceable>m</replaceable>), and then divides that sum by <replaceable>n</replaceable> to return the average.<indexterm id="idx-CHP-3-0117" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>average comparisons as pseudocode</tertiary></indexterm></para><para>If we could compute this number it would make our experiments much more powerful. Rather than having to run many experiments at a single value of <replaceable>n</replaceable> to estimate the mean, a single experiment would give us the true mean. Unfortunately, that power comes at a price: the program runs in time proportional to 3<superscript>n</superscript> (it is an interesting, if self-referential, exercise to analyze that runtime using the techniques described in this chapter).</para><para><indexterm id="idx-CHP-3-0118" significance="normal"><primary>Quicksort program</primary></indexterm><xref linkend="quicksort_average_comparisons_as_pseudocode"/> takes the time that it does because it computes subanswers over <indexterm id="idx-CHP-3-0119" significance="normal"><primary>re-expression and symmetry in programming</primary></indexterm>and over again. When a program does that, we can often use <emphasis>dynamic programming</emphasis> to store the subanswers to avoid recomputing them. In this case, we'll introduce the table <replaceable>t</replaceable>[<replaceable>N</replaceable><literal moreinfo="none">+1</literal>], in which <replaceable>t[n]</replaceable> stores <replaceable>c(n)</replaceable>, and compute its values in increasing order. We will let <replaceable>N</replaceable> denote the maximum size of <replaceable>n</replaceable>, which is the size of the array to be sorted. The result is shown in <xref linkend="quicksort_calculation_with_dynamic_programming"/>.<indexterm id="idx-CHP-3-0120" significance="normal"><primary>dynamic programming</primary></indexterm></para><example id="quicksort_calculation_with_dynamic_programming" label="3-8"><title>Quicksort calculation with dynamic programming</title><programlisting format="linespecific">
t[0] = 0
for (n = 1; n &lt;= N; n++)
    sum = 0
    for (i = 1; i &lt;= n; i++)
        sum += n-1 + t[i-1] + t[n-i]
    t[n] = sum/n
</programlisting></example><para>This program is a rough transcription of <xref linkend="quicksort_average_comparisons_as_pseudocode"/> and replaces <replaceable>c(n)</replaceable> with <replaceable>t[n]</replaceable>. Its runtime is proportional to <replaceable>N<superscript>2</superscript></replaceable> and its space is proportional to <replaceable>N</replaceable>. One of its benefits is that at the end of execution, the array <replaceable>t</replaceable> contains the true average values (not just the estimate of sample means) for array elements <literal moreinfo="none">0</literal> through <replaceable>N</replaceable>. Those values can be analyzed to yield insight about the <indexterm id="idx-CHP-3-0121" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>function</tertiary></indexterm>functional form of the expected number of comparisons used by Quicksort.<indexterm id="idx-CHP-3-0122" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>calculation with dynamic programming</tertiary></indexterm></para><para>We will now simplify that program further. The first step is to move the term <replaceable>n</replaceable><literal moreinfo="none">-1</literal> out of the loop, as shown in <xref linkend="quicksort_calculation_with_code_moved_out_of_the_loop"/>.</para><example id="quicksort_calculation_with_code_moved_out_of_the_loop" label="3-9"><title>Quicksort calculation with code moved out of the loop</title><programlisting format="linespecific">
t[0] = 0
for (n = 1; n &lt;= N; n++)
    sum = 0
    for (i = 1; i &lt;= n; i++)
        sum += t[i-1] + t[n-i]
    t[n] = n-1 + sum/n
</programlisting></example><para>We will now further tune the loop by exploiting <indexterm id="idx-CHP-3-0123" significance="normal"><primary>symmetry</primary></indexterm>symmetry. When <literal moreinfo="none">n</literal> is 4, for instance, the inner loop computes the sum:<indexterm id="idx-CHP-3-0124" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>calculation with code moved out of loop</tertiary></indexterm></para><programlisting id="I_programlisting3_tt26" format="linespecific">
	t[0]+t[3] + t[1]+t[2] + t[2]+t[1] + t[3]+t[0]
</programlisting><para>In the sequence of pairs, the first elements increase while the second elements decrease. We can therefore rewrite the sum as:</para><programlisting id="I_programlisting3_tt27" format="linespecific">
	2 * (t[0] + t[1] + t[2] + t[3])
</programlisting><para>We can use that symmetry to yield the Quicksort shown in <xref linkend="quicksort_calculation_with_symmetry"/>.</para><example id="quicksort_calculation_with_symmetry" label="3-10"><title>Quicksort calculation with symmetry</title><programlisting format="linespecific">
t[0] = 0
for (n = 1; n &lt;= N; n++)
    sum = 0
    for (i = 0; i &lt; n; i++)
        sum += 2 * t[i]
    t[n] = n-1 + sum/n
</programlisting></example><para>However, this code is once again wasteful because it recomputes the same sum over and over again. Rather than adding all the previous terms, we can initialize <literal moreinfo="none">sum</literal> outside the loop and add the next term to yield <indexterm id="idx-CHP-3-0125" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>function</tertiary></indexterm><xref linkend="quicksort_calculation_with_the_inner_loop_removed"/>.<indexterm id="idx-CHP-3-0126" significance="normal"><primary>Quicksort program</primary></indexterm><indexterm id="idx-CHP-3-0127" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>calculation with inner loop removed</tertiary></indexterm></para><example id="quicksort_calculation_with_the_inner_loop_removed" label="3-11"><title>Quicksort calculation with the inner loop removed</title><programlisting format="linespecific">
sum = 0; t[0] = 0
for (n = 1; n &lt;= N; n++)
    sum += 2*t[n-1]
    t[n] = n-1 + sum/n
</programlisting></example><para>This little program is indeed useful. In time proportional to <replaceable>N</replaceable>, it produces a table of the true expected runtimes of Quicksort for every integer from 1 to <replaceable>N</replaceable>.</para><para><xref linkend="quicksort_calculation_with_the_inner_loop_removed"/> is straightforward to implement in a spreadsheet, where the values are immediately made available for further analysis. <xref linkend="output_of_spreadsheet_implementation_of_example_-"/> shows the first rows.</para><table id="output_of_spreadsheet_implementation_of_example_-" label="3-1"><title>Output of spreadsheet implementation of <xref linkend="quicksort_calculation_with_the_inner_loop_removed"/></title><tgroup cols="3"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><colspec colnum="3" colname="col3"/><thead><row><entry><para>N</para></entry><entry><para>Sum</para></entry><entry><para>t[n]</para></entry></row></thead><tbody><row><entry><para><literal moreinfo="none">0</literal></para></entry><entry><para><literal moreinfo="none">0</literal></para></entry><entry><para><literal moreinfo="none">0</literal></para></entry></row><row><entry><para><literal moreinfo="none">1</literal></para></entry><entry><para><literal moreinfo="none">0</literal></para></entry><entry><para><literal moreinfo="none">0</literal></para></entry></row><row><entry><para><literal moreinfo="none">2</literal></para></entry><entry><para><literal moreinfo="none">0</literal></para></entry><entry><para><literal moreinfo="none">1</literal></para></entry></row><row><entry><para><literal moreinfo="none">3</literal></para></entry><entry><para><literal moreinfo="none">2</literal></para></entry><entry><para><literal moreinfo="none">2.667</literal></para></entry></row><row><entry><para><literal moreinfo="none">4</literal></para></entry><entry><para><literal moreinfo="none">7.333</literal></para></entry><entry><para><literal moreinfo="none">4.833</literal></para></entry></row><row><entry><para><literal moreinfo="none">5</literal></para></entry><entry><para><literal moreinfo="none">17</literal></para></entry><entry><para><literal moreinfo="none">7.4</literal></para></entry></row><row><entry><para><literal moreinfo="none">6</literal></para></entry><entry><para><literal moreinfo="none">31.8</literal></para></entry><entry><para><literal moreinfo="none">10.3</literal></para></entry></row><row><entry><para><literal moreinfo="none">7</literal></para></entry><entry><para><literal moreinfo="none">52.4</literal></para></entry><entry><para><literal moreinfo="none">13.486</literal></para></entry></row><row><entry><para><literal moreinfo="none">8</literal></para></entry><entry><para><literal moreinfo="none">79.371</literal></para></entry><entry><para><literal moreinfo="none">16.921</literal></para></entry></row></tbody></tgroup></table><para>The first row of numbers in this table is initialized with the three constants from the code. In spreadsheet notation, the next row of numbers (the third row of the spreadsheet) is calculated using the following relations:</para><programlisting id="I_programlisting3_tt28" format="linespecific">
	A3 = A2+1     B3 = B2 + 2*C2     C3 = A3-1 + B3/A3
</programlisting><para>Dragging those (relative) relations down completes the spreadsheet. That spreadsheet is a real contender for "the most beautiful code I ever wrote," using the criterion of accomplishing a great deal with just a few lines of code.</para><para>But what if we don't need all the values? What if we would prefer to analyze just a few of the values along the way (for example, all the powers of 2 from 2<superscript>0</superscript> to 2<superscript>32</superscript>)? Although <xref linkend="quicksort_calculation_with_the_inner_loop_removed"/> builds the complete table <literal moreinfo="none">t</literal>, it uses only the most recent value of that table.</para><para>We can therefore replace the linear space of the table <literal moreinfo="none">t[]</literal> with the constant space of the variable <literal moreinfo="none">t</literal>, as shown in <indexterm id="idx-CHP-3-0128" significance="normal"><primary>Quicksort program</primary></indexterm><indexterm id="idx-CHP-3-0129" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>function</tertiary></indexterm><xref linkend="quicksort_calculationmdashfinal_version"/>.</para><example id="quicksort_calculationmdashfinal_version" label="3-12"><title>Quicksort calculation—final version</title><programlisting format="linespecific">
sum = 0; t = 0
for (n = 1; n &lt;= N; n++)
    sum += 2*t
    t = n-1 + sum/n
</programlisting></example><para>We could then insert an extra line of code to test for appropriateness of <literal moreinfo="none">n</literal>, and print those results as needed.<indexterm id="idx-CHP-3-0130" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>final version of calculation</tertiary></indexterm></para><para>This tiny program is the final step in our long path. Alan Perlis' observation is apt in consideration of the path this chapter has taken: "Simplicity does not precede complexity, but follows it" ("Epigrams on Programming," <emphasis>Sigplan Notices</emphasis>, Vol. 17, Issue 9).</para></sect1><sect1 id="perspective" label="3.3"><title>Perspective</title><para><xref linkend="evolution_of_quicksort_comparison_counting"/> summarizes the programs used to analyze Quicksort throughout this chapter.</para><table id="evolution_of_quicksort_comparison_counting" label="3-2"><title>Evolution of Quicksort comparison counting</title><tgroup cols="6"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><colspec colnum="3" colname="col3"/><colspec colnum="4" colname="col4"/><colspec colnum="5" colname="col5"/><colspec colnum="6" colname="col6"/><thead><row><entry><para>Example Number</para></entry><entry><para>Lines of code</para></entry><entry><para>Type of answer</para></entry><entry><para>Number of answer</para></entry><entry><para>Runtime</para></entry><entry><para>Space</para></entry></row></thead><tbody><row><entry><para>2</para></entry><entry><para>13</para></entry><entry><para>Sample</para></entry><entry><para>1</para></entry><entry><para><replaceable>n</replaceable><literal moreinfo="none">l</literal><emphasis>g</emphasis><replaceable>n</replaceable></para></entry><entry><para><replaceable>N</replaceable></para></entry></row><row><entry><para>3</para></entry><entry><para>13</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry></row><row><entry><para>4</para></entry><entry><para>8</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para><replaceable>n</replaceable></para></entry><entry><para>lg<replaceable>n</replaceable></para></entry></row><row><entry><para>5</para></entry><entry><para>8</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry></row><row><entry><para>6</para></entry><entry><para>6</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry></row><row><entry><para>7</para></entry><entry><para>6</para></entry><entry><para>Exact</para></entry><entry><para>"</para></entry><entry><para>3<replaceable>N</replaceable></para></entry><entry><para><replaceable>N</replaceable></para></entry></row><row><entry><para>8</para></entry><entry><para>6</para></entry><entry><para>"</para></entry><entry><para><replaceable>N</replaceable></para></entry><entry><para><replaceable>N<superscript>2</superscript></replaceable></para></entry><entry><para><replaceable>N</replaceable></para></entry></row><row><entry><para>9</para></entry><entry><para>6</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry></row><row><entry><para>10</para></entry><entry><para>6</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para>"</para></entry></row><row><entry><para>11</para></entry><entry><para>4</para></entry><entry><para>"</para></entry><entry><para>"</para></entry><entry><para><replaceable>N</replaceable></para></entry><entry><para>"</para></entry></row><row><entry><para>12</para></entry><entry><para>4</para></entry><entry><para>Exact</para></entry><entry><para><replaceable>N</replaceable></para></entry><entry><para><replaceable>N</replaceable></para></entry><entry><para>1</para></entry></row></tbody></tgroup></table><para>Each individual step in the evolution of our code was pretty straightforward; the transition from the sample in <xref linkend="quicksort_skeleton_implemented_as_a_function"/> to the exact answer in <xref linkend="quicksort_average_comparisons_as_pseudocode"/> is probably the most subtle. Along the way, as the code became faster and more useful, it also shrank in size. In the middle of the 19th century, Robert Browning observed that "less is more," and this table helps to quantify one instance of that minimalist philosophy.</para><para>We have seen three fundamentally different types of programs. <xref linkend="quicksort_inner_loop_instrumented_to_count_comparisons"/> and <xref linkend="quicksort_inner_loop_with_increment_moved_out_of_loop"/> are working Quicksorts, instrumented to count comparisons as they sort a real array. <xref linkend="quicksort_skeleton_reduced_to_counting"/> through <xref linkend="quicksort_skeleton_implemented_as_a_function"/> implement a simple model of Quicksort: they mimic one run of the algorithm, without actually doing the work of sorting. <xref linkend="quicksort_average_comparisons_as_pseudocode"/> through <xref linkend="quicksort_calculationmdashfinal_version"/> implement a more sophisticated model: they compute the true average number of comparisons without ever tracing any particular run.</para><para>The <indexterm id="idx-CHP-3-0131" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>techniques used</tertiary></indexterm>techniques used to achieve each program are summarized as follows:</para><itemizedlist><listitem><para><indexterm id="idx-CHP-3-0132" significance="normal"><primary>Quicksort program</primary></indexterm><xref linkend="quicksort_inner_loop_instrumented_to_count_comparisons"/>, <xref linkend="quicksort_skeleton_reduced_to_counting"/>, <xref linkend="quicksort_average_comparisons_as_pseudocode"/>: Fundamental change of problem definition.</para></listitem><listitem><para><xref linkend="quicksort_skeleton_with_single_size_argument"/>, <xref linkend="quicksort_skeleton_implemented_as_a_function"/>, <xref linkend="quicksort_calculationmdashfinal_version"/>: Slight change of function definition.</para></listitem><listitem><para><xref linkend="quicksort_calculation_with_dynamic_programming"/>: New data structure to implement dynamic programming.</para></listitem></itemizedlist><para>These techniques are typical. We can often simplify a program by asking, "What problem do we really need to solve?" or, "Is there a better function to solve that problem?"</para><para>When I presented this analysis to undergraduates, the program finally shrank to zero lines of code and disappeared in a puff of mathematical smoke. We can reinterpret <xref linkend="quicksort_average_comparisons_as_pseudocode"/> as the following recurrence relation:</para><para><mediaobject id="I_mediaobject3_tt29"><imageobject role="print"><imagedata fileref="figs/print/equation1.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation1.png" format="PNG"/></imageobject></mediaobject></para><para>This is precisely the approach taken by <indexterm id="idx-CHP-3-0133" significance="normal"><primary>Hoare</primary></indexterm>Hoare and later presented by D. E. <indexterm id="idx-CHP-3-0134" significance="normal"><primary>Knuth</primary></indexterm>Knuth in his classic <emphasis>The Art of Computer Programming, Volume 3: Sorting and Searching</emphasis> (Addison-Wesley). The programming tricks of <indexterm id="idx-CHP-3-0135" significance="normal"><primary>re-expression and symmetry in programming</primary></indexterm>re-expression and symmetry that give rise to <xref linkend="quicksort_calculation_with_symmetry"/> allow us to simplify the recursive part to:<indexterm id="idx-CHP-3-0136" significance="normal"><primary>Art of Computer Programming</primary></indexterm></para><para><mediaobject id="I_mediaobject3_tt30"><imageobject role="print"><imagedata fileref="figs/print/equation2.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation2.png" format="PNG"/></imageobject></mediaobject></para><para>Knuth's technique to remove the summation sign gives (roughly) <xref linkend="quicksort_calculation_with_the_inner_loop_removed"/>, which can be re-expressed as a system of two recurrence relations in two unknowns as:</para><para><emphasis>C<subscript>0</subscript> = 0 S<subscript>0</subscript> = 0 S<subscript>n</subscript> = S<subscript>n−1</subscript> + 2C<subscript>n−1</subscript> C<subscript>n</subscript> = n − 1 + S<subscript>n</subscript>/n</emphasis></para><para>Knuth uses the mathematical technique of a <indexterm id="idx-CHP-3-0137" significance="normal"><primary>summing factor technique</primary></indexterm>"summing factor" to achieve the solution:</para><para><emphasis>C<subscript>n</subscript></emphasis> = (<emphasis>n + 1</emphasis>)(2<emphasis>H<subscript>n+1</subscript></emphasis>−2) − 2<emphasis><subscript>n</subscript></emphasis> ~ 1.386<emphasis>nlgn</emphasis></para><para>where H<emphasis><subscript>n</subscript></emphasis> denotes the <emphasis>n</emphasis><replaceable><superscript>th</superscript></replaceable> harmonic number, 1 + 1/2 + 1/3 + … 1/<emphasis>n</emphasis>. Thus we have smoothly progressed from experimenting on a program by augmenting it with probes to a completely mathematical analysis of its behavior.</para><para>With this formula, we end our quest. We have followed Einstein's famous advice to "make everything as simple as possible, but no simpler."</para><sect2 id="a_bonus_analysis" label="3.3.1"><title>A Bonus Analysis</title><para>Goethe famously said that "architecture is frozen music." In exactly that sense, I assert that <indexterm id="idx-CHP-3-0138" significance="normal"><primary>data structures as frozen algorithms</primary></indexterm>"data structures are frozen algorithms." And if we freeze the Quicksort algorithm, we get the data structure of a binary search tree. Knuth's publication presents that structure and analyzes its runtime with a recurrence relation similar to that for Quicksort.</para><para>If we wanted to analyze the average cost of <indexterm id="idx-CHP-3-0139" significance="normal"><primary>Quicksort program</primary><secondary>paring down code while increasing</secondary><tertiary>inserting element into binary search tree</tertiary></indexterm>inserting an element into a <indexterm id="idx-CHP-3-0140" significance="normal"><primary>binary search tree (Quicksort)</primary></indexterm>binary search tree, we could start with the code, augment it to count comparisons, and then conduct experiments on the data we gather. We could then simplify that code (and expand its power) in a manner very reminiscent of the previous section. A simpler solution is to define a new <indexterm id="idx-CHP-3-0141" significance="normal"><primary>Quicksort program</primary></indexterm>Quicksort that uses an <emphasis>ideal partitioning</emphasis> method that leaves the elements in the same relative order on both sides. That Quicksort is isomorphic to binary search trees, as illustrated in <indexterm id="idx-CHP-3-0142" significance="normal"><primary>partitioning in Quicksort</primary></indexterm><xref linkend="an_ideal_partitioning_quicksort_and_the_corresponding_binary_se"/>.<indexterm id="idx-CHP-3-0143" significance="normal"><primary>ideal partitioning method (Quicksort)</primary></indexterm></para><figure id="an_ideal_partitioning_quicksort_and_the_corresponding_binary_se" label="3-1" float="0"><title>An ideal partitioning Quicksort and the corresponding binary search tree</title><mediaobject id="I_mediaobject3_tt31"><imageobject role="print"><imagedata fileref="figs/print/beauty_0301.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0301.png" format="PNG"/></imageobject></mediaobject></figure><para>The boxes on the left show an ideal-partitioning Quicksort in progress, and the graph on the right shows the corresponding binary search tree that has been built from the same input. Not only do the two processes make the same <emphasis>number</emphasis> of comparisons, they make exactly the same <emphasis>set</emphasis> of comparisons. Our previous analysis for the average performance of randomizing Quicksort on a set of distinct elements therefore gives us the average number of comparisons to insert randomly permuted distinct elements into a binary search tree.</para></sect2></sect1><sect1 id="what_is_writing" label="3.4"><title>What Is Writing?</title><para>In a weak sense, I "wrote" <xref linkend="quicksort_inner_loop_instrumented_to_count_comparisons"/> through <xref linkend="quicksort_calculationmdashfinal_version"/> of the program. I wrote them first in scribbled notes, then on a chalkboard in front of undergraduates, and eventually in this chapter. I derived the programs systematically, I have spent considerable time analyzing them, and I believe that they are correct. Apart from the spreadsheet implementation of <xref linkend="quicksort_calculation_with_the_inner_loop_removed"/>, though, I have never run any of the examples as a computer program.</para><para>In almost two decades at Bell Labs, I learned from many teachers (and especially from Brian Kernighan, whose chapter on the teaching of programming appears as <xref linkend="a_regular_expression_matcher"/> of this book) that "writing" a program to be displayed in public involves much more than typing symbols. One implements the program in code, runs it first on a few test cases, then builds thorough scaffolding, drivers, and a library of cases to beat on it systematically. Ideally, one mechanically includes the compiled source code into the text without human intervention. I wrote <xref linkend="quicksort_function"/> (and all the code in <emphasis>Programming Pearls</emphasis>) in that strong sense.</para><para>As a point of honor, I wanted to keep my title honest by never implementing <xref linkend="quicksort_inner_loop_instrumented_to_count_comparisons"/> through <xref linkend="quicksort_calculationmdashfinal_version"/>. Almost four decades of computer programming have left me with deep respect for the difficulty of the craft (well, more precisely, abject fear of bugs). I compromised by implementing <indexterm id="idx-CHP-3-0144" significance="normal"><primary>Quicksort program</primary></indexterm><xref linkend="quicksort_calculation_with_the_inner_loop_removed"/> in a spreadsheet, and I tossed in an additional column that gave the closed-form solution. Imagine my delight (and relief) when the two matched exactly! And so I offer the world these beautiful unwritten programs, with some confidence in their correctness, yet painfully aware of the possibility of undiscovered error. I hope that the deep beauty I find in them will be unmarred by superficial blemishes.</para><para>In my discomfort at presenting these unwritten programs, I take consolation from the insight of Alan Perlis, who said, "Is it possible that software is not like anything else, that it is meant to be discarded: that the whole point is to see it as a soap bubble?"</para></sect1><sect1 id="conclusion-id001" label="3.5"><title>Conclusion</title><para>Beauty has many sources. This chapter has concentrated on the beauty conferred by simplicity, elegance, and concision. The following <indexterm id="idx-CHP-3-0145" significance="normal"><primary>Quicksort program</primary><secondary>aphorisms about beauty</secondary></indexterm>aphorisms all express this overarching theme:</para><itemizedlist><listitem><para>Strive to add function by deleting code.</para></listitem><listitem><para>A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away. (Saint-Exupéry)</para></listitem><listitem><para>In software, the most beautiful code, the most beautiful functions, and the most beautiful programs are sometimes not there at all.</para></listitem><listitem><para>Vigorous writing is concise. Omit needless words. (Strunk and White)</para></listitem><listitem><para>The cheapest, fastest, and most reliable components of a computer system are those that aren't there. (Bell)</para></listitem><listitem><para>Endeavor to do more and more with less and less.</para></listitem><listitem><para>If I had more time, I would have written you a shorter letter. (Pascal)</para></listitem><listitem><para>The Inventor's Paradox: The more ambitious plan may have more chance of success. (Pólya)</para></listitem><listitem><para>Simplicity does not precede complexity, but follows it. (Perlis)</para></listitem><listitem><para>Less is more. (Browning)</para></listitem><listitem><para>Make everything as simple as possible, but no simpler. (Einstein)</para></listitem><listitem><para>Software should sometimes be seen as a soap bubble. (Perlis)</para></listitem><listitem><para>Seek beauty through simplicity.</para></listitem></itemizedlist><para>Here endeth the lesson. Go thou and do likewise.</para><para>For those who desire more concrete hints, here are some <indexterm id="idx-CHP-3-0146" significance="normal"><primary>Quicksort program</primary><secondary>ideas for refining code</secondary></indexterm>ideas grouped into three main categories.</para><variablelist><varlistentry><term><emphasis>Analysis of programs</emphasis></term><listitem><para>One way to gain insight into the behavior of a program is to instrument it and then run it on representative data, as in <xref linkend="quicksort_inner_loop_instrumented_to_count_comparisons"/>. Often, though, we are less concerned with the program as a whole than with individual aspects. In this case, for instance, we considered only the number of comparisons that Quicksort uses on the average and ignored many other aspects. Sedgewick ("The analysis of Quicksort programs," <emphasis>Acta Informatica</emphasis>, Vol. 7) studies issues such as the space it requires and many other components of runtime for a variety of Quicksort variants. By concentrating on the key issues, we can ignore (for a while) other aspects of the program. One of my articles, "A Case Study in Applied Algorithm Design" (<emphasis>IEEE Computer</emphasis>, Vol. 17, No. 2) describes how I once faced the problem of evaluating the performance of a <emphasis>strip heuristic</emphasis> for finding an approximate travelling salesman tour through <literal moreinfo="none">N</literal> points in the unit square. I estimated that a complete program for the task might take 100 lines of code. After a series of steps similar in spirit to what we have seen in this chapter, I used a dozen-line simulation to give much more accuracy (and after completing my little simulation, I found that Beardwood et al. ["The Shortest Path Through Many Points," <emphasis>Proc. Cambridge Philosophical Soc.</emphasis>, Vol. 55] had re-expressed my simulation as a double integral, and thereby had solved the problem mathematically some two decades earlier).</para></listitem></varlistentry><varlistentry><term><emphasis>Small pieces of code</emphasis></term><listitem><para>I believe that computer programming is a practical skill, and I agree with Pólya that we "acquire any practical skill by imitation and practice." Programmers who long to write beautiful code should therefore read beautiful programs and imitate the techniques they learn as they write their own programs. I find that one of the most useful places to practice is on small code fragments, say of just one or two dozen lines. It was hard work but great fun preparing the second edition of <emphasis>Programming Pearls</emphasis>. I implemented every piece of code, and labored to pare each down to its essence. I hope that others enjoy reading the code as much as I enjoyed writing it.</para></listitem></varlistentry><varlistentry><term><emphasis>Software systems</emphasis></term><listitem><para>For specificity, I have described one tiny task in excruciating detail. I believe that the glory of these principles lies not in tiny code fragments, but rather in large programs and huge computer systems. Parnas ("Designing software for ease of extension and contraction," <emphasis>IEEE T. Software Engineering</emphasis>, Vol. 5, No. 2) offers techniques to whittle a system down to its essentials. For immediate applicability, don't forget the deep insight of Tom Duff: "Whenever possible, steal code."</para></listitem></varlistentry></variablelist></sect1><sect1 id="acknowledgments" label="3.6"><title>Acknowledgments</title><para>I am grateful for the insightful comments of Dan Bentley, Brian Kernighan, Andy Oram, and David Weiss.<indexterm id="I_indexterm3_tt32" class="endofrange" startref="idx-CHP-3-0097" significance="normal"><primary>Quicksort program</primary></indexterm></para></sect1></chapter><chapter id="finding_things" label="4" role=""><title>Finding Things</title><para><emphasis>Tim Bray</emphasis><indexterm id="idx-CHP-4-0147" significance="normal"><primary>Bray</primary></indexterm></para><para><emphasis>Computers can compute, but that's not what people use them for, mostly</emphasis>. Mostly, computers store and retrieve information. <emphasis>Retrieve</emphasis> implies <emphasis>find</emphasis>, and in the <indexterm id="idx-CHP-4-0148" significance="normal"><primary>searches</primary><secondary>time involved in running and programming</secondary></indexterm>time since the advent of the Web, search has become a dominant application for people using computers.</para><para>As data volumes continue to grow—both absolutely, and relative to the number of people or computers or anything, really—search becomes an increasingly large part of the life of the programmer as well. A few applications lack the need to locate the right morsel in some information store, but very few.</para><para>The subject of search is one of the largest in computer science, and thus I won't try to survey all of it or discuss the mechanics; in fact, I'll only consider one simple search technique in depth. Instead, I'll focus on the trade-offs that go into selecting search techniques, which can be subtle.</para><sect1 id="on_time" label="4.1"><title>On Time</title><para>You really can't talk about search without talking about time. There are two different flavors of time that apply to problems of search. The first is the time it takes the search to run, which is experienced by the user who may well be staring at a message saying something like "Loading…". The second is the time invested by the programmer who builds the search function, and by the programmer's management and customers waiting to use the program.</para></sect1><sect1 id="problem_weblog_data" label="4.2"><title>Problem: Weblog Data</title><para>Let's look at a sample problem to get a feel for how a search works in real life. I have a directory containing logfiles from my weblog (<indexterm id="idx-CHP-4-0149" significance="normal"><primary>Bray</primary></indexterm><ulink url="http://www.tbray.org/ongoing"/>) from early 2003 to late 2006; as of the writing of this chapter, they recorded 140,070,104 transactions and occupied 28,489,788,532 bytes (uncompressed). All these statistics, properly searched, can answer lots of questions about my traffic and readership.<indexterm id="idx-CHP-4-0150" significance="normal"><primary>searches</primary><secondary>weblog data</secondary></indexterm></para><para>Let's look at a simple question first: which articles have been read the most? It may not be instantly obvious that this problem is about search, but it is. First of all, you have to search through the logfiles to find the lines that record someone fetching an article. Second, you have to search through those lines to find the name of the article they fetched. Third, you have to keep track, for each article, of how often it was fetched.</para><para>Here is an example of one line from one of these files, which wraps to fit the page in this book, but is a single long line in the file:</para><programlisting id="I_programlisting4_tt33" format="linespecific">
	c80-216-32-218.cm-upc.chello.se - - [08/Oct/2006:06:37:48 -0700] "GET /ongoing/When/
	200x/2006/10/08/Grief-Lessons HTTP/1.1" 200 5945 "http://www.tbray.org/ongoing/"
	"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)
</programlisting><para>Reading from left to right, this tells us that:</para><simplelist type="vert"><member>Somebody from an organization named <literal moreinfo="none">chello</literal> in Sweden,</member><member>who provided neither a username nor a password,</member><member>contacted my weblog early in the morning of October 8, 2006 (my server's time zone is seven hours off Greenwich),</member><member>and requested a resource named <emphasis>/ongoing/When/200x/2006/10/08/Grief-Lessons</emphasis></member><member>using the HTTP 1.1 protocol;</member><member>the request was successful and returned 5,945 bytes;</member><member>the visitor had been referred from my blog's home page,</member><member>and was using Internet Explorer 6 running on Windows XP.</member></simplelist><para>This is an example of the kind of line I want: one that records the actual fetch of an article. There are lots of other lines that record fetching stylesheets, scripts, pictures, and so on, and attacks by malicious users. You can spot the kind of line I want by the fact that the article's name starts with <literal moreinfo="none">/ongoing/When/</literal> and continues with elements for the decade, year, month, and day.</para><para>Our first step, then, should be to find lines that contain something like:</para><programlisting id="I_programlisting4_tt34" format="linespecific">
	/ongoing/When/200x/2006/10/08/
</programlisting><para>Whatever language you're programming in, you could spend lots of time writing code to match this pattern character by character. Or you could apply regular expressions.</para><sect2 id="regular_expressions" label="4.2.1"><title>Regular Expressions</title><para><indexterm class="startofrange" id="idx-CHP-4-0151" significance="normal"><primary>searches</primary><secondary>regular expressions</secondary></indexterm>Regular expressions are special languages designed specifically for <indexterm id="idx-CHP-4-0152" significance="normal"><primary>* (asterisk)</primary><secondary>matching one or more instances in regular expressions</secondary></indexterm>matching patterns in text. If you learn how to use them well, you'll save yourself immense amounts of time and irritation. I've never met a really accomplished <indexterm class="startofrange" id="idx-CHP-4-0153" significance="normal"><primary>regular expressions</primary><secondary>program for printing article-fetch lines (example)</secondary></indexterm>programmer who wasn't a master of regular expressions (often called <emphasis>regexps</emphasis> for short). <xref linkend="a_regular_expression_matcher"/>, by Brian Kernighan, is dedicated to the beauty of regular expressions.<indexterm id="idx-CHP-4-0154" significance="normal"><primary>regular expressions</primary></indexterm></para><para>Because the filenames on my web site match such a strict, date-based pattern, a very straightforward regular expression can find the logfile lines I'm interested in. Other sites' logfiles might require a more elaborate one. Here it is:</para><programlisting id="I_programlisting4_tt35" format="linespecific">
	"GET /ongoing/When/<indexterm id="idx-CHP-4-0155" significance="normal"><primary>\d</primary></indexterm>\d\d\dx/\d\d\d\d/\d\d/\d\d/<indexterm id="idx-CHP-4-0156" significance="normal"><primary>[^ .]</primary></indexterm>[^ .]+ "
</programlisting><para>A glance at this line instantly reveals one of the problems with regular expressions; they're not the world's most readable text. Some people might challenge their appearance in a book called <emphasis>Beautiful Code</emphasis>. Let's put that issue aside for a moment and look at this particular expression. The only thing you need to know is that in this particular flavor of regular expression:</para><variablelist><varlistentry><term><literal moreinfo="none">\d</literal></term><listitem><para>Means "match any digit, 0 through 9"</para></listitem></varlistentry><varlistentry><term>[^ .]</term><listitem><para>Means "match any character that's not a space or period"<footnote id="CHP-4-FNOTE-1"><para>People who have used regular expressions know that a period is a placeholder for "any character," but it's harder to remember that when a period is enclosed in square brackets, it loses the special meaning and refers to just a period.</para></footnote></para></listitem></varlistentry><varlistentry><term>+</term><listitem><para>Means "match one or more instances of whatever came just before the +"</para></listitem></varlistentry></variablelist><para>That [^ .]+, then, means that the last slash has to be followed by a bunch of nonspace and nonperiod characters. There's a space <emphasis>after</emphasis> the + sign, so the regular expression stops when that space is found.</para><para>This regular expression won't match a line where the filename contains a period. So it will match <literal moreinfo="none">Grief-Lessons</literal>, the example I showed earlier from my logfile, but not <literal moreinfo="none">IMG0038.jpg</literal>.</para></sect2><sect2 id="putting_regular_expressions_to_work" label="4.2.2"><title>Putting Regular Expressions to Work</title><para>A regular expression standing by itself, as shown above, can be used on the command line to search files. But it turns out that most modern computer languages allow you to use them directly <indexterm id="idx-CHP-4-0157" significance="normal"><primary>searches</primary><secondary>regular expressions</secondary><tertiary>using in program that prints article-fetch lines</tertiary></indexterm>in program code. Let's do that, and write a program that prints out only the lines that match the expression, which is to say a program that records all the times someone fetched an article from the weblog.</para><para>This example (and most other examples in this chapter) is in the <indexterm class="startofrange" id="idx-CHP-4-0158" significance="normal"><primary>Ruby programming language</primary></indexterm>Ruby programming language because I believe it to be, while far from perfect, the most readable of languages.</para><para>If you don't know <indexterm id="idx-CHP-4-0159" significance="normal"><primary>searches</primary><secondary>regular expressions</secondary><tertiary>using in program that prints article-fetch lines</tertiary></indexterm><indexterm id="idx-CHP-4-0160" significance="normal"><primary>Ruby programming language</primary></indexterm>Ruby, learning it will probably make you a better <indexterm id="idx-CHP-4-0161" significance="normal"><primary>regular expressions</primary><secondary>program for printing article-fetch lines (example)</secondary></indexterm>programmer. In <xref linkend="treating_code_as_an_essay"/>, the creator of Ruby, Yukihiro Matsumoto (generally known as "Matz"), discusses some of the design choices that have attracted me and so many other programmers to the language.</para><para><xref linkend="printing_article-fetch_lines"/> shows our first Ruby program, with added line numbers on the left side. (All the examples in this chapter are available from the O'Reilly web site for this book.)</para><example id="printing_article-fetch_lines" label="4-1"><title>Printing article-fetch lines</title><programlisting format="linespecific">
1 ARGF.each_line do |line|
2   if line =~ %r{GET /ongoing/When/\d\d\dx/\d\d\d\d/\d\d/\d\d/[^ .]+ }
3   puts line
4   end 
5 end
</programlisting></example><para>Running this program prints out a bunch of logfile lines that look like the first example. Let's have a line-by-line look at it:</para><variablelist><varlistentry><term><emphasis>Line 1</emphasis></term><listitem><para>We want to read all the lines of the input, and we don't care whether they're from files named on the command line or are being piped in from another program on the standard input. The designers of Ruby believe strongly that programmers shouldn't have to write ugly code to deal with common situations, and this is a common situation. So, <literal moreinfo="none">ARGF</literal> is a special variable that represents all the input sources. If the command line includes arguments, ARGF assumes they're names of files and opens them one by one; if there aren't any, it uses the standard input.</para><para><literal moreinfo="none">each_line</literal> is a method that you can call on pretty well any file-like object, such as <literal moreinfo="none">ARGF</literal>. It reads the lines of input and passes them, one at a time, to a "block" of following code.</para><para>The following <literal moreinfo="none">do</literal> says that the block getting the input stretches from there to the corresponding <literal moreinfo="none">end</literal>, and the <literal moreinfo="none">|line|</literal> asks that the <literal moreinfo="none">each_line</literal> method load each line into the variable <literal moreinfo="none">line</literal> before giving it to the block.</para><para>This kind of loop may surprise the eyes of a new convert to Ruby, but it's concise, powerful, and very easy to follow after just a bit of practice.</para></listitem></varlistentry><varlistentry><term><emphasis>Line 2</emphasis></term><listitem><para>This is a pretty straightforward if statement. The only magic is the =~, which means "matches" and expects to be followed by <indexterm id="idx-CHP-4-0162" significance="normal"><primary>regular expressions</primary></indexterm>regular expression. You can tell Ruby that something is a regular expression by putting slashes before and after it—for example, <literal moreinfo="none">/this-is-a-regex/</literal>. But the particular regular expression we want to use is full of slashes. So to use the slash syntax, you'd have to "escape" them by turning each / into \/, which would be ugly. In this case, therefore, the %r trick produces more beautiful code.</para></listitem></varlistentry><varlistentry><term><emphasis>Line 3</emphasis></term><listitem><para>We're inside the <literal moreinfo="none">if</literal> block now. So, if the current <literal moreinfo="none">line</literal> matches the regexp, the program executes <literal moreinfo="none">puts line</literal>, which prints out the line and a line feed.</para></listitem></varlistentry><varlistentry><term><emphasis>Lines 4 and 5</emphasis></term><listitem><para>That's about all there is to it. The first <literal moreinfo="none">end</literal> terminates the <literal moreinfo="none">if</literal>, and the second terminates the <literal moreinfo="none">do</literal>. They look kind of silly dangling off the bottom of the code, and the designers of Python have figured out a way to leave them out, which leads to some Python code being more beautiful than the corresponding <indexterm id="idx-CHP-4-0163" significance="normal"><primary>Ruby programming language</primary></indexterm>Ruby.<indexterm id="idx-CHP-4-0164" significance="normal"><primary>searches</primary><secondary>regular expressions</secondary><tertiary>using in program that prints article-fetch lines</tertiary></indexterm></para></listitem></varlistentry></variablelist><para>So far, we've shown how <indexterm id="idx-CHP-4-0165" significance="normal"><primary>regular expressions</primary></indexterm>regular expressions can be used to find the lines in the logfile that we're interested in. But what we're <emphasis>really</emphasis> interested in is counting the fetches for each article. The first step is to identify the article names. <xref linkend="printing_article_names"/> is a slight variation on the previous <indexterm id="idx-CHP-4-0166" significance="normal"><primary>regular expressions</primary><secondary>program for printing article-fetch lines (example)</secondary></indexterm>program.</para><example id="printing_article_names" label="4-2"><title>Printing article names</title><programlisting format="linespecific">
1 ARGF.each_line do |line|
2   if line =~ %r{GET /ongoing/When/\d\d\dx/(\d\d\d\d/\d\d/\d\d/[^ .]+) } 
3     puts $1
4   end
5 end
</programlisting></example><para>The differences are subtle. In line 2, I've added a pair of parentheses (in boldface) around the interesting part of the article name in the regular expression. In line 3, instead of printing out the whole value of <literal moreinfo="none">line</literal>, I print out <literal moreinfo="none">$1</literal>, which in Ruby (and several other regular-expression-friendly languages) means "the first place in the regular expression marked with parentheses." You can mark lots of different pieces of the expression, and thus use <literal moreinfo="none">$2, $3</literal>, and so on.</para><para>The first few lines of output produced by running this program over some logfile data look like this:</para><programlisting id="I_programlisting4_tt36" format="linespecific">
	2003/10/10/FooCampMacs
	2006/11/13/Rough-Mix
	2003/05/22/StudentLookup
	2003/11/13/FlyToYokohama
	2003/07/31/PerlAngst
	2003/05/21/RDFNet
	2003/02/23/Democracy
	2005/12/30/Spolsky-Recursion
	2004/05/08/Torture
	2004/04/27/RSSticker
</programlisting><para>Before we go to work determining the popularity of different articles, I'd like to argue that in some important ways, this code is beautiful. Take a moment and think of the code you'd have to write to look at an arbitrary chunk of text and do the same matching and selection work done by the parenthesized regexp. It would be quite a few lines of code, and it would be easy to get wrong. Furthermore, if the format of the logfile changed, fixing the pattern matcher would be error-prone and irritating.</para><para>Under the covers, the way that <indexterm id="idx-CHP-4-0167" significance="normal"><primary>searches</primary><secondary>regular expressions</secondary></indexterm>regular expressions work is also among the more wonderful things in computer science. It turns out that they can conveniently be translated into <indexterm id="idx-CHP-4-0168" significance="normal"><primary>finite automata</primary></indexterm>finite <indexterm id="idx-CHP-4-0169" significance="normal"><primary>automata</primary></indexterm>automata. These automata are mathematically elegant, and there are astoundingly efficient algorithms for matching them against the text you're <indexterm id="idx-CHP-4-0170" significance="normal"><primary>values</primary><secondary>searching for</secondary></indexterm>searching. The great thing is that when you're running an automaton, you have to look only once at each character in the text you're trying to match. The effect is that a well-built regular expression engine can do pattern matching and selection faster than almost any custom code, even if it were written in hand-optimized assembly language. That's beautiful.</para><para>I think that the <indexterm id="idx-CHP-4-0171" significance="normal"><primary>Ruby programming language</primary></indexterm>Ruby code is pretty attractive, too. Nearly every character of the <indexterm id="idx-CHP-4-0172" significance="normal"><primary>regular expressions</primary><secondary>program for printing article-fetch lines (example)</secondary></indexterm>program is doing useful work. Note that there are no semicolons on the ends of the lines, nor parentheses around the conditional block, and that you can write <literal moreinfo="none">puts line</literal> instead of <literal moreinfo="none">puts(line)</literal>. Also, variables aren't declared—they're just used. This kind of <indexterm id="idx-CHP-4-0173" significance="normal"><primary>Ruby programming language</primary><secondary>stripped-down design</secondary></indexterm>stripped-down language design makes for programs that are shorter and easier to write, as well as (more important) easier to read and easier to understand.</para><para>Thinking in terms of time, <indexterm id="idx-CHP-4-0174" significance="normal"><primary>regular expressions</primary></indexterm>regular expressions are a win/win. It takes the programmer way less time to write them than the equivalent code, it takes less time to deliver the program to the people waiting for it, it uses the computer really efficiently, and the program's user spends less time sitting there bored.</para></sect2><sect2 id="content-addressable_storage" label="4.2.3"><title>Content-Addressable Storage</title><para>Now we're approaching the core of our problem, computing the popularity of articles. We'll have to pull the article name out of each line, look it up to see how many times it's been fetched, add one to that number, and then store it away again.<indexterm class="startofrange" id="idx-CHP-4-0175" significance="normal"><primary>searches</primary><secondary>content-addressable storage</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-4-0176" significance="normal"><primary>memory</primary><secondary>content-addressable</secondary></indexterm></para><para>This may be the most basic of search patterns: we start with a <emphasis>key</emphasis> (what we're <indexterm id="idx-CHP-4-0177" significance="normal"><primary>searches</primary><secondary>regular expressions</secondary><tertiary>using in program that prints article-fetch lines</tertiary></indexterm>using to search—in this case, an article name), and we're looking for a <emphasis>value</emphasis> (what we want to find—in this case, the number of times the article has been fetched). Here are some other examples:</para><informaltable><tgroup cols="2"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><thead><row><entry><para>Key</para></entry><entry><para>Value</para></entry></row></thead><tbody><row><entry><para>Word</para></entry><entry><para>List of web pages containing the word</para></entry></row><row><entry><para>Employee number</para></entry><entry><para>Employee's personnel record</para></entry></row><row><entry><para>Passport number</para></entry><entry><para>"true" or "false," indicating whether the person with that passport should be subject to extra scrutiny</para></entry></row></tbody></tgroup></informaltable><para>What programmers really want in this situation is a very old idea in computer science: <emphasis>content-addressable memory</emphasis>, also known as an <emphasis>associative store</emphasis> and various other permutations of those words. The idea is to put the key in and get the value out. There actually exists hardware which does just that; it mostly lives deep in the bowels of microprocessors, providing rapid access to page tables and memory caches.<indexterm class="startofrange" id="idx-CHP-4-0178" significance="normal"><primary>content-addressable memory</primary></indexterm><indexterm class="startofrange" id="idx-CHP-4-0179" significance="normal"><primary>associative stores</primary></indexterm><indexterm id="I_indexterm4_tt37" class="endofrange" startref="idx-CHP-4-0153" significance="normal"><primary>regular expressions</primary><secondary>program for printing article-fetch lines (example)</secondary></indexterm><indexterm id="I_indexterm4_tt38" class="endofrange" startref="idx-CHP-4-0151" significance="normal"><primary>searches</primary><secondary>regular expressions</secondary></indexterm></para><para>The good news is that you, the programmer, using any modern computer language, have access to excellent software implementations of associative memory. Different languages call these implementations different things. Often they are implemented as <indexterm id="idx-CHP-4-0180" significance="normal"><primary>hash tables</primary></indexterm>hash tables; in Java, Perl, and <indexterm id="idx-CHP-4-0181" significance="normal"><primary>Ruby programming language</primary></indexterm>Ruby, which use this technique, they are called <emphasis>Hashes, HashMaps</emphasis>, or something similar. In Python, they are called <emphasis>dictionaries</emphasis>, and in the computer algebra language Maple, simply <emphasis>tables</emphasis>.</para><para>Now if you're an eager search-algorithm fan just itching to write your own super-efficient search, this may sound like bad news, not good news. But think about those flavors of time; if you use the built-in associative store, the amount of programmer time and management invested in writing search algorithms goes to nearly zero.</para><para>By writing your own search, you <emphasis>might</emphasis> be able to save a little computer (and thus end-user) time, compared to the built-in version, but on the other hand, you might not; the people who write these things tend to be pretty clever. Andrew Kuchling has written <xref linkend="pythons_dictionary_implementation_being_all_things_to_all_peopl"/> of this book on one such effort.</para><para><indexterm id="idx-CHP-4-0182" significance="normal"><primary>associative stores</primary></indexterm>Associative stores are so important that <indexterm id="idx-CHP-4-0183" significance="normal"><primary>dynamically typed languages</primary></indexterm>dynamically typed languages such as <indexterm id="idx-CHP-4-0184" significance="normal"><primary>hashes</primary><secondary>Ruby</secondary></indexterm>Ruby and Python have not only built-in support, but special syntax for defining and <indexterm id="idx-CHP-4-0185" significance="normal"><primary>associative stores</primary><secondary>using in dynamically typed languages</secondary></indexterm>using them. Let's use Ruby's hashes to count article popularity in <xref linkend="counting_article_fetches"/>.</para><example id="counting_article_fetches" label="4-3"><title>Counting article fetches</title><programlisting format="linespecific">
1 counts = {}
2 counts.default = 0
3
4 ARGF.each_line do |line|
5   if line =~ %r{GET /ongoing/When/\d\d\dx/(\d\d\d\d/\d\d/\d\d/[^ .]+) }
6     counts[$1] += 1
7   end
8 end
</programlisting></example><para>This program isn't that much different from the version in <xref linkend="printing_article_names"/>. Line 1 creates an empty Hash called <literal moreinfo="none">counts</literal>. Line 2 gives the array a "default value" of zero; hold on for an explanation of that.<indexterm id="idx-CHP-4-0186" significance="normal"><primary>Ruby programming language</primary><secondary>counting article fetches</secondary></indexterm></para><para>Then, in line 6, instead of printing out the article name, the name serves as the key to look up the number of fetches of this article seen so far in <literal moreinfo="none">counts</literal>, add one to it, and store the value.</para><para>Now, consider what happens when the program sees some article name stored in <literal moreinfo="none">$1</literal> for the first time. I could write code along the lines of "if there is a <literal moreinfo="none">counts[$1]</literal>, then add one to it; otherwise, set <literal moreinfo="none">counts[$1]</literal> to one." The designers of Ruby hate that kind of awkwardness; this is why they provided the notion of a "default value" for a Hash. If you look up a key the Hash doesn't know about, it says "OK, zero," allowing you to write <literal moreinfo="none">counts[$1]+=1</literal> and have it always just work.</para><para>I originally stated the problem as "Which of my articles have been read the most?" That's kind of fuzzy; let's interpret it to mean "Print out the top 10 most popular articles." The resulting program is shown in <xref linkend="reporting_the_most_popular_articles"/>.</para><example id="reporting_the_most_popular_articles" label="4-4"><title>Reporting the most popular articles</title><programlisting format="linespecific">
1 counts = {}
2 counts.default = 0
3
4 ARGF.each_line do |line|
5   if line =~ %r{GET /ongoing/When/\d\d\dx/(\d\d\d\d/\d\d/\d\d/[^ .]+) }
6     counts[$1] += 1
7   end
8 end
9
10 keys_by_count = counts.keys.sort { |a, b| counts[b] &lt;=&gt; counts[a] }
11 keys_by_count[0 .. 9].each do |key|
12   puts "#{counts[key]}: #{key}"
13 end
</programlisting></example><para>Line 10 looks a little less beautiful to me than most <indexterm id="idx-CHP-4-0187" significance="normal"><primary>Ruby programming language</primary></indexterm>Ruby <indexterm id="idx-CHP-4-0188" significance="normal"><primary>{ } (curly braces)</primary><secondary>delimiting code blocks in Ruby</secondary></indexterm>code, but it's easy enough to understand. The <literal moreinfo="none">keys</literal> method of <literal moreinfo="none">counts</literal> returns an array containing all of the Hash's keys. Because of the hash implementation, the keys are stored in no predictable order, and are also returned by the <literal moreinfo="none">keys</literal> method in random order. So, I have to sort them and store them back in a new array.</para><para>In Ruby, <literal moreinfo="none">sort</literal> is accompanied by a code block, here enclosed in curly braces. (In Ruby, you can delimit a block either with <literal moreinfo="none">do</literal> and <literal moreinfo="none">end</literal> or with { and }.) The sort works its way back and forth through the array being sorted, passing pairs of elements to the block, which has to return a negative number, 0, or a positive number depending on whether the first element is less than, equal to, or greater than the second.</para><para>In this case, we want to get the data out of the hash in an order defined by the values (the counts themselves) rather than by the filenames (the keys), so we have to sort the keys by their values. Have a close look at the code, and you'll see how it works. Because this is something that people do all the time, I'm surprised that Ruby's Hash doesn't come with <literal moreinfo="none">sort_by_value</literal>.</para><para>We use a decreasing order for the sort so that, no matter how many articles we've found, we know the first 10 items in <literal moreinfo="none">keys_by_count</literal> represent the top 10 articles in popularity.</para><para>Now that we have an array of keys (article names) sorted in descending order of how many times they've been fetched, we can accomplish our assignment by printing out the first 10. Line 11 is simple, but a word is in order about that <literal moreinfo="none">each</literal> method. In Ruby, you almost never see a <literal moreinfo="none">for</literal> statement because anything whose elements you might want to loop through has an <literal moreinfo="none">each</literal> method that does it for you.</para><para>Line 12 may be a little hard to read for the non-Rubyist because of the #{} syntax, but it's pretty straightforward.</para><para>So, let's declare victory on our first assignment. It took us only 13 lines of easy-to-read code. A seasoned Rubyist would have squeezed the last three lines into one.</para><para>Let's run this thing and see what it reports. Instead of running it over the whole 28 GB, let's just use it on a week's data: a mere 1.2 million records comprising 245 MB.</para><programlisting id="I_programlisting4_tt39" format="linespecific">
	~/dev/bc/ 548&gt; <userinput moreinfo="none">zcat ~/ongoing/logs/2006-12-17.log.gz | \
                                   time <indexterm id="idx-CHP-4-0189" significance="normal"><primary>Ruby programming language</primary></indexterm>ruby code/report-counts.rb</userinput>
     4765: 2006/12/11/Mac-Crash
     3138: 2006/01/31/Data-Protection
     1865: 2006/12/10/EMail
     1650: 2006/03/30/Teacup
     1645: 2006/12/11/Java
     1100: 2006/07/28/Open-Data
     900: 2006/11/27/Choose-Relax
     705: 2003/09/18/NXML
     692: 2006/07/03/July-1-Fireworks
     673: 2006/12/13/Blog-PR
            13.54 real         7.49 user                      <indexterm id="idx-CHP-4-0190" significance="normal"><primary>Ruby programming language</primary><secondary>optimizing program that reports most popular articles</secondary></indexterm>0.73 sys
</programlisting><para>This run took place on my 1.67 GHz Apple PowerBook. The results are unsurprising, but the program does seem kind of slow. Should we worry about performance?</para></sect2><sect2 id="time_to_optimize" label="4.2.4"><title>Time to Optimize?</title><para>I was wondering whether my sample run was really unreasonably slow, so I pulled together a very similar program in Perl, a language that is less beautiful than Ruby but is <emphasis>extremely</emphasis> fast. Sure enough, the Perl version took half the time. So, should we try to optimize?</para><para>We need to think about time again. Yes, we might be able to make this run faster, and thus reduce the program execution time and the time a user spends waiting for it, but to do this we'd have to burn some of the programmer's time, and thus the time the user waits for the programmer to get the program written. In most cases, my instinct would be that 13.54 seconds to process a week's data is OK, so I'd declare victory. But let's suppose we're starting to get gripes from people who use the program, and we'd like to make it run faster.</para><para>Glancing over <xref linkend="reporting_the_most_popular_articles"/>, we can see that the program falls into two distinct parts. First, it reads all the lines and tabulates the fetches; then it sorts them to find the top 10.</para><para>There's an obvious optimization opportunity here: why bother sorting all the fetch tallies when all we really want to do is pick the top 10? It's easy enough to write a little code to run through the array once and pick the 10 highest elements.</para><para>Would that help? I found out by instrumenting the program to find out how much time it spent doing its two tasks. The answer was (averaging over a few runs) 7.36 seconds in the first part and 0.07 in the second. Which is to say, "No, it wouldn't help."</para><para>Might it be worthwhile to try to optimize the first part? Probably not; all it does is match regular expressions, and store and retrieve data using a Hash, and these are among the most heavily optimized parts of Ruby.</para><para>So, getting fancy in replacing that sort would probably waste the time of the programmer and the customer waiting for the code, without saving any noticeable amount of computer or waiting-user time. Also, experience would teach that you're not apt to go much faster than Perl does for this kind of task, so the amount of speedup you're going to get is pretty well bounded.<indexterm id="I_indexterm4_tt40" class="endofrange" startref="idx-CHP-4-0179" significance="normal"><primary>associative stores</primary></indexterm><indexterm id="I_indexterm4_tt41" class="endofrange" startref="idx-CHP-4-0178" significance="normal"><primary>content-addressable memory</primary></indexterm><indexterm id="I_indexterm4_tt42" class="endofrange" startref="idx-CHP-4-0158" significance="normal"><primary>Ruby programming language</primary></indexterm><indexterm id="I_indexterm4_tt43" class="endofrange" startref="idx-CHP-4-0176" significance="normal"><primary>memory</primary><secondary>content-addressable</secondary></indexterm><indexterm id="I_indexterm4_tt44" class="endofrange" startref="idx-CHP-4-0175" significance="normal"><primary>searches</primary><secondary>content-addressable storage</secondary></indexterm></para><para>We've just finished <indexterm id="idx-CHP-4-0191" significance="normal"><primary>searches</primary><secondary>writing search algorithm</secondary></indexterm>writing <indexterm id="idx-CHP-4-0192" significance="normal"><primary>hash tables</primary><secondary>loading a big hash</secondary></indexterm>a program that does something useful and turns out to be all about search. But we haven't come anywhere near actually writing any search algorithms. So, let's do that.</para><sidebar id="some_history_of_tallying" role="missingmanual"><title>SOME HISTORY OF TALLYING</title><para>In the spirit of credit where credit is due, the notion of getting real work done by scanning lines of textual input using regular expressions and using a content-addressable store to build up results was first popularized in the <emphasis>awk</emphasis> programming language, whose name reflects the surnames of its inventors Aho, Weinberger, and Kernighan.<indexterm id="idx-CHP-4-0193" significance="normal"><primary>awk programming language</primary></indexterm><indexterm id="idx-CHP-4-0194" significance="normal"><primary>tallying</primary></indexterm></para><para>This work, of course, was based on the then-radical Unix philosophy—due mostly to Ritchie and Thompson—that data should generally be stored in files in lines of text, and to some extent validated the philosophy.</para><para>Larry Wall took the ideas behind <emphasis>awk</emphasis> and, as the author of <indexterm id="idx-CHP-4-0195" significance="normal"><primary>Perl</primary></indexterm>Perl, turned them into a high-performance, industrial-strength, general-purpose tool that doesn't get the credit it deserves. It served as the glue that has held together the world's Unix systems, and subsequently large parts of the first-generation Web.</para></sidebar></sect2></sect1><sect1 id="problem_who_fetched_what_when" label="4.3"><title>Problem: Who Fetched What, When?</title><para>Running a couple of quick scripts over the logfile data reveals that there are 12,600,064 instances of an article fetch coming from 2,345,571 different hosts. Suppose we are interested in who was fetching what, and when? An auditor, a police officer, or a marketing professional might be interested.</para><para>So, here's the problem: given a hostname, report what articles were fetched from that host, and when. The result is a list; if the list is empty, no articles were fetched.</para><para>We've already seen that a language's built-in hash or equivalent data structure gives the programmer a quick and easy way to store and look up key/value pairs. So, you might ask, why not use it?</para><para>That's an excellent question, and we should give the idea a try. There are reasons to worry that it might not work very well, so in the back of our minds, we should be thinking of a Plan B. As you may recall if you've ever studied hash tables, in order to go fast, they need to have a small load factor; in other words, they need to be mostly empty. However, a hash table that holds 2.35 million entries and is still mostly empty is going to require the use of a whole lot of memory.</para><para>To simplify things, I wrote a program that ran over all the logfiles and pulled out all the article fetches into a simple file; each line has the hostname, the time of the transaction, and the article name. Here are the first few lines:</para><programlisting id="I_programlisting4_tt45" format="linespecific">
	crawl-66-249-72-77.googlebot.com 1166406026 2003/04/08/Riffs
	egspd42470.ask.com 1166406027 2006/05/03/MARS-T-Shirt
	84.7.249.205 1166406040 2003/03/27/Scanner
</programlisting><para>(The second field, the 10-digit number, is the standard Unix/Linux representation of time as the number of seconds since the beginning of 1970.)</para><para>Then I wrote a simple program to read this file and load a great big hash. <xref linkend="loading_a_big_hash"/> shows the program.</para><example id="loading_a_big_hash" label="4-5"><title>Loading a big hash</title><programlisting format="linespecific">
1 class BigHash
2
3   def initialize(file)
4     @hash = {} 
5     lines = 0   
6     File.open(file).each_line do |line| 
7       s = line.split 
8       article = s[2].intern
9       if @hash[s[0]]
10        @hash[s[0]] &lt;&lt; [ s[1], article ]  
11      else
12        @hash[s[0]] = [ s[1], article ] 
13      end
14      lines += 1
15      STDERR.puts "Line: #{lines}" if (lines % 100000) == 0
16    end
17  end
18
19  def find(key)
20    @hash[key]
21  end
22
23 end
</programlisting></example><para>The program should be fairly self-explanatory, but line 15 is worth a note. When you're running a big program that's going to take a lot of time, it's very disturbing when it works away silently, maybe for hours. What if something's wrong? What if it's going incredibly slow and will never finish? So, line 15 prints out a <indexterm id="idx-CHP-4-0196" significance="normal"><primary>progress report for large programs</primary></indexterm>progress report after every 100,000 lines of input, which is reassuring.</para><para>Running this program was interesting. It took about 55 minutes of CPU time to load up the hash, and the program grew to occupy 1.56 GB of memory. A little calculation suggests that it costs around 680 bytes to store the information for each host, or slicing the data another way, about 126 bytes per fetch. This is a little scary, but probably reasonable for a hash table.</para><para>Retrieval performance was excellent. I ran 2,000 queries, half of which were randomly selected hosts from the log and thus succeeded, while the other half were those same hostnames reversed, none of which succeeded. The 2,000 queries completed in an average of about .02 seconds, so <indexterm id="idx-CHP-4-0197" significance="normal"><primary>Ruby implementation</primary></indexterm>Ruby's hash implementation can look up records in a hash containing 12 million or so records thousands of times per second.</para><para>Those 55 minutes to load up the data are troubling, but there are some tricks to address that. You could, for example, load it up once, then serialize the hash out and read it back in. And I didn't try particularly hard to optimize the program.</para><para>The program was easy and quick to write, and it runs fast once it's initialized, so its performance is good both in terms of waiting-for-the-program time and waiting-for-the-programmer time. Still, I'm unsatisfied. I have the feeling that there ought to be a way to get this kind of performance while burning less memory, less startup time, or both. It involves writing our own search code, though.</para><sect2 id="binary_search" label="4.3.1"><title>Binary Search</title><para>Nobody gets a Computer Science degree without studying a wide variety of <indexterm id="idx-CHP-4-0198" significance="normal"><primary>algorithms</primary><secondary>search algorithms</secondary></indexterm>search algorithms: trees, heaps, hashes, lists, and more. My favorite among all these is <indexterm id="idx-CHP-4-0199" significance="normal"><primary>Java</primary><secondary>binary search implementation</secondary></indexterm>binary search. Let's try it on the who-fetched-what-when problem and then look at what makes it beautiful.<indexterm id="idx-CHP-4-0200" significance="normal"><primary>binary search</primary></indexterm></para><para>My first attempt at putting <indexterm id="idx-CHP-4-0201" significance="normal"><primary>Java</primary><secondary>binary search program (example)</secondary></indexterm>binary search to use was quite disappointing; while the data took 10 minutes less to load, it required almost 100 MB more memory than with the hash. Clearly, there are some surprising things about the Ruby <indexterm id="idx-CHP-4-0202" significance="normal"><primary>Ruby programming language</primary><secondary>array implementation</secondary></indexterm>array implementation. The search also ran several times slower (but still in the range of thousands per second), but this is not surprising at all because the algorithm is running in Ruby code rather than with the underlying hardcoded hash implementation.</para><para>The problem is that in Ruby everything is an object, and <indexterm id="idx-CHP-4-0203" significance="normal"><primary>Java</primary><secondary>arrays</secondary></indexterm>arrays are fairly abstracted things with lots of built-in magic. So, let's reimplement the program in Java, in which integers are just integers, and arrays come with very few extras.<footnote id="CHP-4-FNOTE-2"><para>This discussion of <indexterm id="idx-CHP-4-0204" significance="normal"><primary>searches</primary><secondary>binary search</secondary></indexterm>binary search borrows heavily from my 2003 piece, "<indexterm id="idx-CHP-4-0205" significance="normal"><primary>binary search</primary><secondary>On the Goodness of Binary Search</secondary></indexterm>On the Goodness of Binary Search," available online at <indexterm id="idx-CHP-4-0206" significance="normal"><primary>Bray</primary></indexterm><ulink url="http://www.tbray.org/ongoing/When/200x/2003/03/22/Binary"/>.</para></footnote></para><para>Nothing could be simpler, conceptually, than binary search. You divide your search space in two and see whether you should be looking in the top or bottom half; then you repeat the exercise until done. Instructively, there are a great many ways to code this algorithm incorrectly, and several widely published versions contain bugs. The implementation mentioned in "On the Goodness of Binary Search," and shown in Java in <xref linkend="binary_search"/>, is based on one I learned from Gaston Gonnet, the lead developer of the Maple language for symbolic mathematics and currently Professor of Computer Science at ETH in Zürich.</para><example id="binary_search-id001" label="4-6"><title>Binary search</title><programlisting format="linespecific">
1 package binary;
2
3  public class Finder {
4    public static int find(String[] keys, String target) {
5      int high = keys.length;
6      int low = -1;
7      while (high - low &gt; 1) {
8        int probe = (low + high) &gt;&gt;&gt; 1;
9        if (keys[probe].compareTo(target) &gt; 0)
10         high = probe;
11       else
12         low = probe;
13     }
14     if (low == -1 || keys[low].compareTo(target) != 0)
15       return -1;
16     else
17       return low;
18   }
19 }
</programlisting></example><para>Key aspects of this program are as follows:</para><itemizedlist><listitem><para>In lines 5–6, note that the <literal moreinfo="none">high</literal> and <literal moreinfo="none">low</literal> bounds are set one off the ends of the array, so neither are initially valid indices. This eliminates all sorts of corner cases.</para></listitem><listitem><para>The loop that starts in line 7 runs until the high and low bounds are adjacent; there is no testing to see whether the target has been found. Think for a minute whether you agree with this choice; we'll return to the question later.</para></listitem><listitem><para>The loop has two invariants. <literal moreinfo="none">low</literal> is either –1 or points to something less than or equal to the target value. <literal moreinfo="none">high</literal> is either one off the top of the array or points to something strictly greater than the target value.</para></listitem><listitem><para>Line 8 is particularly interesting. In an earlier version it read:</para><programlisting id="I_programlisting4_tt46" format="linespecific">
probe = (high + low) / 2;
</programlisting><para>but in June 2006, Java guru Josh Bloch showed how, in certain obscure circumstances, that code could lead to integer overflow (see <ulink url="http://googleresearch.blogspot.com/2006/06/extra-extra-read-all-about-it-nearly.html"/>). It is sobering indeed that, many decades into the lifetime of computer science, we are still finding bugs in our core algorithms. (The issue is also discussed by Alberto Savoia in <xref linkend="beautiful_tests"/>.)</para><para>At this point, Rubyists will point out that modern dynamic languages such as Ruby and Python take care of integer overflow for you, and thus don't have this bug.</para></listitem><listitem><para>Because of the loop invariant, once I'm done with the loop, I just need to check <literal moreinfo="none">low</literal> (lines 14–17). If it's not –1, either it points to something that matches the target, or the target isn't there.</para></listitem></itemizedlist><para>The Java version took only six and a half minutes to load, and it ran successfully, using less than 1 GB of heap. Also, while it's harder to measure CPU time in Java than in Ruby, there was no perceptible delay in running the same 2,000 <indexterm id="idx-CHP-4-0207" significance="normal"><primary>searches</primary></indexterm>searches.</para></sect2><sect2 id="binary_search_trade-offs" label="4.3.2"><title>Binary Search Trade-offs</title><para>Binary search has some very large <indexterm id="idx-CHP-4-0208" significance="normal"><primary>binary search</primary><secondary>advantages and disadvantages</secondary></indexterm>advantages. First of all, its performance is <replaceable>O</replaceable>(<literal moreinfo="none">log<subscript>2</subscript></literal> <replaceable>N</replaceable>). People often don't really grasp how powerful this is. On a 32-bit computer, the biggest log2 you'll ever encounter is 32 (similarly, 64 on a 64-bit computer), and any algorithm that competes in an upper bound of a few dozen steps will be "good enough" for many real-world scenarios.<indexterm id="idx-CHP-4-0209" significance="normal"><primary>hash tables</primary><secondary>binary search vs.</secondary></indexterm></para><para>Second, the binary-search code is short and simple. Code that is short and simple is beautiful, for a bunch of reasons. Maybe the most important is that it's easier to understand, and understanding code is harder than writing it. There are fewer places for bugs to hide. Also, compact code plays better with instruction sets, I-caches, and JIT compilers, and thus tends to run faster.</para><para>Third, once you've got that sorted array, you don't need any more index structures; binary search is very space-efficient.</para><para>The big downside to binary search is that the data has to be kept in order in memory. There are some data sets for which this is impossible, but fewer than you might think. If you think you have too much data to fit in memory, check the price of RAM these days and make sure. Any search strategy that requires going to disk is going to be immensely more complex, and in many scenarios slower.</para><para>Suppose you need to update the data set; you might think that would rule out binary search because you have to update a huge, contiguous array in memory. But that turns out to be easier than you might think. In fact, your program's memory is scattered randomly all over the computer's physical RAM, with the operating system's paging software making it look sequential; you can do the same kind of trick with your own data.</para><para>Some might argue that since a hash table is <replaceable>O</replaceable>(<literal moreinfo="none">1</literal>), that has to be better than binary search's <replaceable>O</replaceable>(<literal moreinfo="none">log<subscript>2</subscript></literal> <replaceable>N</replaceable>). In practice, the difference may not be that significant; set up an experiment sometime and do some measurements. Also, consider that hash tables, with the necessary collision-resolution code, are considerably more complex to implement.</para><para>I don't want to be dogmatic, but in recent years, I've started to take the following approach to search problems:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Try to solve it using your language's built-in hash tables.</para></listitem><listitem><para>Then try to solve it with binary search.</para></listitem><listitem><para>Only then should you reluctantly start to consider other more complex options.</para></listitem></orderedlist></sect2><sect2 id="escaping_the_loop" label="4.3.3"><title>Escaping the Loop</title><para>Some look at my binary-search algorithm and ask why the loop always runs to the end without checking whether it's found the target. In fact, this is the correct behavior; the math is beyond the scope of this chapter, but with a little work, you should be able to get an intuitive feeling for it—and this is the kind of intuition I've observed in some of the great programmers I've worked with.<indexterm id="idx-CHP-4-0210" significance="normal"><primary>binary search</primary><secondary>escaping the loop</secondary></indexterm></para><para>Let's think about the progress of the loop. Suppose you have <emphasis>n</emphasis> elements in the array, where <emphasis>n</emphasis> is some really large number. The chance of finding the target the first time through is 1/<emphasis>n</emphasis>, a really small number. The next iteration (after you divide the search set in half) is 1/(<emphasis>n</emphasis>/2)—still small—and so on. In fact, the chance of hitting the target becomes significant only when you're down to 10 or 20 elements, which is to say maybe the last four times through the loop. And in the case where the search fails (which is common in many applications), those extra tests are pure overhead.</para><para>You could do the math to figure out when the probability of hitting the target approaches 50 percent, but qualitatively, ask yourself: does it make sense to add extra complexity to each step of an <replaceable>O</replaceable>(<literal moreinfo="none">log<subscript>2</subscript></literal> <replaceable>N</replaceable>) algorithm when the chances are it will save only a small number of steps at the end?</para><para>The take-away lesson is that binary search, done properly, is a two-step process. First, write an efficient loop that positions your <literal moreinfo="none">low</literal> and <literal moreinfo="none">high</literal> bounds properly, then add a simple check to see whether you hit or missed.</para></sect2></sect1><sect1 id="search_in_the_large" label="4.4"><title>Search in the Large</title><para>When most people think of search they think of <indexterm id="idx-CHP-4-0211" significance="normal"><primary>web searches</primary></indexterm>web search, as offered by Yahoo!, Google, and their competitors. While ubiquitous web search is a new thing, the <indexterm id="idx-CHP-4-0212" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>discipline of <indexterm id="idx-CHP-4-0213" significance="normal"><primary>full-text searches</primary></indexterm>full-text search upon which it is based is not. Most of the seminal papers were written by Gerald Salton at Cornell as far back as the early 1960s. The basic techniques for indexing and searching large volumes of text have not changed dramatically since then. What <emphasis>has</emphasis> changed is how result ranking is done.<footnote id="CHP-4-FNOTE-3"><para>This discussion of full-text search borrows heavily from my 2003 series, <emphasis>On Search</emphasis>, available online at <indexterm id="idx-CHP-4-0214" significance="normal"><primary>Bray</primary></indexterm><ulink url="http://www.tbray.org/ongoing/When/200x/2003/07/30/OnSearchTOC"/>. The series covers the topic of search quite broadly, including issues of user experience, quality control, natural language processing, intelligence, internationalization, and so on.</para></footnote></para><sect2 id="searching_with_postings" label="4.4.1"><title>Searching with Postings</title><para>The standard approach to full-text search is based on the notion of a <emphasis>posting</emphasis>, which is a small, fixed-size record. To build an index, you read all the documents and, for each word, create a posting that says word <emphasis>x</emphasis> appears in document <emphasis>y</emphasis> at position <emphasis>z</emphasis>. Then you sort all the words together, so that for each unique word you have a list of <indexterm id="idx-CHP-4-0215" significance="normal"><primary>searches</primary><secondary>postings</secondary></indexterm>postings, each a pair of numbers consisting of a document ID and the text's offset in that document.<indexterm id="idx-CHP-4-0216" significance="normal"><primary>binary search</primary><secondary>postings</secondary></indexterm><indexterm id="idx-CHP-4-0217" significance="normal"><primary>postings</primary></indexterm></para><para>Because postings are small and fixed in size, and because you tend to have a huge number of them, a natural approach is to use binary search. I have no idea of the details of how Google or Yahoo! do things, but I'd be really unsurprised to hear that those tens of thousands of computers spend a whole lot of their time binary-searching big arrays of postings.</para><para>People who are knowledgeable about search shared a collective snicker a few years ago when the number of documents Google advertised as searching, after having been stuck at two billion and change for some years, suddenly became much larger and then kept growing. Presumably they had switched the document ID in all those postings from 32-bit to 64-bit numbers.</para></sect2><sect2 id="ranking_results" label="4.4.2"><title>Ranking Results</title><para>Given a word, searching a list of postings to figure out which documents contain it is not rocket science. A little thought shows that combining the lists to do AND and OR queries and phrase search is also simple, conceptually at least. What's hard is sorting the result list so that the good results show up near the top. Computer science has a <indexterm id="idx-CHP-4-0218" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>subdiscipline called Information Retrieval (IR for short) that focuses almost entirely on this problem. Historically, the results had been very poor, up until recently.<indexterm id="idx-CHP-4-0219" significance="normal"><primary>searches</primary><secondary>ranking results</secondary></indexterm><indexterm id="idx-CHP-4-0220" significance="normal"><primary>ranking search results</primary></indexterm></para></sect2><sect2 id="searching_the_web" label="4.4.3"><title>Searching the Web</title><para>Google and its competitors have been able to produce good results in the face of unimaginably huge data sets and populations of users. When I say "good," I mean that <indexterm id="idx-CHP-4-0221" significance="normal"><primary>Google</primary><secondary>high-quality search results</secondary></indexterm>high-quality results appear near the top of the result list, and that the result list appears quickly.<indexterm id="idx-CHP-4-0222" significance="normal"><primary>web searches</primary></indexterm></para><para>The promotion of high-quality results is a result of many factors, the most notable of which is what Google calls <emphasis>PageRank</emphasis>, based largely on <indexterm id="idx-CHP-4-0223" significance="normal"><primary>link counting (PageRank)</primary></indexterm>link counting: pages with lots of hyperlinks pointing at them are deemed to be more popular and thus, by popular vote, winners.<indexterm id="idx-CHP-4-0224" significance="normal"><primary>PageRank</primary></indexterm></para><para>In practice, this seems to work well. A couple of interesting observations follow. First, until the rise of PageRank, the leaders in the search-engine space were offerings such as Yahoo! and DMoz, which worked by categorizing results; so, the evidence seems to suggest that it's more useful to know how popular something is than to know what it's about.</para><para>Second, PageRank is applicable only to document collections that are richly populated with links back and forth between the documents. At the moment, two document collections qualify: the World Wide Web and the corpus of peer-reviewed academic publications (which have applied PageRank-like methods for decades).</para><para>The ability of large search engines to scale up with the size of data and number of users has been impressive. It is based on the massive <indexterm id="idx-CHP-4-0225" significance="normal"><primary>parallelism</primary><secondary>application in web searches</secondary></indexterm>application of parallelism: attacking big problems with large numbers of small computers, rather than a few big ones. One of the nice things about postings is that each posting is independent of all the others, so they naturally lend themselves to parallel approaches.</para><para>For example, <indexterm id="idx-CHP-4-0226" significance="normal"><primary>partitioning an index based on binary search in arrays of postings</primary></indexterm>an index based on doing binary search in arrays of postings is fairly straight-forward to partition. In an index containing only English words, you could easily create 26 partitions (the term used in the industry is <emphasis>shards</emphasis>), one for words beginning with each letter. Then you can make as many copies as you need of each shard. Then, a huge volume of word-search queries can be farmed out across an arbitrarily large collection of cooperating search nodes.<indexterm id="idx-CHP-4-0227" significance="normal"><primary>shards</primary></indexterm></para><para>This leaves the problem of combining search results for multiword or phrase searches, and this requires some real innovation, but it's easy to see how the basic word-search function could be parallelized.</para><para>This discussion is a little unfair in that it glosses over a huge number of important issues, notably including fighting the Internet miscreants who continually try to outsmart search-engine algorithms for commercial gain.</para></sect2></sect1><sect1 id="conclusion-id002" label="4.5"><title>Conclusion</title><para>It is hard to imagine any computer application that does not involve storing data and finding it based on its content. The world's single most popular computer application, web search, is a notable example.</para><para>This chapter has considered some of the issues, notably bypassing the traditional "database" domain and the world of search strategies that involve external storage. Whether operating at the level of a single line of text or billions of web documents, search is central. From the programmer's point of view, it also needs to be said that implementing searches of one kind or another is, among other things, fun.</para></sect1></chapter><chapter id="correct_beautiful_fast_in_that_order_lessons_from_designing_xml" label="5" role=""><title>Correct, Beautiful, Fast (in That Order): Lessons from Designing XML Verifiers</title><para><emphasis>Elliotte Rusty Harold</emphasis><indexterm class="startofrange" id="idx-CHP-5-0228" significance="normal"><primary>XML verifiers</primary></indexterm><indexterm id="idx-CHP-5-0229" significance="normal"><primary>Harold</primary></indexterm></para><para><emphasis>This is the story of two routines that perform input verification for XML</emphasis>, the first in JDOM, and the second in XOM. I was intimately involved in the development of both, and while the two code bases are completely separate and share no common code, the ideas from the first clearly trickled into the second. The code, in my opinion, gradually became more beautiful. It certainly became faster.<indexterm id="idx-CHP-5-0230" significance="normal"><primary>validation</primary><secondary>XML</secondary></indexterm></para><para>Speed was the driving factor in each successive refinement, but in this case the improvements in speed were accompanied by improvements in beauty as well. I hope to dispel the myth that fast code must be illegible, ugly code. On the contrary, I believe that more often than not, improvements in beauty <emphasis>lead to</emphasis> improvements in execution speed, especially taking into account the impact of modern optimizing compilers, just-in-time compilers, RISC (reduced instruction set computer) architectures, and multi-core CPUs.</para><sect1 id="the_role_of_xml_validation" label="5.1"><title>The Role of XML Validation</title><para>XML achieves interoperability by rigorously enforcing certain rules about what may and may not appear in an XML document. With a few very small exceptions, a conforming processor can process any well-formed XML document and can identify (and not attempt to process) malformed documents. This ensures a high degree of interoperability between platforms, parsers, and programming languages. You don't have to worry that your parser won't read my document because yours was written in C and runs on Unix, while mine was written in Java and runs on Windows.<indexterm id="idx-CHP-5-0231" significance="normal"><primary>XML verifiers</primary><secondary>role of validation</secondary></indexterm></para><para>Fully maintaining <indexterm id="idx-CHP-5-0232" significance="normal"><primary>XML verifiers</primary></indexterm>XML correctness normally involves two redundant checks on the data:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para><indexterm id="idx-CHP-5-0233" significance="normal"><primary>names</primary><secondary>validation in XML</secondary></indexterm>Validation occurs on input. As a parser reads an XML document, it checks the document for <indexterm id="idx-CHP-5-0234" significance="normal"><primary>well-formedness (XML)</primary></indexterm>well-formedness and, optionally, <indexterm id="idx-CHP-5-0235" significance="normal"><primary>validity (XML)</primary></indexterm>validity. <emphasis>Well-formedness</emphasis> checks purely syntactic constraints, such as whether every start tag has a matching end tag. This is required of all XML parsers. <emphasis>Validity</emphasis> means that only elements and attributes specifically listed in a Document Type Definition (DTD) appear, and only in the proper positions.</para></listitem><listitem><para>Verification happens on output. When generating an XML document through an XML API such as DOM, <indexterm id="idx-CHP-5-0236" significance="normal"><primary>JDOM</primary></indexterm>JDOM, or XOM, the parser checks all strings passing through the API to make sure they're legal in XML.</para></listitem></orderedlist><para>While input validation is more thoroughly defined by the XML specification, output verification can be equally important. In particular, it is critical for debugging and making sure that the code is correct.</para></sect1><sect1 id="the_problem" label="5.2"><title>The Problem</title><para>The very first beta releases of JDOM did not verify the strings used to create element names, text content, or pretty much anything else. Programs were free to generate element names that contained whitespace, comments that ended in hyphens, text nodes that contained nulls, and other malformed content. Maintaining the correctness of the generated XML was completely left up to the client programmer.</para><para>This bothered me. While XML is simpler than some alternatives, it is not simple enough that it can be fully understood without immersing yourself in specification arcana, such as exactly which <indexterm id="idx-CHP-5-0237" significance="normal"><primary>Unicode code points in XML</primary></indexterm>Unicode code points are or are not legal in XML names and text content.</para><para>JDOM aimed to be an API that brought XML to the masses. JDOM aimed to be an API that, unlike DOM, did not require a two-week course and an expensive expert mentor to learn to use properly. To enable this, JDOM needed to lift as much of the burden of understanding XML from the programmer as possible. Properly implemented, JDOM would keep the programmer from making mistakes.</para><para>There are numerous ways JDOM could do this. Some of them fell out as a direct result of its data model. For instance, in JDOM it is not possible to overlap elements (<literal moreinfo="none">&lt;p&gt;Sally said, &lt;quote&gt;let's go the park.&lt;/p&gt;. Then let's play ball.&lt;/quote&gt;</literal>). Because JDOM's internal representation is a tree, there's simply no way to generate this markup from JDOM. However, a number of other constraints need to be checked explicitly, such as whether:</para><itemizedlist><listitem><para>The name of an element, attribute, or processing instruction is a legal XML name</para></listitem><listitem><para>Local names do not contain colons</para></listitem><listitem><para>Attribute namespaces do not conflict with the namespaces of their parent element or sibling attributes</para></listitem><listitem><para>Every Unicode surrogate character appears as part of a surrogate pair consisting of one high surrogate followed by one low surrogate</para></listitem><listitem><para>Processing instruction data does not contain the two-character string ?&gt;</para></listitem></itemizedlist><para>Whenever the client supplies a string for use in one of these areas, it should be checked to see that it meets the relevant constraints. The details vary, but the basic approach is the same.</para><para>For purposes of this chapter, I'm going to examine the rules for checking <indexterm id="idx-CHP-5-0238" significance="normal"><primary>XML verifiers</primary></indexterm>XML 1.0 <indexterm id="idx-CHP-5-0239" significance="normal"><primary>element names (XML 1.0)</primary></indexterm>element names.</para><para>In the XML 1.0 specification (part of which is given in <indexterm id="idx-CHP-5-0240" significance="normal"><primary>BNF (Backus-Naur Form) grammar</primary></indexterm><xref linkend="bnf_grammar_for_checking_xml_names_abridged"/>), rules are given in a <indexterm id="idx-CHP-5-0241" significance="normal"><primary>Backus-Naur Form (BNF) grammar</primary></indexterm>Backus-Naur Form (BNF) grammar. Here <replaceable>#xdddd</replaceable> represents the Unicode code point with the hexadecimal value <replaceable>dddd</replaceable>. [<replaceable>#xdddd-#xeeee</replaceable>] represents all Unicode code points from <replaceable>#xdddd</replaceable> to <replaceable>#xeeee</replaceable>.</para><example id="bnf_grammar_for_checking_xml_names_abridged" label="5-1"><title>BNF grammar for checking XML names (abridged)</title><programlisting format="linespecific">
BaseChar    ::= [#x0041-#x005A] | [#x0061-#x007A] | [#x00C0-#x00D6]
NameChar    ::= Letter | Digit | '.' | '-' | '_' | ':' | CombiningChar | Extender
Name        ::= (Letter | '_' | ':') (NameChar)*
Letter      ::= BaseChar | Ideographic
Ideographic ::= [#x4E00-#x9FA5] | #x3007 | [#x3021-#x3029]
Digit       ::= [#x0030-#x0039] | [#x0660-#x0669] | [#x06F0-#x06F9]
              | [#x0966-#x096F] | [#x09E6-#x09EF] | [#x0A66-#x0A6F]
              | [#x0AE6-#x0AEF] | [#x0B66-#x0B6F] | [#x0BE7-#x0BEF]
              | [#x0C66-#x0C6F] | [#x0CE6-#x0CEF] | [#x0D66-#x0D6F]
              | [#x0E50-#x0E59] | [#x0ED0-#x0ED9] | [#x0F20-#x0F29]
Extender    ::= #x00B7 | #x02D0 | #x02D1 | #x0387 | #x0640 | #x0E46 | #x0EC6
               | #x3005 | [#x3031-#x3035] | [#x309D-#x309E] | [#x30FC-#x30FE]
              | [#x00D8-#x00F6] | [#x00F8-#x00FF] | [#x0100-#x0131]
              | [#x0134-#x013E] | [#x0141-#x0148] | [#x014A-#x017E]
              | [#x0180-#x01C3] ...
CombiningChar ::= [#x0300-#x0345] | [#x0360-#x0361] | [#x0483-#x0486]
                 | [#x0591-#x05A1] | [#x05A3-#x05B9] | [#x05BB-#x05BD] | #x05BF
                 | [#x05C1-#x05C2] | #x05C4 | [#x064B-#x0652] | #x0670
                 | [#x06D6-#x06DC] | [#x06DD-#x06DF] | [#x06E0-#x06E4]
                 | [#x06E7-#x06E8] | [#x06EA-#x06ED]...
</programlisting></example><para>The complete set of rules would take up several pages here, as there are over 90,000 characters in Unicode to consider. In particular, the rules for <literal moreinfo="none">BaseChar</literal> and <literal moreinfo="none">CombiningChar</literal> have been shortened in this example.</para><para>To verify that a string is a legal XML name, it is necessary to iterate through each character in the string and verify that it is a legal name character as defined by the <literal moreinfo="none">NameChar</literal> production.</para></sect1><sect1 id="version_1_the_naiumlve_implementation" label="5.3"><title>Version 1: The Naïve Implementation</title><para>My initial contribution to JDOM (shown in <xref linkend="the_first_version_of_name_character_verification"/>) simply deferred the rule checks to Java's <literal moreinfo="none">Character</literal> class. The <literal moreinfo="none">checkXMLName</literal> method returns an error message if an XML name is invalid, and null if it's valid. This itself is a questionable design; it should probably throw an exception if the name is invalid, and return void in all other cases. Later in this chapter, you'll see how future versions addressed this.<indexterm id="idx-CHP-5-0242" significance="normal"><primary>XML verifiers</primary></indexterm><indexterm id="idx-CHP-5-0243" significance="normal"><primary>XML</primary><secondary>Version 1.0 specification</secondary></indexterm></para><example id="the_first_version_of_name_character_verification" label="5-2"><title>The first version of name character verification</title><programlisting format="linespecific">
	private static String checkXMLName(String name) {
	    // Cannot be empty or null
	    if ((name == null) || (name.length() == 0) || (name.trim().equals(""))) {
	        return "XML names cannot be null or empty";
	    }

	    // Cannot start with a number
	    char first = name.charAt(0);
	    if (Character.isDigit(first)) {
	        return "XML names cannot begin with a number.";
	    }
	    // Cannot start with a $
	    if (first == '$') {
	        return "XML names cannot begin with a dollar sign ($).";
	    }
	    // Cannot start with a _
	    if (first == '-') {
	        return "XML names cannot begin with a hyphen (-).";
	    }

	    // Ensure valid content
	    for (int i=0, len = name.length(); i&lt;len; i++) {
	        char c = name.charAt(i);
	        if ((!Character.isLetterOrDigit(c))
	            &amp;&amp; (c != '-')
	            &amp;&amp; (c != '$')
	            &amp;&amp; (c != '_')) {
	            return c + " is not allowed in XML names.";
	        }
	    }

	    // We got here, so everything is OK
	    return null;
	}
</programlisting></example><para>This method was straightforward and easy to understand. Unfortunately, it was wrong. In particular:<indexterm id="idx-CHP-5-0244" significance="normal"><primary>JDOM</primary><secondary>name character verification</secondary></indexterm></para><itemizedlist><listitem><para>It allowed names that contained colons. Because JDOM attempted to maintain namespace well-formedness, this had to be fixed.</para></listitem><listitem><para>The Java <literal moreinfo="none">Character.isLetterOrDigit</literal> and <literal moreinfo="none">Character.isDigit</literal> methods aren't perfectly aligned with XML's definition of letters and digits. Java considers some characters as letters that XML doesn't, and vice versa.</para></listitem><listitem><para>The Java rules change from one version of Java to the next. XML's rules don't.</para></listitem></itemizedlist><para>Nonetheless, this was a reasonable first attempt. It did catch a large percentage of <indexterm id="idx-CHP-5-0245" significance="normal"><primary>Backus-Naur Form (BNF) grammar</primary></indexterm>malformed names and didn't reject too many well-formed ones. It worked especially well in the common case when all the names were ASCII. Even so, JDOM strived for broader applicability than that. An improved implementation that actually followed <indexterm id="idx-CHP-5-0246" significance="normal"><primary>XML verifiers</primary></indexterm>XML's rules was called for.</para></sect1><sect1 id="version_2_imitating_the_bnf_grammar_on" label="5.4"><title>Version 2: Imitating the BNF Grammar O(N)</title><para>My next contribution to JDOM manually translated the BNF productions into a series of <literal moreinfo="none">if-else</literal> statements. The result looked like <xref linkend="bnf-based_name_character_verification"/>. You'll notice that this version is quite a bit more complicated.<indexterm id="idx-CHP-5-0247" significance="normal"><primary>BNF (Backus-Naur Form) grammar</primary></indexterm></para><example id="bnf-based_name_character_verification" label="5-3"><title>BNF-based name character verification</title><programlisting format="linespecific">
	private static String checkXMLName(String name) {
	    // Cannot be empty or null
	    if ((name == null) || (name.length() == 0)
	                       || (name.trim().equals(""))) {
	        return "XML names cannot be null or empty";
	    }

	    // Cannot start with a number
	    char first = name.charAt(0);
	    if (!isXMLNameStartCharacter(first)) {
	        return "XML names cannot begin with the character \"" +
	               first + "\"";
	    }
	    // Ensure valid content
	    for (int i=0, len = name.length(); i&lt;len; i++) {
	        char c = name.charAt(i);
	        if (!isXMLNameCharacter(c)) {
	            return "XML names cannot contain the character \"" + c + "\"";
	        }
	    }

	    // We got here, so everything is OK
	    return null;
	}

	public static boolean isXMLNameCharacter(char c) {

	  return (isXMLLetter(c) || isXMLDigit(c) || c == '.' || c == '-'
	                         || c == '_' || c == ':' || isXMLCombiningChar(c)
	                         || isXMLExtender(c));

	}

	public static boolean isXMLNameStartCharacter(char c) {
	  return (isXMLLetter(c) || c == '_' || c ==':');
	}
</programlisting></example><para>Instead of simply reusing Java's <literal moreinfo="none">Character.isLetterOrDigit</literal> and <literal moreinfo="none">Character.isDigit</literal> methods, the <literal moreinfo="none">checkXMLName</literal> method in <xref linkend="bnf-based_name_character_verification"/> delegates the checks to <literal moreinfo="none">isXMLNameCharacter</literal> and <literal moreinfo="none">isXMLNameStartCharacter</literal>. These methods further delegate to methods matching the other BNF productions for the different types of characters: letters, digits, combining characters, and extenders. <xref linkend="xml-based_digit_character_verification"/> shows one of these methods, <literal moreinfo="none">isXMLDigit</literal>. Notice that this method considers not only the ASCII digits, but also the other digit characters included in Unicode 2.0. The <literal moreinfo="none">isXMLLetter, isXMLCombiningChar</literal>, and <literal moreinfo="none">isXMLExtender</literal> methods follow the same pattern. They're just longer.</para><example id="xml-based_digit_character_verification" label="5-4"><title>XML-based digit character verification</title><programlisting format="linespecific">
	public static boolean <indexterm id="idx-CHP-5-0248" significance="normal"><primary>isXMLDigit( ) method</primary></indexterm>isXMLDigit(char c) {

	    if (c &gt;= 0x0030 &amp;&amp; c &lt;= 0x0039) return true;
	    if (c &gt;= 0x0660 &amp;&amp; c &lt;= 0x0669) return true;
	    if (c &gt;= 0x06F0 &amp;&amp; c &lt;= 0x06F9) return true;
	    if (c &gt;= 0x0966 &amp;&amp; c &lt;= 0x096F) return true;

	    if (c &gt;= 0x09E6 &amp;&amp; c &lt;= 0x09EF) return true;
	    if (c &gt;= 0x0A66 &amp;&amp; c &lt;= 0x0A6F) return true;
	    if (c &gt;= 0x0AE6 &amp;&amp; c &lt;= 0x0AEF) return true;

	    if (c &gt;= 0x0B66 &amp;&amp; c &lt;= 0x0B6F) return true;
	    if (c &gt;= 0x0BE7 &amp;&amp; c &lt;= 0x0BEF) return true;
	    if (c &gt;= 0x0C66 &amp;&amp; c &lt;= 0x0C6F) return true;

	    if (c &gt;= 0x0CE6 &amp;&amp; c &lt;= 0x0CEF) return true;
	    if (c &gt;= 0x0D66 &amp;&amp; c &lt;= 0x0D6F) return true;
	    if (c &gt;= 0x0E50 &amp;&amp; c &lt;= 0x0E59) return true;

	    if (c &gt;= 0x0ED0 &amp;&amp; c &lt;= 0x0ED9) return true;
	    if (c &gt;= 0x0F20 &amp;&amp; c &lt;= 0x0F29) return true;

	    return false;
	}
</programlisting></example><para>This approach satisfied the basic goals of the upgrade. It worked, and its operation was obvious. There was a clear mapping from the XML specification to the code. We could declare victory and go home.</para><para>Well, not quite. This was where the ugly specter of performance raised its head.</para></sect1><sect1 id="version_3_first_optimization_olog_n" label="5.5"><title>Version 3: First Optimization O(log N)</title><para>As Donald Knuth once said, "Premature optimization is the root of all evil in programming." However, although optimization matters less often than programmers think, it does matter; and this was one of the minority cases where it matters.<indexterm id="idx-CHP-5-0249" significance="normal"><primary>XML verifiers</primary><secondary>first optimization</secondary></indexterm></para><para>Profiling proved that JDOM was spending a significant chunk of time performing verification. Every name character required several checks, and JDOM recognized a nonname character only after checking it first against every possible name character. Consequently, the number of checks increased in direct proportion to the code point value. The project maintainers were beginning to grumble that maybe verification wasn't so important after all, and they might make it optional or ditch it entirely. Now, personally, I'm not willing to compromise correctness in the name of faster code, but it was apparent that the decision was going to be taken out of my hands if someone didn't do something. Fortunately, Jason Hunter did.</para><para>Hunter restructured my naïve code in a very clever way, shown in <xref linkend="optimized_digit_character_verification"/>. Previously, even the common case where a character was legal required over 100 tests for each of the possible ranges of illegal characters. Hunter noticed that we could return a <emphasis>true</emphasis> value much sooner if we recognized both legal and illegal characters. This is especially beneficial in the common case where all names and content are ASCII, because these characters are the first ones we test.</para><example id="optimized_digit_character_verification" label="5-5"><title>Optimized digit character verification</title><programlisting format="linespecific">
	public static boolean <indexterm id="idx-CHP-5-0250" significance="normal"><primary>XML verifiers</primary></indexterm>isXMLDigit(char c) {

	    if (c &lt; 0x0030) return false; if (c &lt;= 0x0039) return true;
	    if (c &lt; 0x0660) return false; if (c &lt;= 0x0669) return true;
	    if (c &lt; 0x06F0) return false; if (c &lt;= 0x06F9) return true;
	    if (c &lt; 0x0966) return false; if (c &lt;= 0x096F) return true;

	    if (c &lt; 0x09E6) return false; if (c &lt;= 0x09EF) return true;
	    if (c &lt; 0x0A66) return false; if (c &lt;= 0x0A6F) return true;
	    if (c &lt; 0x0AE6) return false; if (c &lt;= 0x0AEF) return true;

	    if (c &lt; 0x0B66) return false; if (c &lt;= 0x0B6F) return true;
	    if (c &lt; 0x0BE7) return false; if (c &lt;= 0x0BEF) return true;
	    if (c &lt; 0x0C66) return false; if (c &lt;= 0x0C6F) return true;

	    if (c &lt; 0x0CE6) return false; if (c &lt;= 0x0CEF) return true;
	    if (c &lt; 0x0D66) return false; if (c &lt;= 0x0D6F) return true;
	    if (c &lt; 0x0E50) return false; if (c &lt;= 0x0E59) return true;

	    if (c &lt; 0x0ED0) return false; if (c &lt;= 0x0ED9) return true;
	    if (c &lt; 0x0F20) return false; if (c &lt;= 0x0F29) return true;

	    return false;

	}
</programlisting></example><para>The earlier implementation checked a character against all possible digits, including such unlikely things as é and Φ, before deciding a character wasn't a digit. The newer approach could determine more quickly that a character wasn't a valid digit. Similar and even more significant improvements were made to the checks for letters, extenders, and combining characters.<indexterm id="idx-CHP-5-0251" significance="normal"><primary>optimization</primary><secondary>XML verifier</secondary><tertiary>digit character verification</tertiary></indexterm></para><para>This didn't eliminate the time spent on verification, but it did reduce it enough that the project maintainers were appeased, at least for the case of element names. PCDATA verification still wasn't in the build, but that wasn't quite as big a problem.</para></sect1><sect1 id="version_4_second_optimization_dont_check_twice" label="5.6"><title>Version 4: Second Optimization: Don't Check Twice</title><para>At this point, the time spent on verification had dropped by about a factor of four, and was no longer a huge concern. Version 3 is essentially what shipped in JDOM 1.0. However, by this point I had decided that JDOM was not good enough, and suspected that I could do better. My defection had more to do with issues of API design than with performance. I was also concerned with correctness, since JDOM still wasn't verifying everything it could, and it was still possible (though difficult) to use JDOM to create malformed documents. Consequently, I embarked on XOM.<indexterm id="idx-CHP-5-0252" significance="normal"><primary>XML verifiers</primary><secondary>second optimization</secondary></indexterm></para><para>XOM, unlike JDOM, made no compromises on correctness in the name of performance. The rule in XOM was that correctness came first, always. Nonetheless, for people to choose XOM over JDOM, its performance was going to have to be comparable to or better than that of JDOM. Thus, it was time to take another whack at the verification problem.</para><para>The optimization efforts of JDOM version 3 had improved the performance of the <literal moreinfo="none">checkXMLName</literal> method, but I hoped to eliminate it completely in this next optimization. The reason for this is that you don't always need to check the <indexterm id="idx-CHP-5-0253" significance="normal"><primary>parsers</primary><secondary>XML</secondary></indexterm>XML input if it's coming from a known good source. In particular, an XML parser carries out many of the necessary checks before the input reaches the XML verifier, and there's no reason to duplicate this work. Because the <indexterm id="idx-CHP-5-0254" significance="normal"><primary>constructors (methods)</primary></indexterm>constructors always checked for correctness, they caused a real drain on parsing speed performance, which in practice was a large fraction (often a substantial majority) of the time an application spent on each document.</para><para>The use of separate paths for separate types of input would resolve this issue. I had determined that constructors should <emphasis>not</emphasis> verify the element names when creating an object from strings that the parser had already read and checked in the document. Conversely, constructors <emphasis>should</emphasis> verify the element names when creating an object from strings passed by the library client. Clearly, two different constructors were needed; one for the parser and one for everybody else.</para><para>JDOM developers had considered this optimization, but got hung up on poor <indexterm id="idx-CHP-5-0255" significance="normal"><primary>package designs</primary></indexterm>package design. In JDOM, the <literal moreinfo="none">SAXBuilder</literal> class that creates a new <literal moreinfo="none">Document</literal> object from a SAX parser is in the <literal moreinfo="none">org.jdom.input</literal> package. The <literal moreinfo="none">Element, Document, Attribute</literal>, and other node classes are in the <literal moreinfo="none">org.jdom</literal> package. This means that all verifying and nonverifying constructors called by the builder must be public. Consequently, other clients can also call those constructors—clients that aren't making the appropriate checks. This enables JDOM to produce malformed XML. Later, in JDOM 1.0, the developers reversed themselves and decided to bundle a special factory class that accepted unverified input. This factory class is faster, but opens up a potentially troublesome backdoor in the verification system. The problem was just an artifact of separating the JDOM builder into input and core packages.</para><note id="note-1" role="missingmanual"><para><emphasis role="strong">Excessive package subdivision is a common anti-pattern in Java code. It often leaves developers faced with the unappealing choice of either making things public that shouldn't be, or limiting functionality</emphasis>.</para><para><emphasis role="strong">Do not use packages merely to organize a class structure. Each package should be essentially independent of the internals of all other packages. If two classes in your program or library have to access each other more than they have to access other, nonrelated classes, they should be placed together in one package</emphasis>.</para><para><emphasis role="strong">In C++, <emphasis>friend</emphasis> functions solve this problem neatly. Although Java does not currently have friend functions, Java 7 may make it possible to grant more access to subpackages that members of the general public do not have</emphasis>.</para></note><para>When I commenced work on XOM, I had the example of JDOM to learn from, so I kept the input classes in the same package as the core node classes. This meant I could provide package-protected, nonverifying methods that were available to the parser, but not to client classes from other packages.</para><para>The mechanics of XOM are straightforward. Each node class has a private no-args constructor, along with a package-protected factory method named <literal moreinfo="none">build</literal> that invokes this constructor and sets up the fields without checking the names. <xref linkend="parser-based_digit_character_verification"/> demonstrates this with the relevant code from the <literal moreinfo="none">Element</literal> class. XOM is actually a little pickier than most parsers about namespaces, so it does have to check those. Still, it can omit a lot of redundant checks.</para><example id="parser-based_digit_character_verification" label="5-6"><title>Parser-based digit character verification</title><programlisting format="linespecific">
	private Element() {}

	static Element build(String name, String uri, String localName) {

	    Element result = new Element();
	    String prefix = "";
	    int colon = name.indexOf(':');
	    if (colon &gt;= 0) {
	        prefix = name.substring(0, colon);
	    }
	    result.prefix = prefix;
	    result.localName = localName;
	    // We do need to verify the URI here because parsers are
	    // allowing relative URIs which XOM forbids, for reasons
	    // of canonical <indexterm id="idx-CHP-5-0256" significance="normal"><primary>XML verifiers</primary></indexterm>XML if nothing else. But we only have to verify
	    // that it's an absolute base URI. I don't have to verify
	    // no conflicts.
	    if (! "".equals(uri)) Verifier.checkAbsoluteURIReference(uri);
	    result.URI = uri;
	    return result;

	}
</programlisting></example><para>This approach dramatically and measurably sped up parsing performance, since it didn't require the same large amount of work as its predecessors.</para></sect1><sect1 id="version_5_third_optimization_o1" label="5.7"><title>Version 5: Third Optimization O(1)</title><para>After I implemented the constructor detailed in the previous section and added some additional optimizations, XOM was fast enough for anything I needed to do. Read performance was essentially limited only by parser speed and there were very few bottlenecks left in the document-building process.<indexterm id="idx-CHP-5-0257" significance="normal"><primary>XML verifiers</primary><secondary>third optimization</secondary></indexterm></para><para>However, other users with different use cases were encountering different problems. In particular, some users were writing custom builders that read non-<indexterm id="idx-CHP-5-0258" significance="normal"><primary>XML verifiers</primary></indexterm>XML formats into a XOM tree. They were not using an XML parser, and therefore were not able to take the shortcut that bypassed name verification. These users were still seeing verification as a hot spot, albeit a smaller one than it had been.</para><para>I wasn't willing to turn off verification completely, despite requests to do so. However, it was obvious that the verification process had to be sped up. The approach I took is an old optimization classic: <emphasis>table lookup</emphasis>. In a <indexterm id="idx-CHP-5-0259" significance="normal"><primary>Java</primary><secondary>table lookup</secondary></indexterm>table lookup, you create a table that contains all the answers for all the known inputs. When given any input, the compiler can simply look up the answer in the table, without having to perform a calculation. This is an <emphasis>O</emphasis>(1) operation, and its performance speed is close to the theoretical maximum. Of course, the devil is in the details.<indexterm id="idx-CHP-5-0260" significance="normal"><primary>table lookup</primary></indexterm></para><para>The simplest way to implement table <indexterm id="idx-CHP-5-0261" significance="normal"><primary>optimization</primary><secondary>XML verifier</secondary><tertiary>lookup table</tertiary></indexterm>lookup in Java is with a <literal moreinfo="none">switch</literal> statement. <emphasis>javac</emphasis> com-piles this statement into a table of values stored in the byte code. Depending on the <literal moreinfo="none">switch</literal> statement cases, the compiler creates one of two byte code instructions. If the cases are contiguous (e.g., 72–189 without skipping any values in between) the compiler uses a more efficient <literal moreinfo="none">tableswitch</literal>. However, if any values are skipped, the compiler uses the more indirect and less efficient <literal moreinfo="none">lookupswitch</literal> instruction instead.<indexterm id="idx-CHP-5-0262" significance="normal"><primary>switch statements (Java)</primary></indexterm></para><note id="note-2" role="missingmanual"><para><emphasis role="strong">This behavior isn't absolutely guaranteed, and may perhaps not even be true in more recent virtual machines (VMs), but it certainly was true in the generation of VMs I tested and inspected</emphasis>.</para></note><para>For small tables (a few hundred cases or less), it was possible to fill in the intermediate values with the default value. For instance, a simple test can determine whether a character is a hexadecimal digit (<xref linkend="switch_statement_character_verification"/>). The test starts with the lowest possible true value, '<literal moreinfo="none">0</literal>', and finishes with the highest possible true value, '<literal moreinfo="none">f</literal>'. Every character between <literal moreinfo="none">0</literal> and <literal moreinfo="none">f</literal> must be included as a case.</para><example id="switch_statement_character_verification" label="5-7"><title>switch statement character verification</title><programlisting format="linespecific">
	private static boolean isHexDigit(char c) {

	    switch(c) {
	        case '0': return true;
	        case '1': return true;
	        case '2': return true;
	        case '3': return true;
	        case '4': return true;
	        case '5': return true;
	        case '6': return true;
	        case '7': return true;
	        case '8': return true;
	        case '9': return true;
	        case ':': return false;
	        case ';': return false;
	        case '&lt;': return false;
	        case '=': return false;
	        case '&gt;': return false;
	        case '?': return false;
	        case '@': return true;
	        case 'A': return true;
	        case 'B': return true;
	        case 'C': return true;
	        case 'D': return true;
	        case 'E': return true;
	        case 'F': return true;
	        case 'G': return false;
	        case 'H': return false;
	        case 'I': return false;
	        case 'J': return false;
	        case 'K': return false;
	        case 'L': return false;
	        case 'M': return false;
	        case 'N': return false;
	        case 'O': return false;
	        case 'P': return false;
	        case 'Q': return false;
	        case 'R': return false;
	        case 'S': return false;
	        case 'T': return false;
	        case 'U': return false;
	        case 'V': return false;
	        case 'W': return false;
	        case 'X': return false;
	        case 'Y': return false;
	        case 'Z': return false;
	        case '[': return false;
	        case '\\': return false;
	        case ']': return false;
	        case '^': return false;
	        case '_': return false;
	        case '`': return false;
	        case 'a': return true;
	        case 'b': return true;
	        case 'c': return true;
	        case 'd': return true;
	        case 'e': return true;
	        case 'f': return true;
	    }
	    return false;
	}
</programlisting></example><para>This is long but shallow. It is not complex. It is easy to see what's happening here, and that's good. However, although <literal moreinfo="none">switch</literal> statements are shallow, they do run into <indexterm id="idx-CHP-5-0263" significance="normal"><primary>switch statements (Java)</primary><secondary>problems with larger groups of cases</secondary></indexterm>problems for larger groups of cases. For instance, <indexterm id="idx-CHP-5-0264" significance="normal"><primary>XML verifiers</primary></indexterm>XML character verification checks tens of thousands of cases. I tried writing a <literal moreinfo="none">switch</literal> statement to handle these larger groups and discovered that Java imposes a 64K maximum size on the byte code of a method. This situation required an alternate solution.</para><para>Although the compiler and runtime limited the size of the <indexterm id="idx-CHP-5-0265" significance="normal"><primary>optimization</primary><secondary>XML verifier</secondary><tertiary>lookup table</tertiary></indexterm>lookup table stored in the byte code, there were other places I could hide it. I began by defining a simple <indexterm id="idx-CHP-5-0266" significance="normal"><primary>lookup table</primary><secondary>binary format</secondary></indexterm>binary format, one byte for each of the 65,536 Unicode code points in the Basic Multilingual Plane (BMP). Each byte contains eight <emphasis>bit flags</emphasis> that identify the most important character properties. For instance, bit 1 is <emphasis>on</emphasis> if the character is legal in PCDATA content, and <emphasis>off</emphasis> if it is not legal. Bit 2 is <emphasis>on</emphasis> if the character can be used in an XML name, and <emphasis>off</emphasis> if it cannot. Bit 3 is <emphasis>on</emphasis> if the character can be the start of an XML name, and <emphasis>off</emphasis> if it cannot.<indexterm id="idx-CHP-5-0267" significance="normal"><primary>bit flags (binary lookup table)</primary></indexterm></para><para>I wrote a simple program to read the BNF grammar from the XML specification, calculate the flag values for each of the 65,536 BMP code points, and then store it in one big binary file. I saved this binary data file along with my source code, and modified my Ant compile task to copy it into the build directory (<xref linkend="saving_and_copying_the_binary_lookup_table"/>).</para><example id="saving_and_copying_the_binary_lookup_table" label="5-8"><title>Saving and copying the binary lookup table</title><programlisting format="linespecific">
&lt;target name="compile-core" depends="prepare, compile-jaxen"
          description="Compile the source code"&gt;
   &lt;javac srcdir="${build.src}" destdir="${build.dest}"&gt;
      &lt;classpath refid="compile.class.path"/&gt;
   &lt;/javac&gt;
   <userinput moreinfo="none">&lt;copy file="${build.src}/nu/xom/characters.dat"
        tofile="${build.dest}/nu/xom/characters.dat"/&gt;</userinput>
&lt;/target&gt;
</programlisting></example><para>From there, the <emphasis>jar</emphasis> task will bundle the lookup table with the compiled .<emphasis>class</emphasis> files, so it doesn't add an extra file to the distribution or cause any added dependencies. The <literal moreinfo="none">Verifier</literal> class can then use the class loader to find this file at runtime, as shown in <xref linkend="loading_the_binary_lookup_table"/>.<indexterm id="idx-CHP-5-0268" significance="normal"><primary>lookup table</primary><secondary>binary format</secondary><tertiary>loading</tertiary></indexterm></para><example id="loading_the_binary_lookup_table" label="5-9"><title>Loading the binary lookup table</title><programlisting format="linespecific">
	private static byte[] flags = null;

	static {
	    ClassLoader loader = Verifier.class.getClassLoader();
	    if (loader != null) loadFlags(loader);
	    // If that didn't work, try a different ClassLoader
	    if (flags == null) {
	        loader = Thread.currentThread().getContextClassLoader();
	        loadFlags(loader);
	    }

	}

	private static void loadFlags(ClassLoader loader) {

	    DataInputStream in = null;
	    try {
	        InputStream raw = loader.getResourceAsStream("nu/xom/characters.dat");
	        if (raw == null) {
	            throw new RuntimeException("Broken XOM installation: "
	              + "could not load nu/xom/characters.dat");
	        }
	        in = new DataInputStream(raw);
	        flags = new byte[65536];
	        in.readFully(flags);
	    }
	    catch (IOException ex) {
	        throw new RuntimeException("Broken XOM installation: "
	          + "could not load nu/xom/characters.dat");
	    }
	    finally {
	        try {
	            if (in != null) in.close();
	        }
	        catch (IOException ex) {
	            // no big deal
	        }
	    }

	}
</programlisting></example><para>This task takes up about 64KB of heap space. However, that's not really a problem on a desktop or server, and we only have to load this data once. The code is careful not to reload the data once it's already been loaded.</para><para>Now that the <indexterm id="idx-CHP-5-0269" significance="normal"><primary>optimization</primary><secondary>XML verifier</secondary><tertiary>lookup table</tertiary></indexterm>lookup table is stored in memory, checking any property of any character is a simple matter of performing an array lookup followed by a couple of bitwise operations. <indexterm id="idx-CHP-5-0270" significance="normal"><primary>XML verifiers</primary></indexterm><xref linkend="using_the_lookup_table_to_check_a_name"/> shows the new code for checking a noncolonized name, such as an element or attribute local name. All we have to do is look up the flags in the table and compare the bit corresponding to the desired property.</para><example id="using_the_lookup_table_to_check_a_name" label="5-10"><title>Using the lookup table to check a name</title><programlisting format="linespecific">
// constants for the bit flags in the characters lookup table
private final static byte <indexterm id="idx-CHP-5-0271" significance="normal"><primary>XML verifiers</primary></indexterm>XML_CHARACTER        = 1;
private final static byte NAME_CHARACTER       = 2;
private final static byte NAME_START_CHARACTER = 4;
private final static byte NCNAME_CHARACTER     = 8;

static void checkNCName(String name) {

    if (name == null) {
        throwIllegalNameException(name, "NCNames cannot be null");
    }

    int length = name.length();
    if (length == 0) {
        throwIllegalNameException(name, "NCNames cannot be empty");
    }

    char first = name.charAt(0);
    if ((flags[first] &amp; NAME_START_CHARACTER) == 0) {
        throwIllegalNameException(name, "NCNames cannot start " +
          "with the character " + Integer.toHexString(first));
    }

    for (int i = 1; i &lt; length; i++) {
        char c = name.charAt(i);
        if ((flags[c] &amp; NCNAME_CHARACTER) == 0) {
            if (c == ':') {
              throwIllegalNameException(name, "NCNames cannot contain colons");
            }
            else {
              throwIllegalNameException(name, "0x"
                + Integer.toHexString(c) + " is not a legal NCName character");
            }
        }
    }
}
</programlisting></example><para>Name character verification is now an <emphasis>O</emphasis>(1) operation, and verification of a full name is <emphasis>O</emphasis>(<emphasis>n</emphasis>), where <emphasis>n</emphasis> is the length of the name. You can fiddle with the code to improve the constant factors, as I have, but it's hard to see how this could be faster while still making the necessary checks. However, we're not done yet.<indexterm id="idx-CHP-5-0272" significance="normal"><primary>optimization</primary><secondary>XML verifier</secondary><tertiary>lookup table</tertiary></indexterm></para></sect1><sect1 id="version_6_fourth_optimization_caching" label="5.8"><title>Version 6: Fourth Optimization: Caching</title><para>If you can't make the verification go any faster, the only remaining option is not to do it, or at least not do so much of it. This approach was suggested by Wolfgang Hoschek. He noticed that in an XML document the same names keep coming up over and over. For instance, in an XHTML document, there are only about 100 different element names, and a few dozen of those account for most elements (<literal moreinfo="none">p, table, div, span, strong</literal>, and so on). Once you've verified that a name is legal, you can store it in a collection somewhere. The next time you see a name, you first check to see whether it's one of the names you've seen before; if it is, you just accept it and don't check it again.<indexterm id="idx-CHP-5-0273" significance="normal"><primary>XML verifiers</primary><secondary>fourth optimization</secondary></indexterm><indexterm id="idx-CHP-5-0274" significance="normal"><primary>XML verifiers</primary><secondary>third optimization</secondary></indexterm><indexterm id="idx-CHP-5-0275" significance="normal"><primary>optimization</primary><secondary>XML verifier</secondary><tertiary>caching namespace URIs after verification</tertiary></indexterm></para><para>However, you do have to be very careful here. It may take longer to find some names (especially shorter ones) in a collection such as a hash map than it would take to check them all over again. The only way to tell is to benchmark and profile the caching scheme very carefully on several different VMs using different kinds of documents. You may need to tune parameters such as the size of the collection to fit different kinds of documents, and what works well for one document type may not work well for another. Furthermore, if the cache is shared between threads, thread contention can become a serious problem.</para><para>Consequently, I have not yet implemented this scheme for element names. However, I have implemented it for <indexterm id="idx-CHP-5-0276" significance="normal"><primary>namespace URIs</primary></indexterm>namespace URIs (Uniform Resource Identifiers), which have even more expensive verification checks than do element names, and which are even more repetitive. For instance, many documents have only one namespace URI, and very few have more than four, so the potential gain here is much larger. <indexterm id="idx-CHP-5-0277" significance="normal"><primary>XML verifiers</primary></indexterm><xref linkend="a_cache_for_verified_namespace_uris"/> shows the inner class that XOM uses to cache namespace <indexterm id="idx-CHP-5-0278" significance="normal"><primary>URIs (Uniform Resource Identifiers)</primary></indexterm>URIs after it has verified them.</para><example id="a_cache_for_verified_namespace_uris" label="5-11"><title>A cache for verified namespace URIs</title><programlisting format="linespecific">
private final static class URICache {

    private final static int LOAD = 6;
    private String[] cache = new String[LOAD];
    private int position = 0;

    synchronized boolean contains(String s) {

        for (int i = 0; i &lt; LOAD; i++) {
            // Here I'm assuming the namespace URIs are interned.
            // This is commonly but not always true. This won't
            // break if they haven't been. Using equals() instead
            // of == is faster when the namespace URIs haven't been
            // interned but slower if they have.
            if (s == cache[i]) {
                return true;
            }
        }
        return false;

    }

    synchronized void put(String s) {
        cache[position] = s;
        position++;
        if (position == LOAD) position = 0;
    }

}
</programlisting></example><para>There are a couple of surprising features in this class. First, rather than using the obvious hash map or table, it uses a fixed-size array with a linear search. For such small lists, the constant overhead of hash lookup is slower than simply iterating through the array.</para><para>Second, if the array fills up, it is not expanded. New data just overwrites the old, starting at the first position. This behavior leaves the data structure open to an attack that could decrease performance; it would still function correctly, but more slowly. It's extremely unlikely that any real-world XML document would have such a problem, though. Few have more than six namespaces, and in the rare cases when that happens, the namespaces tend to be localized, not randomly placed throughout the document. Performance hits that result from resetting the array should be very temporary.</para><para>The one case I can imagine where the static size of the array might be a real problem is if multiple threads were simultaneously parsing documents of very different types. In that case, you might exceed the six-namespace limit regularly. A possible solution would probably involve making the cache a thread local variable instead.</para><para>These concerns would become much more prominent if you were to cache element names rather than just namespace URIs. In this case, there are many more names to cache and the names are shorter. It might make more sense to use a table in this case than a simple array. Perhaps verification is just faster; I have not yet performed the detailed measurements necessary to determine the best design, although I plan to for XOM 1.3.</para></sect1><sect1 id="the_moral_of_the_story" label="5.9"><title>The Moral of the Story</title><para>If there's a moral to this story, it is this: do not let performance considerations stop you from doing what is right. You can always make the code faster with a little cleverness. You can rarely recover so easily from a bad design.</para><para>Programs usually become faster over time, not slower. Faster CPUs are a part of that process, but not the most important. Improved algorithms are a much bigger contributor. Therefore, design the program you want in the way it should be designed. Then, and only then, should you worry about performance. More often than not, you'll discover the program is fast enough on your first pass, and you won't even need to play tricks like those outlined here. However, when you do, it's much easier to make beautiful-but-slow code fast than it is to make fast-but-ugly code beautiful.<indexterm id="I_indexterm5_tt47" class="endofrange" startref="idx-CHP-5-0228" significance="normal"><primary>XML verifiers</primary></indexterm></para></sect1></chapter><chapter id="framework_for_integrated_test_beauty_through_fragility" label="6" role=""><title>Framework for Integrated Test: Beauty Through Fragility</title><para><emphasis>Michael Feathers</emphasis><indexterm id="idx-CHP-6-0279" significance="normal"><primary>Feathers</primary></indexterm></para><para><emphasis>I have some ideas about what good design is</emphasis>. Every programmer does. We all develop these ideas through practice, and we draw on them as we work. If we're tempted to use a public variable in a class, we remember that public variables are usually a symptom of bad design, and if we see implementation inheritance, we remember that we should prefer delegation to inheritance.<footnote id="CHP-6-FNOTE-1"><para><emphasis>Design Patterns: Elements of Reusable Object-Oriented Software</emphasis>, Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, Addison-Wesley, 1995.</para></footnote></para><para>Rules like these are useful. They help us move our way through the design space as we work, but we do ourselves a disservice if we forget that they are just rules of thumb. If we forget, we can end up with design where we are "doing everything" right, but we still miss the mark.</para><para>These thoughts were driven home to me back in 2002 when Ward <indexterm id="idx-CHP-6-0280" significance="normal"><primary>Cunningham</primary></indexterm>Cunningham released Framework for Integrated Test (<indexterm class="startofrange" id="idx-CHP-6-0281" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm>FIT), his automated testing framework. FIT consists of a small set of elegant Java classes. They maneuver in a path around nearly every rule of thumb about design in the Java community, and each little turn that they make is compelling. They stand in stark contrast to design that just follows the rules.</para><para>To me, <indexterm id="idx-CHP-6-0282" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm>FIT is beautiful code. It's an invitation to think about the contextual nature of design.</para><para>In this chapter, I'll walk through one of the earliest released versions of FIT. I'll show how FIT deviates from much of the current accepted wisdom of Java and OO framework development, and describe how FIT challenged me to reconsider some of my deeply held preconceptions about design. I don't know whether you'll reconsider yours after reading this chapter, but I invite you to look just the same. With luck, I'll be able to express what makes FIT's design special.</para><sect1 id="an_acceptance_testing_framework_in_three_classes" label="6.1"><title>An Acceptance Testing Framework in Three Classes</title><para>FIT is relatively simple to explain. It's a little framework that lets you write executable application tests in HTML tables. Each type of table is processed by a programmer-defined class called a fixture. When the framework processes a page of HTML, it creates a fixture object for each table in the page. The fixture uses the table as input to validation code of your choice: it reads cell values, communicates with your application, checks expected values, and marks cells green or red to indicate success or failure of a check.<indexterm id="idx-CHP-6-0283" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>classes</secondary></indexterm></para><para>The first cell in the table specifies the name of the fixture class that will be used to process the table. For instance, <xref linkend="html_table_displayed_before_fit_processing"/> shows a table that will be processed by the <literal moreinfo="none">MarketEvaluation</literal> fixture. <xref linkend="html_table_displayed_after_fit_processing"/> shows the same table after FIT has processed it; onscreen, the shaded cells would be red to show a validation failure.</para><figure id="html_table_displayed_before_fit_processing" label="6-1" float="0"><title>HTML table displayed before FIT processing</title><mediaobject id="I_mediaobject6_tt48"><imageobject role="print"><imagedata fileref="figs/print/beauty_0601.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0601.png" format="PNG"/></imageobject></mediaobject></figure><figure id="html_table_displayed_after_fit_processing" label="6-2" float="0"><title>HTML table displayed after FIT processing</title><mediaobject id="I_mediaobject6_tt49"><imageobject role="print"><imagedata fileref="figs/print/beauty_0602.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0602.png" format="PNG"/></imageobject></mediaobject></figure><para>The key idea behind FIT is that <indexterm id="idx-CHP-6-0284" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>documents serving as tests</secondary></indexterm>documents can serve as tests. You could, for instance, embed tables in a requirements document and run the document through FIT to see whether the behavior specified in those tables exists in your software. These documents with tables can be written directly in HTML, or they can be written in Microsoft Word or any other application that can save documents as HTML. Because a FIT fixture is just a piece of software, it can call any portion of an application you care to test, and make those calls at any level. It's all under your control as a programmer.</para><para>I won't spend any more time explaining <indexterm id="idx-CHP-6-0285" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm>FIT and its problem domain; there's more information on the FIT web site (<ulink url="http://fit.c2.com"/>). But I do want to describe the design of FIT and some of the interesting choices it embodies.</para><para>The core of FIT is only three classes: <literal moreinfo="none">Parse, Fixture</literal>, and <literal moreinfo="none">TypeAdapter</literal>. Their fields and methods, and the <indexterm id="idx-CHP-6-0286" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>classes</secondary><tertiary>relationships among</tertiary></indexterm>relationships between them, are shown in <xref linkend="relations_among_fit_classes"/>.<indexterm id="idx-CHP-6-0287" significance="normal"><primary>Parse class (Java)</primary></indexterm><indexterm id="idx-CHP-6-0288" significance="normal"><primary>TypeAdapter class (Java)</primary></indexterm></para><figure id="relations_among_fit_classes" label="6-3" float="0"><title>Relations among FIT classes</title><mediaobject id="I_mediaobject6_tt50"><imageobject role="print"><imagedata fileref="figs/print/beauty_0603.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0603.png" format="PNG"/></imageobject></mediaobject></figure><para>Let's walk through it.</para><para>In a nutshell, the <literal moreinfo="none">Parse</literal> class represents the HTML of a document. The constructor of <literal moreinfo="none">Parse</literal> accepts a string and recursively constructs a tree of <literal moreinfo="none">Parse</literal> objects, knit together using the fields <literal moreinfo="none">parts</literal> and <literal moreinfo="none">more</literal>. Each <literal moreinfo="none">Parse</literal> object represents some portion of the document: there's an individual <literal moreinfo="none">Parse</literal> for each table, row, and cell.</para><para>The <literal moreinfo="none">Fixture</literal> class traverses the tree of parses, and <literal moreinfo="none">TypeAdapter</literal> converts testing values (numerics, dates, etc.) to text and back again. Fixtures talk to the application you are testing and mark individual cells red or green if a check passes or fails.</para><para>Most of the work in FIT happens in subclasses of the <literal moreinfo="none">Fixture</literal> class. Fixtures define the format of the HTML tables they interpret. If you want to create a table that consists of, say, a series of commands to execute against your application, you use the predefined <literal moreinfo="none">ActionFixture</literal> class. If you want to query your application for multiple results and compare them against a set of expected values, you use the <literal moreinfo="none">RowFixture</literal> class. FIT provides these simple subclasses, but it also allows you to subclass <literal moreinfo="none">Fixture</literal> yourself.<indexterm id="idx-CHP-6-0289" significance="normal"><primary>ActionFixture class (Java)</primary></indexterm><indexterm id="idx-CHP-6-0290" significance="normal"><primary>RowFixture class (Java)</primary></indexterm></para><para>FIT is a useful framework. I use it often, and I'm continually amazed at what you can do with that core of three classes. Many frameworks would take three or four times as many classes to do the same amount of work.</para></sect1><sect1 id="the_challenge_of_framework_design" label="6.2"><title>The Challenge of Framework Design</title><para>OK, that's the architecture of <indexterm id="idx-CHP-6-0291" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm>FIT. Let's talk about what makes it different.<indexterm id="idx-CHP-6-0292" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>challenge of framework design</secondary></indexterm></para><para>Framework design is tough. The hardest thing about it is that you have no control over code that uses your framework. Once you've published your framework's API, you can't change the signatures of particular methods or change their semantics without forcing some work on the users of the framework. And, typically, framework users do not like to revisit their code when they upgrade; they want complete backward-compatibility.</para><para>The traditional way of handling this problem is to adopt certain rules of thumb:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Be very careful about what you make public: control visibility to keep the published parts of the framework small.</para></listitem><listitem><para>Use interfaces.</para></listitem><listitem><para>Provide well-defined "hook points" that permit extensibility in the places where you intend it to occur.</para></listitem><listitem><para>Prevent extension in places where you don't want it to occur.</para></listitem></orderedlist><para>Some of these guidelines have been written down in various places,<footnote id="CHP-6-FNOTE-2"><para><emphasis>Effective Java</emphasis>, Joshua Bloch, Prentice Hall PTR, 2001.</para><para><emphasis>Framework Design Guidelines: Conventions, Idioms, and Patterns for Reusable .NET Libraries</emphasis>, Krzysztof Cwalina and Brad Abrams, Addison-Wesley Professional, 2005.</para></footnote> but, for the most part, they are cultural. They are just common ways that framework developers design.</para><para>Let's look at an example outside of FIT that shows those rules in action: the JavaMail API.</para><para>If you want to receive mail using JavaMail, you have to get a reference to a <literal moreinfo="none">Session</literal> object. <literal moreinfo="none">Session</literal> is a class that has a static method named <literal moreinfo="none">getDefaultInstance</literal>:<indexterm id="idx-CHP-6-0293" significance="normal"><primary>Session class (Java)</primary></indexterm></para><programlisting id="I_programlisting6_tt51" format="linespecific">
	package javax.mail;
	
	public final class Session
	{
	   ...
	   public static Session getDefaultInstance(Properties props);
	   ...
	   public Store getStore( ) throws NoSuchProviderException;
	   ...
	}
</programlisting><para>The <literal moreinfo="none">Session</literal> class is final. In Java, this means that we cannot create subclasses of <literal moreinfo="none">Session</literal>. Furthermore, <literal moreinfo="none">Session</literal> doesn't have a public constructor, so we can't create an instance ourselves; we have to use that static method to get an instance.</para><para>Once we have a session, we can use the <literal moreinfo="none">getStore</literal> method to get a <literal moreinfo="none">Store</literal>: an object that contains folders of received mail and a few other helpful things.</para><para><literal moreinfo="none">Store</literal> is an abstract class. The JavaMail framework supplies a couple of subclasses of <literal moreinfo="none">Store</literal>, but as users we don't have to care which one is returned to us; we just accept it and use it to get our mail. If we want to be notified when the framework changes the store, we can register a listener on the store instance using this method:<indexterm id="idx-CHP-6-0294" significance="normal"><primary>Store class (Java)</primary></indexterm></para><programlisting id="I_programlisting6_tt52" format="linespecific">
	public abstract class Store extends javax.mail.Service {
	    ...
	    public void addStoreListener(StoreListener <indexterm id="idx-CHP-6-0295" significance="normal"><primary>Parse class (Java)</primary><secondary>doTables( ) method</secondary></indexterm>listener);
	    ...
	}
</programlisting><para>This little portion of the JavaMail framework epitomizes traditional framework style. The <literal moreinfo="none">Session</literal> class is declared as final to prevent subclassing. JavaMail also uses an abstract class, <literal moreinfo="none">Store</literal>, to provide a point of extension: there can be many kinds of stores.</para><para>However, <literal moreinfo="none">Store</literal> is a guarded extension point. There is no programmatic way to have <literal moreinfo="none">Session</literal> return a different <literal moreinfo="none">Store</literal> object. The returned Store can be configured, but not in the code. The framework has locked down that choice.</para><para>On the other hand, you can register a listener on the <literal moreinfo="none">Store</literal>. This listener is a little "hook point" defined by the framework developers so that users can receive notifications about things that happen on the store without having to subclass <literal moreinfo="none">Store</literal> themselves.</para><para>All in all, the Java Mail API protects itself very well. You have to go through a well-defined sequence of steps to use it, and the framework developers have "cover" for future change; they can go back and change anything they want to in the internals of the <literal moreinfo="none">Session</literal> class without worrying about someone subclassing and overriding particular pieces of it.</para></sect1><sect1 id="an_open_framework" label="6.3"><title>An Open Framework</title><para><indexterm id="idx-CHP-6-0296" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm>FIT is a very different kind of framework. You might have noticed from the UML diagram in <xref linkend="relations_among_fit_classes"/> that nearly everything in the core framework is public, even the data. If you glance though the code of other popular frameworks, you'll find nothing quite like it. How could this possibly work? It works because FIT is an example of an open framework. It doesn't have a small set of designed extension points; the entire framework was designed to be extensible.<indexterm id="idx-CHP-6-0297" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>open framework</secondary></indexterm></para><para>Let's take a look at the <literal moreinfo="none">Fixture</literal> class. Clients of the <literal moreinfo="none">Fixture</literal> class use it in a very direct way. They create an instance of <literal moreinfo="none">Fixture</literal>, create a parse tree for an HTML document using <literal moreinfo="none">Parse</literal>, and then pass the tree to the <literal moreinfo="none">doTables</literal> method. The <literal moreinfo="none">doTables</literal> method then calls <literal moreinfo="none">doTable</literal> for each table in the document, passing along the appropriate parse subtree.<indexterm id="idx-CHP-6-0298" significance="normal"><primary>Fixture class (Java)</primary></indexterm></para><para>The <literal moreinfo="none">doTable</literal> method looks like this:</para><programlisting id="I_programlisting6_tt53" format="linespecific">
	public void doTable(Parse table) {
	    doRows(table.parts.more);
	}
</programlisting><para>And the method it calls, <literal moreinfo="none">doRows</literal>, looks like this:</para><programlisting id="I_programlisting6_tt54" format="linespecific">
	public void <indexterm id="idx-CHP-6-0299" significance="normal"><primary>Parse class (Java)</primary><secondary>doRows( ) method</secondary></indexterm>doRows(<indexterm id="idx-CHP-6-0300" significance="normal"><primary>Parse class (Java)</primary></indexterm>Parse rows) {
	    while (rows != null) {
	        doRow(rows);
	        rows = rows.more;
	    }
	}
</programlisting><para>The <literal moreinfo="none">doRow</literal> method, in turn, calls <literal moreinfo="none">doCells</literal>:</para><programlisting id="I_programlisting6_tt55" format="linespecific">
	public void doRow(Parse row) {
	    <indexterm id="idx-CHP-6-0301" significance="normal"><primary>Parse class (Java)</primary><secondary>doCells( ) method</secondary></indexterm>doCells(row.parts);
	}
</programlisting><para>And the sequence bottoms out in a method called <literal moreinfo="none">doCell</literal>:</para><programlisting id="I_programlisting6_tt56" format="linespecific">
	public void doCell(Parse cell, int columnNumber) {
	    <indexterm id="idx-CHP-6-0302" significance="normal"><primary>Parse class (Java)</primary><secondary>ignore method</secondary></indexterm>ignore(cell);
	}
</programlisting><para>The <literal moreinfo="none">ignore</literal> method simply adds the color gray to the cell, indicating that the cell has been ignored:</para><programlisting id="I_programlisting6_tt57" format="linespecific">
	public static void ignore (Parse cell) {
	    cell.addToTag(" bgcolor=\"#efefef\"");
	    ignores++;
	}
</programlisting><para>As defined, it doesn't look like <literal moreinfo="none">Fixture</literal> does much of anything at all. All it does is traverse a document and turn cells gray. However, subclasses of <literal moreinfo="none">Fixture</literal> can override any of those methods and do different things. They can gather information, save information, communicate with the application under test, and mark cell values. <literal moreinfo="none">Fixture</literal> defines the default sequence for traversing an HMTL document.</para><para>This is a very un-framework-y way of doing things. Users don't "plug into" this frame-work; they subclass a class and override some default actions. Also, there's no real cover for the framework designer. Technically, all a user needs to call is the <literal moreinfo="none">doTables</literal> method, but the entire traversal sequence, from <literal moreinfo="none">doTables</literal> down to <literal moreinfo="none">doCell</literal>, is public. <indexterm id="idx-CHP-6-0303" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm>FIT will have to live with that traversal sequence forever. There's no way to change it without breaking client code. From a traditional framework perspective, this is bad, but what if you are confident in the traversal sequence? The sequence mirrors the parts of HTML that we care about, and it's very stable; it's hard to imagine HTML changing in a way that would break it. Living with it forever might be OK.</para></sect1><sect1 id="how_simple_can_an_html_parser_be" label="6.4"><title>How Simple Can an HTML Parser Be?</title><para>In addition to being an open framework, FIT presents some other surprising design choices. Earlier, I mentioned that all of FIT's <indexterm class="startofrange" id="idx-CHP-6-0304" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>HTML parsing</secondary></indexterm>HTML parsing is done by the <literal moreinfo="none">Parse</literal> class. One of the things that I love the most about the <literal moreinfo="none">Parse</literal> class is that it constructs an entire tree with its constructors.</para><para>Here's how it works. You create an instance of the class with a string of <indexterm id="idx-CHP-6-0305" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>HTML parsing</secondary></indexterm>HTML as a constructor argument:</para><programlisting id="I_programlisting6_tt58" format="linespecific">
	String input = read(new File(argv[0]);
	<indexterm id="idx-CHP-6-0306" significance="normal"><primary>Parse class (Java)</primary></indexterm>Parse parse = new Parse(input);
</programlisting><para>The <literal moreinfo="none">Parse</literal> constructor recursively constructs a tree of <literal moreinfo="none">Parse</literal> instances, each of which represents a portion of the HTML document. The <indexterm id="idx-CHP-6-0307" significance="normal"><primary>Parse class (Java)</primary><secondary>parsing code</secondary></indexterm>parsing code is entirely within the constructors of <literal moreinfo="none">Parse</literal>.</para><para>Each <literal moreinfo="none">Parse</literal> instance has five public strings and two references to other <literal moreinfo="none">Parse</literal> objects:</para><programlisting id="I_programlisting6_tt59" format="linespecific">
	public String leader;
	public String tag;
	public String body;
	public String end;
	public String trailer;

	public Parse more;
	public Parse parts;
</programlisting><para>When you construct your first <literal moreinfo="none">Parse</literal> for an HMTL document, in a sense, you've constructed all of them. From that point on, you can use <literal moreinfo="none">more</literal> and <literal moreinfo="none">parts</literal> to traverse nodes. Here's the parsing code in the <literal moreinfo="none">Parse</literal> class:</para><programlisting id="I_programlisting6_tt60" format="linespecific">
	static String tags[] = {"table", "tr", "td"};

	public Parse (String text) throws ParseException {
	    this (text, tags, 0, 0);
	}

	public Parse (String text, String tags[]) throws ParseException {
	    this (text, tags, 0, 0);
	}

	public Parse (String text, String tags[], int level, int offset) throws ParseException
	{
	    String lc = text.toLowerCase( );
	    int startTag = lc.indexOf("&lt;"+tags[level]);
	    int endTag = lc.indexOf("&gt;", startTag) + 1;
	    int startEnd = lc.indexOf("&lt;/"+tags[level], endTag);
	    int endEnd = lc.indexOf("&gt;", startEnd) + 1;
	    int startMore = lc.indexOf("&lt;"+tags[level], endEnd);
	    if (startTag&lt;0 || endTag&lt;0 || startEnd&lt;0 || endEnd&lt;0) {
	        throw new ParseException ("Can't find tag: "+tags[level], offset);
	    }
	    
	    leader = text.substring(0,startTag);
	    tag = text.substring(startTag, endTag);
	    body = text.substring(endTag, startEnd);
	    end = text.substring(startEnd,endEnd);
	    trailer = text.substring(endEnd);
	    
	    if (level+1 &lt; tags.length) {
	        parts = new <indexterm id="idx-CHP-6-0308" significance="normal"><primary>Parse class (Java)</primary></indexterm>Parse (body, tags, level+1, offset+endTag);
	        body = null;
	    }
	    
	    if (startMore&gt;=0) {
	        more = new Parse (trailer, tags, level, offset+endEnd);
	        trailer = null;
	    }
	}
</programlisting><para>One of the most interesting things about <literal moreinfo="none">Parse</literal> is that it represents the entire <indexterm id="idx-CHP-6-0309" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>HTML parsing</secondary></indexterm>HTML document. The <literal moreinfo="none">leader</literal> string holds all of the text prior to an HTML element, <literal moreinfo="none">tag</literal> holds the tag text, <literal moreinfo="none">body</literal> holds the text between the tag and the end tag, and <literal moreinfo="none">trailer</literal> holds any trailing text. Because <literal moreinfo="none">Parse</literal> holds all the text, you can go to the top-level parse and print it using this method:</para><programlisting id="I_programlisting6_tt61" format="linespecific">
	public void print(PrintWriter out) {
	    out.print(leader);
	    out.print(tag);
	    if (parts != null) {
	        parts.print(out);
	    } else {
	        out.print(body);
	    }
	    out.print(end);
	    if (more != null) {
	        more.print(out);
	    } else {
	        out.print(trailer);
	    }
	}
</programlisting><para>In my opinion, Java code doesn't get much more elegant than that.</para><para>For a long while, I've subscribed to the rule of thumb that constructors should not do the bulk of work in a class. All they should do is put an object into a valid state and leave the real work to the other methods. In general, people don't expect object creation to be an expensive operation, and they are often surprised when it is. However, the construction code for <literal moreinfo="none">Parse</literal> is undeniably elegant. There's a beautiful symmetry to the way it breaks an HTML string down into a couple hundred <literal moreinfo="none">Parse</literal> objects and then reconstitutes it using a single method: <literal moreinfo="none">print</literal>.</para><para>If the parsing code and the <indexterm id="idx-CHP-6-0310" significance="normal"><primary>Parse class (Java)</primary><secondary>representation of entire HTML document</secondary></indexterm>representation code were in separate classes, the framework might be able to handle different formats, such as XML or RTF; however, restricting the design to handling HTML feels like the right choice. It keeps the framework small and easy to understand—the parsing code is only about 25 lines. By fixing a single choice, <indexterm id="idx-CHP-6-0311" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm>FIT became a simpler, more robust framework. One of the deepest lessons in design is that you can gain a great deal if you hold the right things constant.</para><para>Another interesting thing about <literal moreinfo="none">Parse</literal> objects is that they don't use collections to hold references to their neighbors. They use <literal moreinfo="none">parts</literal> and <literal moreinfo="none">more</literal> as direct links. This makes the code a little Lisp-y, but if you are used to looking at things from a functional point of view, it's very straightforward.<indexterm id="idx-CHP-6-0312" significance="normal"><primary>Parse class (Java)</primary></indexterm></para><para>Here's an example of this style of coding. The <literal moreinfo="none">last</literal> method in <literal moreinfo="none">Parse</literal> returns the last element in the <literal moreinfo="none">more</literal> sequence of a <literal moreinfo="none">Parse</literal>:</para><programlisting id="I_programlisting6_tt62" format="linespecific">
	public Parse <indexterm id="idx-CHP-6-0313" significance="normal"><primary>Parse class (Java)</primary><secondary>last( ) and more( ) methods</secondary></indexterm>last() {
	    return more==null ? this : more.last();
	}
</programlisting><para>Again, it's interesting that all of these fields on <literal moreinfo="none">Parse</literal> are public. The framework can't <indexterm id="idx-CHP-6-0314" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>anticipate every way that users might need to modify them. Yes, there are convenience methods such as <literal moreinfo="none">addToTag</literal> and <literal moreinfo="none">addToBody</literal>, but anyone who wants to can directly modify the fields that they act on. <indexterm id="idx-CHP-6-0315" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm>FIT gives you that power at its own expense: future versions of FIT can't easily revoke that access. It's not the sort of choice that all framework designers can or should make, but if you can live with the consequences, it's a valid choice.</para></sect1><sect1 id="conclusion-id003" label="6.5"><title>Conclusion</title><para>Many of us in the industry have learned our lessons through the school of hard knocks. We've run into situations where software we've written earlier is not as extensible as we wish. Over time, we've reacted by gathering rules of thumb that attempt to preserve <indexterm id="idx-CHP-6-0316" significance="normal"><primary>extensibility of software</primary></indexterm>extensibility by restricting choices. If you are developing a framework and you have thousands of users, this may be the best thing that you can do, but it isn't the only way.</para><para>The alternative that FIT demonstrates is radical: try to make the framework as flexible and concise as you can, not by factoring it into dozens of classes but by being very careful about how each class is factored internally. You make methods public so that when users want to stray from the normal course, they can, but you also make some hard choices, like FIT's choice of <indexterm id="idx-CHP-6-0317" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>HTML parsing</secondary></indexterm>HTML as a medium.</para><para>If you design a framework like this, you end with a very different piece of software. Once the classes are <indexterm id="idx-CHP-6-0318" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>open style of development</secondary></indexterm>opened up, it will be hard to change them in future releases, but what you produce may be small and understandable enough to lead people to create something new.</para><para>And that isn't a trivial feat. The world is filled with frameworks that are a little too hard to understand and look like they have a bit too much investment in them—so much investment that it's hard to justify reinventing the wheel. When that happens, we end up with large frameworks that miss important areas of use.</para><para>Putting frameworks aside, there's a lot to say for adopting this "open" style of development in small projects. If you know all of the users of your code—if, for instance, they all sit with you on the same project—you can choose to lower the defenses in some of your code and make it as simple and clean as FIT's code.<indexterm id="I_indexterm6_tt63" class="endofrange" startref="idx-CHP-6-0304" significance="normal"><primary>FIT (Framework for Integrated Test)</primary><secondary>HTML parsing</secondary></indexterm></para><para>Not all code is API code. It's easy for us to forget this because we hear the horror stories (the cases when one team locks down another by silently introducing dependencies that can't be eradicated), but if you are one team—if the clients of your code can and will make changes when you ask them to—you can adopt a different style of development and move toward quite open code. Language-based protection and design-based protection are solutions to a problem, but the problem is social, and it's important to consider whether you really have it or not.</para><para>Every once in a while, I show FIT's code to an experienced developer, and I get an interesting reaction. They immediately say, "Nice, but I would never write code like that." At that point, I ask them to ask themselves why. To me, FIT is a beautiful framework because it leads to that question and invites us to reflect on our answers.<indexterm id="I_indexterm6_tt64" class="endofrange" startref="idx-CHP-6-0281" significance="normal"><primary>FIT (Framework for Integrated Test)</primary></indexterm></para></sect1></chapter><chapter id="beautiful_tests" label="7" role=""><title>Beautiful Tests</title><para><emphasis>Alberto Savoia</emphasis><indexterm id="idx-CHP-7-0319" significance="normal"><primary>Savoia</primary></indexterm></para><para><emphasis>Most programmers have had the experience of looking at a piece of code</emphasis> and thinking it was not only functional but also <emphasis>beautiful</emphasis>. Code is typically considered beautiful if it does what it's supposed to do with unique elegance and economy.</para><para>But what about the tests for that beautiful code—especially the kind of tests that developers write, or <emphasis>should</emphasis> write, while they are working on the code? In this chapter, I am going to focus on tests, because tests can be beautiful themselves. More importantly, they can play a key role in helping you create more beautiful code.</para><para>As we will see, a combination of things makes tests beautiful. Unlike code, I can't bring myself to consider any <emphasis>single</emphasis> test beautiful—at least not in the same way I can look at, say, a sorting routine and call it beautiful. The reason is that <indexterm class="startofrange" id="idx-CHP-7-0320" significance="normal"><primary>testing</primary></indexterm>testing, by its very nature, is a combinatorial and exploratory problem. Every <literal moreinfo="none">if</literal> statement in the code requires at least two tests (one test for when the condition evaluates to true and one when it evaluates to false). An <literal moreinfo="none">if</literal> statement with multiple conditions, such as:</para><programlisting id="I_programlisting7_tt65" format="linespecific">
	if ( a || b || c )
</programlisting><para>could require, in theory, up to eight tests—one for each possible combination of the values of <literal moreinfo="none">a, b</literal>, and <literal moreinfo="none">c</literal>. Throw in control loops, multiple input parameters, dependencies on external code, different hardware and software platforms, etc., and the number and types of tests needed increases considerably.</para><para>Any nontrivial code, beautiful or not, needs not one, but a <emphasis>team</emphasis> of tests, where each test should be focused on checking a specific aspect of the code, similar to the way different players on a sports team are responsible for different tasks and different areas of the playing field.</para><para>Now that we have determined that we should evaluate tests in groups, we need to determine what characteristics would make a group of tests <emphasis>beautiful</emphasis>—an adjective rarely applied to them.</para><para>Generally speaking, the main purpose of tests is to instill, reinforce, or reconfirm our confidence that the code works properly and efficiently. Therefore, to me, the most beautiful tests are those that help me maximize my confidence that the code does, and will continue to do, what it's supposed to. Because different types of tests are needed to verify different properties of the code, the basic criteria for <indexterm id="idx-CHP-7-0321" significance="normal"><primary>testing</primary><secondary>beauty in tests</secondary></indexterm>beauty vary. This chapter explores three ways tests can be beautiful:</para><variablelist><varlistentry><term><emphasis>Tests that are beautiful for their simplicity</emphasis></term><listitem><para>With a few lines of test code, I can document and verify the target code's basic behavior. By automatically running those tests with every build, I can ensure that the intended behavior is preserved as the code evolves. This chapter uses the JUnit <indexterm id="idx-CHP-7-0322" significance="normal"><primary>testing</primary></indexterm>testing framework for examples of basic tests that take minutes to write and keep paying dividends for the life of the project.</para></listitem></varlistentry><varlistentry><term><emphasis>Tests that are beautiful because they reveal ways to make code more elegant, maintainable, and testable</emphasis></term><listitem><para>In other words, tests that help make code more beautiful. The process of writing tests often helps you realize not only logical problems, but also structural and design issues with your implementation. In this chapter, I demonstrate how, while trying to write tests, I have discovered a way to make my code more robust, readable, and well structured.</para></listitem></varlistentry><varlistentry><term><emphasis>Tests that are beautiful for their breadth and depth</emphasis></term><listitem><para>Very thorough and exhaustive tests boost the developer's confidence that the code functions as expected, not only in some basic or handpicked cases, but in <emphasis>all</emphasis> cases. This chapter shows how I write and run this category of tests using the concept of <emphasis>test theories</emphasis>.</para></listitem></varlistentry></variablelist><para>Because most developers are already familiar with basic testing techniques, such as smoke testing and boundary testing, I will spend most of the time on highly effective types of tests and testing techniques that are seldom discussed and rarely practiced.</para><sect1 id="that_pesky_binary_search" label="7.1"><title>That Pesky Binary Search</title><para>To demonstrate various <indexterm id="idx-CHP-7-0323" significance="normal"><primary>testing</primary></indexterm>testing techniques while keeping this chapter reasonably short, I need an example that's simple to describe and that can be implemented in a few lines of code. At the same time, the example must be juicy enough to provide some interesting testing challenges. Ideally, this example should have a long history of buggy implementations, demonstrating the need for thorough testing. And, last but not least, it would be great if this example itself could be considered beautiful code.<indexterm id="idx-CHP-7-0324" significance="normal"><primary>binary search</primary></indexterm></para><para>It's hard to talk about beautiful code without thinking about Jon <indexterm id="idx-CHP-7-0325" significance="normal"><primary>Bentley</primary></indexterm>Bentley's classic book <emphasis>Programming Pearls</emphasis> (Addison-Wesley). As I was rereading the book, I hit the beautiful code example I was looking for: a <indexterm id="idx-CHP-7-0326" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm>binary search.<indexterm id="idx-CHP-7-0327" significance="normal"><primary>Programming Pearls</primary></indexterm></para><para>As a quick refresher, a binary search is a simple and effective algorithm (but, as we'll see, tricky to implement correctly) to determine whether a presorted array of numbers <replaceable>x[0..n-1]</replaceable> contains a target element <replaceable>t</replaceable>. If the array contains <replaceable>t</replaceable>, the program returns its position in the array; otherwise, it returns <literal moreinfo="none">-1</literal>.</para><para>Here's how Jon Bentley described the algorithm to the students:</para><blockquote><para>Binary search solves the problem by keeping track of the range within the array that holds t (if t is anywhere in the array). Initially, the range is the entire array. The range is shrunk by comparing its middle element to t and discarding half the range. The process continues until t is discovered in the array or until the range in which it must lie is known to be empty.</para></blockquote><para>He adds:</para><blockquote><para>Most programmers think that with the above description in hand, writing the code is easy. They are wrong. The only way to believe this is by putting down this column right now and writing the code yourself. Try it.</para></blockquote><para>I second Bentley's suggestion. If you have never implemented binary search, or haven't done so in a few years, I suggest you try that yourself before going forward; it will give you greater appreciation for what follows.</para><para>Binary search is a great example because it's so simple and yet it's so easy to implement incorrectly. In <emphasis>Programming Pearls</emphasis>, Jon Bentley shares how, over the years, he asked hundreds of professional programmers to implement binary search after providing them with a description of the basic algorithm. He gave them a very generous two hours to write it, and even allowed them to use the high-level language of their choice (including pseudocode). Surprisingly, only about 10 percent of the professional programmers implemented binary search correctly.</para><para>More surprisingly, in his <emphasis>Sorting and Searching</emphasis>,<footnote id="CHP-7-FNOTE-1"><para><emphasis>The Art of Computer Programming, Vol. 3: Sorting and Searching</emphasis>, Second Edition, Addison-Wesley, 1998.</para></footnote> Donald Knuth points out that even though the first binary search was published in 1946, it took 12 more years for the first binary search <emphasis>without bugs</emphasis> to be published.</para><para>But most surprising of all is that even Jon Bentley's official and <emphasis>proven</emphasis> algorithm, which (I must assume) has been implemented and adapted thousands of times, turns out to have a problem that can manifest itself when the array is big enough and the algorithm is implemented in a language with fixed-precision arithmetic.</para><para>In Java, the bug manifests itself by throwing an <literal moreinfo="none">ArrayIndexOutOfBoundsException</literal>, whereas in C, you get an array index out of bounds with unpredictable results. You can read more about this latest bug in Joshua Bloch's blog: <ulink url="http://googleresearch.blogspot.com/2006/06/extra-extra-read-all-about-it-nearly.html"/>.</para><para>Here is a Java implementation with the infamous bug:</para><programlisting id="I_programlisting7_tt66" format="linespecific">
	public static int buggyBinarySearch(int[] a, int target) {
	    int low = 0;
	    int high = a.length - 1;

	    while (low &lt;= high) {
	        int mid = (low + high) / 2;
	        int midVal = a[mid];

	        if (midVal &lt; target)
	            low = mid + 1;
	        else if (midVal &gt; target)
	            high = mid - 1;
	        else
	            return mid;
	    }
	    return -1;
	}
</programlisting><para>The bug is in the following line:</para><programlisting id="I_programlisting7_tt67" format="linespecific">
	int mid = (low + high) / 2;
</programlisting><para>If the sum of <literal moreinfo="none">low</literal> and <literal moreinfo="none">high</literal> is greater than <literal moreinfo="none">Integer.MAX_VALUE</literal> (which is 2<superscript>31</superscript> −1 in Java), it overflows into a negative number and, of course, stays negative when divided by 2—ouch!</para><para>The recommended solution is to change the calculation of the midpoint to prevent integer overflow. One way to do it is by subtracting instead of adding:</para><programlisting id="I_programlisting7_tt68" format="linespecific">
	int mid = low + ((high - low) / 2);
</programlisting><para>Or, if you want to show off your knowledge of <indexterm id="idx-CHP-7-0328" significance="normal"><primary>bit shift operators (Java)</primary></indexterm>bit shift operators, the blog (and the official Sun Microsystems bug report<footnote id="CHP-7-FNOTE-2"><para><ulink url="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=5045582"/>.</para></footnote>) suggests using the unsigned bit shift, which is probably faster but may be obscure to most Java developers (including me):</para><programlisting id="I_programlisting7_tt69" format="linespecific">
	int mid = (low + high) &gt;&gt;&gt; 1;
</programlisting><para>Considering how simple the idea behind <indexterm id="idx-CHP-7-0329" significance="normal"><primary>Java</primary><secondary>binary search algorithm bug</secondary></indexterm>binary search is, and the sheer number and collective brain power of the people that have worked on it over the years, it's a great example of why even the simplest code needs <indexterm id="idx-CHP-7-0330" significance="normal"><primary>testing</primary></indexterm>testing—and lots of it. Joshua Bloch expressed this beautifully in his blog about this bug:</para><blockquote><para>The general lesson that I take away from this bug is humility: It is hard to write even the smallest piece of code correctly, and our whole world runs on big, complex pieces of code.</para></blockquote><para>Here is the implementation of binary search I want to test. In theory, the fix to the way the <literal moreinfo="none">mid</literal> is calculated should resolve the final bug in a pesky piece of code that has eluded some of the best programmers for a few decades:</para><programlisting id="I_programlisting7_tt70" format="linespecific">
	public static int binarySearch(int[] a, int target) {
	    int low = 0;
	    int high = a.length - 1;

	    while (low &lt;= high) {
	        int mid = (low + high) &gt;&gt;&gt; 1;
	        int midVal = a[mid];

	        if (midVal &lt; target)
	            low = mid + 1;
	        else if (midVal &gt; target)
	            high = mid - 1;
	        else
	            return mid;
	    }
	    return -1;
	}
</programlisting><para>This version of <literal moreinfo="none">binarySearch</literal> looks right, but there might still be problems with it. Perhaps not bugs, but things that can and should be changed. The changes will make the code not only more robust, but more readable, maintainable, and testable. Let's see whether we can discover some interesting and unexpected opportunities for improvement as we test it.</para></sect1><sect1 id="introducing_junit" label="7.2"><title>Introducing JUnit</title><para>When speaking of beautiful tests, it's hard not to think of the JUnit <indexterm id="idx-CHP-7-0331" significance="normal"><primary>testing</primary></indexterm>testing framework. Because I'm using Java, deciding to build my beautiful tests around JUnit was a very easy decision. But before I do that, in case you are not already familiar with JUnit, let me say a few words about it.<indexterm id="idx-CHP-7-0332" significance="normal"><primary>testing</primary><secondary>JUnit testing framework</secondary></indexterm><indexterm id="idx-CHP-7-0333" significance="normal"><primary>JUnit</primary></indexterm></para><para>JUnit is the brainchild of Kent Beck and Erich Gamma, who created it to help Java developers write and run automated and self-verifying tests. It has the simple, but ambitious, objective of making it easy for software developers to do what they should have done all along: test their own code.</para><para>Unfortunately, we still have a long way to go before the majority of developers are test-infected (i.e., have experimented with developer testing and decided to make it a regular and important part of their development practices). However, since its introduction, JUnit (helped considerably by eXtreme Programming and other Agile methodologies, where developer involvement in testing is nonnegotiable) has gotten more programmers to write tests than anything else.<footnote id="CHP-7-FNOTE-3"><para>Another indication of JUnit's success and influence is that today there are JUnit-inspired frameworks for most modern programming languages, as well as many JUnit extensions.</para></footnote> Martin Fowler summed up JUnit's impact as follows: "Never in the field of software development was so much owed by so many to so few lines of code."</para><para>JUnit is intentionally simple. Simple to learn. Simple to use. This was a key design criterion. Kent Beck and Erich Gamma took great pains to make sure that JUnit was so easy to learn and use that programmers would actually use it. In their own words:</para><blockquote><para>So, the number one goal is to write a framework within which we have some glimmer of hope that developers will actually write tests. The framework has to use familiar tools, so that there is little new to learn. It has to require no more work than absolutely necessary to write a new test. It has to eliminate duplicate effort.<footnote id="CHP-7-FNOTE-4"><para>"JUnit: A Cook's Tour," Kent Beck and Erich Gamma: <ulink url="http://junit.sourceforge.net/doc/cookstour/cookstour.htm"/>.</para></footnote></para></blockquote><para>The official getting-started documentation for JUnit (the <emphasis>JUnit Cookbook</emphasis>) fits in less than two pages: <ulink url="http://junit.sourceforge.net/doc/cookbook/cookbook.htm"/>.</para><para>Here's the key extract from the cookbook (from the 4.x version of JUnit):</para><blockquote><para>When you need to test something, here is what you do:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Annotate a method with <literal moreinfo="none">@org.junit.Test</literal></para></listitem><listitem><para>When you want to check a value, import <literal moreinfo="none">org.junit.Assert</literal>.<footnote id="CHP-7-FNOTE-5"><para>Another indication of JUnit's success and influence is that today there are JUnit-inspired frameworks for most modern programming languages, as well as many JUnit extensions.</para></footnote> statically, call <literal moreinfo="none">assertTrue()</literal>, and pass a Boolean that is true if the test succeeds</para></listitem></orderedlist><para>For example, to test that the sum of two Moneys with the same currency contains a value that is the sum of the values of the two Moneys, write:</para><programlisting id="I_programlisting7_tt71" format="linespecific">
	@Test
	public void simpleAdd() {
	    Money m12CHF= new Money(12, "CHF");
	    Money m14CHF= new Money(14, "CHF");
	    Money expected= new Money(26, "CHF");
	    Money result= m12CHF.add(m14CHF);
	    assertTrue(expected.equals(result));
	}
</programlisting></blockquote><para>If you have any familiarity with Java, those two instructions and the simple example are all you need to get started. That's also all you need to understand the tests I will be writing. Beautifully simple, isn't it? So, let's get going.</para></sect1><sect1 id="nailing_binary_search" label="7.3"><title>Nailing Binary Search</title><para>Given its history, I am not going to be fooled by the apparent simplicity of binary search, or by the obviousness of the fix, especially because I've never used the unsigned bit shift operator (i.e., &gt;&gt;&gt;) in any other code. I am going to test this <emphasis>fixed</emphasis> version of binary search as if I had never heard of it before, nor implemented it before. I am not going to trust anyone's word, or tests, or proofs, that this time it will really work. I want to be confident that it works as it should through my own <indexterm id="idx-CHP-7-0334" significance="normal"><primary>testing</primary></indexterm>testing. I want to <emphasis>nail</emphasis> it.<indexterm id="idx-CHP-7-0335" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm></para><para>Here's my initial <indexterm id="idx-CHP-7-0336" significance="normal"><primary>testing</primary></indexterm>testing strategy (or team of tests):</para><itemizedlist><listitem><para>Start with <emphasis>smoke tests</emphasis>.<indexterm id="idx-CHP-7-0337" significance="normal"><primary>smoke tests</primary></indexterm></para></listitem><listitem><para>Add some <emphasis>boundary value</emphasis> tests.<indexterm id="idx-CHP-7-0338" significance="normal"><primary>boundary value tests</primary></indexterm></para></listitem><listitem><para>Continue with various thorough and exhaustive types of tests.</para></listitem><listitem><para>Finally, add some <emphasis>performance</emphasis> tests.</para></listitem></itemizedlist><para><indexterm id="idx-CHP-7-0339" significance="normal"><primary>binary search</primary><secondary>testing</secondary></indexterm>Testing is rarely a linear process. Instead of showing you the finished set of tests, I am going to walk you through my thought processes while I am working on the tests.</para><sect2 id="smoking_allowed_and_encouraged" label="7.3.1"><title>Smoking Allowed (and Encouraged)</title><para>Let's get started with the <indexterm id="idx-CHP-7-0340" significance="normal"><primary>binary search</primary><secondary>testing</secondary><tertiary>smoke test</tertiary></indexterm>smoke tests. These are designed to make sure that the code does the right thing when used in the most basic manner. They are the first line of defense and the first tests that should be written, because if an implementation does not pass the <indexterm id="idx-CHP-7-0341" significance="normal"><primary>testing</primary><secondary>binary search</secondary><tertiary>smoke test</tertiary></indexterm>smoke tests, further testing is a waste of time. I often write the smoke tests before I write the code; this is called <emphasis>test-driven development</emphasis> (or <emphasis>TDD</emphasis>).</para><para>Here's my smoke test for <indexterm id="idx-CHP-7-0342" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm>binary search:</para><programlisting id="I_programlisting7_tt72" format="linespecific">
	import static org.junit.Assert.*;
	import org.junit.Test;

	public class BinarySearchSmokeTest {

	@Test
	public void smokeTestsForBinarySearch() {

	    int[] arrayWith42 = new int[] { 1, 4, 42, 55, 67, 87, 100, 245 };
	    assertEquals(2, Util.binarySearch(arrayWith42, 42));
	    assertEquals(-1, Util.binarySearch(arrayWith42, 43));

	    }

	}
</programlisting><para>As you can tell, this test is really, <emphasis>really</emphasis>, basic. Not a huge confidence builder by itself, but still beautiful because it's a very fast and efficient first step toward more thorough tests.</para><para>Because this smoke test executes extremely fast (in less than 1/100<superscript>th</superscript> of a second on my system), you might ask why I didn't include a few more tests. The answer is that part of the beauty of smoke tests is that they can continue to pay dividends after the bulk of the development is done. To reconfirm my confidence in the code—call it "confidence maintenance"—I like to combine all smoke tests into a suite that I run every time I do a new build (which might be dozens of times a day), and I want this smoke test suite to run fast—ideally in a minute or two. If you have thousands of classes, and thousands of smoke tests, it's essential to keep each one to a bare minimum.</para></sect2><sect2 id="pushing_the_boundaries" label="7.3.2"><title>Pushing the Boundaries</title><para>As the name implies, boundary <indexterm id="idx-CHP-7-0343" significance="normal"><primary>testing</primary></indexterm>testing is designed to explore and validate what happens when the code has to deal with extremes and corner cases. In the case of <indexterm class="startofrange" id="idx-CHP-7-0344" significance="normal"><primary>boundary value tests</primary><secondary>binary search</secondary></indexterm>binary search, the two parameters are the <indexterm class="startofrange" id="idx-CHP-7-0345" significance="normal"><primary>boundary value tests</primary><secondary>array</secondary></indexterm>array and the target value. Let's think of some boundary cases for each of these parameters.<footnote id="CHP-7-FNOTE-6"><para>The specification for <indexterm id="idx-CHP-7-0346" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm>binary search says that the array <emphasis>must</emphasis> be sorted prior to making this call, and that if it is not sorted, the results are undefined. We are also assuming that a null array parameter should throw a <literal moreinfo="none">NullPointerException</literal>. Because most readers should already be familiar with basic boundary <indexterm id="idx-CHP-7-0347" significance="normal"><primary>binary search</primary><secondary>testing</secondary></indexterm>testing techniques, I am going to skip some of those obvious tests.</para></footnote></para><para>The first set of interesting corner cases that come to mind has to do with the size of the array being searched. I begin with the following basic boundary tests:</para><programlisting id="I_programlisting7_tt73" format="linespecific">
	int[] testArray;

	@Test
	public void searchEmptyArray() {
	    testArray = new int[] {};
	    assertEquals(-1, Util.binarySearch(testArray, 42));
	}

	@Test
	public void searchArrayOfSizeOne() {
	    testArray = new int[] { 42 };
	    assertEquals(0, Util.binarySearch(testArray, 42));
	    assertEquals(-1, Util.binarySearch(testArray, 43));
	}
</programlisting><para>It's pretty clear that an empty array is a good boundary case, and so is an array of size 1 because it's the smallest nonempty array. Both of these tests are beautiful because they increase my confidence that the right thing happens at the lower boundary of array size.</para><para>But I also want to test the search with a very large array, and this is where it gets interesting (especially with the hindsight knowledge that the bug manifests itself only on arrays with over one billion elements).</para><para>My first thought is to create an array large enough to ensure that the integer-overflow bug has been fixed, but I immediately recognize a testability issue: my laptop does not have enough resources to create an array that large in memory. But I know that there are systems that <emphasis>do</emphasis> have many gigabytes of memory and keep large arrays in memory. I want to make sure, one way or another, that the <literal moreinfo="none">mid</literal> integer does not overflow in those cases.</para><para>What can I do?</para><para>I know that by the time I am done with some of the other tests I have in mind, I will have enough tests to give me confidence that the basic algorithm and implementation works <emphasis>provided that the midpoint is calculated correctly and does not overflow into a negative number</emphasis>. So, here's a summary of my reasoning, leading to a possible testing strategy for enormous arrays:<indexterm id="idx-CHP-7-0348" significance="normal"><primary>midpoint calculation</primary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>I cannot test <literal moreinfo="none">binarySearch</literal> directly with <indexterm id="idx-CHP-7-0349" significance="normal"><primary>boundary value tests</primary><secondary>array</secondary></indexterm>arrays large enough to verify that the overflow bug in the calculation of <literal moreinfo="none">mid</literal> does not occur anymore.</para></listitem><listitem><para>However, I <emphasis>can</emphasis> write enough tests to give me confidence that my <literal moreinfo="none">binarySearch</literal> implementation works correctly on smaller arrays.</para></listitem><listitem><para>I can also test the way <emphasis>mid</emphasis> is calculated when very large values are used, without getting arrays involved.</para></listitem><listitem><para>So, if I can gain enough confidence through <indexterm id="idx-CHP-7-0350" significance="normal"><primary>testing</primary></indexterm>testing that:</para><itemizedlist><listitem><para>My implementation of the basic <literal moreinfo="none">binarySearch</literal> algorithm is sound as long as <literal moreinfo="none">mid</literal> is calculated correctly, and</para></listitem><listitem><para>The way the midpoint is calculated is correct</para></listitem></itemizedlist><para>then I can have confidence that <literal moreinfo="none">binarySearch</literal> will do the right thing on very large arrays.</para></listitem></orderedlist><para>So the not-so-obvious, but beautiful, <indexterm id="idx-CHP-7-0351" significance="normal"><primary>binary search</primary><secondary>testing</secondary></indexterm>testing strategy is to isolate and test the pesky, overflow-prone calculation independently.</para><para>One possibility is to create a new method:</para><programlisting id="I_programlisting7_tt74" format="linespecific">
	static int calculateMidpoint(int low, int high) {
	    return (low + high) &gt;&gt;&gt; 1;
	}
</programlisting><para>then change the following line in the code from:</para><programlisting id="I_programlisting7_tt75" format="linespecific">
	int mid = (low + high) &gt;&gt;&gt; 1;
</programlisting><para>to:</para><programlisting id="I_programlisting7_tt76" format="linespecific">
	int mid = calculateMidpoint(low, high);
</programlisting><para>and then test the heck out of the <literal moreinfo="none">calculateMidpoint</literal> method to make sure it always does the right thing.</para><para>I can already hear a few of you screaming about adding the overhead of a method call in an algorithm designed for maximum speed. But there's no need to cry foul. Here's why I believe this change to the code is not only acceptable, but the right thing to do:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>These days, I can trust compiler optimization to do the right thing and inline the method for me, so there is no performance penalty.</para></listitem><listitem><para>The change makes the code more readable. I checked with several other Java programmers, and most of them were not familiar with the unsigned bit shift operator, or were not 100 percent sure how it worked. For them, seeing <literal moreinfo="none">calculateMidpoint(low, high</literal>) is more obvious than seeing (<literal moreinfo="none">low + high) &gt;&gt;&gt; 1</literal>.</para></listitem><listitem><para>The change makes the code more testable.</para></listitem></orderedlist><para>This is actually a good example of how the very act of creating a test for your code will improve its design or legibility. In other words, testing can help you make your code more beautiful.</para><para>Here is a sample boundary test for the new <literal moreinfo="none">calculateMidpoint</literal> method:</para><programlisting id="I_programlisting7_tt77" format="linespecific">
	@Test
	public void calculateMidpointWithBoundaryValues(<indexterm id="idx-CHP-7-0352" significance="normal"><primary>midpoint calculation</primary><secondary>calculateMidpoint( ) method</secondary></indexterm>) {
	    assertEquals(0, calculateMidpoint (0, 1));
	    assertEquals(1, calculateMidpoint (0, 2));
	    assertEquals(1200000000, calculateMidpoint (1100000000, 1300000000));
	    assertEquals(Integer.MAX_VALUE - 2,
	        calculateMidpoint (Integer.MAX_VALUE-2, Integer.MAX_VALUE-1));
	    assertEquals(Integer.MAX_VALUE - 1,
	        calculateMidpoint (Integer.MAX_VALUE-1, Integer.MAX_VALUE));
	}
</programlisting><para>I run the tests, and they pass. Good. I am now confident that calculating <literal moreinfo="none">mid</literal> using the unfamiliar operator does what it's supposed to do within the range of <indexterm id="idx-CHP-7-0353" significance="normal"><primary>boundary value tests</primary><secondary>array</secondary></indexterm>array sizes I want to handle with this implementation of <indexterm id="idx-CHP-7-0354" significance="normal"><primary>boundary value tests</primary><secondary>binary search</secondary></indexterm>binary search.</para><para>The other set of boundary cases has to do with the position of the target number. I can think of three obvious boundary cases for the <indexterm id="idx-CHP-7-0355" significance="normal"><primary>target item location</primary></indexterm>target item location: first item in the list, last item in the list, and right smack in the middle of the list. So, I write a simple test to check these cases:</para><programlisting id="I_programlisting7_tt78" format="linespecific">
	@Test
	public void testBoundaryCasesForItemLocation() {
	    testArray = new int[] { -324, -3, -1, 0, 42, 99, 101 };
	    assertEquals(0, Util.binarySearch(testArray, -324));  // first position
	    assertEquals(3, Util.binarySearch(testArray, 0));      // middle position
	    assertEquals(6, Util.binarySearch(testArray, 101));   // last position
	}
</programlisting><para>Note that in this test I used some negative numbers and 0, both in the array and for the target number. It had occurred to me, while reading the tests I had already written, that I had used only positive numbers. Since that's not part of the specification, I should introduce negative numbers and 0 in my tests. Which leads me to the following piece of <indexterm id="idx-CHP-7-0356" significance="normal"><primary>testing</primary></indexterm>testing wisdom:</para><blockquote><para>The best way to think of more test cases is to start writing <emphasis>some</emphasis> test cases.</para></blockquote><para>Now that I started to think about positive/negative numbers and 0, I realize that it would be good to have a couple of tests that use the minimum and maximum integer values.<indexterm id="I_indexterm7_tt79" class="endofrange" startref="idx-CHP-7-0345" significance="normal"><primary>boundary value tests</primary><secondary>array</secondary></indexterm></para><programlisting id="I_programlisting7_tt80" format="linespecific">
	public void testForMinAndMaxInteger() {
	    testArray = new int[] {
	      Integer.MIN_VALUE, -324, -3, -1, 0, 42, 99, 101, Integer.MAX_VALUE
	    };
	    assertEquals(0, Util.binarySearch(testArray, Integer.MIN_VALUE));
	    assertEquals(8, Util.binarySearch(testArray, Integer.MAX_VALUE));
	}
</programlisting><para>So far, all the boundary cases I thought of passed, and I am starting to feel pretty confident. But then I think of the 90 percent of professional programmers in Jon Bentley's class who implemented <indexterm id="idx-CHP-7-0357" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm>binary search and thought they had it right but didn't, and my confidence begins to wane a little bit. Did I make any unwarranted assumptions about the inputs? I did not think about negative numbers and 0 until this last test case. What other unwarranted assumptions have I made? Because I handcrafted the tests, perhaps I subconsciously created cases that would work and missed ones that would fail.</para><para>This is a known problem with programmers <indexterm id="idx-CHP-7-0358" significance="normal"><primary>testing</primary></indexterm>testing their own code. If they can't think of some scenarios when implementing <indexterm id="idx-CHP-7-0359" significance="normal"><primary>breaking the code (beautiful tests)</primary></indexterm>the code, it's likely that they will not be able to think of them when they switch context and try to <emphasis>break</emphasis> the code. Truly beautiful <indexterm id="idx-CHP-7-0360" significance="normal"><primary>binary search</primary><secondary>testing</secondary></indexterm>testing requires a developer to make an extra effort, think outside the box, explore weird scenarios, look for weaknesses, and try to break things.</para><para>So, what haven't I thought of? My smoke test and <indexterm id="idx-CHP-7-0361" significance="normal"><primary>testing</primary><secondary>binary search</secondary><tertiary>boundary value tests</tertiary></indexterm>boundary tests do not feel sufficient. Is my test set representative enough that I can, through some form of induction,<footnote id="CHP-7-FNOTE-7"><para>By <emphasis>induction</emphasis>, I mean deriving general <indexterm id="idx-CHP-7-0362" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>principles from particular facts or instances.</para></footnote> claim the code will work in all instances? The words of Joshua Bloch echo in my mind: <emphasis>"…It is hard to write even the smallest piece of code correctly."</emphasis></para><para>What kind of tests would make me feel confident enough that my implementation will do the right thing with all sorts of inputs—not just the ones I handcrafted?</para></sect2><sect2 id="random_acts_of_testing" label="7.3.3"><title>Random Acts of Testing</title><para>So far I've written traditional, tried-and-true types of tests. I used a few concrete examples to test the search code against my expectations of what the correct behavior should be in those cases. Those tests all pass, so I have <emphasis>some</emphasis> level of confidence in my code. But I also realize that my tests are very specific and cover only a very small subset of all the possible inputs. What I would like, and what would help me sleep at night knowing my code has been thoroughly covered, is a way of testing over a much broader set of inputs. For this to happen I need two things:<indexterm id="idx-CHP-7-0363" significance="normal"><primary>testing</primary><secondary>binary search</secondary><tertiary>random testing</tertiary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>A way to generate a large and diverse set of inputs</para></listitem><listitem><para>A set of generalized assertions that will work on any input</para></listitem></orderedlist><para>Let's tackle the first requirement.</para><para>What I need here is a way to generate arrays of integers of all shapes and sizes. The only requirement I am going to make is that the resulting arrays are sorted, because that's a precondition. Other than that, anything goes. Here's my initial implementation of the generator:<footnote id="CHP-7-FNOTE-8"><para>I say <emphasis>initial</emphasis> implementation because I quickly realized that I needed to populate the array with negative as well as positive numbers, and changed the generator accordingly.</para></footnote><indexterm id="I_indexterm7_tt81" class="endofrange" startref="idx-CHP-7-0344" significance="normal"><primary>boundary value tests</primary><secondary>binary search</secondary></indexterm></para><programlisting id="I_programlisting7_tt82" format="linespecific">
	public int[] generateRandomSortedArray(int maxArraySize, int maxValue) {
	    int arraySize = 1 + rand.nextInt(maxArraySize);
	    int[] randomArray = new int[arraySize];
	    for (int i = 0; i &lt; arraySize; i++) {
	        randomArray[i] = rand.nextInt(maxValue);
	    }
	    Arrays.sort(randomArray);
	    return randomArray;
	}
</programlisting><para>For my generator, I take advantage of <literal moreinfo="none">java.util</literal>'s <indexterm id="idx-CHP-7-0364" significance="normal"><primary>Java</primary><secondary>random-number generator and Arrays utilities</secondary></indexterm>random-number generator and <literal moreinfo="none">Arrays</literal> utilities. The latter once contained the very same binary-search bug Joshua Bloch mentioned in his blog, but it's fixed in the version of Java I am using. Because I already covered the handling of empty arrays to my satisfaction in my other tests, I use a minimum array size here of 1. The generator is parameterized because I might want to create different sets of tests as I go along: some with small arrays containing big numbers, some with big arrays and small numbers, and so on.</para><para>Now I have to come up with some general statements about the desired behavior of the <indexterm id="idx-CHP-7-0365" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm>binary search that can be expressed as assertions. By "general," I mean statements that must hold true for any input array and target value. My colleagues Marat Boshernitsan and David Saff call these <emphasis>theories</emphasis>. The idea is that we have a theory of how the code should behave, and the more we test the theory, the more confident we can be that what we theorize is actually true. In the following example, I am going to apply a much simplified version of Saff and Boshernitsan's theories.</para><para>Let's try to come up with some theories for <literal moreinfo="none">binarySearch</literal>. Here we go:</para><blockquote><para>For all instances of <replaceable>testArray</replaceable> and <replaceable>target</replaceable>, where <replaceable>testArray</replaceable> is a sorted array of integers and is not null, and <replaceable>target</replaceable> is an integer, the following must always be true of <literal moreinfo="none">binarySearch</literal>:</para><para>Theory 1:<footnote id="CHP-7-FNOTE-9"><para>In practice I would use, and recommend using, descriptive names for the theories, such as: <emphasis>binary-SearchReturnsMinusOneImpliesArrayDoesNotContainElement</emphasis>, but I found that for this chapter, the reasoning is easier to follow if I use Theory1, Theory2, etc.</para></footnote> If <literal moreinfo="none">binarySearch</literal>(<replaceable>testArray, target</replaceable>) returns −1, then <replaceable>testArray</replaceable> does not contain <replaceable>target</replaceable>.</para><para>Theory 2: If <literal moreinfo="none">binarySearch</literal>(<replaceable>testArray, target</replaceable>) returns <replaceable>n</replaceable>, and <replaceable>n</replaceable> is greater than or equal to 0, then <replaceable>testArray</replaceable> contains <replaceable>target</replaceable> at position <replaceable>n</replaceable>.</para></blockquote><para>Here's my code for <indexterm id="idx-CHP-7-0366" significance="normal"><primary>testing</primary></indexterm>testing these two theories:</para><programlisting id="I_programlisting7_tt83" format="linespecific">
	public class BinarySearchTestTheories {

	<indexterm id="idx-CHP-7-0367" significance="normal"><primary>testing</primary><secondary>binary search</secondary><tertiary>random testing</tertiary></indexterm>Random rand;

	@Before
	public void initialize() {
	    rand = new Random();
	}

	@Test
	public void testTheories() {

	    int maxArraySize = 1000;
	    int maxValue = 1000;
	    int experiments = 1000;
	    int[] testArray;
	    int target;
	    int returnValue;

	    while (experiments-- &gt; 0) {
	        testArray = generateRandomSortedArray(maxArraySize, maxValue);<indexterm id="idx-CHP-7-0368" significance="normal"><primary>testing</primary><secondary>binary search</secondary><tertiary>random testing</tertiary></indexterm>
	        if (rand.nextBoolean()) {
	            target = testArray[rand.nextInt(testArray.length)];
	        } else {
	            target = rand.nextInt();
	        }
	        returnValue = Util.<indexterm id="idx-CHP-7-0369" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm>binarySearch(testArray, target);
	        assertTheory1(testArray, target, returnValue);
	        assertTheory2(testArray, target, returnValue);
	    }
	}

	public void assertTheory1(int[] testArray, int target, int returnValue) {
	    if (returnValue == -1)
	        assertFalse(arrayContainsTarget(testArray, target));
	}

	public void assertTheory2(int[] testArray, int target, int returnValue) {
	    if (returnValue &gt;= 0)
	        assertEquals(target, testArray[returnValue]);
	}

	public boolean arrayContainsTarget(int[] testArray, int target) {
	    for (int i = 0; i &lt; testArray.length; i++)
	        if (testArray[i] == target)
	            return true;
	    return false;
	}
</programlisting><para>In the main test method, <literal moreinfo="none">testTheories</literal>, I decide how many experiments I want to run in order to confirm the theories, and use that as my loop counter. Inside the loop, the random-array generator I just wrote gives me a sorted array. I want to test both successful and unsuccessful searches, so I use Java's random number generator again to "toss a coin" (through the <literal moreinfo="none">rand.nextBoolean()</literal> code). Based on the virtual coin toss, I decide whether I am going to pick a target number that I <emphasis>know</emphasis> is in the array or one that's unlikely to be in the array. Finally, I call <literal moreinfo="none">binarySearch</literal>, store the return value, and invoke the methods for the theories I have so far.</para><para>Notice that, in order to implement the tests for my theories, I had to write a test helper method, <literal moreinfo="none">arrayContainsTarget</literal>, that gives me an alternative way of checking whether <literal moreinfo="none">testArray</literal> contains the target element. This is a common practice for this type of <indexterm id="idx-CHP-7-0370" significance="normal"><primary>testing</primary></indexterm>testing. Even though the implementation of this helper method provides functionality similar to <literal moreinfo="none">binarySearch</literal>, it's a much simpler (albeit much slower) search implementation. I have confidence that the helper does the right thing, so I can use it to test an implementation I am much less sure about.</para><para>I start by running 1,000 experiments on arrays of size up to 1,000. The tests take a fraction of a second, and everything passes. Good. Time to explore a little more (remember that <indexterm id="idx-CHP-7-0371" significance="normal"><primary>testing</primary></indexterm>testing is an exploratory activity).</para><para>I change the experiment and <literal moreinfo="none">maxArraySize</literal> values to 10,000, then 100,000. The tests now take closer to a minute, and my CPU maxes out. I feel like I am giving the code a really good workout.</para><para>My confidence is building, but one of my beliefs is: <emphasis>If all your tests pass, chances are that your tests are not good enough</emphasis>. What other properties should I test now that I have this framework?</para><para>I think for a bit and notice that my two theories are both of the form:</para><blockquote><para>If something is true about the return value of <literal moreinfo="none">binarySearch</literal>, then something else must be true about the <literal moreinfo="none">testArray</literal> and the <literal moreinfo="none">target</literal>.</para></blockquote><para>In other words, I have logic of the form <emphasis>p</emphasis> implies <emphasis>q</emphasis> (or, <emphasis>p</emphasis> → <emphasis>q</emphasis>, using logic notation), which means I am only <indexterm id="idx-CHP-7-0372" significance="normal"><primary>binary search</primary><secondary>testing</secondary></indexterm>testing half of what I should be <indexterm id="idx-CHP-7-0373" significance="normal"><primary>testing</primary><secondary>binary search</secondary><tertiary>random testing</tertiary></indexterm>testing. I should also have tests of the form <emphasis>q</emphasis> → <emphasis>p</emphasis>:<footnote id="CHP-7-FNOTE-10"><para>Of course, either <emphasis>p, q</emphasis>, or both, could be negated (e.g., <emphasis>~p →~q</emphasis>, or <emphasis>p →~q</emphasis>). I am arbitrarily using <emphasis>p</emphasis> and <emphasis>q</emphasis> as stand-ins for any predicate about the return value and the array parameter, respectively. What's important here is to recognize that when you are programming, you typically think in terms of <emphasis>p → q</emphasis> (if <emphasis>p</emphasis> is true, then <emphasis>q</emphasis> must happen—the so-called <emphasis>happy path</emphasis>: the normal, most common usage of the code). When you are testing, however, you must force yourself to think both backward (<emphasis>q → ?</emphasis>, or if <emphasis>q</emphasis> is true what must be true about <emphasis>p</emphasis>?), and in negative terms (if p is not true [i.e., <emphasis>~p</emphasis>], what must be true about <emphasis>q</emphasis>?).</para></footnote></para><blockquote><para>If something is true about the <literal moreinfo="none">testArray</literal> and the <literal moreinfo="none">target</literal>, then something else must be true about the return value.</para></blockquote><para>This is a bit tricky, but important, so let me clarify with some specifics. The tests for Theory 1 verify that when the return value is −1, the target element is not in the array. But they don't verify that when the target element is not in the array, the return value is −1. In other words: <emphasis>if I only had this one theory with which to test</emphasis>, an implementation that returned −1 sometimes, but not <emphasis>every</emphasis> time it should, would still pass all my tests. A similar problem exists with Theory 2.</para><para>I can demonstrate this with <emphasis>mutation testing</emphasis>, a technique for <emphasis>testing the tests</emphasis> invented by Jeff Offut. The basic idea is to mutate the code under tests with some known bugs. If the tests you have still pass despite the bug in the code, then the tests are probably not as thorough as they need to be.</para><para>Let me mutate <literal moreinfo="none">binarySearch</literal> in some drastic and arbitrary way. I'll try do this: if <literal moreinfo="none">target</literal> is greater than 424242 and <literal moreinfo="none">target</literal> is not contained in the array, instead of returning −1, I am going to return <emphasis>−42</emphasis>. How's that for software vandalism? See the tail end of the following code:</para><programlisting id="I_programlisting7_tt84" format="linespecific">
	public static int <indexterm id="idx-CHP-7-0374" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm>binarySearch(int[] a, int target) {
	    int low = 0;
	    int high = a.length - 1;

	    while (low &lt;= high) {
	        int mid = (low + high) / 2;
	        int midVal = a[mid];

	        if (midVal &lt; target)
	            low = mid + 1;
	        else if (midVal &gt; target)
	            high = mid - 1;
	        else
	            return mid;
	    }
	    if (target &lt;= 424242)
	        return -1;
	    else
	        return -42;
	}
</programlisting><para>Hopefully, you'll agree that this is a pretty big mutation: the code returns an unexpected and unspecified value if the target is a number greater than 424242 and is not contained in the array. And yet, all the tests we have written so far pass with flying colors.</para><para>We definitely need to add at least a couple more theories to make the tests tighter and catch this category of mutations:</para><blockquote><para>Theory 3: If <replaceable>testArray</replaceable> does not contain <replaceable>target</replaceable>, then it must return <literal moreinfo="none">-1</literal>.</para><para>Theory 4: If <replaceable>testArray</replaceable> contains <replaceable>target</replaceable> at position <replaceable>n</replaceable>, then <literal moreinfo="none">binarySearch</literal> <replaceable>(testArray, target</replaceable>) must return <replaceable>n</replaceable>.</para></blockquote><para>These theories are tested as follows:</para><programlisting id="I_programlisting7_tt85" format="linespecific">
	public void assertTheory3(int[] testArray, int target, int returnValue) {
	    if (!arrayContainsTarget(testArray, target))
	        assertEquals(-1, returnValue);
	}

	public void assertTheory4(int[] testArray, int target, int returnValue) {
	        assertEquals(getTargetPosition(testArray, target), returnValue);
	}

	public int getTargetPosition(int[] testArray, int target) {
	    for (int i = 0; i &lt; testArray.length; i++)
	        if (testArray[i] == target)
	            return i;
	    return -1;
	}
</programlisting><para>Notice that I had to create another helper method, <literal moreinfo="none">getTargetPosition</literal>, which has exactly the same behavior as <literal moreinfo="none">binarySearch</literal> (but I am confident that it works properly, with the huge downside that it requires up to <emphasis>n</emphasis> instead of log<subscript>2</subscript> <emphasis>n</emphasis> comparisons). Because <literal moreinfo="none">getTargetPosition</literal> is very similar to <literal moreinfo="none">arrayContainsTarget</literal>, and code duplication is bad, I rewrite the latter as follows:</para><programlisting id="I_programlisting7_tt86" format="linespecific">
	public boolean arrayContainsTarget(int[] testArray, int target) {
	    return getTargetPosition(testArray, target) &gt;= 0;
	}
</programlisting><para>I run these tests again with my <indexterm id="idx-CHP-7-0375" significance="normal"><primary>testing</primary><secondary>binary search</secondary><tertiary>random testing</tertiary></indexterm>random-array generator, and now the <literal moreinfo="none">return-42</literal> mutation is caught immediately. Good, that helps my confidence. I remove the intentional bug and run the tests again. I expect them to pass, but they don't. Some tests for Theory 4 are not passing. JUnit is failing with messages of the form:</para><programlisting id="I_programlisting7_tt87" format="linespecific">
	expected:&lt;n&gt; but was:&lt;n + 1&gt;
</programlisting><para>Theory 4 says that:</para><blockquote><para>If <replaceable>testArray</replaceable> contains <replaceable>target</replaceable> at position <replaceable>n</replaceable>, then <literal moreinfo="none">binarySearch</literal>(<replaceable>testArray, target</replaceable>) must return <replaceable>n</replaceable>.<indexterm id="idx-CHP-7-0376" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm></para></blockquote><para>So, in some cases, the search routine is returning a location that's off by one. How's that possible?</para><para>I need a bit more data. JUnit's assertions can accept a message of type <literal moreinfo="none">String</literal> as the first parameter, so I change Theory 4's <literal moreinfo="none">assertEqual</literal> to include some text that will give me more information when it fails:</para><programlisting id="I_programlisting7_tt88" format="linespecific">
	public void assertTheory4(int[] testArray, int target, int returnValue) {
	  String testDataInfo = "Theory 4 - Array=" +
	        printArray(testArray)
	        + " target="
	        + target;
	  assertEquals(testDataInfo, getTargetPosition(testArray, target), returnValue);
	}
</programlisting><para>Now, whenever Theory 4 fails to hold, JUnit will show me the contents of the array as well as the target value. I run the tests again (with small values of <literal moreinfo="none">maxArraySize</literal> and <literal moreinfo="none">maxValue</literal> to make the output easier to read) and get the following:</para><programlisting id="I_programlisting7_tt89" format="linespecific">
	java.lang.AssertionError: Theory 4 - Array=[2, 11, 36, 66, 104, 108, 108, 108, 122,
	155, 159, 161, 191] target=108 expected:&lt;5&gt; but was:&lt;6&gt;
</programlisting><para>I see what's happening. Theory 4 does not take into account duplicate values, and I hadn't thought of that. There are three instances of the number 108. I guess I need to find out what the specification is for handling duplicate values, and fix either the code or my theory and tests. But I'll leave this as an exercise to the reader (I always wanted to say that!) because I am running out of space, and I want to say a few words about performance tests before we wrap up this chapter.</para></sect2><sect2 id="performance_anxiety" label="7.3.4"><title>Performance Anxiety</title><para>The tests we've already run based on these theories put a pretty tight net around the implementation. It's going to be tough to pass all these tests and still have a buggy implementation. But there is something we overlooked. All the tests we have are good tests for search, but what we are <indexterm id="idx-CHP-7-0377" significance="normal"><primary>testing</primary></indexterm>testing is specifically a <emphasis>binary</emphasis> search. We need a set of tests for <emphasis>binary-ness</emphasis>. We need to see whether the number of <indexterm id="idx-CHP-7-0378" significance="normal"><primary>comparisons</primary></indexterm>comparisons our implementation performs matches the expectations of a maximum of log<subscript>2</subscript> <emphasis>n</emphasis> comparisons. How can we go about this?<indexterm id="idx-CHP-7-0379" significance="normal"><primary>binary search</primary><secondary>testing</secondary><tertiary>performance</tertiary></indexterm><indexterm id="idx-CHP-7-0380" significance="normal"><primary>binary-ness</primary></indexterm></para><para>My first thought is to use the system clock, but I quickly dismiss the idea because the clock I have available does not have enough resolution for this particular challenge (<indexterm id="idx-CHP-7-0381" significance="normal"><primary>testing</primary><secondary>binary search</secondary></indexterm>binary search is blazingly fast), and I can't really control the execution environment. So, I use another developer <indexterm id="idx-CHP-7-0382" significance="normal"><primary>binary search</primary><secondary>testing</secondary></indexterm>testing trick: I create an alternate implementation of <literal moreinfo="none">binarySearch</literal> called <literal moreinfo="none">binarySearchComparisonsCount</literal>. This version of the code uses the same logic as the original, but it keeps a count of the comparisons and returns that number instead of −1 or the target location.<footnote id="CHP-7-FNOTE-11"><para>Instead of modifying <literal moreinfo="none">binarySearch</literal> to return the comparison count, a better, cleaner, and more object-oriented design (suggested by David Saff) would be to create a <literal moreinfo="none">CountingComparator</literal> class that implements Java's generalized Comparator interface and to modify <literal moreinfo="none">binarySearch</literal> to take an instance of that class as a third parameter. This would generalize <literal moreinfo="none">binarySearch</literal> to work with types other than integers, another example of how <indexterm id="idx-CHP-7-0383" significance="normal"><primary>performance</primary><secondary>testing for binary search</secondary></indexterm>testing can lead to better design and more beautiful code.</para></footnote> Here's that code:</para><programlisting id="I_programlisting7_tt90" format="linespecific">
	public static int binarySearchComparisonCount(int[] a, int target) {
	    int low = 0;
	    int high = a.length - 1;

	    int comparisonCount = 0;

	    while (low &lt;= high) {

	        comparisonCount++;

	        int mid = (low + high) &gt;&gt;&gt; 1;
	        int midVal = a[mid];

	        if (midVal &lt; target)
	            low = mid + 1;
	        else if (midVal &gt; target)
	            high = mid - 1;
	        else
	            return comparisonCount;
	    }
	    return comparisonCount;
	}
</programlisting><para>Then I create another theory based on that code:</para><blockquote><para>Theory 5: If the size of <replaceable>testArray</replaceable> is <replaceable>n</replaceable>, then <replaceable>binarySearchComparisonCount(testArray, target</replaceable>) must return a number less than, or equal to, 1 + log2 <replaceable>n</replaceable>.</para></blockquote><para>Here's the code for the theory:</para><programlisting id="I_programlisting7_tt91" format="linespecific">
	public void assertTheory5(int[] testArray, int target) {
	    int numberOfComparisons =
	        Util.binarySearchComparisonCount(testArray, target);
	    assertTrue(numberOfComparisons &lt;= 1 + log2(testArray.length));
	}
</programlisting><para>I add this latest theory to my existing list inside the method <literal moreinfo="none">testTheories</literal>, which now looks like this:</para><programlisting id="I_programlisting7_tt92" format="linespecific">
	...
	    while (experiments-- &gt; 0) {
	        testArray = generateRandomSortedArray( );
	        if (rand.nextInt( ) % 2 == 0) {
	            target = testArray[rand.nextInt(testArray.length)];
	        } else {
	            target = rand.nextInt( );
	        }
	        returnValue = Util.binarySearch(testArray, target);
	        assertTheory1(testArray, target, returnValue);
	        assertTheory2(testArray, target, returnValue);
	        assertTheory3(testArray, target, returnValue);
	        assertTheory4(testArray, target, returnValue);
	        assertTheory5(testArray, target);
	    }
	...
</programlisting><para>I run a few tests with a <literal moreinfo="none">maxArraySize</literal> set of a few different values, and I find that Theory 5 seems to be holding strong.</para><para>Because it's almost noon, I set the number of <literal moreinfo="none">experiments</literal> to 1,000,000 and go to lunch while my computer crunches away and tests each theory a million times.</para><para>When I get back, I see that all my tests pass. There are probably a couple more things that I would want to test, but I have made great progress in boosting <emphasis>my</emphasis> confidence in this implementation of <literal moreinfo="none">binarySearch</literal>. Because different developers have different backgrounds, styles, and levels of experience, you might have focused on different areas of the code. A developer already familiar with the unsigned shift operator, for example, would not feel the same need I had to test it.</para><para>In this section, I wanted to give you a flavor of performance <indexterm id="idx-CHP-7-0384" significance="normal"><primary>testing</primary></indexterm>testing and show you how you could gain insight into and confidence in your code's performance by combining code instrumentation with test theories. I highly recommend you study <xref linkend="the_most_beautiful_code_i_never_wrote"/>, where Jon Bentley gives this important topic the attention and beautiful treatment it deserves.</para></sect2></sect1><sect1 id="conclusion-id004" label="7.4"><title>Conclusion</title><para>In this chapter, we have seen that even the best developers and the most beautiful code can benefit from <indexterm id="idx-CHP-7-0385" significance="normal"><primary>binary search</primary><secondary>testing</secondary></indexterm>testing. We have also seen that writing test code can be every bit as creative and challenging as writing the target code. And, hopefully, I've shown you that tests themselves can be considered beautiful in at least three different ways.</para><para>Some tests are beautiful for their simplicity and efficiency. With a few lines of JUnit code, run automatically with every build, you can document the code's intended behavior and boundaries, and ensure that both of them are preserved as the code evolves.</para><para>Other tests are beautiful because, in the process of writing them, they help you improve the code they are meant to test in subtle but important ways. They may not discover proper bugs or defects, but they bring to the surface problems with the design, testability, or maintainability of the code; they help you make your code more beautiful.</para><para>Finally, some tests are beautiful for their breadth and thoroughness. They help you gain confidence that the functionality and performance of the code match requirements and expectations, not just on a few handpicked examples, but with a wide range of inputs and conditions.</para><para>Developers who want to write beautiful code can learn something from artists. Painters regularly put down their brushes, step away from the canvas, circle it, cock their heads, squint, and look at it from different angles and under different lights. They need to develop and integrate those perspectives in their quest for beauty. If your canvas is an IDE and your medium is code, think of testing as your way of stepping away from the canvas to look at your work with critical eyes and from different perspectives—it will make you a better programmer and help you create more beautiful code.<indexterm id="I_indexterm7_tt93" class="endofrange" startref="idx-CHP-7-0320" significance="normal"><primary>testing</primary></indexterm></para></sect1></chapter><chapter id="on-the-fly_code_generation_for_image_processing" label="8" role=""><title>On-the-Fly Code Generation for Image Processing</title><para><emphasis>Charles Petzold</emphasis><indexterm id="idx-CHP-8-0386" significance="normal"><primary>code generation</primary></indexterm><indexterm id="idx-CHP-8-0387" significance="normal"><primary>image processing code</primary></indexterm><indexterm id="idx-CHP-8-0388" significance="normal"><primary>Petzold</primary></indexterm></para><para><emphasis>Among the pearls of wisdom and wackiness chronicled</emphasis> in Steven Levy's classic history <emphasis>Hackers: Heroes of the Computer Revolution</emphasis> (Doubleday), my favorite is this one by Bill Gosper, who once said, "Data is just a dumb kind of programming." The corollary, of course, is that code is just a smart kind of data—data designed to trigger processors into performing certain useful or amusing acts.</para><para>The potential interplay of <indexterm id="idx-CHP-8-0389" significance="normal"><primary>code and data</primary></indexterm>code and data tends to be discouraged in most conventional programming instruction. Code and data are usually severely segregated; even in object-oriented programming, code and data have their own special roles to play. Any intermingling of the two—such as data being executed as if it were machine code—is considered to be a violation of natural law.</para><para>Only occasionally is this barrier between code and data breached. Compiler authors write programs that read source code and generate machine code, but compilers do not really violate the separation of code and data. Where the input and output are code to the human programmers, they are just data to the compilers. Other odd jobs, such as those performed by disassemblers or simulators, also read machine code as if it were data.</para><para>As we all accept rationally, if not emotionally, code and data are ultimately just bytes, and there are only 256 of them in the entire universe. It's not the bytes themselves but their ordering that gives them meaning and purpose.</para><para>In some special cases, it can be advantageous for <indexterm id="idx-CHP-8-0390" significance="normal"><primary>programs generating code while running</primary></indexterm>programs that are not compilers to generate code while they're running. This <emphasis>on-the-fly code generation</emphasis> is not easy, so it's usually restricted to very particular circumstances.<indexterm id="idx-CHP-8-0391" significance="normal"><primary>code generation</primary></indexterm></para><para>Throughout this chapter, we will use an example that embodies the most common reason for using on-the-fly code generation. In this example, a time-critical subroutine must perform many repetitive operations. A number of generalized parameters come into play during the execution of these repetitive operations, and the subroutine could run a lot faster if we replaced those generalized parameters with specific values. We can't replace those parameters while we're writing the subroutine because the parameters aren't known until runtime, and they can change from one invocation to the next. However, the subroutine itself could do the code generation while it's running. In other words, the subroutine can examine its own parameters at runtime, generate more efficient code, and then execute the resulting code.</para><para>I first stumbled upon this technique while writing assembly language. I had a subroutine that performed many repetitive operations. At a crucial point, the subroutine would execute either a bitwise AND operation or a bitwise OR operation, depending on some other value that remained constant during these operations. The actual testing of this value to perform the AND or OR operation was inside the loop and was itself taking too much time. I considered splitting the routine into two entirely separate routines, one with the AND operation and one with the OR operation, until I realized that the subroutine could begin by examining the value, then insert the actual AND or OR machine code instruction right into the execution stream.</para><para>The technique of on-the-fly code generation was implemented in a much larger way in the first release of <indexterm id="idx-CHP-8-0392" significance="normal"><primary>Microsoft Windows (version 1.0)</primary></indexterm>Microsoft Windows (version 1.0), which came out in November 1985 and has since come to have some moderate success in the personal computer marketplace. From a programmer's perspective, the first version of Windows offered roughly 200 functions for creating graphical user interfaces and for displaying vector and raster graphics on both the screen and printer in a fairly device-independent manner.</para><para>Among the <indexterm class="startofrange" id="idx-CHP-8-0393" significance="normal"><primary>code generation</primary><secondary>graphics functions in Microsoft Windows 1.0</secondary></indexterm>graphics functions in Windows 1.0 was one called <emphasis>BitBlt</emphasis>, which was named after an instruction on the seminal Xerox Alto and stood for <emphasis>bit block transfer</emphasis>. In its most basic use, BitBlt rendered bitmaps on the screen and printer, but it was also used internally in Windows for displaying many user interface objects. More generally, BitBlt transferred rectangular arrays of pixels from a source to a destination. A related function called <emphasis>StretchBlt</emphasis> could stretch or compress the source pixels into a larger or smaller destination rectangle during this process.<indexterm id="idx-CHP-8-0394" significance="normal"><primary>BitBlt (bit block transfer) function (Windows 1.0)</primary></indexterm><indexterm id="idx-CHP-8-0395" significance="normal"><primary>StretchBlt function (Windows 1.0)</primary></indexterm></para><para>If the BitBlt source is a bitmap, and if the destination is the video display, BitBlt copies the pixels from the bitmap to the display, essentially rendering the bitmap on the screen. If the source is the display and the destination is a bitmap, BitBlt copies pixels from the screen to the bitmap. The bitmap <indexterm id="idx-CHP-8-0396" significance="normal"><primary>image processing code</primary></indexterm>image is then a captured screen image.</para><para>However, if you're writing a routine like BitBlt, you might imagine incorporating some extra value and utility that go beyond the mere transfer of bits. Suppose you want an option that will invert the pixels as they're transferred from the source to the destination; black pixels become white, light gray becomes dark gray, and green becomes magenta.</para><para>And suppose you then discover that a colleague would be overjoyed if BitBlt could examine the destination as it's transferring pixels, and transfer pixels from the source to the destination only if the destination pixels at each particular point are black. This feature would allow the display of nonrectangular images. For example, a black-filled circle could be drawn on the screen, and then BitBlt would display a bitmap only within that circle. And then somebody else requests an option that combines the ones just mentioned, in which BitBlt inverts its source pixels when the destination is black.</para><para>As you start investigating these types of options, you might discover a way to generalize them all. Consider a monochrome <indexterm id="idx-CHP-8-0397" significance="normal"><primary>code generation</primary><secondary>graphics functions in Microsoft Windows 1.0</secondary></indexterm>graphics system; every pixel is just one bit, where 0 means black and 1 means white. In such a system, a source bitmap is an array of 1-bit pixels, and the screen is an array of 1-bit pixels. The destination's color at a particular pixel location depends on the value of the source pixel (0 or 1) and the value of the destination pixel (0 or 1).</para><para>The result at the destination for any particular combination of source and destination pixels is called a <emphasis>raster operation</emphasis> or <emphasis>raster op</emphasis>, and there are 16 of them, as <xref linkend="basic_raster_ops"/> illustrates.<indexterm class="startofrange" id="idx-CHP-8-0398" significance="normal"><primary>raster operations</primary></indexterm></para><table id="basic_raster_ops" label="8-1"><title>Basic raster ops</title><tgroup cols="3"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><colspec colnum="3" colname="col3"/><thead><row><entry namest="col1" nameend="col3"><para><emphasis role="strong">Possible combinations</emphasis></para></entry></row></thead><tbody><row><entry><para><emphasis role="strong">Input parameter</emphasis></para></entry><entry><para><emphasis role="strong">Input value</emphasis></para></entry><entry><para/></entry></row><row><entry><para>Source (S):</para></entry><entry><para>1 1 0 0</para></entry><entry><para/></entry></row><row><entry><para>Destination (D):</para></entry><entry><para>1 0 1 0</para></entry><entry><para/></entry></row><row><entry><para><emphasis role="strong">Operation</emphasis></para></entry><entry><para><emphasis role="strong">Output</emphasis></para></entry><entry><para><emphasis role="strong">Logical representation</emphasis></para></entry></row><row><entry><para>Raster operation 0:</para></entry><entry><para>0 0 0 0</para></entry><entry><para>0</para></entry></row><row><entry><para>Raster operation 1:</para></entry><entry><para>0 0 0 1</para></entry><entry><para>~(S | D)</para></entry></row><row><entry><para>Raster operation 2:</para></entry><entry><para>0 0 1 0</para></entry><entry><para>~S &amp; D</para></entry></row><row><entry><para>Raster operation 3:</para></entry><entry><para>0 0 1 1</para></entry><entry><para>~S</para></entry></row><row><entry><para>Raster operation 4:</para></entry><entry><para>0 1 0 0</para></entry><entry><para>S &amp; ~D</para></entry></row><row><entry><para>Raster operation 5:</para></entry><entry><para>0 1 0 1</para></entry><entry><para>~D</para></entry></row><row><entry><para>Raster operation 6:</para></entry><entry><para>0 1 1 0</para></entry><entry><para>S ^ D</para></entry></row><row><entry><para>Raster operation 7:</para></entry><entry><para>0 1 1 1</para></entry><entry><para>~(S &amp; D)</para></entry></row><row><entry><para>Raster operation 8:</para></entry><entry><para>1 0 0 0</para></entry><entry><para>S &amp; D</para></entry></row><row><entry><para>Raster operation 9:</para></entry><entry><para>1 0 0 1</para></entry><entry><para>~(S ^ D)</para></entry></row><row><entry><para>Raster operation 10:</para></entry><entry><para>1 0 1 0</para></entry><entry><para>D</para></entry></row><row><entry><para>Raster operation 11:</para></entry><entry><para>1 0 1 1</para></entry><entry><para>~S | D</para></entry></row><row><entry><para>Raster operation 12:</para></entry><entry><para>1 1 0 0</para></entry><entry><para>S</para></entry></row><row><entry><para>Raster operation 13:</para></entry><entry><para>1 1 0 1</para></entry><entry><para>S |~D</para></entry></row><row><entry><para>Raster operation 14:</para></entry><entry><para>1 1 1 0</para></entry><entry><para>S | D</para></entry></row><row><entry><para>Raster operation 15:</para></entry><entry><para>1 1 1 1</para></entry><entry><para>1</para></entry></row></tbody></tgroup></table><para>There are four possible combinations of source and destination pixels, and each raster operation does something different for those four combinations, so the total number is 2<superscript>4</superscript>, or 16. Each of the 16 possible <indexterm id="idx-CHP-8-0399" significance="normal"><primary>raster operations</primary></indexterm>raster operations is identified by a number that corresponds to the <indexterm id="idx-CHP-8-0400" significance="normal"><primary>pattern or brush (graphical object)</primary></indexterm>pattern of resultant pixels shown in the table. The "Logical representation" column shows (in C syntax) the actual Boolean operation occurring between the source and destination pixels.</para><para>For example, in <emphasis>raster operation 12</emphasis> (the most common), the source is simply transferred to the destination and in <emphasis>raster operation 14</emphasis>, the source is transferred to the destination only when the destination is black. <emphasis>Raster operation 10</emphasis> leaves the destination the same regardless of the source. <emphasis>Raster operations 0</emphasis> and <emphasis>15</emphasis> simply color the destination black and white, respectively, again independent of the source.<indexterm id="idx-CHP-8-0401" significance="normal"><primary>BitBlt (bit block transfer) function (Windows 1.0)</primary><secondary>raster operations</secondary></indexterm></para><para>In a color <indexterm id="idx-CHP-8-0402" significance="normal"><primary>code generation</primary><secondary>graphics functions in Microsoft Windows 1.0</secondary></indexterm>graphics system, each pixel is generally 24-bits wide, with 8 bits each for the red, green, and blue primaries. If all bits are 0, the color is black; if all bits are 1, the color is white. The <indexterm id="idx-CHP-8-0403" significance="normal"><primary>StretchBlt function (Windows 1.0)</primary><secondary>raster operations</secondary></indexterm>raster operations are applied to corresponding bits of the source and destination. With raster operation 14, for example, the source is displayed in destination areas that were initially colored black. Destination areas initially colored white will remain white. However, if a destination area is red and the source is blue, the result will be a combination of red and blue, or magenta. This is different from the monochrome example, but still entirely predictable.</para><para>In <indexterm id="idx-CHP-8-0404" significance="normal"><primary>Microsoft Windows (version 1.0)</primary></indexterm>Windows, the raster operations for <indexterm id="idx-CHP-8-0405" significance="normal"><primary>raster operations</primary><secondary>BitBlt and StretchBlt functions</secondary></indexterm>BitBlt and StretchBlt were complicated even further. Windows supported a graphical object called a <emphasis>pattern</emphasis> or <emphasis>brush</emphasis>, which was commonly used for filling enclosed areas. This pattern could be a solid color or a repetitive <indexterm id="idx-CHP-8-0406" significance="normal"><primary>image processing code</primary></indexterm>image, such as hash marks or bricks. To carry out this type of operation, BitBlt and StretchBlt performed a raster operation between the source, the destination, and a particular pattern. This pattern allowed the program to alter pixel bits of the source (perhaps inverting them or masking them) without regard to the destination.</para><para>Because the raster operation implemented by BitBlt and StretchBlt involved three objects—a source, destination, and pattern—it was called a <emphasis>ternary</emphasis> raster operation. There are 256 possible <indexterm id="idx-CHP-8-0407" significance="normal"><primary>ternary raster operation</primary></indexterm>ternary raster operations, and BitBlt and StretchBlt supported every single one.</para><para>As in our earlier discussion, these 256 ternary <indexterm id="idx-CHP-8-0408" significance="normal"><primary>raster operations</primary></indexterm>raster operations are easier to comprehend if you begin by considering a monochrome <indexterm id="idx-CHP-8-0409" significance="normal"><primary>code generation</primary><secondary>graphics functions in Microsoft Windows 1.0</secondary></indexterm>graphics system. In addition to the source and destination, the pattern is also an array of 1-bit pixels; visualize the pattern overlaying a destination surface. <xref linkend="ternary_raster_ops"/> shows selections from the 256 ways in which the 0 and 1 pixels of the pattern, source, and destination can be combined.</para><table id="ternary_raster_ops" label="8-2"><title>Ternary raster ops</title><tgroup cols="2"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><thead><row><entry namest="col1" nameend="col2"><para><emphasis role="strong">Possible Combination</emphasis></para></entry></row></thead><tbody><row><entry><para><emphasis role="strong">Input parameter</emphasis></para></entry><entry><para><emphasis role="strong">Input value</emphasis></para></entry></row><row><entry><para>Pattern (P):</para></entry><entry><para>1 1 1 1 0 0 0 0</para></entry></row><row><entry><para>Source (S):</para></entry><entry><para>1 1 0 0 1 1 0 0</para></entry></row><row><entry><para><emphasis role="strong">Operation</emphasis></para></entry><entry><para><emphasis role="strong">Output</emphasis></para></entry></row><row><entry><para>Raster operation 0x00:</para></entry><entry><para>0 0 0 0 0 0 0 0</para></entry></row><row><entry><para>Raster operation 0x01:</para></entry><entry><para>0 0 0 0 0 0 0 1</para></entry></row><row><entry><para>Raster operation 0x02:</para></entry><entry><para>0 0 0 0 0 0 1 0</para></entry></row><row><entry><para>…</para></entry><entry><para>…</para></entry></row><row><entry><para>Raster operation 0x60:</para></entry><entry><para>0 1 1 0 0 0 0 0</para></entry></row><row><entry><para>…</para></entry><entry><para>…</para></entry></row><row><entry><para>Raster operation 0xFD:</para></entry><entry><para>1 1 1 1 1 1 0 1</para></entry></row><row><entry><para>Raster operation 0xFE:</para></entry><entry><para>1 1 1 1 1 1 1 0</para></entry></row><row><entry><para>Raster operation 0xFF:</para></entry><entry><para>1 1 1 1 1 1 1 1</para></entry></row></tbody></tgroup></table><para>This table shows sample inputs followed by the resulting destinations for 7 of the 256 possible ternary raster operations. Each of these raster operations can be identified by a one-byte hexadecimal number corresponding to the pattern of resultant destination bits shown in the table. For example, for <emphasis>raster operation 0x60</emphasis>, if the pattern pixel is 1 (white), the source pixel is 0 (black), and the destination pixel is 1, the destination will be 1 (white).</para><para>In the early versions of Windows, 15 of the total 256 raster operations were identified with names in both the documentation and the Windows header file that C programmers used. The first—where the destination is colored with all 0s regardless of the pattern, source, and destination—was known as BLACKNESS; the last was called WHITENESS.</para><para>The Windows programming reference identified all 256 raster operations by the bitwise Boolean operation they performed, expressed in reverse Polish notation. For example, raster operation 0x60 corresponds to the Boolean operation <emphasis>PDSxa</emphasis>.</para><para>This means that an Exclusive-OR (x) operation is performed between the destination (D) and the source (S), and the result is combined with the pattern (P) in a bitwise AND operation (a). In color systems, the same Boolean operation is performed among the color bits of the source, destination, and pattern. As of this writing, these raster operations are documented online at <indexterm id="idx-CHP-8-0410" significance="normal"><primary>Microsoft Windows (version 1.0)</primary></indexterm><ulink url="http://msdn.microsoft.com/library/en-us/gdi/pantdraw_6n77.asp"/>.</para><para>Some of these <indexterm id="idx-CHP-8-0411" significance="normal"><primary>raster operations</primary></indexterm>raster operations are quite useful in certain circumstances. For example, you might want to invert the destination pixels that correspond to areas where a brush is black, but display a source bitmap in areas where the brush is white. That's <emphasis>raster operation 0xC5</emphasis>. Of course, many of the 256 possibilities have little practical use, and I suspect that most of them have never been used outside of demonstration or exploratory <indexterm id="idx-CHP-8-0412" significance="normal"><primary>code generation</primary></indexterm>code. Still, the sense of completeness and versatility is quite satisfying.</para><para>If we were implementing this versatile BitBlt function ourselves, how would we do it? Assume that it's 1985 and we're using the C programming language. For illustrative purposes, let's also assume that we're dealing with a one-byte-per-pixel gray shade <indexterm id="idx-CHP-8-0413" significance="normal"><primary>code generation</primary><secondary>graphics functions in Microsoft Windows 1.0</secondary></indexterm>graphics system, and that the source, destination, and pattern can be accessed through two-dimensional arrays named <literal moreinfo="none">S, D</literal>, and <literal moreinfo="none">P</literal>. That is, each of these variables is a pointer to a collection of byte pointers, and each byte pointer points to the beginning of a horizontal row of pixels, so that <replaceable>S[y][x]</replaceable> accesses the byte at row <replaceable>y</replaceable> and column <replaceable>x</replaceable>. The width and height of the area you're working with is stored in <replaceable>cx</replaceable> and <replaceable>cy</replaceable> (this is a traditional <indexterm id="idx-CHP-8-0414" significance="normal"><primary>Microsoft Windows (version 1.0)</primary></indexterm>Windows programming variable-naming convention: the <emphasis>c</emphasis> stands for <emphasis>count</emphasis>, so these variables indicate a count of x and y values, or width and height). The <literal moreinfo="none">rop</literal> variable stores a raster operation <indexterm id="idx-CHP-8-0415" significance="normal"><primary>bitmaps</primary><secondary>code dealing with</secondary></indexterm>code from 0 to 255.</para><para>Here's some simple <indexterm id="idx-CHP-8-0416" significance="normal"><primary>BitBlt (bit block transfer) function (Windows 1.0)</primary><secondary>C code implementing</secondary></indexterm>C code to implement using BitBlt. A <literal moreinfo="none">switch</literal> statement uses <literal moreinfo="none">rop</literal> to determine which operation is performed to calculate the pixel values in the destination. Only 3 of the 256 raster operations are shown here, but you get the general idea:</para><programlisting id="I_programlisting8_tt94" format="linespecific">
	for (y = 0; y &lt; cy; y++)
	for (x = 0; x &lt; cx; x++)
	{
	     switch(rop)
	     {
	     case 0x00:
	          D[y][x] = 0x00;
	          break;
	     ...
	     case 0x60:
	          D[y][x] = (D[y][x] ^ S[y][x]) &amp; P[y][x];
	          break;
	     ...
	     case 0xFF:
	          D[y][x] = 0xFF;
	          break;
	     }
	}
</programlisting><para>This certainly is <emphasis>pretty</emphasis> code, which means that it's nice to look at and certainly crystal clear in its intentions and functionality. But beautiful code it is <emphasis>not</emphasis>, because beautiful code is also satisfying when you run it.</para><para>This code is actually a <emphasis>disaster</emphasis> because it deals with bitmaps, and bitmaps can be <emphasis>huge</emphasis>. These days, bitmaps that come out of inexpensive digital cameras can have <emphasis>millions</emphasis> of pixels. Do you really want that <literal moreinfo="none">switch</literal> statement to be inside the row and column loops?</para><para>Should the <literal moreinfo="none">switch</literal> logic be executed for each and every pixel? Probably not. Moving the loops inside each <literal moreinfo="none">case</literal> certainly clutters up the <indexterm id="idx-CHP-8-0417" significance="normal"><primary>code generation</primary></indexterm>code, but now at least it has a fighting chance of reasonable performance:</para><programlisting id="I_programlisting8_tt95" format="linespecific">
	switch(rop)
	{
	case 0x00:
	     for (y = 0; y &lt; cy; y++)
	     for (x = 0; x &lt; cx; x++)
	          D[y][x] = 0x00;
	     break;
	...
	case 0x60:
	     for (y = 0; y &lt; cy; y++)
	     for (x = 0; x &lt; cx; x++)
	          D[y][x] = (D[y][x] ^ S[y][x]) &amp; P[y][x];
	     break;
	...
	case 0xFF:
	     for (y = 0; y &lt; cy; y++)
	     for (x = 0; x &lt; cx; x++)
	          D[y][x] = 0xFF;
	     break;
	}
</programlisting><para>Of course, if it really were 1985 and you were writing Windows, you wouldn't even be doing it in C. <indexterm id="idx-CHP-8-0418" significance="normal"><primary>C language</primary><secondary>early Windows applications</secondary></indexterm>Early Windows <emphasis>applications</emphasis> were mostly written in C, but Windows itself was written in <indexterm id="idx-CHP-8-0419" significance="normal"><primary>8086 assembly language (Windows 1.0)</primary></indexterm>8086 assembly language.</para><para>For something as important to Windows as BitBlt, an even more radical solution was required—something even faster than assembly language, as incredible as that may seem. The <indexterm id="idx-CHP-8-0420" significance="normal"><primary>Microsoft Windows (version 1.0)</primary></indexterm>Microsoft programmers who implemented BitBlt were quite proud of what they had done, and those of us learning Windows programming in the mid-1980s were equally impressed when they bragged of their achievement.</para><para>The BitBlt function actually contained a mini compiler of sorts. Based on the raster operation (as well as the <indexterm id="idx-CHP-8-0421" significance="normal"><primary>code generation</primary><secondary>graphics functions in Microsoft Windows 1.0</secondary></indexterm>graphics format, the number of bits per pixel, and the size of the area), the BitBlt function assembled <indexterm id="idx-CHP-8-0422" significance="normal"><primary>BitBlt (bit block transfer) function (Windows 1.0)</primary><secondary>8086 machine code instructions as subroutine</secondary></indexterm>8086 machine code instructions on the stack in the form of a subroutine and then executed it. This makeshift machine code routine looped through all the pixels and performed the requested raster operation.</para><para>It was the perfect solution to implementing BitBlt and its 256 <indexterm id="idx-CHP-8-0423" significance="normal"><primary>raster operations</primary></indexterm>raster operations. Although this mini compiler required a bit of overhead to put the machine code together on the stack, the per-pixel <indexterm id="idx-CHP-8-0424" significance="normal"><primary>image processing code</primary></indexterm>processing was as fast as possible, and that's what is most important when working with bitmaps. Moreover, the BitBlt code in Windows was probably much shorter than it would have been had it contained explicit code for all 256 raster operations.</para><para>It was even possible to get a little glimpse into the workings of this BitBlt mini compiler by examining the documentation of the ternary <indexterm id="idx-CHP-8-0425" significance="normal"><primary>raster operations</primary></indexterm>raster operations. For example, the raster operation identified by the number 0x60 implements a Boolean operation of <literal moreinfo="none">PDSxa</literal>. When calling BitBlt, you actually supply a 32-bit raster operation code, which is documented as <literal moreinfo="none">0x00600365</literal> for this operation. Notice the <literal moreinfo="none">0x60</literal> byte embedded in that number, but also take note that the bottom two bytes form the number 0x0365.</para><para>The raster operation with the result of 11110110 or 0xF6 has the Boolean operation <literal moreinfo="none">PDSxo</literal>, which is very similar to <literal moreinfo="none">PDSxa</literal> except that it performs an OR operation rather than AND. The complete 32-bit raster operation code passed to the BitBlt function is <literal moreinfo="none">0x00F70265</literal>. The bottom two bytes form the number 0x0265, which is very close to the 0x0365 of <literal moreinfo="none">PDSxa</literal>. If you examine more of these 32-bit raster operation codes, it becomes very obvious that the raster operation code itself serves as a template of sorts for the BitBlt mini compiler to assemble the proper machine code. That technique saves BitBlt both the memory and time required to use a lookup table.</para><para>Of course, Windows 1.0 was created over 20 years ago. We have all moved on, and so has Windows itself. These days my preferred programming language is neither assembly language nor C, but <indexterm id="idx-CHP-8-0426" significance="normal"><primary>C#</primary></indexterm>C#. I usually write what's called <emphasis>managed code</emphasis> that runs under the <indexterm id="idx-CHP-8-0427" significance="normal"><primary>Microsoft Windows (version 1.0)</primary></indexterm>Microsoft .NET Framework. The C# compiler turns my source code into processor-independent <emphasis>Intermediate Language</emphasis> (often referred to as Microsoft Intermediate Language, or MSIL). Only later, when the program is run, does the <indexterm id="idx-CHP-8-0428" significance="normal"><primary sortas="NET Common Language Runtime">.NET Common Language Runtime</primary></indexterm>.NET Common Language Run-time use a just-in-time compiler to convert that Intermediate Language into machine code appropriate for the runtime processor.<indexterm id="idx-CHP-8-0429" significance="normal"><primary>managed code</primary></indexterm><indexterm id="idx-CHP-8-0430" significance="normal"><primary>Intermediate Language (IL)</primary></indexterm></para><para>And yet digital <indexterm id="idx-CHP-8-0431" significance="normal"><primary>image processing code</primary></indexterm>image processing of all sorts still cries out for unusual approaches to coding. When working with millions of pixels, the per-pixel processing has to be fast, fast, fast. For commercial products, you will probably want to hire an assembly language programmer or someone who knows how to target the <indexterm id="idx-CHP-8-0432" significance="normal"><primary>code generation</primary><secondary>graphics functions in Microsoft Windows 1.0</secondary></indexterm>Graphics Processing Unit (GPU) found on video boards. Even for casual or noncommercial software, you will probably want something faster than the normal high-level language loop.</para><para>I was recently reminded of the on-the-fly <indexterm id="idx-CHP-8-0433" significance="normal"><primary>code generation</primary></indexterm>code generation of the original Windows BitBlt function while experimenting with some C# <indexterm id="idx-CHP-8-0434" significance="normal"><primary>C#</primary><secondary>code to implement digital image filters</secondary></indexterm>code to implement <indexterm id="idx-CHP-8-0435" significance="normal"><primary>digital image filters</primary></indexterm>digital image filters, also called <emphasis>image filters</emphasis> or <emphasis>digital filters</emphasis>. Raster operations such as those implemented in the Windows BitBlt and StretchBlt functions apply only to corresponding pixels of a source, destination, and pattern. <indexterm id="idx-CHP-8-0436" significance="normal"><primary>bitmaps</primary><secondary>digital filter applied to</secondary></indexterm>Digital filters take <emphasis>surrounding</emphasis> pixels into account. You apply a particular digital filter to a bitmap to change it in some way, perhaps to sharpen the edges or even blur the overall image. A blur filter, for example, averages a group of surrounding pixels to calculate a destination pixel.<indexterm id="idx-CHP-8-0437" significance="normal"><primary>image filters</primary></indexterm><indexterm id="idx-CHP-8-0438" significance="normal"><primary>digital filters</primary></indexterm></para><para>Simple digital image filters are often implemented as small arrays of numbers. These arrays are usually square and have an odd number of rows and columns. <xref linkend="simple_digital_image_filter"/> shows a simple example.<indexterm id="I_indexterm8_tt96" class="endofrange" startref="idx-CHP-8-0398" significance="normal"><primary>raster operations</primary></indexterm><indexterm id="I_indexterm8_tt97" class="endofrange" startref="idx-CHP-8-0393" significance="normal"><primary>code generation</primary><secondary>graphics functions in Microsoft Windows 1.0</secondary></indexterm></para><figure id="simple_digital_image_filter" label="8-1" float="0"><title>Simple digital image filter</title><mediaobject id="I_mediaobject8_tt98"><imageobject role="print"><imagedata fileref="figs/print/beauty_0801.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0801.png" format="PNG"/></imageobject></mediaobject></figure><para><xref linkend="simple_digital_image_filter"/> is a 3 x 3 filter, and you can think of it as transforming a source bitmap into a destination bitmap. For each pixel of the source bitmap, align this filter so its center is over the desired pixel and the other eight cells are aligned with the surrounding pixels. Multiply the nine values in the filter by the nine source pixels, and add up the results. That's the corresponding pixel for the destination bitmap. If the pixels <indexterm id="idx-CHP-8-0439" significance="normal"><primary>code generation</primary></indexterm>encode color or transparency, you'll want to apply the filter to each color channel separately. Some filters have different arrays for the different color channels or are implemented with algorithms, but we'll stick to the really simple ones for this exercise.<indexterm id="idx-CHP-8-0440" significance="normal"><primary>bitmaps</primary><secondary>digital filter transforming source into destination bitmap</secondary></indexterm><indexterm id="idx-CHP-8-0441" significance="normal"><primary>image processing code</primary></indexterm></para><para>A filter with the value 1/9 in all its cells is a <indexterm id="idx-CHP-8-0442" significance="normal"><primary>blur filter</primary></indexterm>blur filter. Each pixel in the destination bitmap is an average of nine adjacent pixels in the source bitmap. It's convenient that the numbers add up to 1 so the image doesn't get any brighter or darker, but this filter could easily contain all 1s or any other number. All that would be necessary to compensate would be to divide the sum of the products by the sum of the filter cells (as will become apparent, I actually prefer that method).</para><para><xref linkend="sharpness_filter"/> shows a <indexterm id="idx-CHP-8-0443" significance="normal"><primary>sharpness filter</primary></indexterm>sharpness filter. This filter tends to highlight areas of high contrast.</para><figure id="sharpness_filter" label="8-2" float="0"><title>Sharpness filter</title><mediaobject id="I_mediaobject8_tt99"><imageobject role="print"><imagedata fileref="figs/print/beauty_0802.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0802.png" format="PNG"/></imageobject></mediaobject></figure><para>Let's suppose we're dealing with gray-shaded bitmaps with one byte per pixel. The pixels of the source bitmap are stored in a two-dimensional array named <literal moreinfo="none">S</literal>. Our job is to calculate the pixels of the destination array named <literal moreinfo="none">D</literal>. The horizontal and vertical sizes of both arrays are stored in the variables <literal moreinfo="none">cxBitmap</literal> and <literal moreinfo="none">cyBitmap</literal>. The <literal moreinfo="none">Filter</literal> is a two-dimensional array named <literal moreinfo="none">F</literal> with dimensions <literal moreinfo="none">cxFilter</literal> and <literal moreinfo="none">cyFilter</literal>. <xref linkend="naiumlve_c_code_to_apply_a_digital_filter"/> shows some simple C <indexterm id="idx-CHP-8-0444" significance="normal"><primary>C language</primary><secondary>code for applying a digital filter</secondary></indexterm>code for applying the filter.<indexterm id="idx-CHP-8-0445" significance="normal"><primary>digital image filters</primary><secondary>sharpness filter</secondary></indexterm></para><example id="naiumlve_c_code_to_apply_a_digital_filter" label="8-1"><title>Naïve C code to apply a digital filter</title><programlisting format="linespecific">
for (yDestination = 0; yDestination &lt; cyBitmap; yDestination++)
for (xDestination = 0; xDestination &lt; cxBitmap; xDestination++)
{
     double pixelsAccum = 0;
     double filterAccum = 0;

     for (yFilter = 0; yFilter &lt; cyFilter; yFilter++)
     for (xFilter = 0; xFilter &lt; cxFilter; xFilter++)
     {
          int ySource = yDestination + yFilter - cyFilter / 2;
          int xSource = xDestination + xFilter - cxFilter / 2;

          (if ySource &gt;= 0 &amp;&amp; ySource &lt; cyBitmap &amp;&amp;
              xSource &gt;= 0 &amp;&amp; xSource &lt; cxBitmap)
          {
               pixelsAccum += F[y][x] * S[y][x];
               filterAccum += F[y][x];
          }
     }
     if (filterAccum != 0)
          pixelsAccum /= filterAccum;

     if (pixelsAccum &lt; 0)
          D[y][x] = 0;

     else if (pixelsAccum &gt; 255)
          D[y][x] = 255;

     else
          D[y][x] = (unsigned char) pixelsAccum;
}
</programlisting></example><para>Notice that looping through the filter cells results in accumulating two totals. The <literal moreinfo="none">pixelsAccum</literal> variable is a sum of the products of the source bitmap values and the filter cells, while <literal moreinfo="none">filterAccum</literal> is a sum of the filter cells only. For destination pixels around the edges of the bitmap, some cells of the filter correspond to pixels outside the extent of the source bitmap. I prefer to ignore those cells by adding nothing to <literal moreinfo="none">pixelsAccum</literal> and <literal moreinfo="none">filterAccum</literal>, but to later divide <literal moreinfo="none">pixelsAccum</literal> by <literal moreinfo="none">filterAccum</literal> so that the destination pixel is approximately correct. That's why <literal moreinfo="none">filterAccum</literal> isn't calculated outside the loop and why the filter cells don't have to be normalized to add up to one. Also notice toward the end of this code that the ratio of <literal moreinfo="none">pixelsAccum</literal> to <literal moreinfo="none">filterAccum</literal> has to be clamped between 0 and 255 so no strange effects result.<indexterm id="idx-CHP-8-0446" significance="normal"><primary>code generation</primary></indexterm></para><para>For every pixel of the destination bitmap, both the source bitmap and the filter must be accessed nine times. Moreover, as the resolution of bitmaps gets higher, filters must often get larger as well to have a noticeable effect on the image.</para><para>It's a lot of processing for a high-level language, but I was curious to discover how C# and .NET would fare in handling the pressure. For my experimentation with C# <indexterm id="idx-CHP-8-0447" significance="normal"><primary>image processing code</primary></indexterm>image processing, I began with some <indexterm id="idx-CHP-8-0448" significance="normal"><primary>Windows Forms code (ImageClip program)</primary></indexterm>Windows Forms code from my book <emphasis>Programming Windows with</emphasis> <emphasis>C</emphasis># (Microsoft Press). The <literal moreinfo="none">ImageClip</literal> progam in <xref linkend="beautiful_concurrency"/> of that book incorporates <indexterm id="idx-CHP-8-0449" significance="normal"><primary>code generation</primary></indexterm>code that will load, view, print, and save bitmaps of various popular formats, including JPEG, GIF, and PNG. That <indexterm id="idx-CHP-8-0450" significance="normal"><primary>C#</primary><secondary>code written for best performance</secondary></indexterm>code, along with the code I wrote for this exercise, is available for downloading and contributes to a <indexterm id="idx-CHP-8-0451" significance="normal"><primary>bitmaps</primary><secondary>ImageFilterTest program</secondary></indexterm>program named <literal moreinfo="none">ImageFilterTest</literal>. The project file requires Visual Studio 2005 for compilation; the executable should run under the .NET Framework 2.0 and later. Perform the following steps to use the program:<indexterm id="idx-CHP-8-0452" significance="normal"><primary>Programming Windows with C#</primary></indexterm><indexterm id="idx-CHP-8-0453" significance="normal"><primary>image processing code</primary></indexterm><indexterm id="idx-CHP-8-0454" significance="normal"><primary>ImageFilter class</primary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>In the File menu, select Open and load in a full-color bitmap. The filter-related code in the program only works with 24-bit-per-pixel or 32-bit-per-pixel bitmaps; it doesn't work with bitmaps that use color palette tables, including those where the palette table contains gray shades.</para></listitem><listitem><para>Select one of the filters in the Filter menu. The filter will be applied to the bitmap and the elapsed time will be reported. The first item in the Filter menu ("Use method that generates Intermediate Language") lets you select the method used to apply the filter. By default, the program uses a method called <literal moreinfo="none">FilterMethodCS</literal> (short for "Filter Method using C#"). If you enable this menu item, the program uses <literal moreinfo="none">FilterMethodIL</literal> ("Filter Method with Intermediate Language"). Both of these methods will be described later in this chapter.</para></listitem></orderedlist><para>Whenever you attempt to write C# code for best performance, one of the more interesting exercises is to examine the compiled file using a little utility included with the .NET Software Development Kit called <emphasis>IL Disassembler</emphasis>. The IL Disassembler shows you the Intermediate Language <indexterm id="idx-CHP-8-0455" significance="normal"><primary>Intermediate Language (IL)</primary><secondary>generated by C# compiler</secondary></indexterm>generated by the C# compiler. Although the program doesn't show you the final step—the conversion of the Intermediate Language into machine code by the just-in-time compiler—you can usually use it to locate some problem areas.<indexterm id="idx-CHP-8-0456" significance="normal"><primary>IL Disassembler</primary></indexterm></para><para>Very early on, I gave up on the idea of storing <indexterm id="idx-CHP-8-0457" significance="normal"><primary>arrays</primary><secondary>bitmap pixels stored in</secondary></indexterm>bitmap pixels in two-dimensional arrays. C# supports multidimensional arrays, but on the Intermediate Language level, getting elements in and out of multidimensional arrays requires method calls. Intermediate Language instructions do, however, support access to one-dimensional arrays. Furthermore, the standard (and fast) code for transferring pixels from a Bitmap object into an array and back into a Bitmap object involves a one-dimensional array. The code I wrote to transfer everything into a two-dimensional array involved a considerable amount of time just by itself.</para><para>To encapsulate image filters and the methods that apply these filters to bitmaps, I created a class named <literal moreinfo="none">ImageFilter</literal> that contains three private fields and a constructor that sets the fields. The private field <literal moreinfo="none">filter</literal> is a one-dimensional array that contains a two-dimensional filter, so the <literal moreinfo="none">cxFilter</literal> and <literal moreinfo="none">cyFilter</literal> fields are necessary to indicate the implicit number of columns and rows:</para><programlisting id="I_programlisting8_tt100" format="linespecific">
	class ImageFilter
	{
	    double[] filter;
	    int cxFilter;
	    int cyFilter;
	    public ImageFilter(int cxFilter, double[] filter)
	    {
	        this.<indexterm id="idx-CHP-8-0458" significance="normal"><primary>Filter class</primary></indexterm>filter = filter;
	        this.cxFilter = cxFilter;
	        this.cyFilter = filter.Length / cxFilter;
	    }
	    ...
	}
</programlisting><para>If only square filters were allowed, the <literal moreinfo="none">cxFilter</literal> parameter to the constructor wouldn't be necessary, and the number of rows and columns could simply be calculated as the square root of the size of the <literal moreinfo="none">filter</literal> array, which is available as <literal moreinfo="none">filter.Length</literal>. The <literal moreinfo="none">cxFilter</literal> parameter allows for rectangular filter arrays rather than just square ones. If <literal moreinfo="none">cxFilter</literal> indicates the number of columns in the filter, the number of rows is <literal moreinfo="none">filter.Length/cxFilter</literal>, which my <indexterm id="idx-CHP-8-0459" significance="normal"><primary>code generation</primary></indexterm>code implicitly assumes is an integer.</para><para>The <literal moreinfo="none">Filter</literal> class includes a method named <literal moreinfo="none">ApplyFilter</literal>, which has a parameter of type <literal moreinfo="none">Bitmap</literal>. I won't show you the <literal moreinfo="none">ApplyFilter</literal> method here because it simply contains standard code to first access the pixels of the <literal moreinfo="none">Bitmap</literal> object (using a method named <literal moreinfo="none">LockBits</literal>), and then to transfer the pixels into a <indexterm id="idx-CHP-8-0460" significance="normal"><primary>one-dimensional array and digital filter algorithm in C#</primary></indexterm>one-dimensional array. A second parameter of <literal moreinfo="none">ApplyFilter</literal> is a Boolean named <literal moreinfo="none">willGenerateCode</literal>. If <emphasis>false</emphasis>, the <literal moreinfo="none">ApplyFilter</literal> method calls <literal moreinfo="none">FilterMethodCS</literal>.<indexterm id="idx-CHP-8-0461" significance="normal"><primary>FilterMethodCS</primary></indexterm></para><para><literal moreinfo="none">FilterMethodCS</literal>, shown in <xref linkend="a_digital_filter_algorithm_in_csharp"/>, is a fairly straightforward implementation of the filtering algorithm from <xref linkend="naiumlve_c_code_to_apply_a_digital_filter"/>, but it has been translated to C# and uses one-dimensional arrays.<indexterm class="startofrange" id="idx-CHP-8-0462" significance="normal"><primary>code generation</primary><secondary>FilterMethodCS</secondary></indexterm></para><example id="a_digital_filter_algorithm_in_csharp" label="8-2"><title>A digital filter algorithm in C#</title><programlisting format="linespecific">
1  void <indexterm class="startofrange" id="idx-CHP-8-0463" significance="normal"><primary>image processing code</primary><secondary>FilterMethodCS</secondary></indexterm>FilterMethodCS(byte[] src, byte[] dst, int stride, int bytesPerPixel)
2  {
3      int cBytes = src.Length;
4      int cFilter = filter.Length;
5
6      for (int iDst = 0; iDst &lt; cBytes; iDst++)
7      {
8          double pixelsAccum = 0;
9          double filterAccum = 0;
10
11         for (int iFilter = 0; iFilter &lt; cFilter; iFilter++)
12         {
13             int yFilter = iFilter / cyFilter;
14             int xFilter = iFilter % cxFilter;
15
16             int iSrc = iDst + stride * (yFilter - cyFilter / 2) +
17                                 bytesPerPixel * (xFilter - cxFilter / 2);
18
19             if (iSrc &gt;= 0 &amp;&amp; iSrc &lt; cBytes)
20             {
21                 pixelsAccum += filter[iFilter] * src[iSrc];
22                 filterAccum += filter[iFilter];
23             }
24         }
25         if (filterAccum != 0)
26             pixelsAccum /= filterAccum;
27
28         dst[iDst] = pixelsAccum &lt; 0 ? (byte)0 : (pixelsAccum &gt; 255 ?
29                                           (byte)255 : (byte)pixelsAccum);
30     }
31  }
</programlisting></example><para>The first two parameters are the source and destination arrays <literal moreinfo="none">src</literal> and <literal moreinfo="none">dst</literal>. The third parameter is <literal moreinfo="none">stride</literal>, which is the number of bytes in each row of the source and destination bitmaps. This <literal moreinfo="none">stride</literal> value is generally equal to the pixel width of the bitmap times the number of bytes per pixel, but for performance reasons it might be rounded up to a four-byte boundary. (Because the program only works with full-color bitmaps, the number of bytes per pixel will always be three or four.) It's not necessary to calculate the <literal moreinfo="none">stride</literal> value because it's provided with the information returned by the <literal moreinfo="none">LockBits</literal> method when you get access to the bitmap bits. The method begins by saving the number of bytes in both the <literal moreinfo="none">src</literal> and <literal moreinfo="none">filter</literal> arrays to avoid frequent accesses of the <literal moreinfo="none">Length</literal> property. The variables that begin with the letter <replaceable>i</replaceable> are indexes to the three arrays used in the method.<indexterm id="idx-CHP-8-0464" significance="normal"><primary>C#</primary><secondary>digital filter algorithm</secondary></indexterm></para><para>If the goal here is to write a <emphasis>fast</emphasis> digital filter algorithm, then <literal moreinfo="none">FilterMethodCS</literal> is a failure. With a 24-bit-per-pixel 300,000-pixel bitmap and a 5 x 5 filter, this method requires about two seconds on my 1.5 GHz Pentium 4. Two seconds might not seem too bad, but a 5 x 5 filter applied to a 32-bit-per-pixel 4.3 megapixel bitmap requires about half a minute, and that is <emphasis>very</emphasis> long. Yet I can't see any way to improve the C# <indexterm id="idx-CHP-8-0465" significance="normal"><primary>code generation</primary></indexterm>code to make it more efficient.<indexterm id="idx-CHP-8-0466" significance="normal"><primary>digital filters</primary><secondary>fast digital filter algorithm</secondary></indexterm></para><para>Traditionally, if a <indexterm id="idx-CHP-8-0467" significance="normal"><primary>Intermediate Language (IL)</primary><secondary>function optimization for fast digital filter</secondary></indexterm>function isn't working fast enough and you don't feel you can optimize it any further, you start considering assembly language. In this era of platform independence and managed code, you might instead consider the vaguely equivalent approach of writing the routine directly in <indexterm id="idx-CHP-8-0468" significance="normal"><primary sortas="NET Intermediate Language">.NET Intermediate Language</primary></indexterm>.NET Intermediate Language. This is certainly an entirely plausible solution, and might even be considered fun (to the right type of mentality). However, even coding in Intermediate Language might not be sufficient. Use the IL Disassembler to look at the Intermediate Language generated by the C# compiler for <literal moreinfo="none">FilterMethodCS</literal>. Do you really think you can improve greatly on that?<indexterm id="idx-CHP-8-0469" significance="normal"><primary>image processing code</primary><secondary>FilterMethodCS</secondary></indexterm></para><para>The real problem with <literal moreinfo="none">FilterMethodCS</literal> is that it's generalized for bitmaps of any dimension and for filters of any dimension. Much of the code in <literal moreinfo="none">FilterMethodCS</literal> is just "busy work" involved with looping and indexing. This method could be improved dramatically if it didn't have to be so generalized. Suppose you were always dealing with 32-bit-per-pixel bitmaps of the same size, which I'll symbolize as <emphasis>CX</emphasis> and <emphasis>CY</emphasis> (think of these uppercase letters as <literal moreinfo="none">#defines</literal> in C or C++, or <literal moreinfo="none">const</literal> values in C#). And suppose you always used the same filter— a 3 x 3 filter with fixed elements whose fields are symbolized like the ones in <xref linkend="array_layout_of_a_3x3_filter"/>.</para><figure id="array_layout_of_a_3x3_filter" label="8-3" float="0"><title>Array layout of a 3x3 filter</title><mediaobject id="I_mediaobject8_tt101"><imageobject role="print"><imagedata fileref="figs/print/beauty_0803.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0803.png" format="PNG"/></imageobject></mediaobject></figure><para>How would you write the filter method then? You might decide to dispense with the <literal moreinfo="none">iFilter</literal> loop and just <indexterm id="idx-CHP-8-0470" significance="normal"><primary>code generation</primary></indexterm>hardcode the logic for the nine filter elements:</para><programlisting id="I_programlisting8_tt102" format="linespecific">
	// Filter cell F11
	int iSrc = iDst - 4 * CX - 4;

	if (iSrc &gt;= 0 &amp;&amp; iSrc &lt; 4 * CX * CY)
	{
	     pixelsAccum += src[iSrc] * F11;
	     filterAccum += F11;
	}

	// Filter cell F12
	iSrc = iDst - 4 * CX;

	if (iSrc &gt;= 0 &amp;&amp; iSrc &lt; 4 * CX * CY)
	{
	     pixelsAccum += src[iSrc] * F12;
	     filterAccum += F12;
	}

	// Filter cells F13 through F32
	...

	// Filter cell F33
	iSrc = iDst + 4 * CX + 4;

	if (iSrc &gt;= 0 &amp;&amp; iSrc &lt; 4 * CX * CY)
	{
	     pixelsAccum += src[iSrc] * F33;
	     filterAccum += F33;
	}
</programlisting><para>This approach gets rid of the looping logic, simplifies the calculation of <literal moreinfo="none">iSrc</literal>, and eliminates the access of the <literal moreinfo="none">filter</literal> array. Although the code is definitely bulkier, it is guaranteed to be faster. In fact, because you know the values of all the filter elements, you can reduce the code somewhat by eliminating those cases where the filter element is 0, and simplifying those cases where the filter element is 1 or –1.</para><para>Of course, hardcoding this logic isn't practical because you really want the ability to deal with many differently sized bitmaps and many types of filters. These properties are not known until it's time to actually apply the filter.</para><para>Rather than hardcoding the filter logic, a much better approach would be to generate custom code on the fly based on the size and pixel depth of the bitmap, and the size and elements of the filter. In olden days, you might do as the Windows developers did with BitBlt, which was to generate machine code in memory, and then execute it. Translated to modern times, with our concern for portability, the solution might be to generate .NET <indexterm id="idx-CHP-8-0471" significance="normal"><primary>C#</primary><secondary>Intermediate Language</secondary></indexterm>Intermediate Language using C#, and then execute it.<indexterm id="I_indexterm8_tt103" class="endofrange" startref="idx-CHP-8-0462" significance="normal"><primary>code generation</primary><secondary>FilterMethodCS</secondary></indexterm><indexterm id="I_indexterm8_tt104" class="endofrange" startref="idx-CHP-8-0463" significance="normal"><primary>image processing code</primary><secondary>FilterMethodCS</secondary></indexterm></para><para>This is actually a workable solution. In a C# program you can create a static method in memory that consists of instructions in Intermediate Language, and then execute that method, at which point the .NET just-in-time compiler enters the picture to convert your Intermediate Language to machine <indexterm id="idx-CHP-8-0472" significance="normal"><primary>code generation</primary></indexterm>code. At no time during this entire process do you stop writing managed code.</para><para>The facility to <indexterm id="idx-CHP-8-0473" significance="normal"><primary>Intermediate Language (IL)</primary><secondary>dynamic generation of</secondary></indexterm>dynamically generate Intermediate Language was introduced in .NET 2.0 and involves classes in the <literal moreinfo="none">System.Reflection.Emit</literal> namespace. You can generate whole classes and even entire assemblies, but for smaller applications (such as the one we're developing), you can simply generate a static method and then call it. This is what I've done in <literal moreinfo="none">FilterMethodIL</literal> in the <literal moreinfo="none">ImageFilter</literal> class.<indexterm class="startofrange" id="idx-CHP-8-0474" significance="normal"><primary>FilterMethodIL</primary></indexterm><indexterm id="idx-CHP-8-0475" significance="normal"><primary>image processing code</primary></indexterm></para><para>I'm going to show you all of <literal moreinfo="none">FilterMethodIL</literal> here (but eliminating many of the comments you'll find in the <emphasis>ImageFilter.cs</emphasis> source code file) because it involves some interesting interplay between the C# code and the generated Intermediate Language. Keep in mind throughout this exercise that <literal moreinfo="none">FilterMethodIL</literal> generates this Intermediate Language whenever a specific filter is applied to a specific bitmap, so all aspects of the filter can be hard-coded into the Intermediate Language, as well as the size and pixel depth of the bitmap. Obviously, some overhead is required to generate this code, but that cost is dwarfed by the number of operations required by large bitmaps, which might easily have over a million pixels.<indexterm class="startofrange" id="idx-CHP-8-0476" significance="normal"><primary>code generation</primary><secondary>FilterMethodIL</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-8-0477" significance="normal"><primary>image processing code</primary><secondary>FilterMethodIL</secondary></indexterm></para><para>All the code in <literal moreinfo="none">FilterMethodIL</literal> is shown below in sequence, with explanations throughout to describe what's going on and introduce new concepts. <literal moreinfo="none">FilterMethodIL</literal> has the same parameters as <literal moreinfo="none">FilterMethodCS</literal> and begins by obtaining the total byte size of the bitmap:</para><programlisting id="I_programlisting8_tt105" format="linespecific">
	void FilterMethodIL(byte[] src, byte[] dst, int stride, int bytesPerPixel)
	{
	    int cBytes = src.Length;
</programlisting><para>To create a static method in code, you create a new object of type <literal moreinfo="none">DynamicMethod</literal>. The second argument to the constructor indicates the method's return type, and the third argument is an array of the method's parameter types. The fourth argument is the class that's creating this method, and is available from the <literal moreinfo="none">GetType</literal> method:<indexterm id="idx-CHP-8-0478" significance="normal"><primary>DynamicMethod class</primary></indexterm></para><programlisting id="I_programlisting8_tt106" format="linespecific">
	DynamicMethod dynameth = new DynamicMethod("Go", typeof(void),
	    new Type[] { typeof(byte[]), typeof(byte[]) }, GetType());
</programlisting><para>As you can see by the third argument to the constructor, the two parameters in this dynamic method are both <literal moreinfo="none">byte</literal> arrays, and these will be the <literal moreinfo="none">src</literal> and <literal moreinfo="none">dst</literal> arrays from <xref linkend="a_digital_filter_algorithm_in_csharp"/>. Throughout the Intermediate Language, these two arguments are referred to with indexes 0 and 1.</para><para>To generate the Intermediate Language that comprises the body of this method, you obtain an object of type <literal moreinfo="none">ILGenerator</literal>:<indexterm id="idx-CHP-8-0479" significance="normal"><primary>ILGenerator class</primary></indexterm></para><programlisting id="I_programlisting8_tt107" format="linespecific">
	ILGenerator generator = dynameth.GetILGenerator();
</programlisting><para>Most of what follows will use this <literal moreinfo="none">generator</literal> object. You can begin by defining local variables of the method. I determined that it would be convenient to have three local variables corresponding to three of the local variables in the <literal moreinfo="none">FilterMethodCS</literal>:</para><programlisting id="I_programlisting8_tt108" format="linespecific">
	generator.DeclareLocal(typeof(int));       // Index 0 = iDst
	generator.DeclareLocal(typeof(double));    // Index 1 = pixelsAccum
	generator.DeclareLocal(typeof(double));    // Index 2 = filterAccum
</programlisting><para>As the comments indicate, these local variables will be referred to by indexes. We are now ready to begin defining a loop based around <literal moreinfo="none">iDst</literal> that will access all the pixels of the destination array. These three statements correspond to the declarations of these variables in lines 3, 4, and 6 of <xref linkend="a_digital_filter_algorithm_in_csharp"/>.</para><para>Much of the remainder of this exercise requires generating Intermediate Language operation <indexterm id="idx-CHP-8-0480" significance="normal"><primary>code generation</primary></indexterm>codes, which are similar to machine language op codes. Intermediate Language consists of one-byte op codes, sometimes with arguments. However, you don't need to get your hands dirty with the actual bits and bytes. To generate these op codes, call one of the overloads of the <literal moreinfo="none">Emit</literal> method defined by the <literal moreinfo="none">IlGenerator</literal> class. The first argument to <literal moreinfo="none">Emit</literal> is always an object of type <literal moreinfo="none">OpCode</literal>, and all the available op codes are predefined as static read-only fields of the <literal moreinfo="none">OpCodes</literal> class (notice the plural). As of this writing, the <literal moreinfo="none">OpCodes</literal> class is documented online at <ulink url="http://msdn2.microsoft.com/library/system.reflection.emit.opcodes.aspx"/>.<indexterm id="idx-CHP-8-0481" significance="normal"><primary>ILGenerator class</primary><secondary>Emit method</secondary></indexterm><indexterm id="idx-CHP-8-0482" significance="normal"><primary>OpCodes class</primary></indexterm></para><para>Most of the <indexterm id="idx-CHP-8-0483" significance="normal"><primary>Intermediate Language (IL)</primary><secondary>assignment and operational logic based on virtual evaluation stack</secondary></indexterm>assignment and operational logic in Intermediate Language is based on a <indexterm id="idx-CHP-8-0484" significance="normal"><primary>virtual evaluation stack (in IL)</primary></indexterm>virtual <emphasis>evaluation stack</emphasis>. (I say it's virtual because the actual code that will eventually be executed by your computer processor is machine code generated by the just-in-time compiler, and this code might or might not mimic the evaluation stack of the Intermediate Language.) A <literal moreinfo="none">load</literal> instruction pushes a value onto the stack. This can be either a specific number or a value from a local variable, or something else. A <literal moreinfo="none">store</literal> instruction retrieves the value from the stack and stores it in a local variable or someplace else. Arithmetic and logical operations are also performed on the stack. <literal moreinfo="none">Add</literal>, for example, pops two values from the stack, adds them, and pushes the result onto the stack.<indexterm id="idx-CHP-8-0485" significance="normal"><primary>evaluation stack (virtual) in IL</primary></indexterm></para><para>Setting the local <literal moreinfo="none">iDst</literal> variable to <literal moreinfo="none">0</literal> in Intermediate Language requires a load instruction and a store instruction. The <literal moreinfo="none">Ldc_I4_0</literal> instruction places a four-byte integer value of 0 on the stack, and the <literal moreinfo="none">Stloc_0</literal> instruction stores that value in the local variable with index 0, which is the local variable corresponding to <literal moreinfo="none">iDst</literal>:</para><programlisting id="I_programlisting8_tt109" format="linespecific">
	generator.Emit(OpCodes.Ldc_I4_0);
	generator.Emit(OpCodes.Stloc_0);
</programlisting><para>Although many high-level programming languages include a <literal moreinfo="none">goto</literal> (or equivalent) instruction, modern programmers are discouraged from using it. However, in assembly language and Intermediate Language, the <literal moreinfo="none">goto</literal>—generally known as a <emphasis>jump</emphasis> or <emphasis>ranch</emphasis> instruction—is the only form of flow control available. All <literal moreinfo="none">for</literal> and <literal moreinfo="none">if</literal> statements must be mimicked with <indexterm id="idx-CHP-8-0486" significance="normal"><primary>branch instructions (Intermediate Language)</primary></indexterm>branching.<indexterm id="idx-CHP-8-0487" significance="normal"><primary>jump or branch instruction (Intermediate Language)</primary></indexterm><indexterm id="idx-CHP-8-0488" significance="normal"><primary>goto instruction</primary></indexterm></para><para>The .NET Intermediate Language supports an unconditional branch statement and several conditional branch statements. These conditional branches depend on the results of a specified prior comparison. For example a <emphasis>branch if less than</emphasis> instruction performs a branch if, in a previous comparison, one value was less than another. Mimicking an <literal moreinfo="none">if</literal> and <literal moreinfo="none">else</literal> construction <indexterm id="idx-CHP-8-0489" significance="normal"><primary>labels</primary><secondary>in Intermediate Language</secondary></indexterm>in Intermediate Language requires two <indexterm id="idx-CHP-8-0490" significance="normal"><primary>branch instructions (Intermediate Language)</primary><secondary>labels</secondary></indexterm>labels, one corresponding to the beginning of the <literal moreinfo="none">else</literal> block, and the other pointing after the <literal moreinfo="none">else</literal> block. If the <literal moreinfo="none">if</literal> condition is not true, a conditional branch goes to the first label; otherwise, the <literal moreinfo="none">if</literal> block is executed. At the end of the <literal moreinfo="none">if</literal> block, an unconditional branch goes to the label following the <literal moreinfo="none">else</literal> block. The two possibilities are illustrated by <xref linkend="intermediate_language_branches_to_implement_ifelse"/>.</para><figure id="intermediate_language_branches_to_implement_ifelse" label="8-4" float="0"><title>Intermediate Language branches to implement if/else</title><mediaobject id="I_mediaobject8_tt110"><imageobject role="print"><imagedata fileref="figs/print/beauty_0804.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_0804.png" format="PNG"/></imageobject></mediaobject></figure><para>The actual branch instruction <indexterm id="idx-CHP-8-0491" significance="normal"><primary>code generation</primary></indexterm>code in Intermediate Language contains a numeric value indicating the address of the destination instruction as an offset to the address of the current instruction. Figuring out these offsets would be too painful for programmers, so a labeling system is provided to make things easier. All that is required is that you define where labels should be inserted in the instruction stream, so that when you indicate a branch to that label, the code generator can calculate the proper numeric offset.</para><para>Two method calls are required for using a label. The <literal moreinfo="none">DefineLabel</literal> call defines a label that you can then refer to in branching instructions. The <literal moreinfo="none">MarkLabel</literal> call actually inserts the label into the Intermediate Language instruction stream. This two-step process allows you to define a label and then emit an op code that branches to that label, even though the label won't actually appear until later in the instruction stream. The following lines call both <literal moreinfo="none">DefineLabel</literal> and <literal moreinfo="none">MarkLabel</literal> to put a <literal moreinfo="none">Label</literal> object named <literal moreinfo="none">labelTop</literal> at the top of the <replaceable>iDst</replaceable> loop:</para><programlisting id="I_programlisting8_tt111" format="linespecific">
	Label labelTop = generator.DefineLabel();
	generator.MarkLabel(labelTop);
</programlisting><para>This label is equivalent to the location of the <literal moreinfo="none">for</literal> statement in line 6 of the C# code listing in <xref linkend="a_digital_filter_algorithm_in_csharp"/>. A label is required here because code at the end of the loop has to branch to the top of the loop.</para><para>We're now generating code within the <literal moreinfo="none">iDst</literal> loop. This is the per-pixel processing. The first step is to initialize <literal moreinfo="none">pixelsAccum</literal> and <literal moreinfo="none">filterAccum</literal> to 0. The first <literal moreinfo="none">Emit</literal> call shown in the following code snippet has an op code of <literal moreinfo="none">Ldc_R8</literal>, which will load an 8-bit <literal moreinfo="none">real</literal> (that is, a floating-point number) on the stack. The second argument of <literal moreinfo="none">Emit</literal> is the actual number. The type of this number must match the type implied by the op <indexterm id="idx-CHP-8-0492" significance="normal"><primary>code generation</primary></indexterm>code. If you just use a <literal moreinfo="none">0</literal> with no decimal point, the C# compiler will interpret it as an integer, and you won't know you blundered until a runtime exception indicates an invalid program:</para><programlisting id="I_programlisting8_tt112" format="linespecific">
	generator.Emit(OpCodes.Ldc_R8, 0.0);
	generator.Emit(OpCodes.Dup);
	generator.Emit(OpCodes.Stloc_1);
	generator.Emit(OpCodes.Stloc_2);
</programlisting><para>The <literal moreinfo="none">Dup</literal> instruction duplicates the <literal moreinfo="none">0</literal> value on the stack, and the <literal moreinfo="none">Stloc_1</literal> and <literal moreinfo="none">Stloc_2</literal> op codes store the value in the local variables representing <literal moreinfo="none">pixelsAccum</literal> and <literal moreinfo="none">filterAccum</literal>. Again, you must make sure that all the types agree here; otherwise, a runtime exception will be raised indicating that the just-in-time compiler detected an invalid program.</para><para>At this point, we're ready to generate <indexterm id="idx-CHP-8-0493" significance="normal"><primary>digital filters</primary><secondary>generating code for elements</secondary></indexterm>code for each of the elements in the <literal moreinfo="none">filter</literal> array. However, we don't want the Intermediate Language to loop through the <literal moreinfo="none">filter</literal> array and access each element. Instead, we want all the filter elements to be hardcoded in Intermediate Language. If the filter has nine elements, we want nine similar sections of Intermediate Language. For that reason, we use a C# <literal moreinfo="none">for</literal> statement to loop through the filter elements:</para><programlisting id="I_programlisting8_tt113" format="linespecific">
	for (int iFilter = 0; iFilter &lt; filter.Length; iFilter++)
	{
</programlisting><para>If a particular element of the filter is <literal moreinfo="none">0</literal>, that element can be entirely ignored—no Intermediate Language code has to be generated, so we can just skip to the next element of the <literal moreinfo="none">filter</literal> array:</para><programlisting id="I_programlisting8_tt114" format="linespecific">
	if (filter[iFilter] == 0)
	    continue;
</programlisting><para>For each filter element, the index of the <literal moreinfo="none">src</literal> array will be a particular offset from the <literal moreinfo="none">iDst</literal> index. The following C# code calculates that offset. The <literal moreinfo="none">offset</literal> value can be calculated in C# code because it only has to be represented as a constant in Intermediate Language:</para><programlisting id="I_programlisting8_tt115" format="linespecific">
	int xFilter = iFilter % cxFilter;
	int yFilter = iFilter / cxFilter;
	int offset = stride * (yFilter - cyFilter / 2) +
	            bytesPerPixel * (xFilter - cxFilter / 2);
</programlisting><para>Accessing or setting an element of an array is a three-step process. First, you need to put a reference to the array on the stack. Then you need to put an index of the array on the stack. Finally, if you're accessing that element, you need a load instruction, and if you're setting the array element, you need a store instruction. The <literal moreinfo="none">src</literal> array must be accessed for each nonzero element of the filter array, so now is a convenient time to put a reference to that array on the evaluation stack:</para><programlisting id="I_programlisting8_tt116" format="linespecific">
	generator.Emit(OpCodes.Ldarg_0);
</programlisting><para>The <literal moreinfo="none">Ldarg</literal> instruction refers to the arguments to the generated method, and the <literal moreinfo="none">src</literal> array will be the first argument associated with an index of <literal moreinfo="none">0</literal>.</para><para>Next, we will specify several labels. Notice that these three labels are defined so that Intermediate Language instructions can refer to them, but they're not marked yet because they will be inserted at a later point in the Intermediate Language instruction stream:</para><programlisting id="I_programlisting8_tt117" format="linespecific">
	Label labelLessThanZero = generator.DefineLabel();
	Label labelGreaterThan = generator.DefineLabel();
	Label labelLoopBottom = generator.DefineLabel();
</programlisting><para>For each element of the filter, the <literal moreinfo="none">src</literal> array must be accessed with the <literal moreinfo="none">iDst</literal> index plus an <literal moreinfo="none">offset</literal> value that has already been calculated by C# <indexterm id="idx-CHP-8-0494" significance="normal"><primary>code generation</primary></indexterm>code. The following code puts <literal moreinfo="none">iDst</literal> on the stack, followed by the actual <literal moreinfo="none">offset</literal> value, adds the two together (which effectively pops the two operands from the stack and pushes the sum on the stack), and makes two duplicates of the sum:</para><programlisting id="I_programlisting8_tt118" format="linespecific">
	generator.Emit(OpCodes.Ldloc_0);        // dst index on stack
	generator.Emit(OpCodes.Ldc_I4, offset); // offset on stack
	generator.Emit(OpCodes.Add);            // Add the two
	generator.Emit(OpCodes.Dup);            // Duplicate twice
	generator.Emit(OpCodes.Dup);
</programlisting><para>The resultant index (which was called <literal moreinfo="none">iSrc</literal> in <literal moreinfo="none">FilterMethodCS</literal>) might be outside the bounds of the array. The following code loads an integer <literal moreinfo="none">0</literal> on the stack and branches if <literal moreinfo="none">iSrc</literal> is less than <literal moreinfo="none">0</literal>, effectively popping both operands from the stack. This is a partial equivalent of the <literal moreinfo="none">if</literal> statement conditional in line 19 of <xref linkend="a_digital_filter_algorithm_in_csharp"/>:</para><programlisting id="I_programlisting8_tt119" format="linespecific">
	generator.Emit(OpCodes.Ldc_I4_0);
	generator.Emit(OpCodes.<indexterm id="idx-CHP-8-0495" significance="normal"><primary>branch instructions (Intermediate Language)</primary><secondary>Blt (branch if less than) and S (short branch)</secondary></indexterm>Blt_S, labelLessThanZero);
</programlisting><para><literal moreinfo="none">Blt</literal> stands for <emphasis>branch if less than</emphasis> and <literal moreinfo="none">S</literal> indicates a <emphasis>short</emphasis> branch (one in which the target is fewer than 256 op code bytes away).</para><para>A second check determines whether <literal moreinfo="none">iSrc</literal> is greater than the byte size of the bitmap. Notice that the literal <literal moreinfo="none">cBytes</literal> value is pushed on the stack for this comparison. This is the remainder of the <literal moreinfo="none">if</literal> conditional in line 19 of <xref linkend="a_digital_filter_algorithm_in_csharp"/>:</para><programlisting id="I_programlisting8_tt120" format="linespecific">
	generator.Emit(OpCodes.Ldc_I4, cBytes);
	generator.Emit(OpCodes.Bge_S, labelGreaterThan);
</programlisting><para>If <literal moreinfo="none">iSrc</literal> is good, the source array can be accessed. The <literal moreinfo="none">Ldelem</literal> op code assumes that the array itself and an index to the array are already on the stack. Those two values are effectively popped and replaced with the array element at that index. The <literal moreinfo="none">U1</literal> part of this op code specifies that the array element is an unsigned one-byte value:</para><programlisting id="I_programlisting8_tt121" format="linespecific">
	generator.Emit(OpCodes.Ldelem_U1);
	generator.Emit(OpCodes.Conv_R8);
</programlisting><para>The <literal moreinfo="none">Conv_R8</literal> op code converts the value on the stack to an eight-byte floating-point value and replaces it on the stack.</para><para>At this point, the byte at <literal moreinfo="none">iSrc</literal> is on the stack and has been converted to a floating point. It is ready to be multiplied by a filter element. Because the value of the filter element is known at the time the method is being generated, C# <indexterm id="idx-CHP-8-0496" significance="normal"><primary>code generation</primary></indexterm>code skips the multiplication if the filter element is 1 (no multiplication is required if the filter element is 1):</para><programlisting id="I_programlisting8_tt122" format="linespecific">
	if (filter[iFilter] == 1)
	{
	    // src element is on stack, so do nothing
	}
</programlisting><para>If the filter element is –1, the source byte can simply be negated, perhaps saving a little <indexterm id="idx-CHP-8-0497" significance="normal"><primary>image processing code</primary></indexterm>processing time over the multiplication:</para><programlisting id="I_programlisting8_tt123" format="linespecific">
	else if (filter[iFilter] == -1)
	{
	    generator.Emit(OpCodes.Neg);
	}
</programlisting><para>Otherwise, the byte is multiplied by the filter element:</para><programlisting id="I_programlisting8_tt124" format="linespecific">
	else
	{
	    generator.Emit(OpCodes.Ldc_R8, filter[iFilter]);
	    generator.Emit(OpCodes.Mul);
	}
</programlisting><para>You might recall that <literal moreinfo="none">pixelsAccum</literal> was defined as a local variable with an index of <literal moreinfo="none">1</literal>. The following code puts <literal moreinfo="none">pixelsAccum</literal> on the stack, adds to it the source byte value multiplied by the filter element, and stores the result back in <literal moreinfo="none">pixelsAccum</literal>:</para><programlisting id="I_programlisting8_tt125" format="linespecific">
	generator.Emit(OpCodes.Ldloc_1);
	generator.Emit(OpCodes.Add);
	generator.Emit(OpCodes.Stloc_1);
</programlisting><para>Similarly, <literal moreinfo="none">filterAccum</literal> (which has a local variable index of <literal moreinfo="none">2</literal>) must accumulate the values of the filter elements:</para><programlisting id="I_programlisting8_tt126" format="linespecific">
	generator.Emit(OpCodes.Ldc_R8, filter[iFilter]);
	generator.Emit(OpCodes.Ldloc_2);
	generator.Emit(OpCodes.Add);
	generator.Emit(OpCodes.Stloc_2);
	generator.Emit(OpCodes.Br, labelLoopBottom);
</programlisting><para>At this point, we're at the bottom of the inner <literal moreinfo="none">for</literal> loop, equivalent to line 24 of <xref linkend="a_digital_filter_algorithm_in_csharp"/>. We are essentially finished with the processing for each filter element, except that the stack has to be cleaned up for cases where the calculated <literal moreinfo="none">iSrc</literal> index is outside the bounds of the bitmap. This section of the generated code (at the bottom of the C# <literal moreinfo="none">for</literal> loop for <literal moreinfo="none">iFilter</literal>) marks the three labels and performs cleanup by popping unused items from the stack:</para><programlisting id="I_programlisting8_tt127" format="linespecific">
	   generator.MarkLabel(labelLessThanZero);
	   generator.Emit(OpCodes.Pop);
	   generator.MarkLabel(labelGreaterThan);
	   generator.Emit(OpCodes.Pop);
	   generator.Emit(OpCodes.Pop);
	   generator.MarkLabel(labelLoopBottom);
	}
</programlisting><para>So far, all the <indexterm id="idx-CHP-8-0498" significance="normal"><primary>code generation</primary></indexterm>code has been generated to calculate <literal moreinfo="none">pixelsAccum</literal> and <literal moreinfo="none">filterAccum</literal> for a particular destination pixel. The result is almost ready to be transferred into the <literal moreinfo="none">dst</literal> array. The array reference (which has a method argument index of <literal moreinfo="none">1</literal>) and the <literal moreinfo="none">iDst</literal> index (which has a local variable index of <literal moreinfo="none">0</literal>) are both loaded on the stack:</para><programlisting id="I_programlisting8_tt128" format="linespecific">
	generator.Emit(OpCodes.Ldarg_1);     // dst array
	generator.Emit(OpCodes.Ldloc_0);     // iDst index
</programlisting><para>There will be some branching involved, so the following labels are defined:</para><programlisting id="I_programlisting8_tt129" format="linespecific">
	Label labelSkipDivide = generator.DefineLabel();
	Label labelCopyQuotient = generator.DefineLabel();
	Label labelBlack = generator.DefineLabel();
	Label labelWhite = generator.DefineLabel();
	Label labelDone = generator.DefineLabel();
</programlisting><para>The following code loads both the <literal moreinfo="none">pixelsAccum</literal> and <literal moreinfo="none">filterAccum</literal> local variables on the stack in preparation for division. The first task is to check for a potential zero-divide by comparing <literal moreinfo="none">filterAccum</literal> with <literal moreinfo="none">0</literal>. This code is equivalent to line 25 in <xref linkend="a_digital_filter_algorithm_in_csharp"/>:</para><programlisting id="I_programlisting8_tt130" format="linespecific">
	generator.Emit(OpCodes.Ldloc_1);        // pixelsAccum
	generator.Emit(OpCodes.Ldloc_2);        // filterAccum
	generator.Emit(OpCodes.Dup);            // Make a copy
	generator.Emit(OpCodes.Ldc_R8, 0.0);    // Put 0 on stack
	generator.Emit(OpCodes.Beq_S, labelSkipDivide);
</programlisting><para>If the denominator is not <literal moreinfo="none">0</literal>, the division is executed and the quotient remains on the stack:</para><programlisting id="I_programlisting8_tt131" format="linespecific">
	generator.Emit(OpCodes.Div);
	generator.Emit(OpCodes.Br_S, labelCopyQuotient);
</programlisting><para>If <literal moreinfo="none">filterAccum</literal> is <literal moreinfo="none">0</literal>, the following code is executed and the original instance of <literal moreinfo="none">filterAccum</literal> is popped from the stack:</para><programlisting id="I_programlisting8_tt132" format="linespecific">
	generator.MarkLabel(labelSkipDivide);
	generator.Emit(OpCodes.Pop);             // Pop filterAccum
</programlisting><para>In either case, what remains on the stack is <literal moreinfo="none">pixelsAccum</literal>, either divided by <literal moreinfo="none">filterAccum</literal> or not. Two copies of that quotient are made:</para><programlisting id="I_programlisting8_tt133" format="linespecific">
	generator.MarkLabel(labelCopyQuotient);
	generator.Emit(OpCodes.Dup);            // Make a copy of quotient
	generator.Emit(OpCodes.Dup);            // And another
</programlisting><para>Most of what follows is the Intermediate Language equivalent of the statement in lines 28 and 29 of <xref linkend="a_digital_filter_algorithm_in_csharp"/>. If the quotient is less than zero, the code branches to a label where the destination pixel will be set to <literal moreinfo="none">0</literal>:</para><programlisting id="I_programlisting8_tt134" format="linespecific">
	generator.Emit(OpCodes.Ldc_R8, 0.0);
	generator.Emit(OpCodes.Blt_S, labelBlack);
</programlisting><para>If the quotient is greater than 255, the following code branches to a label where the destination pixel will be set to <literal moreinfo="none">255</literal>:</para><programlisting id="I_programlisting8_tt135" format="linespecific">
	generator.Emit(OpCodes.Ldc_R8, 255.0);
	generator.Emit(OpCodes.Bgt_S, labelWhite);
</programlisting><para>Otherwise, the value on the stack is converted to an unsigned one-byte value:</para><programlisting id="I_programlisting8_tt136" format="linespecific">
	generator.Emit(OpCodes.Conv_U1);<indexterm id="idx-CHP-8-0499" significance="normal"><primary>code generation</primary></indexterm>
	generator.Emit(OpCodes.Br_S, labelDone);
</programlisting><para>The following code is for the case where a <indexterm id="idx-CHP-8-0500" significance="normal"><primary>arrays</primary><secondary>digital filter</secondary><tertiary>zero byte stored in destination array</tertiary></indexterm>zero byte must be stored in the destination array. The <literal moreinfo="none">Ldc_I4_S</literal> instruction puts a one-byte value on the stack, but it goes onto the stack as a four-<indexterm id="idx-CHP-8-0501" significance="normal"><primary>arrays</primary><secondary>digital filter</secondary><tertiary>storing byte in destination array</tertiary></indexterm>byte integer because the slot widths on the stack are in increments of four bytes:</para><programlisting id="I_programlisting8_tt137" format="linespecific">
	generator.MarkLabel(labelBlack);
	generator.Emit(OpCodes.Pop);
	generator.Emit(OpCodes.Pop);
	generator.Emit(OpCodes.Ldc_I4_S, 0);
	generator.Emit(OpCodes.Br_S, labelDone);
</programlisting><para>This part of the code is similar to the part in which <literal moreinfo="none">255</literal> must be stored in the destination array:</para><programlisting id="I_programlisting8_tt138" format="linespecific">
	generator.MarkLabel(labelWhite);
	generator.Emit(OpCodes.Pop);
	generator.Emit(OpCodes.Ldc_I4_S, 255);
</programlisting><para>And now we're finally ready to store the byte in the destination array. The <literal moreinfo="none">dst</literal> array is already on the stack, the <literal moreinfo="none">iDst</literal> index is already on the stack, and the value to be stored in the array is on the stack. The <literal moreinfo="none">Stelem_I1</literal> instruction stores a one-byte value into the array:</para><programlisting id="I_programlisting8_tt139" format="linespecific">
	generator.MarkLabel(labelDone);
	generator.Emit(OpCodes.Stelem_I1);
</programlisting><para>We're now at the bottom of the <literal moreinfo="none">iDst</literal> loop, equivalent to line 30 of <xref linkend="a_digital_filter_algorithm_in_csharp"/>. The <literal moreinfo="none">iDst</literal> local variable must now be incremented and compared to the number of bytes in the array. If it's less, the code branches to the top of the loop:</para><programlisting id="I_programlisting8_tt140" format="linespecific">
	generator.Emit(OpCodes.Ldloc_0);    // Put iDst on stack
	generator.Emit(OpCodes.Ldc_I4_1);   // Put 1 on stack
	generator.Emit(OpCodes.Add);        // Add 1 to iDst
	generator.Emit(OpCodes.Dup);        // Duplicate
	generator.Emit(OpCodes.Stloc_0);    // Store result in iDst
	generator.Emit(OpCodes.Ldc_I4, cBytes);  // Put cBytes value on stack
	generator.Emit(OpCodes.Blt, labelTop);   // Go to top if iDst &lt; cBytes
</programlisting><para>After the loop is finished, the generated method concludes with a return instruction:</para><programlisting id="I_programlisting8_tt141" format="linespecific">
	generator.Emit(OpCodes.Ret);
</programlisting><para>All the Intermediate Language code has now been generated. The <literal moreinfo="none">DynamicMethod</literal> instance created at the beginning of <literal moreinfo="none">FilterMethodIL</literal> is complete and ready to be executed, or <emphasis>invoked</emphasis>, as the following method name implies. The second argument to <literal moreinfo="none">Invoke</literal> specifies the two arguments to the generated method as the <literal moreinfo="none">src</literal> and <literal moreinfo="none">dst</literal> arrays:<indexterm id="idx-CHP-8-0502" significance="normal"><primary>DynamicMethod class</primary><secondary>Invoke method</secondary></indexterm><indexterm id="idx-CHP-8-0503" significance="normal"><primary>FilterMethodIL</primary><secondary>DynamicMethod instance</secondary></indexterm></para><programlisting id="I_programlisting8_tt142" format="linespecific">
	   dynameth.Invoke(this, new object[] { src, dst });
	}
</programlisting><para>And that concludes <literal moreinfo="none">FilterMethodIL</literal>. The <literal moreinfo="none">DynamicMethod</literal> object and the <literal moreinfo="none">ILGenerator</literal> object are now out of scope, and the memory they occupied can be reclaimed by the .NET garbage collector.</para><para>Algorithms written in low-level languages are usually faster than those written in high-level languages, and custom algorithms are almost always faster than generalized algorithms. By customizing an algorithm in Intermediate Language on the fly right before it's used, we seem to have the best of both worlds. The algorithm is generalized until it has to be customized, and then it's customized with efficient code.</para><para>The downside is that you need to become a compiler writer of sorts, and breach that barrier between code and data, thus entering a strange netherworld where code and data become mirror images of each other.</para><para><literal moreinfo="none">FilterMethodIL</literal> was surely a lot of work, but how well does it perform? Generally, <literal moreinfo="none">FilterMethodIL</literal>, which generates Intermediate Language instructions on the fly, runs in about one-quarter of the time hogged by the straight C# version, <literal moreinfo="none">FilterMethodCS</literal>, and sometimes better.</para><para>Now, you might regard <literal moreinfo="none">FilterMethodIL</literal> as ugly, and I'd be willing to concede that it sure isn't the prettiest code I've ever seen. But when an algorithm clocks in at a quarter of the execution time of some earlier code, then the only word that I find appropriate is <emphasis>beautiful</emphasis>.<indexterm id="I_indexterm8_tt143" class="endofrange" startref="idx-CHP-8-0474" significance="normal"><primary>FilterMethodIL</primary></indexterm><indexterm id="I_indexterm8_tt144" class="endofrange" startref="idx-CHP-8-0476" significance="normal"><primary>code generation</primary><secondary>FilterMethodIL</secondary></indexterm><indexterm id="I_indexterm8_tt145" class="endofrange" startref="idx-CHP-8-0477" significance="normal"><primary>image processing code</primary><secondary>FilterMethodIL</secondary></indexterm></para></chapter><chapter id="top_down_operator_precedence" label="9" role=""><title>Top Down Operator Precedence</title><para><emphasis>Douglas Crockford</emphasis><indexterm id="idx-CHP-9-0504" significance="normal"><primary>operator precedence</primary><secondary>top down</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-9-0505" significance="normal"><primary>operator precedence</primary></indexterm><indexterm id="idx-CHP-9-0506" significance="normal"><primary>Crockford</primary></indexterm></para><para><emphasis>In 1973, vaughan pratt presented "top down operator precedence"</emphasis><footnote id="CHP-9-FNOTE-1"><para>Pratt's paper is available at <ulink url="http://portal.acm.org/citation.cfm?id=512931"/>; more information about Pratt himself can be found at <ulink url="http://boole.stanford.edu/pratt.html"/>.</para></footnote> at the first annual <indexterm id="idx-CHP-9-0507" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>Principles of Programming Languages Symposium in Boston. In the paper, Pratt described a parsing technique that combines the best properties of <indexterm id="idx-CHP-9-0508" significance="normal"><primary>Recursive Descent</primary></indexterm>Recursive Descent and the <indexterm id="idx-CHP-9-0509" significance="normal"><primary>parsers</primary><secondary>top-down operator</secondary></indexterm>Operator Precedence syntax technique of Robert W Floyd.<footnote id="CHP-9-FNOTE-2"><para>For a description of Floyd, see "Robert W Floyd, In Memoriam," Donald E. Knuth, <ulink url="http://sigact.acm.org/floyd"/></para></footnote>. He claimed that the technique is simple to understand, trivial to implement, easy to use, extremely efficient, and very flexible. I will add that it is also beautiful.<indexterm id="idx-CHP-9-0510" significance="normal"><primary>Pratt</primary></indexterm><indexterm id="idx-CHP-9-0511" significance="normal"><primary>Top Down Operator Precedence</primary></indexterm></para><para>It might seem odd that such an obviously utopian approach to compiler construction is completely neglected today. Why is this the case? Pratt suggested in the paper that preoccupation with BNF grammars and their various offspring, along with their related automata and theorems, have precluded development in directions that are not visibly in the domain of automata theory.</para><para>Another explanation is that his technique is most effective when used in a dynamic, functional programming language. Its use in a static, procedural language would be considerably more difficult. In his paper, Pratt used LISP and almost effortlessly built parse trees from streams of tokens.</para><para>But <indexterm id="idx-CHP-9-0512" significance="normal"><primary>parsing techniques in LISP</primary></indexterm>parsing techniques are not greatly valued in the LISP community, which celebrates the Spartan denial of syntax. There have been many attempts since LISP's creation to give the language a rich, <indexterm id="idx-CHP-9-0513" significance="normal"><primary>ALGOL-like syntax for LISP</primary></indexterm>ALGOL-like syntax, including:</para><variablelist><varlistentry><term>Pratt's CGOL</term><listitem><para><ulink url="http://zane.brouhaha.com/~healyzh/doc/cgol.doc.txt"/></para></listitem></varlistentry><varlistentry><term>LISP 2</term><listitem><para><ulink url="http://community.computerhistory.org/scc/projects/LISP/index.html#LISP_2_"/></para></listitem></varlistentry><varlistentry><term>MLISP</term><listitem><para><ulink url="ftp://reports.stanford.edu/pub/cstr/reports/cs/tr/68/92/CS-TR-68-92.pdf"/></para></listitem></varlistentry><varlistentry><term>Dylan</term><listitem><para><ulink url="http://www.opendylan.org"/></para></listitem></varlistentry><varlistentry><term>Interlisp's Clisp</term><listitem><para><ulink url="http://community.computerhistory.org/scc/projects/LISP/interlisp/Teitelman-3IJCAI.pdf"/></para></listitem></varlistentry><varlistentry><term>McCarthy's original M-expressions</term><listitem><para><ulink url="http://www-formal.stanford.edu/jmc/history/lisp/lisp.html"/></para></listitem></varlistentry></variablelist><para>All failed to find acceptance. The functional programming community found the correspondence between programs and data to be much more valuable than expressive syntax. But the mainstream programming community likes its syntax, so LISP has never been accepted by the mainstream. Pratt's technique befits a dynamic language, but dynamic language communities historically have had no use for the syntax that Pratt's technique realizes.</para><sect1 id="javascript" label="9.1"><title>JavaScript</title><para>The situation changed with the advent of <indexterm class="startofrange" id="idx-CHP-9-0514" significance="normal"><primary>parsers</primary><secondary>JavaScript</secondary></indexterm>JavaScript. JavaScript is a dynamic, functional language, but in a syntactic sense, it is obviously a member of the C family. JavaScript is a dynamic language with a community that likes syntax. In addition, JavaScript is object oriented. Pratt's 1973 paper <indexterm id="idx-CHP-9-0515" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>anticipated object orientation but lacked an expressive notation for it. JavaScript has an expressive object notation. Thus, JavaScript is an ideal language for exploiting Pratt's technique. I will show that we can quickly and inexpensively produce parsers in JavaScript.<indexterm class="startofrange" id="idx-CHP-9-0516" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-9-0517" significance="normal"><primary>JavaScript</primary></indexterm></para><para>We don't have time in this short chapter to deal with the whole JavaScript language, and perhaps we wouldn't want to because the language is a mess. But it has some brilliant stuff in it, which is worthy of your consideration. We will build a parser that can process <indexterm id="idx-CHP-9-0518" significance="normal"><primary>Simplified JavaScript</primary></indexterm>Simplified JavaScript, and we will write that parser in <indexterm id="idx-CHP-9-0519" significance="normal"><primary>JavaScript</primary><secondary>Simplified</secondary></indexterm>Simplified JavaScript. Simplified JavaScript is just the good stuff, including:</para><variablelist><varlistentry><term><emphasis>Functions as first-class objects</emphasis></term><listitem><para>Functions are lambdas with lexical scoping.</para></listitem></varlistentry><varlistentry><term><emphasis>Dynamic objects with prototypal inheritance</emphasis></term><listitem><para>Objects are class-free. We can add a new member to any object by ordinary assignment. An object can inherit members from another object.<indexterm id="idx-CHP-9-0520" significance="normal"><primary>objects</primary><secondary>dynamic</secondary></indexterm><indexterm id="idx-CHP-9-0521" significance="normal"><primary>inheritance</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Object literals and array literals</emphasis>.</term><listitem><para>This is a very convenient notation for creating new objects and arrays. <indexterm id="idx-CHP-9-0522" significance="normal"><primary>JavaScript</primary></indexterm>JavaScript <indexterm id="idx-CHP-9-0523" significance="normal"><primary>list comprehension (Haskell)</primary><secondary>literals (in JavaScript)</secondary></indexterm>literals were the inspiration for the JSON data interchange (<ulink url="http://www.JSON.org"/>) format.<indexterm id="idx-CHP-9-0524" significance="normal"><primary>object literals (JavaScript)</primary></indexterm><indexterm id="idx-CHP-9-0525" significance="normal"><primary>array literals (JavaScript)</primary></indexterm></para></listitem></varlistentry></variablelist><para>We will take advantage of <indexterm id="idx-CHP-9-0526" significance="normal"><primary>functions</primary><secondary>JavaScript</secondary></indexterm>JavaScript's <indexterm id="idx-CHP-9-0527" significance="normal"><primary>prototypal nature</primary></indexterm>prototypal nature to make token objects that inherit from symbols, and symbols that inherit from an original symbol. We will depend on the <literal moreinfo="none">object</literal> function, which makes a new object that inherits members from an existing object. Our implementation will also depend on a tokenizer that produces an array of simple token objects from a string. We will advance through the array of tokens as we weave our parse tree.</para></sect1><sect1 id="symbol_table" label="9.2"><title>Symbol Table</title><para>We will use a <indexterm id="idx-CHP-9-0528" significance="normal"><primary>JavaScript</primary><secondary>symbol table</secondary></indexterm>symbol table to drive our parser:<indexterm id="idx-CHP-9-0529" significance="normal"><primary>symbol table (JavaScript parser)</primary></indexterm></para><programlisting id="I_programlisting9_tt146" format="linespecific">
	var symbol_table = {};
</programlisting><para>The <literal moreinfo="none">original_symbol</literal> object will be the prototype for all other symbols. It contains methods that report errors. These will usually be overridden with more useful methods:</para><programlisting id="I_programlisting9_tt147" format="linespecific">
	var original_symbol = {
	    nud: function ( ) {
	        this.error("Undefined.");
	    },
	    led: function (left) {
	        this.error("Missing <indexterm id="idx-CHP-9-0530" significance="normal"><primary>operator precedence</primary></indexterm>operator.");
	    }
	};
</programlisting><para>Let's define a function that defines symbols. It takes a symbol <literal moreinfo="none">id</literal> and an optional binding power that defaults to zero. It returns a symbol object for that <literal moreinfo="none">id</literal>. If the symbol already exists in the <literal moreinfo="none">symbol_table</literal>, it returns that symbol object. Otherwise, it makes a new symbol object that inherits from <literal moreinfo="none">original_symbol</literal>, stores it in the <indexterm id="idx-CHP-9-0531" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>symbol table</tertiary></indexterm>symbol table, and returns it. A symbol object initially contains an <literal moreinfo="none">id</literal>, a value, a left binding power, and the stuff it inherits from the <literal moreinfo="none">original_symbol</literal>:</para><programlisting id="I_programlisting9_tt148" format="linespecific">
	var symbol = function (id, bp) {
	    var s = symbol_table[id];
	    bp = bp || 0;
	    if (s) {
	        if (bp &gt;= s.lbp) {
	            s.lbp = bp;
	        }
	    } else {
	        s = object(original_symbol);
	        s.id = s.value = id;
	        s.lbp = bp;
	        symbol_table[id] = s;
	    }
	    return z;
	};
</programlisting><para>The following symbols are popular separators and closers:</para><programlisting id="I_programlisting9_tt149" format="linespecific">
	symbol(":");
	symbol(";");
	symbol(",");
	symbol(")");
	symbol("]");
	symbol("}");
	symbol("else");
</programlisting><para>The <indexterm id="idx-CHP-9-0532" significance="normal"><primary>literal symbol in JavaScript parser</primary></indexterm><literal moreinfo="none">(end)</literal> symbol indicates that there are no more <indexterm id="idx-CHP-9-0533" significance="normal"><primary>JavaScript</primary><secondary>tokens</secondary></indexterm>tokens. The <literal moreinfo="none">(name)</literal> symbol is the prototype for new names, such as variable names. They are spelled strangely to avoid collisions:</para><programlisting id="I_programlisting9_tt150" format="linespecific">
	symbol("(end)");
	symbol("(name)");
</programlisting><para>The <literal moreinfo="none">(literal)</literal> symbol is the prototype for all string and number literals:</para><programlisting id="I_programlisting9_tt151" format="linespecific">
	var itself = function ( ) {
	    return this;
	};
	symbol("(literal)").nud = itself;
</programlisting><para>The <literal moreinfo="none">this</literal> symbol is a special variable. In a method invocation, it is the reference to the object:</para><programlisting id="I_programlisting9_tt152" format="linespecific">
	symbol("this").nud = function ( ) {
	    scope.reserve(this);
	    this.<indexterm id="idx-CHP-9-0534" significance="normal"><primary>tokens</primary><secondary>JavaScript</secondary><tertiary>arity</tertiary></indexterm>arity = "this";
	    return this;
	};
</programlisting></sect1><sect1 id="tokens" label="9.3"><title>Tokens</title><para>We assume that the source text has been transformed into an array of simple token objects <literal moreinfo="none">(tokens)</literal>, each containing a <literal moreinfo="none">type</literal> member that is a string <literal moreinfo="none">("name", "string", "number", "operator")</literal> and a <literal moreinfo="none">value</literal> member that is a string or number.<indexterm id="idx-CHP-9-0535" significance="normal"><primary>parsers</primary><secondary>JavaScript</secondary><tertiary>tokens</tertiary></indexterm><indexterm id="idx-CHP-9-0536" significance="normal"><primary>operator precedence</primary></indexterm><indexterm id="idx-CHP-9-0537" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>tokens</tertiary></indexterm></para><para>The <literal moreinfo="none">token</literal> variable always contains the current token:</para><programlisting id="I_programlisting9_tt153" format="linespecific">
	var token;
</programlisting><para>The <literal moreinfo="none">advance</literal> function makes a new token object and assigns it to the <literal moreinfo="none">token</literal> variable. It takes an optional <literal moreinfo="none">id</literal> parameter, which it can check against the <literal moreinfo="none">id</literal> of the previous token. The new token object's prototype will be a name token in the current scope or a symbol from the symbol table. The new token's <literal moreinfo="none">arity</literal> will be <literal moreinfo="none">"name", "literal"</literal>, or <literal moreinfo="none">"operator"</literal>. Its <literal moreinfo="none">arity</literal> may be changed later to <literal moreinfo="none">"binary", "unary"</literal>, or <literal moreinfo="none">"statement"</literal> when we know more about the token's role in the program:</para><programlisting id="I_programlisting9_tt154" format="linespecific">
	var advance = function (id) {
	    var a, o, t, v;
	    if (id &amp;&amp; token.id !== id) {
	        token.error("Expected '" + id + "'.");
	    }
	    if (token_nr &gt;= tokens.length) {
	        token = symbol_table["(end)"];
	        return;
	    }
	    t = tokens[token_nr];
	    token_nr += 1;
	    v = t.value;
	    a = t.type;
	    if (a === "name") {
	        o = scope.find(v);
	    } else if (a === "<indexterm id="idx-CHP-9-0538" significance="normal"><primary>operator precedence</primary></indexterm>operator") {
	        o = symbol_table[v];
	        if (!o) {
	            t.error("Unknown operator.");
	        }
	    } else if (a === "string" || a === number") {
	        a = "literal";
	        o = symbol_table["(literal)"];
	    } else {
	        t.error("Unexpected token.");
	    }
	    token = object(o);
	    token.value = v;
	    token.arity = a;
	    return token;
	};
</programlisting></sect1><sect1 id="precedence" label="9.4"><title>Precedence</title><para>Tokens are objects that bear methods that allow them to make <indexterm id="idx-CHP-9-0539" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>precedence</tertiary></indexterm>precedence decisions, match other tokens, and build trees (and in a more ambitious project also check types, optimize, and generate code). The basic <indexterm id="idx-CHP-9-0540" significance="normal"><primary>parsers</primary><secondary>JavaScript</secondary><tertiary>precedence</tertiary></indexterm>precedence problem is this: given an operand between two operators, is the operand bound to the left operator or the right? Thus, if <replaceable>A</replaceable> and <replaceable>B</replaceable> are operators in:<indexterm id="idx-CHP-9-0541" significance="normal"><primary>JavaScript</primary><secondary>precedence</secondary></indexterm><indexterm id="idx-CHP-9-0542" significance="normal"><primary>precedence</primary></indexterm></para><programlisting id="I_programlisting9_tt155" format="linespecific">
	d <replaceable>A</replaceable> e <replaceable>B</replaceable> f
</programlisting><para>does operand <literal moreinfo="none">e</literal> bind to <replaceable>A</replaceable> or to <replaceable>B</replaceable>? In other words, are we talking about:</para><programlisting id="I_programlisting9_tt156" format="linespecific">
	(d <replaceable>A</replaceable> e) <replaceable>B</replaceable> f
</programlisting><para>or:</para><programlisting id="I_programlisting9_tt157" format="linespecific">
	d <replaceable>A</replaceable> (e <replaceable>B</replaceable> f)
</programlisting><para>Ultimately, the complexity in the process of parsing comes down to the resolution of this ambiguity. The technique we will develop here uses token objects whose members include <indexterm id="idx-CHP-9-0543" significance="normal"><primary>binding powers (JavaScript tokens)</primary></indexterm>binding powers (or precedence levels), and simple methods <indexterm id="idx-CHP-9-0544" significance="normal"><primary>led (left denotation) method</primary></indexterm>called <literal moreinfo="none">nud</literal> (null denotation) and <literal moreinfo="none">led</literal> (left denotation). A <literal moreinfo="none">nud</literal> does not care about the tokens to the left. A <literal moreinfo="none">led</literal> does. A <literal moreinfo="none">nud</literal> method is used by values (such as variables and literals) and by prefix <indexterm id="idx-CHP-9-0545" significance="normal"><primary>operator precedence</primary></indexterm>operators. A <literal moreinfo="none">led</literal> method is used by <indexterm class="startofrange" id="idx-CHP-9-0546" significance="normal"><primary>infix operators (JavaScript)</primary></indexterm>infix operators and suffix operators. A token may have both a <literal moreinfo="none">nud</literal> and a <literal moreinfo="none">led</literal>. For example, -might be both a prefix operator (negation) and an infix operator (subtraction), so it would have both <literal moreinfo="none">nud</literal> and <literal moreinfo="none">led</literal> methods.<indexterm id="idx-CHP-9-0547" significance="normal"><primary>nud (null denotation) method</primary></indexterm></para></sect1><sect1 id="expressions" label="9.5"><title>Expressions</title><para>The heart of Pratt's technique is the <literal moreinfo="none">expression</literal> function. It takes a right binding power that controls the aggressiveness of its consumption of tokens that it sees to the right. It returns the result of calling methods on the tokens it acts upon:<indexterm id="idx-CHP-9-0548" significance="normal"><primary>JavaScript</primary><secondary>expressions</secondary></indexterm><indexterm id="idx-CHP-9-0549" significance="normal"><primary>expression function</primary></indexterm></para><programlisting id="I_programlisting9_tt158" format="linespecific">
	var expression = function (rbp) {
	    var left;
	    var t = token;
	    advance( );
	    left = t.nud( );
	    while (rbp &lt; token.lbp) {
	        t = token;
	        advance( );
	        left = t.led(left);
	    }
	    return left;
	}
</programlisting><para><literal moreinfo="none">expression</literal> calls the <literal moreinfo="none">nud</literal> method of the <literal moreinfo="none">token</literal>. The <literal moreinfo="none">nud</literal> is used to process literals, variables, and prefix operators. After that, as long as the right binding power is less than the left binding power of the next token, the <literal moreinfo="none">led</literal> methods are invoked. The <literal moreinfo="none">led</literal> is used to process infix and suffix operators. This process can be recursive because the <literal moreinfo="none">nud</literal> and <literal moreinfo="none">led</literal> methods can call <literal moreinfo="none">expression</literal>.</para></sect1><sect1 id="infix_operators" label="9.6"><title>Infix Operators</title><para>The <indexterm id="idx-CHP-9-0550" significance="normal"><primary>binding powers (JavaScript tokens)</primary><secondary>+ operator</secondary></indexterm>+ operator is an infix operator, so it will have a <literal moreinfo="none">led</literal> method that makes the token object into a tree, where the two branches are the operand to the left of the + and the operand to the right. The left operand is passed into the <literal moreinfo="none">led</literal>, and the right is obtained by calling the <literal moreinfo="none">expression</literal> method.<indexterm class="startofrange" id="idx-CHP-9-0551" significance="normal"><primary>JavaScript</primary><secondary>infix operators</secondary></indexterm></para><para>The number <literal moreinfo="none">60</literal> is the binding power of +. Operators that bind tighter or have higher precedence have greater binding powers. In the course of mutating the stream of tokens into a parse tree, we will use the operator tokens as containers of operand nodes:</para><programlisting id="I_programlisting9_tt159" format="linespecific">
	symbol("+", 60).led = function (left) {
	    this.first = left;
	    this.second = expression(60);
	    this.arity = "binary";
	    return this;
	};
</programlisting><para>When we define the symbol for <indexterm id="idx-CHP-9-0552" significance="normal"><primary>= (equals sign)</primary></indexterm><footnote id="CHP-9-FNOTE-3"><para>Pratt's paper is available at <indexterm id="idx-CHP-9-0553" significance="normal"><primary>? (question mark)</primary></indexterm><ulink url="http://portal.acm.org/citation.cfm?id=512931"/>; more information about Pratt himself can be found at <ulink url="http://boole.stanford.edu/pratt.html"/>.</para></footnote>, we see that only the <literal moreinfo="none">id</literal> and binding powers are different. It has a higher binding power because it binds more tightly:</para><programlisting id="I_programlisting9_tt160" format="linespecific">
	symbol("*", 70).led = function (left) {
	    this.first = left;
	    this.second = expression(70);
	    this.arity = "binary";
	    return this;
	};
</programlisting><para>Not all <indexterm id="idx-CHP-9-0554" significance="normal"><primary>infix function (JavaScript)</primary></indexterm>infix <indexterm id="idx-CHP-9-0555" significance="normal"><primary>operator precedence</primary></indexterm>operators will be this similar, but many will, so we can make our work easier by defining an <literal moreinfo="none">infix</literal> function that will help us specify <indexterm id="idx-CHP-9-0556" significance="normal"><primary>infix operators (JavaScript)</primary></indexterm>infix operators. The <literal moreinfo="none">infix</literal> function will take an <literal moreinfo="none">id</literal> and a binding power, and optionally a <literal moreinfo="none">led</literal> function. If a <literal moreinfo="none">led</literal> function is not provided, it will supply a default <literal moreinfo="none">led</literal> that is useful in most cases:</para><programlisting id="I_programlisting9_tt161" format="linespecific">
	var infix = function (id, bp, led) {
	    var s = symbol(id, bp);
	    s.led = led || function (left) {
	        this.first = left;
	        this.second = expression(bp);
	        this.arity = "binary";
	        return this;
	    };
	    return s;
	}
</programlisting><para>This allows a more declarative style for specifying operators:</para><programlisting id="I_programlisting9_tt162" format="linespecific">
	infix("+", 60);
	infix("-", 60);
	infix("*", 70);
	infix("/", 70);
</programlisting><para>The string === is <indexterm id="idx-CHP-9-0557" significance="normal"><primary>JavaScript</primary></indexterm>JavaScript's exact-equality comparison operator:</para><programlisting id="I_programlisting9_tt163" format="linespecific">
	infix("===", 50);
	infix("!==", 50);
	infix("&lt;", 50);
	infix("&lt;=", 50);
	infix("&gt;", 50);
	infix("&gt;=", 50);
</programlisting><para>The <indexterm id="idx-CHP-9-0558" significance="normal"><primary>ternary operator (?:) in JavaScript</primary></indexterm>ternary operator takes three expressions, separated by ? and :. It is not an ordinary infix operator, so we need to supply its <literal moreinfo="none">led</literal> function:</para><programlisting id="I_programlisting9_tt164" format="linespecific">
	infix("?", 20, function (left) {
	    this.first = left;
	    this.second = expression(0);
	    advance(":");
	    this.third = expression(0);
	    this.arity = "ternary";
	    return this;
	});
</programlisting><para>The <indexterm id="idx-CHP-9-0559" significance="normal"><primary sortas=" operator in JavaScript">. operator in JavaScript</primary></indexterm>. operator is used to select a member of an object. The token on the right must be a name, but it will be used as a literal:</para><programlisting id="I_programlisting9_tt165" format="linespecific">
	infix(".", 90, function (left) {
	    this.first = left;
	    if (token.arity !== "name") {
	        token.error("Expected a property name.");
	    }
	    token.arity = "literal";
	    this.second = token;
	    this.arity = "binary";
	    advance( );
	    return this;
	});
</programlisting><para>The <indexterm id="idx-CHP-9-0560" significance="normal"><primary>[ ] operator in JavaScript</primary></indexterm>[ <indexterm id="idx-CHP-9-0561" significance="normal"><primary>operator precedence</primary></indexterm>operator is used to dynamically select a member from an object or array. The expression on the right must be followed by a closing ]:</para><programlisting id="I_programlisting9_tt166" format="linespecific">
	infix("[", 90, function (left) {
	    this.first = left;
	    this.second = expression(0);
	    this.arity = "binary";
	    advance("]");
	    return this;
	});
</programlisting><para>Those <indexterm id="idx-CHP-9-0562" significance="normal"><primary>infix operators (JavaScript)</primary></indexterm>infix operators are left associative. We can also make <indexterm id="idx-CHP-9-0563" significance="normal"><primary>right associative operators (JavaScript)</primary></indexterm>right associative operators, such as <indexterm id="idx-CHP-9-0564" significance="normal"><primary>short-circuiting logical operators (JavaScript)</primary></indexterm>short-circuiting <indexterm id="idx-CHP-9-0565" significance="normal"><primary>logical operators (short-circuiting)</primary></indexterm>logical operators, by reducing the right binding power:</para><programlisting id="I_programlisting9_tt167" format="linespecific">
	var infixr = function (id, bp, led) {
	    var s = symbol(id, bp);
	    s.led = led <indexterm id="idx-CHP-9-0566" significance="normal"><primary>| (vertical bar)</primary></indexterm>|| function (left) {
	        this.first = left;
	        this.second = expression(bp - 1);
	        this.arity = "binary";
	        return this;
	    };
	    return s;
	}
</programlisting><para>The <indexterm id="idx-CHP-9-0567" significance="normal"><primary>&amp; (ampersand)</primary></indexterm>&amp;&amp; operator returns the first operand if the first operand is falsy. Otherwise, it returns the second operand. The || operator returns the first operand if the first operand is truthy; otherwise, it returns the second operand:</para><programlisting id="I_programlisting9_tt168" format="linespecific">
	infixr("&amp;&amp;", 40);
	infixr("||", 40);
</programlisting></sect1><sect1 id="prefix_operators" label="9.7"><title>Prefix Operators</title><para>We can do a similar thing for <indexterm id="idx-CHP-9-0568" significance="normal"><primary>JavaScript</primary><secondary>prefix operators</secondary></indexterm>prefix operators. <indexterm id="idx-CHP-9-0569" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>prefix operators</tertiary></indexterm>Prefix operators are right associative. A prefix does not have a left binding power because it does not bind to the left. <indexterm id="idx-CHP-9-0570" significance="normal"><primary>parsers</primary><secondary>JavaScript</secondary><tertiary>prefix operators</tertiary></indexterm>Prefix operators can sometimes be reserved words (reserved words are discussed in the section "Scope," later in this chapter):<indexterm id="idx-CHP-9-0571" significance="normal"><primary>prefix operators (in JavaScript)</primary></indexterm><indexterm id="I_indexterm9_tt169" class="endofrange" startref="idx-CHP-9-0546" significance="normal"><primary>infix operators (JavaScript)</primary></indexterm><indexterm id="I_indexterm9_tt170" class="endofrange" startref="idx-CHP-9-0551" significance="normal"><primary>JavaScript</primary><secondary>infix operators</secondary></indexterm></para><programlisting id="I_programlisting9_tt171" format="linespecific">
	var prefix = function (id, nud) {
	    var s = symbol(id);
	    s.nud = nud || function ( ) {
	        scope.reserve(this);
	        this.first = expression(80);
	        this.arity = "unary";
	        return this;
	    };
	    return s;
	}
	prefix("-");
	prefix("!");
	prefix("typeof");
</programlisting><para>The <literal moreinfo="none">nud</literal> of ( will call <literal moreinfo="none">advance</literal>(")") to match a balancing ) token. The ( token does not become part of the parse tree because the <literal moreinfo="none">nud</literal> returns the expression:</para><programlisting id="I_programlisting9_tt172" format="linespecific">
	prefix("(", function ( ) {
	    var e = expression(0);
	    advance(")");
	    return e;
	});
</programlisting></sect1><sect1 id="assignment_operators" label="9.8"><title>Assignment Operators</title><para>We could use <literal moreinfo="none">infixr</literal> to define our <indexterm id="idx-CHP-9-0572" significance="normal"><primary>JavaScript</primary><secondary>assignment operators</secondary></indexterm>assignment operators, but we want to do two extra bits of business, so we will make a specialized <literal moreinfo="none">assignment</literal> function. It will examine the left operand to make sure that it is a proper lvalue. We will also set an <literal moreinfo="none">assignment</literal> flag so that we can later quickly identify assignment statements:<indexterm id="idx-CHP-9-0573" significance="normal"><primary>assignment operators (JavaScript)</primary></indexterm><indexterm id="idx-CHP-9-0574" significance="normal"><primary>operator precedence</primary></indexterm></para><programlisting id="I_programlisting9_tt173" format="linespecific">
	var assignment = function (id) {
	    return infixr(id, 10, function (left) {
	        if (left.id !== "." &amp;&amp; left.id !== "[" &amp;&amp;
	                left.arity !== "name") {
	            left.error("Bad lvalue.");
	        }
	        this.first = left;
	        this.second = expression(9);
	        this.assignment = true;
	        this.arity = "binary";
	        return this;
	    });
	};
	assignment("=");
	assignment("+=");
	assignment("-=");
</programlisting><para>Notice that we have a sort of inheritance pattern, where <literal moreinfo="none">assignment</literal> returns the result of calling <literal moreinfo="none">infixr</literal>, and <literal moreinfo="none">infixr</literal> returns the result of calling <literal moreinfo="none">symbol</literal>.</para></sect1><sect1 id="constants" label="9.9"><title>Constants</title><para>The <literal moreinfo="none">constant</literal> function builds <indexterm id="idx-CHP-9-0575" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>constants</tertiary></indexterm>constants into the language. The <literal moreinfo="none">nud</literal> mutates a name token into a literal token:<indexterm id="idx-CHP-9-0576" significance="normal"><primary>JavaScript</primary><secondary>constants</secondary></indexterm></para><programlisting id="I_programlisting9_tt174" format="linespecific">
	var constant = function (s, v) {
	    var x = symbol(s);
	    x.nud = function ( ) {
	        <indexterm class="startofrange" id="idx-CHP-9-0577" significance="normal"><primary>scope</primary></indexterm>scope.reserve(this);
	        this.value = symbol_table[this.id].value;
	        this.arity = "literal";
	        return this;
	    };
	    x.value = v;
	    return x;
	};
	constant("true", true);
	constant("false", false);
	constant("null", null);
	constant("pi", 3.141592653589793);
</programlisting></sect1><sect1 id="scope" label="9.10"><title>Scope</title><para>We use functions such as <literal moreinfo="none">infix</literal> and <literal moreinfo="none">prefix</literal> to define the symbols used in the language. Most languages have some notation for <indexterm id="idx-CHP-9-0578" significance="normal"><primary>defining new variables in a scope (JavaScript parser)</primary></indexterm>defining new symbols, such as variable names. In a very simple language, when we encounter a new word, we might give it a definition and put it in the symbol table. In a more sophisticated language, we would want a notion of <indexterm id="idx-CHP-9-0579" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>scope</tertiary></indexterm>scope, giving the programmer convenient control over the lifespan and visibility of a variable.<indexterm class="startofrange" id="idx-CHP-9-0580" significance="normal"><primary>variables</primary><secondary>scope in JavaScript</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-9-0581" significance="normal"><primary>JavaScript</primary><secondary>scope</secondary></indexterm></para><para>A <emphasis>scope</emphasis> is a region of a program in which a variable is defined and accessible. Scopes can be nested inside of other scopes. Variables defined in a scope are not visible outside of the scope.<indexterm id="idx-CHP-9-0582" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>scope</tertiary></indexterm></para><para>We will keep the current scope object in the <literal moreinfo="none">scope</literal> variable:</para><programlisting id="I_programlisting9_tt175" format="linespecific">
	var scope;
</programlisting><para><literal moreinfo="none">original_scope</literal> is the prototype for all scope objects. It contains a <literal moreinfo="none">define</literal> method that is used to define new variables in the scope. The <literal moreinfo="none">define</literal> method transforms a name token into a variable token. It produces an error if the variable has already been defined in the scope or if the name has already been used as a reserved word:</para><programlisting id="I_programlisting9_tt176" format="linespecific">
	var original_scope = {
	    define: function (n) {
	        var t = this.def[n.value];
	        if (typeof t === "object") {
	            n.error(t.reserved ?
	                "Already reserved." :
	                "Already defined.");
	        }
	        this.def[n.value] = n;
	        n.<indexterm id="idx-CHP-9-0583" significance="normal"><primary>reserved words</primary></indexterm>reserved = false;
	        n.nud      = itself;
	        n.led      = null;
	        n.std      = null;
	        n.lbp      = 0;
	        n.<indexterm id="idx-CHP-9-0584" significance="normal"><primary>scope</primary></indexterm>scope    = <indexterm id="idx-CHP-9-0585" significance="normal"><primary>JavaScript</primary><secondary>scope</secondary></indexterm>scope;
	        return n;
	    },
</programlisting><para>The <literal moreinfo="none">find</literal> method is used to find <indexterm id="idx-CHP-9-0586" significance="normal"><primary>finding the definition of a name (JavaScript parser)</primary></indexterm>the definition of a name. It starts with the current <indexterm id="idx-CHP-9-0587" significance="normal"><primary>variables</primary><secondary>scope in JavaScript</secondary></indexterm>scope and will go, if necessary, back through the chain of parent <indexterm id="idx-CHP-9-0588" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>scope</tertiary></indexterm>scopes and ultimately to the symbol table. It returns <literal moreinfo="none">symbol_table["(name")]</literal> if it cannot find a definition:</para><programlisting id="I_programlisting9_tt177" format="linespecific">
	find: function (n) {
	    var e = this;
	    while (true) {
	        var o = e.def[n];
	        if (o) {
	            return o;
	        }
	        e = e.parent;
	        if (!e) {
	            return symbol_table[
	                symbol_table.hasOwnProperty(n) ?
	                n : "(name)"];
	        }
	    }
	},
</programlisting><para>The <literal moreinfo="none">pop</literal> method closes a <indexterm id="idx-CHP-9-0589" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>scope</tertiary></indexterm>scope:<indexterm id="idx-CHP-9-0590" significance="normal"><primary>pop method</primary></indexterm></para><programlisting id="I_programlisting9_tt178" format="linespecific">
	pop: function () {
	    scope = this.parent;
	},
</programlisting><para>The <literal moreinfo="none">reserve</literal> method is used to indicate that a name has been used as a reserved word in the current scope:</para><programlisting id="I_programlisting9_tt179" format="linespecific">
	    reserve: function (n) {
	        if (n.arity !== "name" || n.reserved) {
	            return;
	        }
	        var t = this.def[n.value];
	        if (t) {
	            if (t.reserved) {
	                return;
	            }
	            if (t.arity === "name") {
	                n.error("Already defined.");
	            }
	        }
	        this.def[n.value] = n;
	        n.reserved = true;
	    }
	};
</programlisting><para>We need a policy for reserved words. In some languages, words that are used structurally (such as <literal moreinfo="none">if</literal>) are reserved and cannot be used as variable names. The flexibility of our parser allows us to have a more useful policy. For example, we can say that in any function, any name may be used as a structure word or as a variable, but not as both. Also, we will reserve words locally only after they are used as reserved words. This makes things better for the language designer because adding <indexterm id="idx-CHP-9-0591" significance="normal"><primary>scope</primary><secondary>new scope for a function or a block</secondary></indexterm>new structure words to the language will not break existing programs, and it makes things better for programmers because they are not hampered by irrelevant restrictions on the use of names.</para><para>Whenever we want to establish a new <indexterm id="idx-CHP-9-0592" significance="normal"><primary>scope</primary></indexterm>scope for a function or a block, we call the <literal moreinfo="none">new_scope</literal> function, which makes a new instance of the original <indexterm id="idx-CHP-9-0593" significance="normal"><primary>variables</primary><secondary>scope in JavaScript</secondary></indexterm>scope prototype:<indexterm id="idx-CHP-9-0594" significance="normal"><primary>JavaScript</primary><secondary>scope</secondary></indexterm></para><programlisting id="I_programlisting9_tt180" format="linespecific">
	var new_<indexterm id="idx-CHP-9-0595" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>scope</tertiary></indexterm>scope = function () {
	    var s = <indexterm id="idx-CHP-9-0596" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>scope</tertiary></indexterm>scope;
	    scope = object(original_scope);
	    scope.def = {};
	    scope.parent = s;
	    return scope;
	};
</programlisting></sect1><sect1 id="statements" label="9.11"><title>Statements</title><para>Pratt's original formulation worked with functional languages in which everything is an expression. Most mainstream languages have <indexterm class="startofrange" id="idx-CHP-9-0597" significance="normal"><primary>JavaScript</primary><secondary>statements</secondary></indexterm>statements. We can easily handle <indexterm id="idx-CHP-9-0598" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>statements</tertiary></indexterm>statements by adding another method to tokens, <literal moreinfo="none">std</literal> (statement denotation). An <literal moreinfo="none">std</literal> is like a <literal moreinfo="none">nud</literal> except that it is only used at the beginning of a statement.<indexterm id="idx-CHP-9-0599" significance="normal"><primary>expressions</primary><secondary>statements vs.</secondary></indexterm><indexterm id="idx-CHP-9-0600" significance="normal"><primary>std (statement denotation) method (JavaScript tokens)</primary></indexterm><indexterm id="idx-CHP-9-0601" significance="normal"><primary>tokens</primary><secondary>JavaScript</secondary><tertiary>std method</tertiary></indexterm><indexterm class="startofrange" id="idx-CHP-9-0602" significance="normal"><primary>statements (JavaScript)</primary></indexterm></para><para>The <literal moreinfo="none">statement</literal> function parses one statement. If the current token has an <literal moreinfo="none">std</literal> method, the token is reserved and the <literal moreinfo="none">std</literal> is invoked. Otherwise, we assume an expression statement terminated with a ;. For reliability, we reject an expression statement that is not an assignment or invocation:</para><programlisting id="I_programlisting9_tt181" format="linespecific">
	var statement = function ( ) {
	    var n = token, v;
	    if (n.std) {
	        advance( );
	        scope.reserve(n);
	        return n.std( );
	    }
	    v = expression(0);
	    if (!v.assignment &amp;&amp; v.id !== "(") {
	        v.error("Bad expression statement.");
	    }
	    advance(";");
	    return v;
	};
</programlisting><para>The <literal moreinfo="none">statements</literal> function parses statements until it sees <literal moreinfo="none">(end)</literal> or } signaling the end of a block. It returns a statement, an array of statements, or (if there were no statements present) simply <literal moreinfo="none">null</literal>:<indexterm id="idx-CHP-9-0603" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>statements</tertiary></indexterm><indexterm id="I_indexterm9_tt182" class="endofrange" startref="idx-CHP-9-0577" significance="normal"><primary>scope</primary></indexterm><indexterm id="I_indexterm9_tt183" class="endofrange" startref="idx-CHP-9-0581" significance="normal"><primary>JavaScript</primary><secondary>scope</secondary></indexterm><indexterm id="I_indexterm9_tt184" class="endofrange" startref="idx-CHP-9-0580" significance="normal"><primary>variables</primary><secondary>scope in JavaScript</secondary></indexterm></para><programlisting id="I_programlisting9_tt185" format="linespecific">
	var statements = function ( ) {
	    <indexterm id="idx-CHP-9-0604" significance="normal"><primary>variables</primary><secondary>defining in current block (JavaScript)</secondary></indexterm><indexterm id="idx-CHP-9-0605" significance="normal"><primary>var statement (JavaScript)</primary></indexterm>var a = [], s;
	    while (true) {
	        if (token.id === "}" || token.id === "(end)") {
	            break;
	        }
	        s = <indexterm id="idx-CHP-9-0606" significance="normal"><primary>{ } (curly braces)</primary><secondary>statement blocks in JavaScript</secondary></indexterm>statement( );
	        if (s) {
	            a.push(s);
	        }
	    }
	    return a.length === 0 ? null : a.length === 1 ? a[0] : a;
	};
</programlisting><para>The <literal moreinfo="none">stmt</literal> function is used to add <indexterm id="idx-CHP-9-0607" significance="normal"><primary>statements (JavaScript)</primary></indexterm>statements to the symbol table. It takes a statement <literal moreinfo="none">id</literal> and an <literal moreinfo="none">std</literal> function:</para><programlisting id="I_programlisting9_tt186" format="linespecific">
	var stmt = function (s, f) {
	    var x = symbol(s);
	    x.std = f;
	    return x;
	};
</programlisting><para>The <indexterm id="idx-CHP-9-0608" significance="normal"><primary>block statement (JavaScript)</primary></indexterm>block statement wraps a pair <indexterm id="idx-CHP-9-0609" significance="normal"><primary>blocks of code (JavaScript)</primary></indexterm>of curly braces around a list of <indexterm id="idx-CHP-9-0610" significance="normal"><primary>JavaScript</primary><secondary>statements</secondary></indexterm>statements, giving them a new scope:</para><programlisting id="I_programlisting9_tt187" format="linespecific">
	stmt("{", function ( ) {
	    new_scope( );
	    var a = <indexterm id="idx-CHP-9-0611" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>statements</tertiary></indexterm>statements( );
	    advance("}");
	    scope.pop( );
	    return a;
	});
</programlisting><para>The <literal moreinfo="none">block</literal> function parses a block:</para><programlisting id="I_programlisting9_tt188" format="linespecific">
	var block = function ( ) {
	    var t = token;
	    advance("{");
	    return t.std( );
	};
</programlisting><para>The <literal moreinfo="none">var</literal> statement defines one or more variables in the current block. Each name can optionally be followed by = and an expression:</para><programlisting id="I_programlisting9_tt189" format="linespecific">
	stmt("var", function ( ) {
	    var a = [], n, t;
	    while (true) {
	        n = token;
	        if (n.arity !== "name") {
	            n.error("Expected a new variable name.");
	        }
	        scope.define(n);
	        advance( );
	        if (token.id === "=") {
	            t = token;
	            advance("=");
	            t.first = n;
	            t.second = expression(0);
	            t.arity = "binary";
	            a.push(t);
	        }
	        <indexterm id="idx-CHP-9-0612" significance="normal"><primary>if statement (JavaScript)</primary></indexterm>if (token.id !== ",") {
	            <indexterm id="idx-CHP-9-0613" significance="normal"><primary>break statement (JavaScript)</primary></indexterm>break;
	        }
	        advance(",");
	    }
	    advance(";");
	    return a.length === 0 ? null : a.length === 1 ? a[0] : a;
	});
</programlisting><para>The <literal moreinfo="none">while</literal> statement defines a loop. It contains an expression in parentheses and a block:<indexterm id="idx-CHP-9-0614" significance="normal"><primary>while statement (JavaScript)</primary></indexterm></para><programlisting id="I_programlisting9_tt190" format="linespecific">
	stmt("while", function ( ) {
	    advance("(");
	    this.first = expression(0);
	    advance(")");
	    this.second = block( );
	    this.arity = "statement";
	    return this;
	});
</programlisting><para>The <literal moreinfo="none">if</literal> statement allows for conditional execution. If we see the <literal moreinfo="none">else</literal> symbol after the block, we parse the next block or <literal moreinfo="none">if</literal> statement:</para><programlisting id="I_programlisting9_tt191" format="linespecific">
	stmt("if", function ( ) {
	    advance("(");
	    this.first = expression(0);
	    advance(")");
	    this.second = block( );
	    if (token.id === "else") {
	        scope.reserve(token);
	        advance("else");
	        this.third = token.id === "if" ? statement() : block( );
	    }
	    this.arity = "statement";
	    return this;
	});
</programlisting><para>The <literal moreinfo="none">break</literal> statement is used to break out of loops. We make sure that the next symbol is }:</para><programlisting id="I_programlisting9_tt192" format="linespecific">
	stmt("break", function ( ) {
	    advance(";");
	    if (token.id !== "}") {
	        token.error("Unreachable statement.");
	    }
	    this.arity = "statement";
	    return this;
	});
</programlisting><para>The <literal moreinfo="none">return</literal> statement is used to return from <indexterm id="idx-CHP-9-0615" significance="normal"><primary>{ } (curly braces)</primary><secondary>enclosing function body in JavaScript</secondary></indexterm>functions. It can return an optional expression:<indexterm id="idx-CHP-9-0616" significance="normal"><primary>return statement (JavaScript)</primary></indexterm></para><programlisting id="I_programlisting9_tt193" format="linespecific">
	stmt("return", function ( ) {
	    if (token.id !== ";") {
	        this.first = expression(0);
	    }
	    advance(";");
	    if (token.id !== "}") {
	        token.error("Unreachable statement.");
	    }
	    this.arity = "statement";
	    return this;
	});
</programlisting></sect1><sect1 id="functions" label="9.12"><title>Functions</title><para><indexterm id="idx-CHP-9-0617" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary><tertiary>functions</tertiary></indexterm>Functions are executable object values. A function has an optional name (so that it can call itself recursively), a list of parameter names wrapped in parentheses, and a body that is a list of <indexterm id="idx-CHP-9-0618" significance="normal"><primary>statements (JavaScript)</primary></indexterm>statements wrapped in curly braces. A function has its own scope:<indexterm id="idx-CHP-9-0619" significance="normal"><primary>scope</primary><secondary>functions</secondary></indexterm><indexterm id="idx-CHP-9-0620" significance="normal"><primary>JavaScript</primary><secondary>functions</secondary></indexterm><indexterm id="I_indexterm9_tt194" class="endofrange" startref="idx-CHP-9-0602" significance="normal"><primary>statements (JavaScript)</primary></indexterm><indexterm id="I_indexterm9_tt195" class="endofrange" startref="idx-CHP-9-0597" significance="normal"><primary>JavaScript</primary><secondary>statements</secondary></indexterm></para><programlisting id="I_programlisting9_tt196" format="linespecific">
	prefix("function", function ( ) {
	    var a = [];
	    scope = new_scope( );
	    if (token.arity === "name") {
	        scope.define(token);
	        this.name = token.value;
	        advance( );
	    }
	    advance("(");
	    if (token.id !== ")") {
	        while (true) {
	            if (token.arity !== "name") {
	                token.error("Expected a parameter name.");
	            }
	            scope.define(token);
	            a.push(token);
	            advance( );
	            if (token.id !== ",") {
	                break;
	            }
	            advance(",");
	        }
	    }
	    this.first = a;
	    advance(")");
	    advance("{");
	    this.second = <indexterm id="idx-CHP-9-0621" significance="normal"><primary>JavaScript</primary><secondary>statements</secondary></indexterm>statements( );
	    advance("}");
	    this.arity = "function";
	    scope.pop( );
	    return this;
	});
</programlisting><para><indexterm id="idx-CHP-9-0622" significance="normal"><primary>( ) (parentheses)</primary><secondary>invoking functions</secondary></indexterm>Functions are invoked with the ( <indexterm id="idx-CHP-9-0623" significance="normal"><primary>operator precedence</primary></indexterm>operator. It can take zero or more comma-separated arguments. We look at the left operand to detect expressions that cannot possibly be function values:</para><programlisting id="I_programlisting9_tt197" format="linespecific">
	infix("(", 90, function (left) {
	    var a = [];
	    this.first = left;
	    this.second = a;
	    this.arity = "binary";
	    if ((left.arity !== "unary" ||
	            left.id !== "function") &amp;&amp;
	        left.arity !== "name" &amp;&amp;
	        (left.arity !== "binary" ||
	            (left.id !== "." &amp;&amp;
	            left.id !== "(" &amp;&amp;
	            left.id !== "["))) {
	        left.error("Expected a variable name.");
	    }
	    if (token.id !== ")") {
	        while (true) {
	            a.push(expression(0));
	            if (token.id !== ",") {
	                break;
	            }
	            advance(",");
	         }
	    }
	    advance(")");
	    return this;
	});
</programlisting></sect1><sect1 id="array_and_object_literals" label="9.13"><title>Array and Object Literals</title><para>An array literal is a set of square brackets around zero or more comma-separated expressions. Each of the expressions is evaluated, and the results are collected into a new array:<indexterm id="idx-CHP-9-0624" significance="normal"><primary>JavaScript</primary><secondary>array and object literals</secondary></indexterm><indexterm id="idx-CHP-9-0625" significance="normal"><primary>array literals in JavaScript</primary></indexterm><indexterm id="idx-CHP-9-0626" significance="normal"><primary>list comprehension (Haskell)</primary><secondary>literals (in JavaScript)</secondary></indexterm></para><programlisting id="I_programlisting9_tt198" format="linespecific">
	prefix("[", function ( ) {
	    var a = [];
	    if (token.id !== "]") {
	        while (true) {
	            a.push(expression(0));
	            if (token.id !== ",") {
	                break;
	            }
	            advance(",");
	         }
	    }
	    advance("]");
	    this.first = a;
	    this.arity = "unary";
	    return this;
	});
</programlisting><para>An object literal is a set of curly braces around zero or more comma-separated pairs. A <emphasis>pair</emphasis> is a key/expression pair separated by a :. The key is a literal or a name treated as a literal:</para><programlisting id="I_programlisting9_tt199" format="linespecific">
	prefix("{", function ( ) {
	    var a = [];
	    if (token.id !== "}") {
	        while (true) {
	            var n = token;
	            if (n.arity !== "name" &amp;&amp; n.arity !== "literal") {
	                token.error("Bad key.");
	            }
	            advance( );
	            advance(":");
	            var v = expression(0);
	            v.key = n.value;
	            a.push(v);
	            if (token.id !== ",") {
	                break;
	            }
	            advance(",");
	         }
	    }
	    advance("}");
	    this.first = a;
	    this.arity = "unary";
	    return this;
	});
</programlisting></sect1><sect1 id="things_to_do_and_think_about" label="9.14"><title>Things to Do and Think About</title><para>The simple parser shown in this chapter is easily extensible. The tree could be passed to a code generator, or it could be passed to an interpreter. Very little computation is required to produce the tree. And as we saw, very little effort was required to write the programming that built the tree.</para><para>We could make the <literal moreinfo="none">infix</literal> function take an opcode that would aid in code generation. We could also have it take additional methods that would be used to do constant folding and code generation.</para><para>We could add additional statements, such as <literal moreinfo="none">for, switch</literal>, and <literal moreinfo="none">try</literal>. We could add statement labels. We could add more error checking and error recovery. We could add lots more operators. We could add type specification and inference.</para><para>We could make our language extensible. With the same ease that we can define new variables, we can let the programmer add new operators and new statements.</para><para>You can try the demonstration of the parser that was described in this chapter at <ulink url="http://javascript.crockford.com/tdop/index.html"/>.</para><para>Another example of this parsing technique can be found in JSLint at <ulink url="http://JSLint.com"/>.<indexterm id="I_indexterm9_tt200" class="endofrange" startref="idx-CHP-9-0505" significance="normal"><primary>operator precedence</primary></indexterm><indexterm id="I_indexterm9_tt201" class="endofrange" startref="idx-CHP-9-0514" significance="normal"><primary>parsers</primary><secondary>JavaScript</secondary></indexterm><indexterm id="I_indexterm9_tt202" class="endofrange" startref="idx-CHP-9-0516" significance="normal"><primary>operator precedence</primary><secondary>JavaScript</secondary></indexterm><indexterm id="I_indexterm9_tt203" class="endofrange" startref="idx-CHP-9-0517" significance="normal"><primary>JavaScript</primary></indexterm></para></sect1></chapter><chapter id="the_quest_for_an_accelerated_population_count" label="10" role=""><title>The Quest for an Accelerated Population Count</title><para><emphasis>Henry S. Warren, Jr</emphasis>.<indexterm class="startofrange" id="idx-CHP-10-0627" significance="normal"><primary>population count</primary></indexterm><indexterm id="idx-CHP-10-0628" significance="normal"><primary>Warren</primary></indexterm></para><para><emphasis>A fundamental computer algorithm, and a deceptively simple one</emphasis>, is the <emphasis>population count</emphasis> or <emphasis>sideways sum</emphasis>, which calculates the number of bits in a computer word that are 1. The population count function has applications that range from the very simple to the quite sublime. For example, if sets are represented by bit strings, population count gives the size of the set. It can also be used to generate binomially distributed random integers. These and other applications are discussed at the end of this chapter.</para><para>Although uses of this operation are not terribly common, many computers—often the supercomputers of their day—had an instruction for it. These included the Ferranti Mark I (1951), the IBM Stretch computer (1960), the CDC 6600 (1964), the Russian-built BESM-6 (1967), the Cray 1 (1976), the Sun SPARCv9 (1994), and the IBM Power 5 (2004).</para><para>This chapter discusses how to compute the population count function on a machine that does not have that instruction, but which has the <indexterm id="idx-CHP-10-0629" significance="normal"><primary>fundamental instructions on RISC and CISC computers</primary></indexterm>fundamental instructions generally found on a RISC or <indexterm id="idx-CHP-10-0630" significance="normal"><primary>CISC computers</primary></indexterm>CISC computer: <emphasis>shift, add, and, load, conditional branch</emphasis>, and so forth. For illustration, we assume the computer has a <indexterm id="idx-CHP-10-0631" significance="normal"><primary>32-bit word</primary></indexterm>32-bit word size, but most of the techniques discussed here can be easily adapted to other word sizes.</para><para>Two problems in <indexterm id="idx-CHP-10-0632" significance="normal"><primary>population count</primary></indexterm>population counting are addressed: counting the 1-bits in a single computer word, and counting the 1-bits in a large number of words, perhaps arranged in an array. In each case, we show that the obvious solution, even if carefully honed, can be beaten substantially by very different algorithms that take some imagination to find. The first is an application of the divide-and-conquer strategy, and the second is an application of a certain logic circuit that is familiar to computer logic designers but not so familiar to programmers.</para><sect1 id="basic_methods" label="10.1"><title>Basic Methods</title><para>As a first cut, a programmer might count the 1-bits in a word <replaceable>x</replaceable>, as illustrated in the following C-language solution. Here <replaceable>x</replaceable> is an unsigned integer, so the right shift is with 0-fill:<indexterm id="idx-CHP-10-0633" significance="normal"><primary>population count</primary><secondary>basic methods</secondary></indexterm></para><programlisting id="I_programlisting10_tt204" format="linespecific">
	pop = 0;
	for (i = 0; i &lt; 32; i++){
	   if (x &amp; 1) pop = pop + 1;
	   x = x &gt;&gt; 1;
	}
</programlisting><para>On a typical RISC computer, the loop might compile into about seven instructions, two of which are conditional branches. (One of the conditional branches is for loop control.) These seven instructions are executed 32 times, but one of them is bypassed about half the time (we might presume), so that it executes about 32 x 6.5 = 208 instructions.</para><para>It would probably not take the programmer long to realize that this code can be easily improved. For one thing, on many computers, counting down from 31 to 0 is more efficient than counting up, because it saves a <emphasis>compare</emphasis> instruction. Better yet, why count at all? Just let the loop go until <replaceable>x</replaceable> is 0. This eliminates some iterations if <replaceable>x</replaceable> has high-order 0-bits. Another optimization is to replace the <literal moreinfo="none">if</literal> test with code that simply adds the rightmost bit of <replaceable>x</replaceable> to the count. This leads to the code:</para><programlisting id="I_programlisting10_tt205" format="linespecific">
	pop = 0;
	while (x) {
	   pop = pop + (x &amp; 1);
	   x = x &gt;&gt; 1;
	}
</programlisting><para>This has only four or five RISC instructions in the loop, depending upon whether or not a <emphasis>compare</emphasis> of <replaceable>x</replaceable> to 0 is required, and only one branch. (We assume the compiler rearranges the loop so that the conditional branch is at the bottom.) Thus, it takes a maximum of 128 to 160 instructions. The maximum occurs if <replaceable>x</replaceable> begins with a 1-bit, but it will take far fewer instructions if <replaceable>x</replaceable> has many leading 0s.</para><para>Some readers may recall that the simple expression <literal moreinfo="none">x&amp;(x-1)</literal> is <replaceable>x</replaceable> with its least significant 1-bit turned off, or is 0 if <replaceable>x</replaceable>= 0. Thus, to count the 1-bits in <replaceable>x</replaceable>, one can turn them off one at a time until the result is 0, keeping count of how many were turned off. This leads to the code:</para><programlisting id="I_programlisting10_tt206" format="linespecific">
	pop = 0;
	while (x) {
	   pop = pop + 1;
	   x = x &amp; (x - 1);
	}
</programlisting><para>Like the preceding code, this takes four or five instructions in the loop, but the loop runs only the same number of times as the number of 1s in <replaceable>x</replaceable>. This is surely an improvement.</para><para>A complementary approach, applicable if the number of 1-bits is expected to be large, is to keep turning on the rightmost 0-bit with <literal moreinfo="none">x = x|(x+1)</literal> until the result is all 1s (−1). Count the number of iterations executed in a variable <replaceable>n</replaceable>, and return 32 − <replaceable>n</replaceable>. (Alternatively, the original number <replaceable>x</replaceable> can be complemented, or <replaceable>n</replaceable> can be initialized to 32 and counted down.)</para><para>The first program in this series is rather dull, but the others might be considered to have some beauty to an eye that values efficiency, conciseness, and useful cleverness. The first program can be made to run substantially faster by unrolling the loop, but the other two programs would be improved very little, if at all, by this change.</para><para>One can also employ table lookup, translating perhaps a byte of <replaceable>x</replaceable> at a time to the number of 1-bits in that byte. The code is quite short and will be very fast on many machines (approximately 17 instructions on a basic RISC that doesn't have indexed loads). In the following code, <literal moreinfo="none">table[<replaceable>i</replaceable>]</literal> is the number of 1-bits in <replaceable>i</replaceable>, for <replaceable>i</replaceable> ranging from 0 to 255:</para><programlisting id="I_programlisting10_tt207" format="linespecific">
	static char table[256] = {0, 1, 1, 2, 1, 2, 2, 3, ..., 8};
	pop = table[x &amp; 0xFF] + table[(x &gt;&gt; 8) &amp; 0xFF] +
	      table[(x &gt;&gt; 16) &amp; 0xFF] + table[x &gt;&gt; 24];
</programlisting></sect1><sect1 id="divide_and_conquer" label="10.2"><title>Divide and Conquer</title><para>Another interesting and useful way to compute the <indexterm id="idx-CHP-10-0634" significance="normal"><primary>population count</primary></indexterm>population count of a word is based on the "divide and conquer" paradigm. This algorithm might be devised by reasoning, "Suppose I had a way to compute the <indexterm class="startofrange" id="idx-CHP-10-0635" significance="normal"><primary>divide and conquer strategy</primary><secondary>population count</secondary></indexterm>population count of a 16-bit quantity. Then I could run that on the left and right halves of the 32-bit word, and add the results, to obtain the population count of the 32-bit word." This strategy won't pay off if the basic algorithm must be run sequentially on the two halves and it takes time proportional to the number of bits being analyzed, because it would then take 16<emphasis>k</emphasis> + 16<emphasis>k</emphasis> = 32<emphasis>k</emphasis> units of time, where <emphasis>k</emphasis> is the constant of proportionality, plus another instruction for the addition. But if we can somehow do the operation on the two halfwords in parallel, there will be an improvement from, essentially, 32<emphasis>k</emphasis> to 16<emphasis>k</emphasis> + 1.</para><para>To efficiently compute the population count of two 16-bit quantities, we need a way to do it for 8-bit quantities, and to do 4 of them in parallel. Continuing this reasoning, we need a way to compute the population count of 2-bit quantities, and to do 16 of them in parallel.</para><para>The algorithm to be described in no way depends on running operations on separate processors, or on unusual instructions such as the SIMD<footnote id="CHP-10-FNOTE-1"><para>Single-instruction, multiple-data instructions are instructions that operate on multiple fields (such as bytes or halfwords) of a computer word in parallel. For example, an 8-bit SIMD <emphasis>add</emphasis> might add the corresponding bytes of two words without propagating the carry from one byte to the next.</para></footnote>instructions found on some computers. It uses only the facilities usually found on a conventional uniprocessor RISC or CISC.</para><para>The plan is illustrated in <indexterm id="idx-CHP-10-0636" significance="normal"><primary>population count</primary></indexterm><xref linkend="counting_1-bits_divide_and_conquer_strategy"/>.</para><figure id="counting_1-bits_divide_and_conquer_strategy" label="10-1" float="0"><title>Counting 1-bits, "divide and conquer" strategy</title><mediaobject id="I_mediaobject10_tt208"><imageobject role="print"><imagedata fileref="figs/print/beauty_1001.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1001.png" format="PNG"/></imageobject></mediaobject></figure><para>The first line in <xref linkend="counting_1-bits_divide_and_conquer_strategy"/> is the word <emphasis>x</emphasis> for which we wish to count the number of 1-bits. Each 2-bit field of the second line contains the count of the number of 1-bits in the 2-bit field immediately above. The subscripts are the decimal values of these 2-bit fields. Each 4-bit field in the third line contains the sum of the numbers in two adjacent 2-bit fields of the second line, with the subscripts showing the decimal values, and so forth. The last line contains the number of 1-bits in <emphasis>x</emphasis>. The algorithm is executed in log<subscript>2</subscript>(32) = 5 steps, where each step contains some shifting and masking instructions to do the addition of adjacent fields.<indexterm id="idx-CHP-10-0637" significance="normal"><primary>population count</primary><secondary>divide and conquer strategy</secondary></indexterm></para><para>The method illustrated in <xref linkend="counting_1-bits_divide_and_conquer_strategy"/> may be committed to C code as follows:</para><programlisting id="I_programlisting10_tt209" format="linespecific">
	x = (x &amp; 0x55555555) + ((x &gt;&gt; 1) &amp; 0x55555555);
	x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);
	x = (x &amp; 0x0F0F0F0F) + ((x &gt;&gt; 4) &amp; 0x0F0F0F0F);
	x = (x &amp; 0x00FF00FF) + ((x &gt;&gt; 8) &amp; 0x00FF00FF);
	x = (x &amp; 0x0000FFFF) + ((x &gt;&gt;16) &amp; 0x0000FFFF);
</programlisting><para>(Constants beginning with <literal moreinfo="none">0x</literal> <indexterm id="idx-CHP-10-0638" significance="normal"><primary>constants</primary><secondary>hexadecimals in C</secondary></indexterm>in C are hexadecimal.) The first line uses <literal moreinfo="none">(x &gt;&gt; 1) &amp; 0x55555555</literal> rather than the perhaps more natural <literal moreinfo="none">(x&amp; 0xAAAAAAAA) &gt;&gt; 1</literal> because the code shown avoids generating two large constants in a register. This would cost an instruction if the machine lacks the <emphasis>and not</emphasis> instruction. A similar remark applies to the other lines.</para><para>Clearly the last <emphasis>and</emphasis> is unnecessary because <literal moreinfo="none">x &gt;&gt; 16</literal> must begin with 16 0-bits, so the <emphasis>and</emphasis> does not alter the value of <literal moreinfo="none">x &gt;&gt; 16</literal>. Other <emphasis>ands</emphasis> may be omitted when there is no danger that a field's sum will carry over into the adjacent field. And there is a way to code the first line that uses one less instruction. This leads to the simplification shown in <xref linkend="counting_bits_in_a_word"/>, which executes in 21 instructions and is free of branches and memory references.</para><example id="counting_bits_in_a_word" label="10-1"><title>Counting 1-bits in a word</title><programlisting format="linespecific">
int pop(unsigned x) {
   x = x - ((x &gt;&gt; 1) &amp; 0x55555555);
   x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);
   x = (x + (x &gt;&gt; 4)) &amp; 0x0F0F0F0F;
   x = x + (x &gt;&gt; 8);
   x = x + (x &gt;&gt; 16);
   return x &amp; 0x0000003F;
}
</programlisting></example><para>The first assignment to x is based on the first two terms of the formula:<indexterm id="idx-CHP-10-0639" significance="normal"><primary>population count</primary></indexterm></para><para><mediaobject id="I_mediaobject10_tt210"><imageobject role="print"><imagedata fileref="figs/print/equation3.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation3.png" format="PNG"/></imageobject></mediaobject>
</para><para>Here we must have <replaceable>x</replaceable> ≥ 0. By treating <replaceable>x</replaceable> as an unsigned integer, this equation can be implemented with a sequence of 31 <emphasis>shift right immediates</emphasis> of 1, and 31 <emphasis>subtracts</emphasis>. The procedure of <xref linkend="counting_bits_in_a_word"/> uses the first two terms of this on each 2-bit field, in parallel. I leave the proof of this equation to the reader.<indexterm id="idx-CHP-10-0640" significance="normal"><primary>shift right immediates instruction</primary></indexterm><indexterm id="idx-CHP-10-0641" significance="normal"><primary>subtracts instruction</primary></indexterm></para><para>Unfortunately, the code of <xref linkend="counting_bits_in_a_word"/> has lost most of the regularity and elegance of the code from which it was derived. A consequence of this is that it is no longer immediately clear how to extend the code to a 64-bit machine. But it's hard to pass up all those opportunities to save instructions!</para><para><indexterm id="idx-CHP-10-0642" significance="normal"><primary>population count</primary><secondary>divide and conquer strategy</secondary></indexterm>Divide and conquer is an important technique that should be near the top of every programmer's bag of tricks. And that goes for computer logic designers, too. Other applications of divide and conquer are the well-known technique of binary search, a sorting method known as Quicksort, and a method for reversing the bits of a word.</para></sect1><sect1 id="other_methods" label="10.3"><title>Other Methods</title><para>Item 169 in the <indexterm id="idx-CHP-10-0643" significance="normal"><primary>HAKMEM memo</primary></indexterm>HAKMEM memo<footnote id="CHP-10-FNOTE-2"><para>Michael Beeler, R. William Gosper, and Richard Schroeppel, "<indexterm id="idx-CHP-10-0644" significance="normal"><primary>32-bit word</primary><secondary>adapting HAKMEM population count for 36-bit word</secondary></indexterm>HAKMEM," <emphasis>MIT Artificial Intelligence Laboratory AIM</emphasis> 239, February 1972. This is now available on the Web at  <ulink url="http://www.inwap.com/pdp10/hbaker/hakmem/hakmem.html"/>, thanks to Henry Baker.</para></footnote>is an algorithm that counts the number of 1-bits in a word x by using the first three terms of the formula shown in the previous section on each 3-bit field of x separately, to produce a word of 3-bit fields, each of which contains the number of 1-bits that were in it. It then adds adjacent 3-bit fields to form 6-bit field sums, and then adds the 6-bit fields by computing the value of the word modulo 63. Although originally developed for a machine with a 36-bit word, the algorithm is easily adapted to a 32-bit word. This is shown below in C (the long constants are in octal):<indexterm id="I_indexterm10_tt211" class="endofrange" startref="idx-CHP-10-0635" significance="normal"><primary>divide and conquer strategy</primary><secondary>population count</secondary></indexterm></para><programlisting id="I_programlisting10_tt212" format="linespecific">
	int pop(unsigned x) {
	   unsigned n;

	   n = (x &gt;&gt; 1) &amp; 033333333333;            // Count bits in
	   x = x - n;                              // each three-bit
	   n = (n &gt;&gt; 1) &amp; 033333333333;            // field.
	   x = x - n;
	   x = (x + (x &gt;&gt; 3)) &amp; 030707070707;      // Six-bit sums.
	   return x%63;                            // Add six-bit sums.
	}
</programlisting><para>The last line uses the unsigned <indexterm id="idx-CHP-10-0645" significance="normal"><primary>modulus function</primary></indexterm>modulus function. (It could be either signed or unsigned if the word length were a multiple of 3.) It's clear that the modulus function sums the 6-bit fields when you regard the word <emphasis>x</emphasis> as an integer written in base 64. Upon dividing a base <emphasis>b</emphasis> integer by <emphasis>b</emphasis> − 1, the remainder is, for <emphasis>b</emphasis> ≥ 3, congruent to the sum of the digits and, of course, is less than <emphasis>b</emphasis> − 1. Because the sum of the digits in this case must be less than or equal to 32, mod(<emphasis>x</emphasis>, 63) must be equal to the sum of the digits of <emphasis>x</emphasis>, which is to say equal to the number of 1-bits in the original <emphasis>x</emphasis>.</para><para>This algorithm requires only 10 instructions on the DEC PDP-10, as that machine has an instruction for computing the remainder with its second operand directly referencing a fullword in memory. On a basic RISC, it requires about 15 instructions, assuming the machine offers <emphasis>unsigned modulus</emphasis> as one instruction (but not directly referencing a <indexterm id="idx-CHP-10-0646" significance="normal"><primary>fullword immediate</primary></indexterm>fullword immediate or memory operand). But it is probably not very fast, because division is almost always a slow operation. Also, it doesn't apply to 64-bit word lengths by simply extending the constants, although it does work for word lengths up to 62.<indexterm id="idx-CHP-10-0647" significance="normal"><primary>unsigned modulus instruction</primary></indexterm></para><para>A rather amazing algorithm is to rotate <emphasis>x</emphasis> left one position, 31 times, adding the 32 terms.<footnote id="CHP-10-FNOTE-3"><para>Mike Morton, "Quibbles &amp; Bits," <emphasis>Computer Language</emphasis>, Vol. 7, No.12, December 1990, pp. 45–55.</para></footnote>The sum is the negative of pop(<emphasis>x</emphasis>)! That is:</para><para><mediaobject id="I_mediaobject10_tt213"><imageobject role="print"><imagedata fileref="figs/print/equation4.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation4.png" format="PNG"/></imageobject></mediaobject></para><para>where the additions are done modulo the word size, and the final sum is interpreted as a two's-complement integer. This is just a novelty; it would not be useful on most machines because the loop is executed 31 times and thus requires 63 instructions plus the loop-control overhead. I leave it to the reader to figure out why this works.</para></sect1><sect1 id="sum_and_difference_of_population_counts_of_two_words" label="10.4"><title>Sum and Difference of Population Counts of Two Words</title><para>To compute pop(<emphasis>x</emphasis>) + pop(<emphasis>y</emphasis>) (if your computer does not have the population count instruction), some time can be saved by using the first two executable lines of <xref linkend="counting_bits_in_a_word"/> on <emphasis>x</emphasis> and <emphasis>y</emphasis> separately, and then adding <emphasis>x</emphasis> and <emphasis>y</emphasis> and executing the last three stages of the algorithm on the sum. After the first two lines of <xref linkend="counting_bits_in_a_word"/> are executed, <emphasis>x</emphasis> and <emphasis>y</emphasis> consist of eight 4-bit fields, each containing a maximum value of 4. Thus x and y may safely be added, because the maximum value in any 4-bit field of the sum would be 8, so no overflow occurs. (In fact, three words may be combined in this way.)<indexterm id="idx-CHP-10-0648" significance="normal"><primary>population count</primary><secondary>sum and difference of two words</secondary></indexterm><indexterm id="idx-CHP-10-0649" significance="normal"><primary>population count</primary></indexterm></para><para>This idea also applies to subtraction. To compute pop(<emphasis>x</emphasis>) – pop(<emphasis>y</emphasis>), use: <footnote id="CHP-10-FNOTE-4"><para><emphasis>y</emphasis> denotes the one's-complement of <emphasis>y</emphasis>, which in C is written ~<replaceable>y</replaceable>.</para></footnote></para><programlisting id="I_programlisting10_tt214" format="linespecific">
	pop(x) – pop(y) = pop(x) – (32 – pop(y))
	                = pop(x) + pop(y) – 32
</programlisting><para>Then, use the technique just described to compute pop(<emphasis>x</emphasis>) + pop(<emphasis>y</emphasis>). The code is shown in <xref linkend="computing_popx_ndash_popy"/>. It uses 32 instructions, versus 43 for two applications of the code of <xref linkend="counting_bits_in_a_word"/> followed by a subtraction.</para><example id="computing_popx_ndash_popy" label="10-2"><title>Computing pop(x) – pop(y)</title><programlisting format="linespecific">
int popDiff(unsigned x, unsigned y) {
   x = x - ((x &gt;&gt; 1) &amp; 0x55555555);
   x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);
   y = ~y;
   y = y - ((y &gt;&gt; 1) &amp; 0x55555555);
   y = (y &amp; 0x33333333) + ((y &gt;&gt; 2) &amp; 0x33333333);
   x = x + y;
   x = (x &amp; 0x0F0F0F0F) + ((x &gt;&gt; 4) &amp; 0x0F0F0F0F);
   x = x + (x &gt;&gt; 8);
   x = x + (x &gt;&gt; 16);
   return (x &amp; 0x0000007F) - 32;
}
</programlisting></example></sect1><sect1 id="comparing_the_population_counts_of_two_words" label="10.5"><title>Comparing the Population Counts of Two Words</title><para>Sometimes one wants to know which of two words has the larger population count, without regard to the actual counts. Can this be determined without doing a population count of the two words? Computing the difference of two population counts, as in <xref linkend="computing_popx_ndash_popy"/>, and comparing the result to 0, is one way, but there is another way that is preferable if either the population counts are expected to be low, or if there is a strong correlation between the particular bits that are set in the two words.<indexterm id="idx-CHP-10-0650" significance="normal"><primary>population count</primary></indexterm><indexterm id="idx-CHP-10-0651" significance="normal"><primary>population count</primary><secondary>comparing for two words</secondary></indexterm></para><para>The idea is to clear a single bit in each word until one of the words is all zero; the other word then has the larger population count. The process runs faster in its worst and average cases if the bits that are 1 at the same positions in each word are first cleared. The code is shown in <xref linkend="comparing_popx_with_popy"/>. The procedure returns a negative number if pop(<emphasis>x</emphasis>) &lt; pop(<emphasis>y</emphasis>), 0 if pop(<emphasis>x</emphasis>) = pop(<emphasis>y</emphasis>), and a positive number (1) if pop(<emphasis>x</emphasis>) &gt; pop(<emphasis>y</emphasis>).</para><example id="comparing_popx_with_popy" label="10-3"><title>Comparing pop(x) with pop(y)</title><programlisting format="linespecific">
int popCmpr(unsigned xp, unsigned yp) {
   unsigned x, y;
   x = xp &amp; ~yp;                // Clear bits where
   y = yp &amp; ~xp;                // both are 1.
   while (1){
      if (x == 0) return y | -y;
      if (y == 0) return 1;
      x = x &amp; (x - 1);          // Clear one bit
      y = y &amp; (y - 1);          // from each.
   }
}
</programlisting></example><para>After clearing the common 1-bits in each 32-bit word, the maximum possible number of 1-bits in both words together is 32. Therefore the word with the smaller number of 1-bits can have at most 16, and the loop in <xref linkend="comparing_popx_with_popy"/> is executed a maximum of 16 times, which gives a worst case of 119 instructions executed on a basic RISC (16 x 7 + 7). A simulation using uniformly distributed random 32-bit numbers showed that the average <indexterm id="idx-CHP-10-0652" significance="normal"><primary>population count</primary></indexterm>population count of the word with the smaller <indexterm id="idx-CHP-10-0653" significance="normal"><primary>population count</primary></indexterm>population count is approximately 6.186, after clearing the common 1-bits. This gives an average execution time of about 50 instructions when executed on random 32-bit inputs, not as good as using <xref linkend="computing_popx_ndash_popy"/>. For this procedure to beat that of <xref linkend="computing_popx_ndash_popy"/>, the number of 1-bits in either <emphasis>x</emphasis> or <emphasis>y</emphasis>, after clearing the common 1-bits, would have to be three or less.</para></sect1><sect1 id="counting_the_1-bits_in_an_array" label="10.6"><title>Counting the 1-Bits in an Array</title><para>The simplest way to count the number of 1-bits in an array (vector) of fullwords, in the absence of the <emphasis>population count</emphasis> instruction, is to use a procedure such as that of <xref linkend="counting_bits_in_a_word"/> on each word of the array, and simply add the results. We call this the naïve method. Ignoring loop control, the generation of constants, and loads from the array, it takes 16 instructions per word: 15 for the code of <xref linkend="counting_bits_in_a_word"/>, plus 1 for the addition. We assume the procedure is expanded inline, the masks are loaded outside of the loop, and the machine has a sufficient number of registers to hold all the quantities used in the calculation.<indexterm class="startofrange" id="idx-CHP-10-0654" significance="normal"><primary>population count</primary><secondary>counting 1-bits in an array</secondary></indexterm></para><para>Another way is to use the first two executable lines of <xref linkend="counting_bits_in_a_word"/> on groups of three words in the array, adding the three partial results. Because each partial result has a maximum value of 4 in each 4-bit field, the sum of the three has a maximum value of 12 in each 4-bit field, so no overflow occurs. This idea can be applied to the 8-and 16-bit fields. Coding and compiling this method indicates that it gives about a 20 percent reduction over the naíve method in total number of instructions executed on a basic RISC. Much of the savings is canceled by the additional housekeeping instructions required. We will not dwell on this method because there is a much better way to do it.</para><para>The better way seems to have been invented by Robert Harley and David Seal in about 1996.<footnote id="CHP-10-FNOTE-5"><para>David Seal, Newsgroup <emphasis>comp.arch.arithmetic</emphasis>, May 13, 1997. Robert Harley was the first person known to this writer to apply the <indexterm class="startofrange" id="idx-CHP-10-0655" significance="normal"><primary>CSA (carry-save adder) circuits</primary></indexterm>CSA to this problem, and David Seal showed a particularly good way to use it for counting the bits in a large array (as illustrated in <xref linkend="a_circuit_for_the_array_population_count"/> and <xref linkend="array_population_count_processing_elements_in_groups_of_eight"/>), and also for an array of size 7 (similar to the plan in <xref linkend="a_circuit_for_the_total_population_count_of_seven_words"/>).</para></footnote>It is based on a circuit called a <emphasis>carry-save adder</emphasis> (<indexterm id="idx-CHP-10-0656" significance="normal"><primary>arrays</primary><secondary>population count</secondary><tertiary>CSA circuits</tertiary></indexterm>CSA) or 3:2 compressor. A CSA is simply a sequence of independent full adders<footnote id="CHP-10-FNOTE-6"><para>A full adder is a circuit with three 1-bit inputs (the bits to be added) and two 1-bit outputs (the sum and carry). See John L. Hennessy and David A. Patterson, <emphasis>Computer Architecture</emphasis>: <emphasis>A Quantitative Approach</emphasis>. Morgan Kaufmann, 1990.</para></footnote> and is often used in binary multiplier circuits.<indexterm class="startofrange" id="idx-CHP-10-0657" significance="normal"><primary>carry-save adder (CSA) circuits</primary></indexterm></para><para>In Boolean algebra notation (juxtaposition denotes <emphasis>and</emphasis>, + denotes <emphasis>or</emphasis>, and ⊕ denotes exclusive or), the logic for each full <indexterm id="idx-CHP-10-0658" significance="normal"><primary>carry-save adder (CSA) circuits</primary></indexterm>adder is:</para><programlisting id="I_programlisting10_tt215" format="linespecific">
	h ← ab + ac + bc = ab + (a + b)c = ab + (a ⊕ b)c
	l ← (a ⊕ b) ⊕ c
</programlisting><para>where <emphasis>a, b</emphasis>, and <emphasis>c</emphasis> are the 1-bit inputs, <emphasis>l</emphasis> is the low-bit output (sum), and <emphasis>h</emphasis> is the high-bit output (carry). Changing <emphasis>a</emphasis> + <emphasis>b</emphasis> on the first line to <emphasis>a</emphasis> ⊕ <emphasis>b</emphasis> is justified because when <emphasis>a</emphasis> and <emphasis>b</emphasis> are both 1, the term <emphasis>ab</emphasis> makes the value of the whole expression 1. By first assigning <emphasis>a</emphasis> ⊕ <emphasis>b</emphasis> to a temporary, the full adder logic can be evaluated in five logical instructions, each operating on 32 bits in parallel (on a 32-bit machine). We will refer to these five instructions as <indexterm id="idx-CHP-10-0659" significance="normal"><primary>CSA (carry-save adder) circuits</primary></indexterm>CSA(<emphasis>h, l, a, b, c</emphasis>). This is a "macro," with <emphasis>h</emphasis> and <emphasis>l</emphasis> being outputs.</para><para>One way to use the <indexterm id="idx-CHP-10-0660" significance="normal"><primary>arrays</primary><secondary>population count</secondary><tertiary>CSA circuits</tertiary></indexterm>CSA operation is to process elements of the array <emphasis>A</emphasis> in groups of three, reducing each group of three words to two and applying the <indexterm id="idx-CHP-10-0661" significance="normal"><primary>population count</primary></indexterm>population count operation to these two words. In the loop, these two <indexterm id="idx-CHP-10-0662" significance="normal"><primary>population count</primary></indexterm>population counts are summed. After executing the loop, the total population count of the array is twice the accumulated population count of the CSA's high-bit outputs plus the accumulated population count of the low-bit outputs.</para><para>The following sequence illustrates the process for a 16-bit word:</para><programlisting id="I_programlisting10_tt216" format="linespecific">
	     a = 0110 1001 1110 0101 9
	     b = 1000 1000 0100 0111 6
	     c = 1100 1010 0011 0101 8
	     -------------------------
	     l = 0010 1011 1001 0111 9
	     h = 1100 1000 0110 0101 7*2 = 14
</programlisting><para>Observe that in each column, the (<emphasis>h, l</emphasis>) pair, written in that order, is a two-bit binary number whose value is the number of <indexterm id="idx-CHP-10-0663" significance="normal"><primary>population count</primary><secondary>counting 1-bits in an array</secondary></indexterm>1-bits in <emphasis>a, b</emphasis>, and <emphasis>c</emphasis>, in the column. Thus each 1-bit in <emphasis>h</emphasis> represents two 1-bits in <emphasis>a, b</emphasis>, and <emphasis>c</emphasis>, and each 1-bit in l represents one 1-bit in <emphasis>a, b</emphasis>, and <emphasis>c</emphasis>. Therefore the total population (shown at the right) is twice the number of 1-bits in <emphasis>h</emphasis> plus the number of 1-bits in <emphasis>l</emphasis>, which totals to 23 in the illustration.</para><para>Let <emphasis>n<subscript>c</subscript></emphasis> be the number of instructions required for the CSA steps, and <emphasis>n<subscript>p</subscript></emphasis> be the number of instructions required to do the population count of one word. On a typical RISC machine, <emphasis>n<subscript>c</subscript></emphasis> = 5 and <emphasis>n<subscript>p</subscript></emphasis> = 15. Ignoring loads from the array and loop control (the code for which may vary quite a bit from one machine to another), the loop discussed previously takes (<emphasis>n<subscript>c</subscript></emphasis> + 2<emphasis>n<subscript>p</subscript></emphasis> + 2) / 3 ≈ 12.33 instructions per word of the array (the "+ 2" is for the two additions in the loop). This contrasts with the 16 instructions per word required by the naïve method.</para><para>There is another way to use the CSA operation that results in a more efficient and slightly more compact program. This is shown in <xref linkend="array_population_count_processing_elements_in_groups_of_two"/>. It takes (<emphasis>n<subscript>c</subscript></emphasis> + <emphasis>n<subscript>p</subscript></emphasis> + 1) / 2 = 10.5 instructions per word (ignoring loop control and loads).</para><example id="array_population_count_processing_elements_in_groups_of_two" label="10-4"><title>Array population count, processing elements in groups of two</title><programlisting format="linespecific">
#define <indexterm id="idx-CHP-10-0664" significance="normal"><primary>CSA (carry-save adder) circuits</primary></indexterm>CSA(h,l, a,b,c) \
   {unsigned u = a ^ b; unsigned v = c; \
      h = (a &amp; b) | (u &amp; v); l = u ^ v;}
int popArray(unsigned A[], int n) {
   int tot, i;
   unsigned ones, twos;
   tot = 0;                     // Initialize.
   ones = 0;
   for (i = 0; i &lt;= n - 2; i = i + 2) {
      <indexterm id="idx-CHP-10-0665" significance="normal"><primary>arrays</primary><secondary>population count</secondary><tertiary>CSA circuits</tertiary></indexterm>CSA(twos, ones, ones, A[i], A[i+1])
      tot = tot + pop(twos);
   }
   tot = 2*tot + pop(ones);
   if (n &amp; 1)                  // If there's a last one,
   tot = tot + pop(A[i]);      // add it in.
   return tot;
}
</programlisting></example><para>When <xref linkend="array_population_count_processing_elements_in_groups_of_two"/> is compiled, the CSA operation expands into:<indexterm id="idx-CHP-10-0666" significance="normal"><primary>population count</primary></indexterm></para><programlisting id="I_programlisting10_tt217" format="linespecific">
	u = ones ^ A[i];
	v = A[i+1];
	twos = (ones &amp; A[i]) | (u &amp; v);
	ones = u ^ v;
</programlisting><para>The code relies on the compiler to omit subsequent loads of a quantity that has already been loaded (a process known as <emphasis>commoning</emphasis>).</para><para>There are ways to use the CSA operation to further reduce the number of instructions required to compute the <indexterm id="idx-CHP-10-0667" significance="normal"><primary>population count</primary></indexterm>population count of an array. They are most easily understood by means of a circuit diagram. For example, <xref linkend="a_circuit_for_the_array_population_count"/> illustrates a way to code a loop that takes array elements eight at a time and compresses them into four quantities, labeled <emphasis>eights, fours, twos</emphasis>, and <emphasis>ones</emphasis>. The <emphasis>fours, twos</emphasis>, and <emphasis>ones</emphasis> are fed back into the CSAs on the next loop iteration, the <indexterm id="idx-CHP-10-0668" significance="normal"><primary>population count</primary><secondary>counting 1-bits in an array</secondary></indexterm>1-bits in <emphasis>eights</emphasis> are counted by an execution of the word-level population count function, and this count is accumulated. When the entire array has been processed, the total population count is:</para><programlisting id="I_programlisting10_tt218" format="linespecific">
	8 x pop(<replaceable>eights</replaceable>) + 4 x pop(<replaceable>fours</replaceable>) + 2 x pop(<replaceable>twos</replaceable>) + pop(<replaceable>ones</replaceable>)
</programlisting><para>The code is shown in <xref linkend="array_population_count_processing_elements_in_groups_of_eight"/>, which uses the CSA macro defined in <xref linkend="array_population_count_processing_elements_in_groups_of_two"/>. The numbering of the CSA blocks in <xref linkend="a_circuit_for_the_array_population_count"/> corresponds to the order of the CSA macro calls in <xref linkend="array_population_count_processing_elements_in_groups_of_eight"/>. The execution time of the loop, exclusive of array loads and loop control, is (7<emphasis>n<subscript>c</subscript></emphasis> + <emphasis>n<subscript>p</subscript></emphasis> + 1) / 8 = 6.375 instructions per word of the array.</para><example id="array_population_count_processing_elements_in_groups_of_eight" label="10-5"><title>Array population count, processing elements in groups of eight</title><programlisting format="linespecific">
int popArray(unsigned A[], int n) {
   int tot, i;
   unsigned ones, twos, twosA, twosB,
      fours, foursA, foursB, eights;
   tot = 0;                     // Initialize.
   fours = twos = ones = 0;
   for (i = 0; i &lt;= n - 8; i = i + 8) {
      <indexterm id="idx-CHP-10-0669" significance="normal"><primary>CSA (carry-save adder) circuits</primary></indexterm>CSA(twosA, ones, ones, A[i], A[i+1])
      <indexterm id="idx-CHP-10-0670" significance="normal"><primary>arrays</primary><secondary>population count</secondary><tertiary>CSA circuits</tertiary></indexterm>CSA(twosB, ones, ones, A[i+2], A[i+3])
      CSA(foursA, twos, twos, twosA, twosB)
      CSA(twosA, ones, ones, A[i+4], A[i+5])
      CSA(twosB, ones, ones, A[i+6], A[i+7])
      CSA(foursB, twos, twos, twosA, twosB)
      CSA(eights, fours, fours, foursA, foursB)
      tot = tot + pop(eights);
   }
   tot = 8*tot + 4*pop(fours) + 2*pop(twos) + pop(ones);
   for (i = i; i &lt; n; i++)      // Simply add in the last
      tot = tot + pop(A[i]);    // 0 to 7 elements.
   return tot;
}
</programlisting></example><para>The CSAs may be connected in many arrangements other than that shown in <xref linkend="a_circuit_for_the_array_population_count"/>. For example, increased instruction-level parallelism might result from feeding the first three array elements into one CSA, and the next three into a second CSA, which allows the instructions of these two CSAs to execute in parallel. One might also be able to permute the three input operands of the CSA macros for increased parallelism. With the plan shown in <xref linkend="a_circuit_for_the_array_population_count"/>, one can easily see how to use only the first three CSAs to construct a program that processes array elements in groups of four, and also how to expand it to construct programs that process array elements in groups of 16 or more. The plan shown also spreads out the loads somewhat, which is advantageous for a machine that has a relatively low limit on the number of loads that can be outstanding at any one time.</para><figure id="a_circuit_for_the_array_population_count" label="10-2" float="0"><title>A circuit for the array population count</title><mediaobject id="I_mediaobject10_tt219"><imageobject role="print"><imagedata fileref="figs/print/beauty_1002.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1002.png" format="PNG"/></imageobject></mediaobject></figure><para><xref linkend="instructions_per_word_for_the_array_population_count"/> summarizes the number of instructions executed by generalizations of the plan of <xref linkend="a_circuit_for_the_array_population_count"/> for various group sizes. The values in the middle two columns ignore loads and loop control. The third column gives the total loop instruction execution count per word of the input array, produced by a compiler for a basic RISC machine that does not have indexed loads.<indexterm id="idx-CHP-10-0671" significance="normal"><primary>population count</primary></indexterm></para><table id="instructions_per_word_for_the_array_population_count" label="10-1"><title>Instructions per word for the array population count</title><tgroup cols="3"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><colspec colnum="3" colname="col3"/><thead><row><entry><para>Program</para></entry><entry namest="col2" nameend="col3"><para>Instructions exclusive of loads and loop control</para></entry><entry><para>All instructions in loop (compiler output)</para></entry></row><row><entry><para/></entry><entry><para>Formula</para></entry><entry><para>For <emphasis>n<subscript>c</subscript></emphasis> = 5, <emphasis>n<subscript>p</subscript></emphasis> = 15</para></entry><entry><para/></entry></row></thead><tbody><row><entry><para>Naive method</para></entry><entry><para><emphasis>np</emphasis> + 1</para></entry><entry><para>16</para></entry><entry><para>21</para></entry></row><row><entry><para>Groups of 2</para></entry><entry><para>(<emphasis>n<subscript>c</subscript></emphasis> + <emphasis>n<subscript>p</subscript></emphasis> + 1 ) / 2</para></entry><entry><para>10.5</para></entry><entry><para>14</para></entry></row><row><entry><para>Groups of 4</para></entry><entry><para>(3<emphasis>n<subscript>c</subscript></emphasis> + <emphasis>n<subscript>p</subscript></emphasis> + 1 ) / 4</para></entry><entry><para>7.75</para></entry><entry><para>10</para></entry></row><row><entry><para>Groups of 8</para></entry><entry><para>(7<emphasis>n<subscript>c</subscript></emphasis> + <emphasis>n<subscript>p</subscript></emphasis> + 1 ) / 8</para></entry><entry><para>6.38</para></entry><entry><para>8</para></entry></row><row><entry><para>Groups of 16</para></entry><entry><para>15<emphasis>n<subscript>c</subscript></emphasis> + <emphasis>n<subscript>p</subscript></emphasis> + 1 ) / 16</para></entry><entry><para>5.69</para></entry><entry><para>7</para></entry></row><row><entry><para>Groups of 32</para></entry><entry><para>31<emphasis>n<subscript>c</subscript></emphasis> + <emphasis>n<subscript>p</subscript></emphasis> + 1 ) / 32</para></entry><entry><para>5.34</para></entry><entry><para>6.5</para></entry></row><row><entry><para>Groups of 2<subscript>n</subscript></para></entry><entry><para><mediaobject id="I_mediaobject10_tt220"><imageobject role="print"><imagedata fileref="figs/print/equation5.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation5.png" format="PNG"/></imageobject></mediaobject></para></entry><entry><para><mediaobject id="I_mediaobject10_tt221"><imageobject role="print"><imagedata fileref="figs/print/equation6.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation6.png" format="PNG"/></imageobject></mediaobject></para></entry><entry/></row></tbody></tgroup></table><para>It is a pleasant surprise that in the limit, the number of computational instructions required to compute the <indexterm id="idx-CHP-10-0672" significance="normal"><primary>population count</primary></indexterm>population count of <emphasis>n</emphasis> words is reduced from the naïve method's 16<emphasis>n</emphasis> to the <indexterm id="idx-CHP-10-0673" significance="normal"><primary>CSA (carry-save adder) circuits</primary></indexterm>CSA method's 5<emphasis>n</emphasis>, where the 5 is the number of instructions required to implement one <indexterm id="idx-CHP-10-0674" significance="normal"><primary>arrays</primary><secondary>population count</secondary><tertiary>CSA circuits</tertiary></indexterm>CSA circuit.<indexterm id="idx-CHP-10-0675" significance="normal"><primary>population count</primary></indexterm></para><para>For small arrays, there are better plans than that of <xref linkend="a_circuit_for_the_array_population_count"/>. For example, for an array of seven words, the plan of <xref linkend="a_circuit_for_the_total_population_count_of_seven_words"/> is quite efficient.<footnote id="CHP-10-FNOTE-7"><para>Seal, <emphasis>op. cit</emphasis>.</para></footnote>It executes in 4<emphasis>n<subscript>c</subscript></emphasis> +3<emphasis>n<subscript>p</subscript></emphasis> +4=69 instructions, or 9.86 instructions per word. Similar plans exist that apply to arrays of size 2<emphasis><superscript>k</superscript></emphasis>–1 words, for any positive integer <emphasis>k</emphasis>. The plan for 15 words executes in 11<emphasis>n<subscript>c</subscript></emphasis> +4<emphasis>n<subscript>p</subscript></emphasis> +6= 121 instructions, or 8.07 instructions per word.</para></sect1><sect1 id="applications" label="10.7"><title>Applications</title><para>The <emphasis>population count</emphasis> instruction has a miscellany of <indexterm id="idx-CHP-10-0676" significance="normal"><primary>population count</primary><secondary>uses of</secondary></indexterm>uses. As mentioned at the beginning of this chapter, one use is to compute the size of a set when <indexterm id="idx-CHP-10-0677" significance="normal"><primary>sets</primary></indexterm>sets are represented by bit strings. In this representation, there is a "universe" set whose members are numbered sequentially. A set is represented by a bit string in which bit <emphasis>i</emphasis> is 1 if and only if member <emphasis>i</emphasis> is in the set.</para><figure id="a_circuit_for_the_total_population_count_of_seven_words" label="10-3" float="0"><title>A circuit for the total population count of seven words</title><mediaobject id="I_mediaobject10_tt222"><imageobject role="print"><imagedata fileref="figs/print/beauty_1003.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1003.png" format="PNG"/></imageobject></mediaobject></figure><para>Another simple application is to compute the <indexterm id="idx-CHP-10-0678" significance="normal"><primary>Hamming distance between two bit vectors</primary></indexterm>Hamming distance between two bit vectors, a concept from the theory of <indexterm id="idx-CHP-10-0679" significance="normal"><primary>error-correcting codes</primary></indexterm>error-correcting codes. The <emphasis>Hamming distance</emphasis> is simply the number of places where the vectors differ, that is:<footnote id="CHP-10-FNOTE-8"><para>See, for example, the chapter on error-correcting codes in A. K. Dewdney, <emphasis>The Turing Omnibus</emphasis>. Computer Science Press, 1989.</para></footnote><indexterm id="idx-CHP-10-0680" significance="normal"><primary>population count</primary></indexterm></para><programlisting id="I_programlisting10_tt223" format="linespecific">
	dist(<replaceable>x, y</replaceable>) = pop(<replaceable>x</replaceable> ⊕ <replaceable>y</replaceable>)
</programlisting><para>The <emphasis>population count</emphasis> instruction may be used to compute the number of <indexterm id="idx-CHP-10-0681" significance="normal"><primary>trailing 0s in a word</primary></indexterm>trailing 0s in a word, using relations such as:<indexterm id="idx-CHP-10-0682" significance="normal"><primary>population count</primary></indexterm></para><programlisting id="I_programlisting10_tt224" format="linespecific">
	ntz(<replaceable>x</replaceable>) = pop(¬<replaceable>x</replaceable> &amp; (<replaceable>x</replaceable> – 1)) = 32 – pop(<replaceable>x</replaceable> | –<replaceable>x</replaceable>)
</programlisting><para>(The reader who is not familiar with these mixtures of arithmetic and logical operations might pause for a few moments to discover why they work.) The function <literal moreinfo="none">ntz</literal>(<emphasis>x</emphasis>) also has a miscellany of uses. For example, some early computers, upon interrupt, would store a "reason for interrupt" bit in a special register. The bits were placed in a position that identified which type of interrupt occurred. The positions were chosen in priority order, usually with the higher-priority <indexterm id="idx-CHP-10-0683" significance="normal"><primary>interrupts</primary></indexterm>interrupts in the less significant positions. Two or more bits could be set at the same time. To determine which interrupt to process, the supervisor program would execute the <literal moreinfo="none">ntz</literal> function on the quantity in the special register.</para><para>Another application of <emphasis>population count</emphasis> is to allow reasonably fast <indexterm id="idx-CHP-10-0684" significance="normal"><primary>population count</primary><secondary>digital filter</secondary><tertiary>direct indexed access to moderately sparse array</tertiary></indexterm>direct indexed access to a moderately sparse array <emphasis>A</emphasis> that is represented in a certain compact way. In the compact representation, only the defined, or nonzero, elements of the array are stored. There is an auxiliary bit string <emphasis>bits</emphasis> that has a 1-bit for each bit position <emphasis>i</emphasis> for which A[<emphasis>i</emphasis>] is defined. Since <emphasis>bits</emphasis> is generally quite long, it is broken up into 32-bit words, with the first bit of the long string being at bit 0 (the least significant bit) of the first word of <emphasis>bits</emphasis>.<indexterm id="I_indexterm10_tt225" class="endofrange" startref="idx-CHP-10-0657" significance="normal"><primary>carry-save adder (CSA) circuits</primary></indexterm><indexterm id="I_indexterm10_tt226" class="endofrange" startref="idx-CHP-10-0655" significance="normal"><primary>CSA (carry-save adder) circuits</primary></indexterm><indexterm id="I_indexterm10_tt227" class="endofrange" startref="idx-CHP-10-0654" significance="normal"><primary>population count</primary><secondary>counting 1-bits in an array</secondary></indexterm></para><para>As a speedup device, there is also an array of words <emphasis>bitsum</emphasis> such that <emphasis>bitsum</emphasis>[<emphasis>j</emphasis>] is the total number of 1-bits in all the words of <emphasis>bits</emphasis> that precede entry <emphasis>j</emphasis>. This is illustrated in the following table for an array in which elements 0, 2, 32, 47, 48, and 95 are defined:</para><informaltable><tgroup cols="3"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><colspec colnum="3" colname="col3"/><thead><row><entry><para>bits</para></entry><entry><para>bitsum</para></entry><entry><para>data</para></entry></row></thead><tbody><row><entry><para>0x00000005</para></entry><entry><para>0</para></entry><entry><para>A[0]</para></entry></row><row><entry><para>0x00018001</para></entry><entry><para>2</para></entry><entry><para>A[2]</para></entry></row><row><entry><para>0x80000000</para></entry><entry><para>5</para></entry><entry>
<para>A[32]</para>
<para>A[47]</para>
<para>A[48]</para>
<para>A[95]</para>
</entry></row></tbody></tgroup></informaltable><para>Here's the key task: given a "logical" index <emphasis>i</emphasis> into the full array, translate it into the "physical" index <emphasis>sparse_i</emphasis> where the array element is stored, if that element exists, or give some indication if it does not exist. For the array in the previous table, we wish to translate 47 to 3, 48 to 4, and 49 to "does not exist." Given a logical index <emphasis>i</emphasis>, the corresponding index <emphasis>sparse_i</emphasis> into the <emphasis>data</emphasis> array is given by the number of 1-bits in array <emphasis>bits</emphasis> that precede the bit corresponding to <emphasis>i</emphasis>. This may be calculated as follows:</para><programlisting id="I_programlisting10_tt228" format="linespecific">
	j = i &gt;&gt; 5;                  // j = i/32.
	k = i &amp; 31;                  // k = rem(i, 32);
	mask = 1 &lt;&lt; k;               // A "1" at position k.
	if ((bits[j] &amp; mask) == 0) goto no_such_element;
	mask = mask - 1;             // 1's to right of k.
	sparse_i = bitsum[j] + pop(bits[j] &amp; mask);
</programlisting><para>The space cost of this representation is two bits per position in the full array.</para><para>The population count function can be used to generate binomially distributed random integers. To generate an integer drawn from a population given by <emphasis>Binomial</emphasis>(<emphasis>t, p</emphasis>) where <emphasis>t</emphasis> is the number of trials and <emphasis>p</emphasis> = 1/2, generate <emphasis>t</emphasis> random bits and count the number of 1s in the <emphasis>t</emphasis> bits. This can be generalized to probabilities <emphasis>p</emphasis> other than 1/2.<footnote id="CHP-10-FNOTE-9"><para>See section 3.4.1, problem 27 in Donald E. Knuth, <emphasis>The Art of Computer Programming</emphasis>: <emphasis>Seminumerical Algorithms</emphasis> (Vol. 2, 3rd. ed.). Addison-Wesley, 1998.</para></footnote></para><para>According to computer folklore, <emphasis>population count</emphasis> is important to the National Security Agency. No one (outside of NSA) seems to know just what they use it for, but it may be in cryptography work or in searching huge amounts of material.<indexterm id="I_indexterm10_tt229" class="endofrange" startref="idx-CHP-10-0627" significance="normal"><primary>population count</primary></indexterm></para></sect1></chapter><chapter id="secure_communication_the_technology_of_freedom" label="11" role=""><title>Secure Communication: The Technology Of Freedom</title><para><emphasis>Ashish Gulhati</emphasis><indexterm class="startofrange" id="idx-CHP-11-0685" significance="normal"><primary>secure communications</primary></indexterm><indexterm id="idx-CHP-11-0686" significance="normal"><primary>Gulhati</primary></indexterm></para><blockquote><para>I speak of none other than the computer that is to come after me. A computer whose merest operational parameters I am not worthy to calculate—and yet I will design it for you. A computer which can calculate the Question to the Ultimate Answer, a computer of such infinite and subtle complexity that organic life itself shall form part of its operational matrix.</para></blockquote><para>Deep Thought, The Hitchhiker's Guide to the Galaxy</para><para><emphasis>In mid-1999 i flew to costa rica to work with laissez faire city</emphasis>, a group that was working to create software systems to help usher in a new era of individual sovereignty.<footnote id="CHP-11-FNOTE-1"><para>See <emphasis>The Sovereign Individual: Mastering the Transition to the Information Age</emphasis>, James Dale Davidson and Sir William Rees Mogg, Free Press, 1999.</para></footnote></para><para>The group at LFC was working primarily to develop a suite of software designed to protect and enhance <indexterm id="idx-CHP-11-0687" significance="normal"><primary>individual rights in the digital age</primary></indexterm>individual rights in the digital age, including easy-to-use secure email, online dispute mediation services, an online stock exchange, and a private asset trading and banking system. My interest in many of the same technologies had been piqued long ago by the cypherpunks list and Bruce Schneier's <emphasis>Applied Cryptography</emphasis> (Wiley), and I'd already been working on prototype implementations of some of these systems.</para><para>The most fundamental of these were systems to deliver strong and <emphasis>usable</emphasis> communications privacy to just about everybody.</para><para>When I stepped into LFC's sprawling "interim consulate" outside San José, Costa Rica, they had a working prototype of a secure webmail system they called MailVault. It ran on Mac OS 9, used FileMaker as its database, and was written in Frontier. Not at all the mix of technologies you'd want to run a mission-critical communications service on, but that's what the programmers had produced.</para><para>It was no surprise the system crashed early and often, and was extremely fragile. It could hardly support two concurrent users. LFC was facing a credibility crisis with its investors, as their software releases had been delayed many times, and their first beta of MailVault, the flagship product, was no gem. So in the free time left over <indexterm id="idx-CHP-11-0688" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>insights from development process</secondary></indexterm>from my contract network and system administration work at LFC, I started writing a new <indexterm id="idx-CHP-11-0689" significance="normal"><primary>secure communications</primary></indexterm>secure <indexterm class="startofrange" id="idx-CHP-11-0690" significance="normal"><primary>mail system (Cryptonite)</primary></indexterm>mail system from scratch.</para><para>This system is now named <indexterm class="startofrange" id="idx-CHP-11-0691" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite and has been in constant off-and-on development and testing since then, in between other projects.</para><para>The first functioning prototype of <indexterm class="startofrange" id="idx-CHP-11-0692" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite was licensed to LFC as MailVault beta 2, and was open for testing in September 1999. It was the first OpenPGP-compatible webmail system available for public use and was almost immediately put to the test by LFC's investors and beta testers. Since that time, Cryptonite has evolved in many ways through interaction with users, the open source community, and the market. While not an open source product itself, it has led to the development of numerous components I decided to release as open source along the way.</para><sect1 id="the_heart_of_the_start" label="11.1"><title>The Heart of the Start</title><para>Developing Cryptonite and marketing and supporting associated services single-handedly for many years (with unwavering support and many invaluable ideas from my wife, Barkha) has been an incredibly interesting and rewarding journey, not only from a development perspective but also from an entrepreneurial one.</para><para>Before jumping into the nitty-gritty of the system, I thought I'd touch upon some points that have impressed themselves strongly in my consciousness over the course of this project:</para><itemizedlist><listitem><para>My friend Rishab Ghosh once quipped that there's a lot of hype about how the Internet can enable wired hackers to work from anywhere, but most of the people who create this hype live within a small area in California. The great thing about an independent startup project is that it really can be done anywhere, and dropped and picked up again when convenient. I've hacked on Cryptonite over many years on four continents, and it may well be the first high-quality software application developed in large part in the Himalayan mountains. (I used the word "wired" before loosely. In reality, five wireless technologies facilitated our connectivity in the Himalayas: a VSAT satellite Internet link, Wi-Fi, Bluetooth, GPRS, and CDMA.)</para></listitem><listitem><para>When working on a project as a single developer in your spare time, remember the old hacker wisdom that "six months in the lab can save you ten minutes in the library." It's critical to maximize your reuse of existing code libraries. For this reason, I elected to develop the system in Perl, a popular and flexible high-level language with a rich library of mature, free software modules, and the Perl hacker's first virtue of laziness informed every design decision.</para></listitem><listitem><para>Especially for end-user application software, ease of use is a critical issue. It is essential to the function of such code to present a simple, accessible interface to the user. The usability considerations of developing an end-user security application are even more significant, and were in fact a key factor in making the <indexterm id="idx-CHP-11-0693" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite system worth developing.</para></listitem><listitem><para>To get off to a running start, it's a good idea to implement a working prototype first, and use a prototype-to-production path to move to production deployment after the essential functionality is implemented. This can be a huge help in getting the basic design and structure right before you unleash the code on hundreds or (hopefully!) millions of users.</para></listitem><listitem><para>Keeping your system as simple as possible is always a great idea. Resist the urge to get suckered into using the latest complex buzzword technology, unless the application really demands it.</para></listitem><listitem><para>Processors are pretty fast now, and programmer time is generally more valuable than processor time, but speed is still critical for application software. Users expect their applications to be snappy. For web applications, which many users will use concurrently, investing some time in optimizing for speed is a Very Good Thing.</para></listitem><listitem><para>A software application is a living entity, in constant need of attention, updating, enhancement, testing, fixing, tweaking, marketing, and support. Its success and beauty in an economic sense depends directly on the code being flexible enough to evolve over time and meet the requirements of its users, and to do it again and again and again over the course of many years.</para></listitem><listitem><para>It really does help if the problem you're trying to solve is something that personally interests you. This not only makes it possible to flip between user and developer roles easily, but ensures you'll still be interested in the project five years later—because building and marketing a software application is generally quite a long-term proposition.</para></listitem></itemizedlist><para>The development of <indexterm id="idx-CHP-11-0694" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite has been powered in large measure by my desire to create tools to help individuals all over the world achieve practical liberty. And while developing the system single-handedly has been difficult at times, I find that being a single-developer project has also given the code a certain stylistic and structural unity that's rare in code developed by multiple programmers.</para></sect1><sect1 id="untangling_the_complexity_of_secure_messaging" label="11.2"><title>Untangling the Complexity of Secure Messaging</title><para>While bringing <indexterm id="idx-CHP-11-0695" significance="normal"><primary>secure communications</primary></indexterm>secure communications capabilities to the world is a whoppingly great idea for the protection of individual human rights (more on this later), getting it right is a trickier task than it may seem. <indexterm id="idx-CHP-11-0696" significance="normal"><primary>public-key cryptography</primary></indexterm>Public-key cryptosystems can, in <indexterm id="idx-CHP-11-0697" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>principle, facilitate ad hoc secure communications, but practical implementations are very often needlessly complex and disconnected from on-the-ground realities concerning who will use such systems, and how.<indexterm id="idx-CHP-11-0698" significance="normal"><primary>secure communications</primary><secondary>complexity of secure messaging</secondary></indexterm></para><para>The fundamental problem to be solved in practical implementations based on <indexterm id="idx-CHP-11-0699" significance="normal"><primary>key authentication</primary><secondary>public-key cryptography</secondary></indexterm>public-key cryptography is <indexterm id="idx-CHP-11-0700" significance="normal"><primary>public-key cryptography</primary><secondary>key authentication</secondary></indexterm>key authentication. To send an encrypted message to someone, you need her public key. If you can be tricked into using the wrong public key, your privacy vanishes.</para><para>There are two very different approaches to the key authentication problem.</para><para>The conventional Public Key Infrastructure (PKI) approach, typically based on ISO standard X.509, depends on a system <indexterm id="idx-CHP-11-0701" significance="normal"><primary>PKI (Public Key Infrastructure)</primary><secondary>shortcomings of</secondary></indexterm>of trusted third-party <indexterm id="idx-CHP-11-0702" significance="normal"><primary>Certification Authorities (CAs)</primary></indexterm>Certification Authorities (<indexterm id="idx-CHP-11-0703" significance="normal"><primary>CAs (Certification Authorities)</primary></indexterm>CAs), and is in many ways fundamentally unsuited to meet the real needs of users in ad hoc networks.<footnote id="CHP-11-FNOTE-2"><para>The drawbacks of conventional PKI have been concisely summarized by Roger Clarke at <ulink url="http://www.anu.edu.au/people/Roger.Clarke/II/PKIMisFit.html"/>.</para></footnote> PKI implementations have achieved significant success in more structured domains, such as corporate VPNs and the authentication of <indexterm id="idx-CHP-11-0704" significance="normal"><primary>secure communications</primary></indexterm>secure web sites, but have made little headway in the real-world heterogeneous <indexterm id="idx-CHP-11-0705" significance="normal"><primary>mail system (Cryptonite)</primary></indexterm>email environment.</para><para>The other approach is exemplified by the most popular public-key-based messaging security solution in use today: Phil <indexterm id="idx-CHP-11-0706" significance="normal"><primary>Zimmermann</primary></indexterm>Zimmermann's <indexterm id="idx-CHP-11-0707" significance="normal"><primary>PGP</primary></indexterm>PGP and its descendants, now formalized as the IETF <indexterm id="idx-CHP-11-0708" significance="normal"><primary>OpenPGP</primary></indexterm>OpenPGP protocol. OpenPGP preserves the flexibility and fundamentally decentralized nature of public-key cryptography by facilitating distributed key authentication through "<indexterm id="idx-CHP-11-0709" significance="normal"><primary>webs of trust</primary></indexterm>webs of trust" rather than depending on a centralized, hierarchical system of CAs, as PKI approaches do (including OpenPGP's primary competitor, S/MIME). Not surprisingly, S/MIME, which is almost ubiquitously available in popular email clients, enjoys a vastly smaller user base than OpenPGP, despite email clients' general lack of comprehensive support for OpenPGP.</para><para>But the web-of-trust approach, which relies on users to build their own chains of trust for certifying and authenticating public keys, has its own issues. Prime among these are the interrelated challenges of ensuring that users understand how to use the web of trust to authenticate keys, and the need to achieve a critical mass of users in order to ensure that any two users can easily find a trust path between each other.</para><para>As <xref linkend="how_keys_are_validated_through_the_web_of_trust"/> shows, in a web of trust implementation, no third parties are arbitrarily designated as "trusted." Each individual user is her own most trusted certifying authority, and may assign varying levels of trust to others for the purpose of validating keys. You consider a key valid if it is certified directly by you, by another person who is fully trusted by you to certify keys, or by a user-definable number of people, each of whom is partially trusted by you to certify keys.</para><para>Because the web-of-trust approach doesn't attempt to outsource key authentication the way PKI approaches do, users must play a central role in building their webs of trust and ascertaining the authenticity of public keys. This puts usability considerations front and center in the design of OpenPGP-based secure messaging systems.</para><figure id="how_keys_are_validated_through_the_web_of_trust" label="11-1" float="0"><title>How keys are validated through the web of trust</title><mediaobject id="I_mediaobject11_tt230"><imageobject role="print"><imagedata fileref="figs/print/beauty_1101.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1101.png" format="PNG"/></imageobject></mediaobject></figure></sect1><sect1 id="usability_is_the_key" label="11.3"><title>Usability Is the Key</title><para>Email privacy software often requires users to jump through too many hoops, so very few bother to use it. Usability is critical to the success of any <indexterm id="idx-CHP-11-0710" significance="normal"><primary>OpenPGP</primary><secondary>security embedded in Cryptonite</secondary></indexterm>security solution, because if the system isn't usable, it will end up being bypassed or used in an <indexterm id="idx-CHP-11-0711" significance="normal"><primary>secure communications</primary></indexterm>insecure manner, in either case defeating its whole purpose.</para><para>A case study of the usability of PGP conducted at Carnegie Mellon University in 1998 pointed out the specialized challenges of creating an effective and usable interface for email <indexterm id="idx-CHP-11-0712" significance="normal"><primary>encryption of email</primary></indexterm>encryption and found that of 12 study <indexterm id="idx-CHP-11-0713" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>participants, all of whom were experienced at using email, "only one-third of them were able to use PGP to correctly sign and encrypt an email message when given 90 minutes in which to do so."<footnote id="CHP-11-FNOTE-3"><para>"Usability of Security: A Case Study." Alma Whitten and J. D. Tygar, Carnegie Mellon University. <ulink url="http://reports-archive.adm.cs.cmu.edu/anon/1998/CMU-CS-98-155.pdf"/>.</para></footnote></para><para>I saw <indexterm id="idx-CHP-11-0714" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite as an interesting project in terms of designing a secure, reliable, and efficient <indexterm id="idx-CHP-11-0715" significance="normal"><primary>mail system (Cryptonite)</primary></indexterm>email system while achieving a very high level of usability. I set out to create a web-mail system that would embed OpenPGP security into the very structure of the email experience, and help even casual users to effectively utilize OpenPGP to achieve communications privacy. The webmail format was chosen specifically because it could bring powerful communications privacy technology to anyone with access to an Internet café, or a cellphone with a web browser, not just to the few able to run desktop email encryption software on powerful computers.</para><para><indexterm id="idx-CHP-11-0716" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite was designed to make encryption a normal part <indexterm id="idx-CHP-11-0717" significance="normal"><primary>web of trust</primary><secondary>visibility of information in Cryptonite Key Ring view</secondary></indexterm>of everyday email, not by masking the complexities of the public-key cryptosystems that it relies on, but rather by making the elements of these systems clearer and more accessible to the user. <indexterm id="idx-CHP-11-0718" significance="normal"><primary>usability considerations in public-key cryptosystems</primary></indexterm>Usability considerations were thus central to <indexterm id="idx-CHP-11-0719" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite's design and development, as was manifested in a number of ways:</para><variablelist><varlistentry><term><emphasis>Development of UI functionality from user feedback and usability studies</emphasis></term><listitem><para>The CMU user study provided many good ideas for the initial design, and many features evolved out of usability testing with Cryptonite itself by casual email users. The interface was kept clean, minimalist, and consistent, with all important actions being at most one or two clicks away at all times.</para><para>Significant insights gleaned from usability testing included the need to integrate key management into the email client, the need to offer persistence for decrypted messages, and the desirability of exposing message structure information in the message list view.</para><para>The final three-pane layout, similar to that found on desktop email programs, was decided on after testing a simple single-pane HTML interface as well as an AJAX inter-face. The three-pane interface optimized the user's experience by not forcing a page reload every time one returned to the message list, as a single-pane design does, and a simple three-pane HTML interface was both more portable and cleaner to implement than an AJAX one, while not being much more bandwidth-intensive.</para></listitem></varlistentry><varlistentry><term><emphasis>Rich and meaningful exposure of OpenPGP objects to the user in an intuitive way</emphasis></term><listitem><para>All <indexterm id="idx-CHP-11-0720" significance="normal"><primary>OpenPGP</primary><secondary>key operations made available to users</secondary></indexterm>key operations are available to the user, including generating, importing and exporting keys; checking key signatures and fingerprints; certifying keys and revoking key certifications; and publishing keys to and retrieving them from a key server. This puts the user in full control of her own web of trust. The validity and trust levels of keys are visible explicitly in text, as well as by color-coding in the key list. Key trust values are always kept updated with the latest state of the key ring and trust database.</para><para>The UI's Key Ring view, illustrated in <xref linkend="the_key_ring_view_exposes_information_on_keys_and_trust"/>, shows the validity of all user identities for each key, both in text and by color-coding. It also shows the key type, using icons, and owner trust values for each key (both in text and by color-coding). Full details for any key are available through the "edit" link for the key.</para></listitem></varlistentry><varlistentry><term><emphasis>Warnings and feedback about security implications of user actions</emphasis></term><listitem><para>Giving users the power to manage keys brings the risk that they will use their abilities in ways that weaken the security of the system. So, it is also the application's job to educate the user about security implications of actions such as certifying a key, altering a key's trust level, or signing a message.</para><para>All screens in Cryptonite that allow for actions with security implications contain short, highlighted warnings about these implications. And they're right on the same screen, not in irritating pop-up boxes.</para><figure id="the_key_ring_view_exposes_information_on_keys_and_trust" label="11-2" float="0"><title>The Key Ring view exposes information on keys and trust</title><mediaobject id="I_mediaobject11_tt231"><imageobject role="print"><imagedata fileref="figs/print/beauty_1102.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1102.png" format="PNG"/></imageobject></mediaobject></figure></listitem></varlistentry><varlistentry><term><emphasis>Built-in associations</emphasis></term><listitem><para><indexterm id="idx-CHP-11-0721" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite's concept of a user's identity is strongly tied to the <indexterm id="idx-CHP-11-0722" significance="normal"><primary>private keys</primary></indexterm>private keys in the user's key ring. When sending mail, users can use any "From" address that corresponds to a private key in their key ring. This helps the user grasp in an intuitive and inescapable way the idea of a private key. <indexterm id="idx-CHP-11-0723" significance="normal"><primary>public keys tied to contacts in the user's address book (Cryptonite)</primary></indexterm>Public keys can be tied to contacts in the user's address book, so they can be picked up for automatic encryption whenever available.</para></listitem></varlistentry><varlistentry><term><emphasis>Full-featured email client</emphasis></term><listitem><para><indexterm id="idx-CHP-11-0724" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite is primarily an email client that just happens to have complete support for OpenPGP-based security and key management built in. An important usability goal was to provide the user with a full-featured email client without letting the security functionality get in the way of its usability for email. This required not only providing the full range of features a user would expect to find in an email client but, most significantly, enabling users to search through their mail folders, including text within encrypted messages, without much more complexity than a regular email client where all messages are stored unencrypted.<indexterm id="idx-CHP-11-0725" significance="normal"><primary>email client</primary></indexterm></para></listitem></varlistentry></variablelist></sect1><sect1 id="the_foundation" label="11.4"><title>The Foundation</title><para>Application software today, of course, is many levels removed from the bare hardware and builds on top of many layers of existing code. So when starting a new project, getting the foundation right has to be the crucial starting point.</para><para>For a number of reasons, I chose to write <indexterm id="idx-CHP-11-0726" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite in <indexterm id="idx-CHP-11-0727" significance="normal"><primary>C language</primary><secondary>Perl interface to libraries</secondary></indexterm>Perl. The rich pool of open source reusable modules on CPAN (<ulink url="http://www.cpan.org"/>) helped minimize the need to write new code where existing solutions could be leveraged, and also allowed a great deal of flexibility in interfaces and options. This was borne out well by prior experience with the language as well as by later experiences with the <indexterm id="idx-CHP-11-0728" significance="normal"><primary>Perl</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite project.</para><para>The ability to interface to C and other libraries through Perl's XS API allowed access to even more libraries. Perl's excellent portability and robust support for object-oriented programming were other important advantages. Cryptonite was intended to be easily modifiable by licensees, which would also be facilitated by writing it in Perl.</para><para>So, the Cryptonite system is implemented entirely in object-oriented Perl. The project has led to the creation of numerous open source Perl modules, which I have made available on CPAN.</para><para>GNU/Linux jumped out as the obvious development platform, because code developed on a Unix-like environment would be easiest to port to whatever deployment platform it would be used on, which could only be another Unix-like platform. No Windows or <indexterm id="idx-CHP-11-0729" significance="normal"><primary>Mac OS X</primary></indexterm>Mac system at the time (<indexterm id="idx-CHP-11-0730" significance="normal"><primary>OS X</primary></indexterm>OS X was in pre-beta) had what it took to run mission-critical software to be used concurrently by thousands of users. Linux was my preferred <indexterm id="idx-CHP-11-0731" significance="normal"><primary>Linux</primary><secondary>desktop environment for secure mail system</secondary></indexterm>desktop environment anyway, so it was also the default choice.</para><para>In 2001, development and deployment moved to <indexterm id="idx-CHP-11-0732" significance="normal"><primary>OpenBSD</primary></indexterm>OpenBSD, and since 2003, development has proceeded on OS X and OpenBSD (as well as Linux). OS X was chosen for its out-of-box usability as a portable primary desktop, combined with its Unix-like underpinnings and ability to run a <indexterm id="idx-CHP-11-0733" significance="normal"><primary>Emacs</primary><secondary>IDE for development of secure mail system</secondary></indexterm>wide variety of open source software. OpenBSD was chosen as a deployment platform for its reliability, superlative security record, and focus on code quality and code auditing.</para><para>The IDE used for development was Emacs, selected for its power, extensibility, and excellent portability, including portability to handheld and wearable devices that I often used for development on the move. I also appreciated the availability of <indexterm id="idx-CHP-11-0734" significance="normal"><primary>Perl</primary><secondary>Emacs's cperl mode</secondary></indexterm>Emacs's <emphasis>cperl</emphasis> mode, which manages to offer pretty good auto-formatting for Perl code, even though "only <emphasis>perl</emphasis> can parse Perl."</para><sect2 id="design_goals_and_decisions" label="11.4.1"><title>Design Goals and Decisions</title><para>Cryptonite was envisioned as an OpenPGP-compatible <indexterm id="idx-CHP-11-0735" significance="normal"><primary>mail system (Cryptonite)</primary></indexterm>webmail system designed to be <indexterm id="idx-CHP-11-0736" significance="normal"><primary>secure communications</primary></indexterm>secure, scalable, reliable, and easy to use. Portability and extensibility were other important goals of the project.<indexterm id="idx-CHP-11-0737" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>design goals and decisions</secondary></indexterm></para><para>A key decision made early on was to develop a fully independent core engine to facilitate interface diversity and cross-platform access. It was important for interface specialists to be able to build interfaces without needing to modify the core. Clean separation of the core from the interface would allow experimentation with a variety of interface styles, which could then be subjected to usability testing to help evolve the optimal interface. This separation is also the essential design feature that will enable a diversity of interfaces to be built in the future, including interfaces designed for small devices such as cellphones and PDAs.</para><para>This design called for a client-server system, with a well-defined internal API and a clear separation of functionality and privilege between the <indexterm id="idx-CHP-11-0738" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite engine and the user interface. Interfaces to the core could then be implemented in any language with any UI framework. A reference interface would be developed to enable live usability testing.</para><para>Another consideration was to enable flexibility in deployment, by providing the option to perform cryptographic operations either on the server or on the user's own machine. Both approaches have their advantages and drawbacks.</para><para>While in <indexterm id="idx-CHP-11-0739" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>principle it is desirable to restrict cryptographic operations to the user's machine, these machines in practice are very often physically <indexterm id="idx-CHP-11-0740" significance="normal"><primary>secure communications</primary></indexterm>insecure and riddled with spyware. The server, on the other hand, can benefit from both high physical security and dedicated software maintenance by experts, making server-side cryptography (especially in conjunction with hardware token authentication) a more secure option for many users. This was another reason behind the choice of Perl as the implementation language: its high portability would make it possible to run the application (or components of it) on both server and user machines, as needed.</para><para>An object-oriented implementation would help keep the code easy to comprehend, extend, maintain, and modify over many years. As the code would be available in source form to licensees and end users, readability and accessibility of the code were themselves important objectives.</para></sect2><sect2 id="basic_system_design" label="11.4.2"><title>Basic System Design</title><para>The initial design of <indexterm id="idx-CHP-11-0741" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite is shown in <xref linkend="the_initial_design_of_cryptonite_cm_is_shorthand_for_cryptonite"/>.<indexterm id="idx-CHP-11-0742" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>basic design</secondary></indexterm></para><figure id="the_initial_design_of_cryptonite_cm_is_shorthand_for_cryptonite" label="11-3" float="0"><title>The initial design of Cryptonite (C::M is shorthand for Cryptonite::Mail)</title><mediaobject id="I_mediaobject11_tt232"><imageobject role="print"><imagedata fileref="figs/print/beauty_1103.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1103.png" format="PNG"/></imageobject></mediaobject></figure><para>Most of the work is done by the <indexterm id="idx-CHP-11-0743" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite::Mail::<indexterm id="idx-CHP-11-0744" significance="normal"><primary>Service class (Cryptonite)</primary></indexterm>Service class, which defines a high-level service object that implements all the core functionality of the <indexterm id="idx-CHP-11-0745" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite system. The methods of this class simply perform operations based on their arguments and return a status code and the results of the operation, if any. All the methods are noninteractive, and there is no user interface code in this class:</para><programlisting id="I_programlisting11_tt233" format="linespecific">
	package <indexterm id="idx-CHP-11-0746" significance="normal"><primary>Cryptonite::Mail::Service class</primary></indexterm>Cryptonite::Mail::Service;

	sub new {       #       Object constructor
	   ...
	}
	
	sub newuser {   #       Create new user account.
	   ...
	}

	sub newkey {    #       Generate a new key for a user.
	   ...
	}
	...
</programlisting><para>Cryptonite::Mail::Service encapsulates all the core functionality of the system, including user creation and management; creating, opening and closing folders; sending, deleting and copying mail; encryption, decryption and signature verification; and parsing multipart MIME messages.</para><para>The Service class is used by <indexterm id="idx-CHP-11-0747" significance="normal"><primary>Cryptonite::Mail::Server</primary></indexterm>Cryptonite::Mail::Server to implement a server that receives serialized Cryptonite API calls and dispatches them to a Service object.</para><para><indexterm id="idx-CHP-11-0748" significance="normal"><primary>serialization</primary></indexterm>Serialization was initially achieved via SOAP calls, but the SOAP object parsing and handling added too much needless complexity and overhead. So, a simple home-brewed serialization scheme was implemented instead. (Seven years in, this looks like a really good move, judging from <ulink url="http://wanderingbarque.com/nonintersecting/2006/11/15/the-s-stands-for-simple"/> and its comments.) This is the <indexterm id="idx-CHP-11-0749" significance="normal"><primary>command dispatcher in Cryptonite::Mail::Server</primary></indexterm>command dispatcher in Cryptonite::Mail::Server:</para><programlisting id="I_programlisting11_tt234" format="linespecific">
	package Cryptonite::Mail::Server;

	use Net::Daemon;

	use vars qw(@ISA);
	use Cryptonite::Mail::Service;

	@ISA = qw(Net::Daemon);

	my $debug = 1;
	my $cmail = new Cryptonite::Mail::Service;

	sub process_request {
	  my $self = shift; my ($retcode, $input);

	  # Wrap in eval to catch timeout exception.
	  eval {
	    local $SIG{ALRM} = sub { die "Timed Out!\n" };

	    # Timeout after 2 minutes of no input.
	    my $timeout = 120;

	    my $previous_<indexterm id="idx-CHP-11-0750" significance="normal"><primary>alarm function (Perl)</primary></indexterm>alarm = alarm($timeout);
	    while( &lt;STDIN&gt; ){
	      s/\r?\n$//;

	      # Get caller, command and cmd args.
	      my ($caller, $command, @args) = split /(?&lt;!\\):/;
	      $debug ? $debug == 2 ? warn "$$: $_\n" :
	        warn "$$: $caller:$command:$args[0]\n" : '';

	      # Unescape arg separators in the stream.
	      for (@args) { s/(?&lt;!;);(?!;)/:/sg; s/;;/;/sg }
	      return if $command =~ /^\s*quit\s*$/i;

	      # Validate command.
	      my $valid = $cmail-&gt;valid_cmd;
	      if ($command=~/$valid/x) {
	        # Call service method.
	        $ret = join ("\n", ($cmail-&gt;$command (@args), ''));
	        print STDOUT $ret;
	      }
	      else {
	        # Invalid command.
	        print STDOUT ($cmail-&gt;cluebat (ECOMMAND, $command) . "\n");
	      }
	      alarm($timeout);
	    }
	    alarm($previous_alarm);
	  };

	  if( $@=~/timed out/i ){
	    print STDOUT "Timed Out.\r\n";
	    return;
	  }
	}
</programlisting><para>The <indexterm id="idx-CHP-11-0751" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite <indexterm id="idx-CHP-11-0752" significance="normal"><primary>Mail Daemon (cmaild)</primary></indexterm>Mail Daemon (<emphasis>cmaild</emphasis>) receives serialized method calls via Unix or TCP sockets, calls the method on the service object, and returns a result code (+<literal moreinfo="none">OK</literal> or -<literal moreinfo="none">ERR</literal>) along with a human-readable status message (e.g., "Everything is under control!") and optional return values (such as a list of messages in a folder, or the text of a message part). If multiple lines of return values are being returned, the status message indicates how many lines the client should expect to read.</para><para>The server forks a new process every time a new client connects, so Perl's built-in <emphasis>alarm</emphasis> function is used to send each new server process a SIGALRM <emphasis>$timeout</emphasis> seconds after the last message received from the client, which causes the server to time out and disconnect the client.</para></sect2></sect1><sect1 id="the_test_suite" label="11.5"><title>The Test Suite</title><para>Because automated testing is a crucial component of long-term development, I developed a <indexterm id="idx-CHP-11-0753" significance="normal"><primary>Mail Daemon (cmaild)</primary><secondary>test suite</secondary></indexterm>test suite simultaneously with the project code.<indexterm id="idx-CHP-11-0754" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>test suite</secondary></indexterm></para><para>The clean separation of the core from the interface makes it easy to test both components separately, as well as to quickly diagnose bugs and pinpoint where they are in the code. Writing tests for <emphasis>cmaild</emphasis> is just a matter of calling its methods with valid (or invalid) inputs and making sure that the return codes and values are as expected.</para><para>The test suite for <emphasis>cmaild</emphasis> uses the client API calls <literal moreinfo="none">cmdopen</literal> (to open a connection to the <indexterm id="idx-CHP-11-0755" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite Mail Daemon), <literal moreinfo="none">cmdsend</literal> (to send an API call to the daemon), and <literal moreinfo="none">cmdayt</literal> (to send an "Are you there?" ping to the server):</para><programlisting id="I_programlisting11_tt235" format="linespecific">
	use strict;
	use Test;

	BEGIN { plan tests =&gt; 392, todo =&gt; [] }

	use <indexterm id="idx-CHP-11-0756" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite::Mail::HTML qw (&amp;cmdopen &amp;cmdsend &amp;cmdayt);

	$Test::Harness::Verbose = 1;

	my ($cmailclient, $select, $sessionkey);
	my ($USER, $CMAILID, $PASSWORD) = 'test';
	my $a = $Cryptonite::Mail::Config::CONFIG{ADMINPW};

	ok(sub {               # 1: cmdopen
	     my $status;
	     ($status, $cmailclient, $select) = cmdopen;
	     return $status unless $cmailclient;
	     1;
	  }, 1);

	ok(sub {               # 2: newuser
	     my $status = cmdsend('test.pl', $a, $cmailclient, $select,
	                          'newuser', $USER);
	     return $status unless $status =~ /^\+OK.*with password (.*)$/;
	     $PASSWORD = $1;
	     1;
	   }, 1);

	...
</programlisting></sect1><sect1 id="the_functioning_prototype" label="11.6"><title>The Functioning Prototype</title><para>For the first prototype, I used a simple object persistence module, Persistence::Object::Simple (which my friend Vipul had written for a project we'd worked on earlier) to whip up a basic user database. Using persistent objects helped keep the code clean and intuitive, and also provided a straightforward upgrade path to production database engines (simply create or derive a compatible Persistence::Object::<footnote id="CHP-11-FNOTE-4"><para>"There's More Than One Way To Do It," a central tenet of the Perl way of life.</para></footnote> class for the database engine).<indexterm id="idx-CHP-11-0757" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>functioning prototype</secondary></indexterm></para><para>In late 2002, Matt Sergeant created another simple <indexterm id="idx-CHP-11-0758" significance="normal"><primary>Perl</primary><secondary>prototype-to-production path</secondary></indexterm>prototype-to-production path for Perl hackers, <indexterm id="idx-CHP-11-0759" significance="normal"><primary>DBD::SQLite module (Perl)</primary></indexterm>DBD::SQLite module, a "self-contained RDBMS in a DBI driver," which can be used for rapid prototyping of <indexterm id="idx-CHP-11-0760" significance="normal"><primary>database code</primary></indexterm>database code without the need for a full database engine during development. Personally, though, I prefer the elegance and simplicity of persistent objects to having my <indexterm id="idx-CHP-11-0761" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>code cleanup</secondary></indexterm>code littered with SQL queries and DBI calls.</para><para>Mail received into the <indexterm id="idx-CHP-11-0762" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite system was saved to regular <emphasis>mbox</emphasis> files, which worked fine for the prototype. Of course, a production implementation would have to use a more sophisticated <indexterm id="idx-CHP-11-0763" significance="normal"><primary>mail system (Cryptonite)</primary><secondary>mail store</secondary></indexterm>mail store. I decided to use PGP itself as the <indexterm id="idx-CHP-11-0764" significance="normal"><primary>PGP</primary><secondary>encryption backend for Cryptonite mail</secondary></indexterm>encryption backend, to avoid rewriting (and maintaining) all the encryption functionality already contained in PGP.<indexterm id="idx-CHP-11-0765" significance="normal"><primary>mbox files</primary></indexterm></para><para><indexterm id="idx-CHP-11-0766" significance="normal"><primary>GnuPG</primary></indexterm>GnuPG was coming along, and I kept in mind that I might want to use it for cryptography support in the future. So, I wrote <indexterm id="idx-CHP-11-0767" significance="normal"><primary>Crypt::PGP5 module (Perl)</primary></indexterm>Crypt::PGP5 to encapsulate the PGP5 functionality in a Perl module. This module is available from CPAN (though I haven't updated it in ages).</para><para>For the cryptographic core of Crypt::PGP5, I could have used the proprietary PGPSDK library, but I would have had to create a Perl interface to it, which would likely have been more work than just using the PGP binary. So, with a healthy dose of Perlish laziness and keeping in mind that TMTOWTDI,<footnote id="CHP-11-FNOTE-5"><para>"There's More Than One Way To Do It," a central tenet of the Perl way of life.</para></footnote> I decided to use the Expect module to automate interactions with the PGP binary, using the same interface that's available to human users of the program. This worked well enough for the first prototype.</para><para>A basic web interface was developed, using the <indexterm id="idx-CHP-11-0768" significance="normal"><primary>Text::Template module (Perl)</primary></indexterm>Text::Template module, to populate HTML templates. The <indexterm id="idx-CHP-11-0769" significance="normal"><primary>Cryptonite::Mail::HTML package</primary></indexterm>Cryptonite::Mail::HTML module contained all web-interface-related code, including session handling.</para><para>The prototype system was ready after just three months of part-time coding. It implemented a full web interface, basic MIME support, OpenPGP encryption, decryption, signing and signature verification, online new user registration, and a new and interesting alternative to login passwords for authentication: PassFaces from ID Arts.</para></sect1><sect1 id="clean_up_plug_in_rock_onhellip" label="11.7"><title>Clean Up, Plug In, Rock On…</title><para>After developing the initial prototype of Cryptonite in Costa Rica, I continued working on it independently. After a much needed cleanup of the code (prototype development had been hectic and had left not much time to refactor or test the code), I worked on a number of Perl modules and components that would be needed next, to make the jump from a simple prototype to a scalable product. These included <indexterm id="idx-CHP-11-0770" significance="normal"><primary>Crypt::GPG module (Perl)</primary></indexterm>Crypt::GPG (with an interface almost identical to that of Crypt::PGP5, so that switching to GnuPG for the crypto operations in Cryptonite involved little more than a single-line change to the code), and <indexterm id="idx-CHP-11-0771" significance="normal"><primary>Persistence::Database::SQL class</primary></indexterm>Persistence::Database::SQL and <indexterm id="idx-CHP-11-0772" significance="normal"><primary>Persistence::Object::Postgres class</primary></indexterm>Persistence::Object::Postgres (which provide object persistence in a <indexterm id="idx-CHP-11-0773" significance="normal"><primary>Postgres database</primary></indexterm>Postgres database, with a similar interface to <indexterm id="idx-CHP-11-0774" significance="normal"><primary>Persistence::Object::Simple class</primary></indexterm>Persistence::Object::Simple, making the backend database switch quite seamless as well).</para><para>Persistence::Object::Postgres, like Persistence::Object::Simple, uses a <indexterm id="idx-CHP-11-0775" significance="normal"><primary>blessed reference</primary></indexterm>blessed reference<footnote id="CHP-11-FNOTE-6"><para>In Perl, a reference becomes an object when associated to a class by bless, so "blessed reference" is just a Perlish term for an object.</para></footnote> to a hash container to store key-value pairs, which can be committed to the database with a <literal moreinfo="none">commit</literal> method call. It also uses Perl's <indexterm id="idx-CHP-11-0776" significance="normal"><primary>Perl</primary><secondary>Tie interface</secondary></indexterm>Tie mechanism to tie Postgres' large objects (BLOBs) to filehandles, enabling natural filehandle-based access to large binary objects in the data-base. One of the major benefits of Persistence::Database::SQL over Persistence::Object:: Simple, of course, is that it enables proper queries into a real database. For example, with Persistence::Object::Simple, there's no clean way to quickly search for a particular user's record, whereas with Persistence::Database::SQL, getting a specific user record from the database is straightforward:</para><programlisting id="I_programlisting11_tt236" format="linespecific">
	sub _getuser { # Get a user object from the database.
	  my $self = shift; my $username = shift;
	  $self-&gt;db-&gt;table('users'); $self-&gt;db-&gt;template($usertmpl);
	  my ($user) = $self-&gt;db-&gt;select("WHERE USERNAME = '$username'");
	  return $user;
	}
</programlisting><para>With Persistence::Object::Simple one would have to either iterate over all the persistent objects in the data directory or resort to a hack such as directly grepping the plaintext persistence files in the data directory.</para><para>In most respects, the interface of Persistence::Object::Postgres is very similar to that of Persistence::Object::Simple. To modify an object with either module, the code is identical:</para><programlisting id="I_programlisting11_tt237" format="linespecific">
	my $user = $self-&gt;_getuser($username);
	return $self-&gt;cluebat (EBADLOGIN) unless $user and $user-&gt;timestamp;
	$user-&gt;set_level($level);
	$user-&gt;commit;
</programlisting><para>The switch from a plaintext database to a real DBMS was made after most of the prototype code was basically working well, and marked the second stage of <indexterm id="idx-CHP-11-0777" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite development: getting the system ready for real-world deployment. For prototype development, Persistence::Object::Simple was great, as it didn't require a database server to be available for development, and objects were stored in plaintext files so they could be easily examined for debugging.</para><para>The use of homomorphic interfaces for Crypt::GPG and Persistence::Object::Postgres allowed these major changes (of the encryption and the database backends) to be made with very minor edits to the code in <indexterm id="idx-CHP-11-0778" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite::Mail::Service.</para><sect2 id="revamping_the_mail_store" label="11.7.1"><title>Revamping the Mail Store</title><para>Storing user mail in plain <emphasis>mbox</emphasis> files worked for the first prototype, but a production system needed to be able to access and update individual messages more efficiently than a single flat file mailbox allowed. I also wanted to move toward the very important objective of providing mail store replication for fault-tolerance.<indexterm id="idx-CHP-11-0779" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>revamping the mail store</secondary></indexterm><indexterm id="idx-CHP-11-0780" significance="normal"><primary>mail system (Cryptonite)</primary><secondary>mail store</secondary><tertiary>revamping</tertiary></indexterm></para><para>A usability consideration also imposed some requirements on the mail store. In <indexterm id="idx-CHP-11-0781" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite, unlike most email clients, information about MIME structures of messages would be made visible to users in the message list. This would make it possible for a user to visually identify which messages were encrypted and/or signed, directly in the message list. Availability of information about message parts in the message list would also enable the user to open a message subpart directly. The message parts are visible as icons in the rightmost column of the message list view, as shown in <xref linkend="message_list_with_parts"/>.</para><figure id="message_list_with_parts" label="11-4" float="0"><title>Message list with parts</title><mediaobject id="I_mediaobject11_tt238"><imageobject role="print"><imagedata fileref="figs/print/beauty_1104.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1104.png" format="PNG"/></imageobject></mediaobject></figure><para>To enable such visual feedback, the mail store would need to efficiently provide accurate information about the <indexterm id="idx-CHP-11-0782" significance="normal"><primary>MIME structure of Cryptonite mail messages</primary></indexterm>MIME structure of a list of messages. A further complication was the fact that the OpenPGP/MIME spec allows for MIME parts to be nested within signed and/or encrypted parts, so only an OpenPGP/<indexterm id="idx-CHP-11-0783" significance="normal"><primary>OpenPGP</primary><secondary>MIME-aware mail store</secondary></indexterm>MIME-aware mail store could return accurate information about MIME structures of <indexterm id="idx-CHP-11-0784" significance="normal"><primary>encrypted or signed messages</primary></indexterm>encrypted or signed messages.</para><para>So I decided to implement, based on the <indexterm id="idx-CHP-11-0785" significance="normal"><primary>Mail::Folder module (Perl)</primary></indexterm>Mail::Folder module, an SQL-based <indexterm id="idx-CHP-11-0786" significance="normal"><primary>SQL</primary><secondary>mail storage backend (Cryptonite)</secondary></indexterm>mail storage backend with most of the abilities of an IMAP4rev1 server. The core of this system is the Mail::Folder::SQL class, based on Mail::Folder and using Persistence::Object::Postgres. This was back when IMAP had not yet gained much traction. I opted not to use an existing <indexterm id="idx-CHP-11-0787" significance="normal"><primary>IMAP server as a mail store (Cryptonite)</primary></indexterm>IMAP server as a mail store because I <indexterm id="idx-CHP-11-0788" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>anticipated needing some features that most IMAP servers didn't support well, such as mail store <indexterm id="idx-CHP-11-0789" significance="normal"><primary>replication</primary></indexterm>replication and the ability to retrieve detailed information about the structure of a MIME message without having to retrieve and parse the entire message.</para><para>Even though some IMAP servers might have suited my needs, I also didn't want Cryptonite to be dependent on and tied down to the capabilities of any specific IMAP server implementation. All in all, this turned out to be a good decision, even though it did lead to a lot of effort being expended on code that was later demoted to a less central role in the system.</para><para>Mail store <indexterm id="idx-CHP-11-0790" significance="normal"><primary>mail system (Cryptonite)</primary><secondary>mail store</secondary><tertiary>replication</tertiary></indexterm>replication was hacked up using two Perl modules I wrote: <indexterm id="idx-CHP-11-0791" significance="normal"><primary>Replication::Recall module (Perl)</primary></indexterm>Replication::Recall and <indexterm id="idx-CHP-11-0792" significance="normal"><primary>DBD::Recall module (Perl)</primary></indexterm>DBD::Recall, which used Eric Newton's <indexterm id="idx-CHP-11-0793" significance="normal"><primary>Recall replication framework</primary></indexterm>Recall replication framework (<ulink url="http://www.fault-tolerant.org/recall"/>) to replicate databases across multiple servers. The idea was to use this as a prototype and to custom-build a new database replication system in the future.</para><para>With the encryption, database, and mail store backends revamped, and with a new, cleaner theme, the first internal beta of Cryptonite went online in October 2001. It was tested by many users of varying skill levels, some of whom even used it as their primary mail client. Usability testing during the internal beta indicated that novice users were able to successfully generate and import keys, and to send and read encrypted and signed messages without much trouble.</para></sect2><sect2 id="persistence_of_decryption" label="11.7.2"><title>Persistence of Decryption</title><para>An essential feature for an <indexterm id="idx-CHP-11-0794" significance="normal"><primary>encrypted mail client</primary></indexterm>encrypted mail client is the ability to keep <indexterm id="idx-CHP-11-0795" significance="normal"><primary>decrypted email messages</primary></indexterm>decrypted messages available in decrypted form for the duration of the user's session. A <indexterm id="idx-CHP-11-0796" significance="normal"><primary>secure communications</primary></indexterm>secure mail client that lacks this facility can get very irritating and inefficient to use, as it would require typing in long passphrases and waiting for decryption every time you want to read an encrypted message or search within encrypted messages.</para><para>Persistence for previously <indexterm id="idx-CHP-11-0797" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>decrypted messages</secondary></indexterm>decrypted messages in <indexterm id="idx-CHP-11-0798" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite was accomplished by creating a new Mail::Folder class, based on Mail::Folder::SQL. Mail::Folder::Shadow would delegate mailbox accesses to a <emphasis>shadow folder</emphasis> if the message had a counterpart in the shadow folder; otherwise, it would access the underlying (or <emphasis>shadowed</emphasis>) folder.</para><para>By this means, decrypted messages could be kept in the shadow folder while a session was alive, and little modification of the code was necessary to add persistent decrypts, other than to plug in the <indexterm id="idx-CHP-11-0799" significance="normal"><primary>Mail::Folder::Shadow module (Perl)</primary></indexterm>Mail::Folder::Shadow module everywhere Mail::Folder::SQL was used. Mail::Folder::Shadow implements its magic with a simple, tweakable delegation table:</para><programlisting id="I_programlisting11_tt239" format="linespecific">
	my %method =
	qw (get_message 1 get_mime_message 1 get_message_file 1 get_header 1
	    get_mime_message 1 mime_type 1 get_mime_header 1 get_fields 1
	    get_header_fields 1 refile 1 add_label 2 delete_label 2
	    label_exists 2 list_labels 2 message_exists 1 delete_message 5
	    sync 2 delete 2 open 2 set_header_fields 2 close 2 DESTROY 2
	    get_mime_skeleton 1 get_body_part 1);
</programlisting><para>Mail::Folder::Shadow delegates method calls as appropriate to the shadow folder, the original shadowed folder, or to both. Perl's powerful <literal moreinfo="none">AUTOLOAD</literal> feature, which provides a mechanism to handle methods that are not explicitly defined in a class, is a simple way to accomplish this delegation, while also providing a simple mechanism to tweak at runtime how different methods are handled.<indexterm id="idx-CHP-11-0800" significance="normal"><primary>Perl</primary><secondary>AUTOLOAD feature</secondary></indexterm></para><para>Methods that have to check the shadow store, such as <literal moreinfo="none">get_message</literal> and <literal moreinfo="none">get_header</literal>, are delegated to the shadow if the message concerned exists in the shadow folder; otherwise, they are delegated to the original shadowed folder. Other methods, such as <literal moreinfo="none">add_label</literal> and <literal moreinfo="none">delete</literal> (which deletes a folder), need to be dispatched to both the shadow and the shadowed folder, as these messages must change the state of the original folder, as well as that of the shadow folder.</para><para>Yet other methods, such as <literal moreinfo="none">delete_message</literal>, can accept a message list through an array reference. Some of the messages in the message list may be shadowed, and others may not. Mail::Folder::Shadow's <literal moreinfo="none">AUTOLOAD</literal> handles such methods by building two lists from the message list passed to it, one of shadowed messages and one of nonshadowed messages. It then calls the method on both the shadowed and <indexterm id="idx-CHP-11-0801" significance="normal"><primary>shadow folder for mailbox messages</primary></indexterm>shadow folder for messages that are shadowed, and only on the <indexterm id="idx-CHP-11-0802" significance="normal"><primary>shadowed folder for mailbox messages</primary></indexterm>shadowed folder for messages that aren't.</para><para>The practical upshot of all of this is that <emphasis>cmaild</emphasis> can continue to use folders just as it did before, and stash decrypted messages in the shadow folder for the duration of a session. There are a few extra methods in Mail::Folder::Shadow to enable this, including <literal moreinfo="none">update_shadow</literal>, which is used to save the decrypted message in the shadow folder; <literal moreinfo="none">delete_shadow</literal>, used to delete individual shadowed messages at user request; and <literal moreinfo="none">unshadow</literal>, used to delete all messages in shadow folders before session termination.</para><para>Mail::Folder::Shadow makes it possible to offer persistence of decrypted messages for a session and to implement search within encrypted messages—both essential features from a user's perspective, but rarely implemented in current-generation OpenPGP-compliant <indexterm id="idx-CHP-11-0803" significance="normal"><primary>mail system (Cryptonite)</primary></indexterm>email systems.</para></sect2></sect1><sect1 id="hacking_in_the_himalayas" label="11.8"><title>Hacking in the Himalayas</title><para>Through 2000 and 2001 I was able to work on <indexterm id="idx-CHP-11-0804" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite only intermittently, both because of other commitments and because the project needed peace and quiet, which was in limited supply when I was traveling around and living in chaotic, cacophonous, polluted Indian cities.</para><para>In the summer of 2002, my wife and I took a vacation in the Himalayas, where I finally managed to get the time to finish writing major chunks of the code, including adding important <indexterm id="idx-CHP-11-0805" significance="normal"><primary>key management</primary></indexterm>key management abilities to Crypt::GPG, and creating an <indexterm id="idx-CHP-11-0806" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>integrated interface for key management</secondary></indexterm>integrated interface for key management, which is a critical part of the whole web-of-trust mechanism. The core of this management interface, the Edit Key dialog, is shown in <xref linkend="the_edit_key_dialog"/>. It enables fingerprint verification, the viewing and creation of user identity certifications, and the assigning of trust values to keys.</para><para>I also ported the system over to OpenBSD, which would be the ultimate deployment platform.</para><para>We already had all the other major components for a <indexterm id="idx-CHP-11-0807" significance="normal"><primary>secure communications</primary></indexterm>secure email service in place, and as it would still take some time to get <indexterm id="idx-CHP-11-0808" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite ready for public use, we decided to go ahead and launch a commercial secure email service right away. This would enable me to spend more time on Cryptonite development, and to begin building a community of testers immediately.</para><para>So in mid-2003, we launched the <indexterm id="idx-CHP-11-0809" significance="normal"><primary>Neomailbox secure email service</primary></indexterm>Neomailbox secure IMAP, POP3, and SMTP email service. In the following years, this proved to be an excellent move that would help fund development, freeing me from the need to take on other contract work and simultaneously keeping me in close touch with the market for secure, private messaging.</para><para>In the fall of 2003, we set up a semi-permanent development base in a small Himalayan hamlet, about 2000 meters above sea level, and this is primarily where development has progressed since then. This kept our cash burn low, which is critical for a bootstrapping startup, and gave me lots of time and peace to work on Neomailbox and Cryptonite.</para><figure id="the_edit_key_dialog" label="11-5" float="0"><title>The Edit Key dialog</title><mediaobject id="I_mediaobject11_tt240"><imageobject role="print"><imagedata fileref="figs/print/beauty_1105.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1105.png" format="PNG"/></imageobject></mediaobject></figure><para>Even though we had our share of trials working on mission-critical high-tech systems from a remote Himalayan village that was, for the most part, still stuck in the 19th century, the words of Nikolai Roerich, the prolific Russian artist, writer, and philosopher who lived in the same part of the Himalayas for many years, did to a large extent hold true for us, too: "In truth, only here, only in the Himalayas, exist the unique, unprecedented, calm conditions for achieving results."</para><sect2 id="securing_the_code" label="11.8.1"><title>Securing the Code</title><para>Originally the code was designed as a prototype, and I didn't worry about securing it too much. But as time to make the system available as a public beta came around, it was time to lock down the code with, at least:<indexterm id="idx-CHP-11-0810" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>securing the code</secondary></indexterm></para><itemizedlist><listitem><para>Complete privilege separation</para></listitem><listitem><para>Paranoid input validation</para></listitem><listitem><para>Security audit of Crypt::GPG</para></listitem><listitem><para>Documentation of any potential security issues</para></listitem></itemizedlist><para>Privilege separation was already built in from the ground up, by running <emphasis>cmaild</emphasis> as a privileged user and interacting with it via its API. This allowed <emphasis>cmaild</emphasis> to perform privileged operations such as modifying system configuration files and performing cryptographic operations in a controlled manner, without giving the web server process access to sensitive resources. Only a few areas required cleanup of the separation between the core and the interface.<indexterm id="idx-CHP-11-0811" significance="normal"><primary>mail system (Cryptonite)</primary></indexterm></para><para>One of these was the composition of MIME messages with binary attachments. When the code was built using Persistence::Object::Simple, the <emphasis>cmaild</emphasis> protocol had been circumvented <indexterm id="idx-CHP-11-0812" significance="normal"><primary>regular expressions</primary><secondary>for input validity in Cryptonite mail system</secondary></indexterm>for <indexterm id="idx-CHP-11-0813" significance="normal"><primary>binary MIME message composition</primary></indexterm>binary MIME message composition. Attachments uploaded by the <indexterm id="idx-CHP-11-0814" significance="normal"><primary>validation</primary><secondary>user input</secondary></indexterm>user were saved in a temporary directory, which both <emphasis>cmaild</emphasis> and the web server process had access to. Thus, it was necessary to run <emphasis>cmaild</emphasis> and the <indexterm id="idx-CHP-11-0815" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite web interface on the same server.</para><para>With the move to Persistence::Object::Postgres, it became possible to easily pass binary objects between the frontend and the backend via the database, without relying on direct filesystem operations. This was important because the interface, the database, and the Cryptonite engine were all intended to run on their own independent servers or in load-balancing clusters.</para><para><indexterm id="idx-CHP-11-0816" significance="normal"><primary>input validation (Cryptonite mail system)</primary></indexterm>Input validation (to check the validity of user-supplied inputs, such as folder and message identifiers) was straightforward to add. The <indexterm id="idx-CHP-11-0817" significance="normal"><primary>Params::Validate module (Perl)</primary></indexterm>Params::Validate module, very slightly modified, was used to add input validation to every method of Cryptonite::Mail::Service. The <literal moreinfo="none">mvmsgs</literal> method, for example, validates its inputs with:</para><programlisting id="I_programlisting11_tt241" format="linespecific">
	sub mvmsgs  {    #      Move a list of messages to some other mailbox.
	  my ($self, $username, $key, $dest, $copy, @msgnums) =
	    (shift, lc shift, shift);
	  my ($user, $session, $err) = $self-&gt;validateuser($username, $key);
	  return $err if $err;
	  return $self-&gt;cluebat(@{$@}) unless eval {
	    ($dest, $copy, @msgnums) = validate_with ( params =&gt; \@_,
	      extra =&gt; [$self], spec = [
	        { type =&gt; SCALAR, callbacks =&gt;
	          { 'Legal Folder Name' =&gt; $self-&gt;legal_foldername } },
	        { type =&gt; SCALAR, callbacks =&gt;
	          { 'Boolean Flag' =&gt; $self-&gt;opt_boolean }, optional =&gt; 1 },
	        ({ type =&gt; SCALAR, callbacks =&gt;
	          { 'Legal Message Number' =&gt; $self-&gt;legal_msgnum } })
	            x (@_ - 2) ]
	   )
	};
</programlisting><para>The acceptability of user-supplied input for each type of input field is specified via callback subroutine references stored in a hash in the <indexterm id="idx-CHP-11-0818" significance="normal"><primary>Cryptonite::Mail::Config module (Perl)</primary></indexterm>Cryptonite::Mail::Config module:</para><programlisting id="I_programlisting11_tt242" format="linespecific">
	LGL_FOLDERNAME =&gt; sub { $_[0] =~ /$_[1]-&gt;{"VFOLDER"}/i
	                           or die (['EBADFOLDER', $_[0]]) },
	OPT_BOOLEAN    =&gt; sub { $_[0] eq '' or $_[0] eq 0 or $_[0] eq 1
	                           or die (['EBADBOOL', $_[0]]) },
	LGL_MSGNUM     =&gt; sub { $_[0] =~ /$_[1]-&gt;{"VMSGNUM"}/
	                           or die (['EBADMSGNUM', $_[0]]) },
</programlisting><para>Similar subroutines are invoked whenever an input parameter is validated. The regular expressions for validity are stored separately in Cryptonite::Mail::Config.</para><para>Even though most of the validation subroutines are essentially the same, they are all distinct, to enable each one to be tweaked as necessary without affecting the others or sacrificing clarity in this part of the code. The validation regular expressions and error strings are stored in a table as well, to enable localization in the future.</para><para>Persistence::Object::Postgres also performs its own input sanity checks, to protect against SQL injection attacks.</para></sect2><sect2 id="auditing_cryptgpg" label="11.8.2"><title>Auditing Crypt::GPG</title><para>Crypt::GPG had been written to be a working prototype and needed complete auditing to eliminate any potential <indexterm class="startofrange" id="idx-CHP-11-0819" significance="normal"><primary>Crypt::GPG module (Perl)</primary><secondary>security audit</secondary></indexterm>security issues before public testing of the <indexterm id="idx-CHP-11-0820" significance="normal"><primary>mail system (Cryptonite)</primary></indexterm>system.<indexterm id="idx-CHP-11-0821" significance="normal"><primary>GPG</primary></indexterm></para><para>Crypt::GPG had been freely available on CPAN since 2001, and I'd received much valuable feedback from its users. While many users said that they really liked the module's clean and simple interface, some had trouble getting it to run on certain platforms, where the <indexterm id="idx-CHP-11-0822" significance="normal"><primary>Expect module (Perl)</primary></indexterm>Expect module it used to interact with GnuPG didn't work right. (Expect uses Unix pseudoterminals [ptys] as its IPC mechanism, and that doesn't work on Windows, for example.)</para><para>The Expect module's interface and syntax were also somewhat convoluted, which made the code a little difficult to read, as can be seen from this section of the <literal moreinfo="none">sign</literal> method:</para><programlisting id="I_programlisting11_tt243" format="linespecific">
	my $expect = Expect-&gt;spawn ($self-&gt;gpgbin, @opts, '-o-', '--sign',
	                               @extras, @secretkey, $tmpnam);
	$expect-&gt;log_stdout($self-&gt;debug);

	$expect-&gt;expect (undef, '-re',
	                    '-----BEGIN', 'passphrase:', 'signing failed');

	if ($expect-&gt;exp_match_number == 2) {
	  $self-&gt;doze; print $expect ($self-&gt;passphrase . "\r");
	  $expect-&gt;expect (undef, '-re', '-----BEGIN', 'passphrase:');

	  if ($expect-&gt;exp_match_number == 2) { # Passphrase incorrect
	    $self-&gt;doze;
	    print $expect ($self-&gt;passphrase . "\r");
	    $expect-&gt;expect (undef, 'passphrase:'); $self-&gt;doze;
	    print $expect ($self-&gt;passphrase . "\r");
	    $expect-&gt;expect (undef);
	    unlink $tmpnam;
	    return;
	  }
	}

	elsif ($expect-&gt;exp_match_number == 3) {
	  unlink $tmpnam; $expect-&gt;close;
	  return;
	}

	$expect-&gt;expect (undef);
	my $info = $expect-&gt;exp_match . $expect-&gt;exp_before;
</programlisting><para>Using the Expect-based module also caused <emphasis>Heisenbugs</emphasis>—failures that weren't easily reproducible, and that I discovered were the result of sending input to <emphasis>gpg</emphasis> too fast. The calls to <literal moreinfo="none">doze</literal> in the previous code are a workaround for this: they introduce a few milliseconds of delay before sending the next bit of input to <emphasis>gpg</emphasis>. This generally worked, but failures would still occur on heavily loaded systems.</para><para>All these issues pointed to moving away from Expect and using another mechanism to interact with the GnuPG binary. I considered the idea of writing a pure Perl implementation of OpenPGP, but decided against it for basically the same reasons that I had decided to use GnuPG in the first place: <indexterm id="idx-CHP-11-0823" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite is primarily an email client, <indexterm id="idx-CHP-11-0824" significance="normal"><primary>OpenPGP</primary><secondary>communicating with in Cryptonite mail system</secondary></indexterm>with integrated Open-PGP support. A full OpenPGP implementation would at least double the complexity of the code I would have to maintain.<footnote id="CHP-11-FNOTE-7"><para>A pure-Perl OpenPGP implementation, Crypt::OpenPGP, was written by Ben Trott in 2001–2002, and is available from CPAN. I'm looking forward to using it in future versions of Cryptonite that will support multiple cryptographic backends.</para></footnote></para><para>After a little experimenting, it looked like <indexterm id="idx-CHP-11-0825" significance="normal"><primary>IPC::Run module (Perl)</primary></indexterm>IPC::Run by Barrie Slaymaker might do the trick for communication with GnuPG. With IPC::Run, the previous code became:</para><programlisting id="I_programlisting11_tt244" format="linespecific">
	my ($in, $out, $err, $in_q, $out_q, $err_q);
	my $h = start ([$self-&gt;<indexterm id="idx-CHP-11-0826" significance="normal"><primary>GPG</primary></indexterm>gpgbin, @opts, @secretkey, '-o-',
	                '--sign', @extras, $tmpnam],
	                \$in, \$out, \$err, timeout( 30 ));

	my $i = 0;

	while (1) {
	  pump $h until ($out =~ /NEED_PASSPHRASE (.{16}) (.{16}).*\n/g or
	                 $out =~ /GOOD_PASSPHRASE/g);
	  if ($2) {
	    $in .= $self-&gt;passphrase . "\n";
	    pump $h until $out =~ /(GOOD|BAD)_PASSPHRASE/g;
	    last if $1 eq 'GOOD' or $i++ == 2;
	  }
	}
	finish $h;
	my $d = $detach ? 'SIGNATURE' : 'MESSAGE';
	$out =~ /(-----BEGIN PGP $d-----.*-----END PGP $d-----)/s;
	my $info = $1;
</programlisting><para>IPC::Run works reliably without the mini-delays needed with Expect, is much clearer to read, and works perfectly on most platforms.</para><para>Some operations with <emphasis>gpg</emphasis> didn't require any interaction, and earlier versions of the module had used Perl's backtick operator for such cases. Because the backtick operator invokes a shell, it's a <indexterm id="idx-CHP-11-0827" significance="normal"><primary>Crypt::GPG module (Perl)</primary><secondary>security audit</secondary></indexterm>security risk. With IPC::Run, it was easy to replace the use of the backtick operator with a tiny <indexterm id="idx-CHP-11-0828" significance="normal"><primary>secure communications</primary></indexterm>secure <indexterm id="idx-CHP-11-0829" significance="normal"><primary>backtick function (Cryptonite)</primary></indexterm>backtick function, thereby bypassing the shell. This made it possible to eliminate all shell invocations in Crypt::GPG.</para><programlisting id="I_programlisting11_tt245" format="linespecific">
	sub backtick {
	  my ($in, $out, $err, $in_q, $out_q, $err_q);
	  my $h = start ([@_], \$in, \$out, \$err, timeout( 10 ));
	  local $SIG{CHLD} = 'IGNORE';
	  local $SIG{PIPE} = 'IGNORE';
	  finish $h;
	  return ($out, $err);
	}
</programlisting><para>Some users had also pointed out that using temporary files to store plaintext could be <indexterm id="idx-CHP-11-0830" significance="normal"><primary>secure communications</primary></indexterm>insecure. This problem could be easily overcome without touching the code, simply by using temporary files on a RAM disk with encrypted swap (such as OpenBSD provides) or an encrypted RAM disk, so plaintext would never be written to disk unencrypted.</para><para>Of course, it would be nice to modify the code to avoid writing plaintext to temporary files at all, but as there already existed a practical workaround, eliminating temporary files went on the to-do list rather than being implemented immediately.</para><para>The new IPC::Run-based Crypt::<indexterm id="idx-CHP-11-0831" significance="normal"><primary>GPG</primary></indexterm>GPG was uploaded to CPAN at the end of 2005. It now worked on a larger range of operating systems, and was more reliable and secure than its Expect-based predecessor.</para></sect2></sect1><sect1 id="the_invisible_hand_moves" label="11.9"><title>The Invisible Hand Moves</title><para>By mid-2004, Neomailbox was a year old and had attracted quite a few paying customers. <indexterm id="idx-CHP-11-0832" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite development was put on hold for a bit while I worked on developing various aspects of the Neomailbox service as well as on a few other projects I just couldn't wait to get started on.</para><para>But being out in the market was great, as it brought market forces, from competition to user feedback, to bear on the development process, and helped sharpen and clarify priorities. Customer requests and queries helped keep me intimately connected to what the users and the market wanted. Meeting the market's demands is how application code becomes beautiful in a commercial sense, after all, so interaction with the market became an integral and critical component of the development process.</para><para>Cryptonite was designed to be easy to maintain and modify, precisely because I knew that at some point it would have to start to evolve in new ways, both in response to and in <indexterm id="idx-CHP-11-0833" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>anticipation of what the customer wanted. Being in the market enabled me to see that emerging demand: it was clear that IMAP was the future of remote mailbox access.</para><para>IMAP has a lot of attractive features that make it a very powerful and practical mail access protocol. One of the most important of these is the ability to access the same mailbox using multiple clients, which becomes increasingly important with the proliferation of computing devices. The typical user now has a desktop, a laptop, a PDA, and a cellphone, all capable of accessing her mailbox.</para><para>This posed a slight problem, as I'd already implemented a full <indexterm id="idx-CHP-11-0834" significance="normal"><primary>Cryptonite (mail system)</primary><secondary>mail store</secondary></indexterm>mail store for Cryptonite, and it was not IMAP-based. There were two ways forward: either implement a full IMAP server based on the <indexterm id="idx-CHP-11-0835" significance="normal"><primary>IMAP</primary><secondary>modifying Cryptonite mail store to use</secondary></indexterm>Cryptonite mail store (a big job), or modify Cryptonite to enable it to use an IMAP mail store as a backend. In fact, the second would have to be done either way.<indexterm id="I_indexterm11_tt246" class="endofrange" startref="idx-CHP-11-0819" significance="normal"><primary>Crypt::GPG module (Perl)</primary><secondary>security audit</secondary></indexterm><indexterm id="I_indexterm11_tt247" class="endofrange" startref="idx-CHP-11-0819" significance="normal"><primary>Crypt::GPG module (Perl)</primary><secondary>security audit</secondary></indexterm></para><para>Again, opting to reduce complexity of the system, and focusing on its primary purpose, I decided not to develop the <indexterm id="idx-CHP-11-0836" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite mail store into a full-blown IMAP server. Instead, I modified it into a caching mechanism, which caches MIME skeletons (just the structure information, without the content) of multipart MIME messages listed by the user, and also entire messages read by the user, so that the next time a user opens a message she's read before, <indexterm id="idx-CHP-11-0837" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite doesn't need to go back to the IMAP server to fetch it again.</para><para>This gave me the best of both worlds. Cryptonite could reflect the contents of an IMAP mailbox, while simultaneously posessing full information of each message's exact <indexterm id="idx-CHP-11-0838" significance="normal"><primary>MIME structure of Cryptonite mail messages</primary></indexterm>MIME structure, as well as being able to keep decrypted messages available in the shadow folders the <indexterm id="idx-CHP-11-0839" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite mail store supported.</para><para>The modifications to the code were straightforward. Whenever the user clicks to read a message that isn't in the cache, Cryptonite caches it in the corresponding Mail::Folder:: Shadow folder:</para><programlisting id="I_programlisting11_tt248" format="linespecific">
	my $folder = $session-&gt;folder;             # The folder name
	my $mbox = _opencache($username, $folder); # The M::F::Shadow cache

	unless ($msgnum and grep { $_ == $msgnum } $mbox-&gt;message_list) {

	  # Message is not in cache. Fetch from IMAP server and cache it.

	  my $imap = $self-&gt;_open_imapconn($username, $user-&gt;password)
	    or sleep(int(rand(3))+2), return $self-&gt;cluebat (EBADLOGIN);

	  $imap-&gt;select($folder) or return $self-&gt;cluebat (ENOFOLDER, $folder);

	  $imap-&gt;Uid(1);

	  my ($tmpfh, $tmpnam) =
	    tempfile( $self-&gt;tmpfiles, DIR =&gt; "$HOME/tmp",
	              SUFFIX =&gt; $self-&gt;tmpsuffix, UNLINK =&gt; 1);
	  $imap-&gt;message_to_file($tmpfh, $msgnum);

	  $imap-&gt;logout;

	  my $parser = new MIME::Parser; $parser-&gt;output_dir("$HOME/tmp/");

	  $parser-&gt;filer-&gt;ignore_filename(1); # Do NOT use suggested filename

	  seek ($tmpfh,0,0);
	  my $mail = $parser-&gt;parse($tmpfh);

	  return $self-&gt;cluebat (ENOSUCHMSG, 0 + $msgnum) unless $mail;
	  $mbox-&gt;update_message($msgnum,$mail);
	}
</programlisting><para>In a similar manner, MIME skeletons are cached for all messages listed by the user through the message list view. The rest of the code continues to work as before, by operating on the cache for all read operations. Now we have IMAP compatibility, without compromising the features afforded by my mail store or modifying the main code much.</para><para>Mail store <indexterm id="idx-CHP-11-0840" significance="normal"><primary>replication</primary></indexterm>replication would need to be worked in again because the switch from Mail:: Folder::SQL to an IMAP server for the mail store meant <indexterm id="idx-CHP-11-0841" significance="normal"><primary>mail system (Cryptonite)</primary><secondary>mail store</secondary><tertiary>replication</tertiary></indexterm>Replication::Recall couldn't be used for replication. But in any case, Replication::Recall wasn't the most elegant or easy to implement replication system, and the Recall library had been rewritten in Python, making my Perl interface to the earlier C++ implementation obsolete anyway.</para><para>In hindsight, I spent a lot of time on the replication functionality, which had to be scrapped, and I probably would have been better off not bothering with replication at that stage. On the other hand, it did teach me a lot that will come in handy when I get down to implementing replication again.</para><para>Market forces and changing standards mean that application software is always evolving, and much of the beauty of such code from the programmer's point of view is certainly in how easy it is to adapt the code to ever-changing requirements. <indexterm id="idx-CHP-11-0842" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm>Cryptonite's object-oriented architecture makes it possible to implement major revisions with ease.</para></sect1><sect1 id="speed_does_matter" label="11.10"><title>Speed Does Matter</title><para>With the <indexterm id="idx-CHP-11-0843" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm>Cryptonite mail store, <indexterm id="idx-CHP-11-0844" significance="normal"><primary>IMAP</primary><secondary>performance bottlenecks in Cryptonite mail store after implementing</secondary></indexterm>performance had been quite snappy, and most mail store operations had been independent of mailbox size. But with the switch to IMAP, I noticed some major slowdowns with large mailboxes. A little profiling revealed that the performace bottleneck was the pure-Perl <indexterm id="idx-CHP-11-0845" significance="normal"><primary>Mail::IMAPClient module (Perl)</primary></indexterm>Mail::IMAPClient module, which I'd used to implement the IMAP capability.</para><para>A quick benchmark script (written using the Benchmark module) helped me check whether another CPAN module, <indexterm id="idx-CHP-11-0846" significance="normal"><primary>Mail::Cclient module (Perl)</primary></indexterm>Mail::Cclient, which interfaces to the UW C-Client library, was more efficient than Mail::IMAPClient. The results showed clearly that I'd have to redo the IMAP code using Mail::Cclient:</para><programlisting id="I_programlisting11_tt249" format="linespecific">
	                   Rate IMAPClientSearch    CclientSearch
	IMAPClientSearch 39.8/s               --             -73%
	CclientSearch     145/s             264%               --

	                 Rate IMAPClientSort CclientSort
	IMAPClientSort 21.3/s             --        -99%
	CclientSort    2000/s          9280%          --
</programlisting><para>I probably should have thought of benchmarking the different modules before writing the code with Mail::IMAPClient. I'd originally avoided the C-Client library because I wanted to keep the build process as simple as possible, and Mail::IMAPClient's build process is definitely simpler than that of Mail::Cclient.</para><para>Fortunately, the switch from the former to the latter was generally quite straightforward. For some operations, I noticed that IMAPClient could do the job better than C-Client without much of a performance penalty, so Cryptonite::Mail::Service now uses both modules, each to do whatever it's better at.</para><para>A program like Cryptonite is never "finished," of course, but the code is now mature, robust, full of features, and efficient enough to serve its purpose: to provide thousands of concurrent users a <indexterm id="idx-CHP-11-0847" significance="normal"><primary>secure communications</primary></indexterm>secure, intuitive, and responsive email experience while helping them effectively protect the privacy of their communications.<indexterm id="I_indexterm11_tt250" class="endofrange" startref="idx-CHP-11-0691" significance="normal"><primary>Cryptonite (mail system)</primary></indexterm><indexterm id="I_indexterm11_tt251" class="endofrange" startref="idx-CHP-11-0690" significance="normal"><primary>mail system (Cryptonite)</primary></indexterm><indexterm id="I_indexterm11_tt252" class="endofrange" startref="idx-CHP-11-0692" significance="normal"><primary>secure communications</primary><secondary>Cryptonite mail system</secondary></indexterm></para></sect1><sect1 id="communications_privacy_for_individual_rights" label="11.11"><title>Communications Privacy for Individual Rights</title><para>I mentioned at the beginning of this chapter that making <indexterm id="idx-CHP-11-0848" significance="normal"><primary>secure communications</primary></indexterm>secure communications technology widely available is a very effective means of protecting individual rights. As this recognition is the basic motivation behind the Cryptonite project, I'd like to end with a few observations on this point.<indexterm id="idx-CHP-11-0849" significance="normal"><primary>privacy in communications</primary></indexterm></para><para>Cryptographic technology can, among other things:<footnote id="CHP-11-FNOTE-8"><para>See <ulink url="http://www.idiom.com/~arkuat/consent/Anarchy.html"/> and <ulink url="http://www.chaum.com/articles/Security_Wthout_Identification.htm"/>.</para></footnote></para><itemizedlist><listitem><para>Provide strong life-saving <indexterm id="idx-CHP-11-0850" significance="normal"><primary>individual rights in the digital age</primary><secondary>protection with communications privacy</secondary></indexterm>protection for activists, NGOs, and reporters working in repressive countries.<footnote id="CHP-11-FNOTE-9"><para>See <ulink url="http://philzimmermann.com/EN/letters/index.html"/>.</para></footnote></para></listitem><listitem><para>Preserve the communicability of censored news and controversial ideas.</para></listitem><listitem><para>Protect the anonymity of whistle-blowers, witnesses, and victims of domestic abuse.</para></listitem><listitem><para>For dessert, catalyze the geodesic society by enabling the free and unfettered exchange of ideas, goods, and services globally.</para></listitem></itemizedlist><para>The motley crew of hackers known as the <indexterm id="idx-CHP-11-0851" significance="normal"><primary>Cypherpunks</primary></indexterm>Cypherpunks has been developing <indexterm id="idx-CHP-11-0852" significance="normal"><primary>secure communications</primary><secondary>privacy protection for individual rights</secondary></indexterm>privacy-enhancing software for years, with the intent of enhancing personal freedom and individual sovereignty in the digital age. Some <indexterm id="idx-CHP-11-0853" significance="normal"><primary>cryptographic software</primary></indexterm>cryptographic software is already a cornerstone of how the world works today. This includes the Secure SHell (SSH) remote terminal software, which is essential to securing the Internet's infrastructure, and the Secure Sockets Layer (SSL) encryption suite, which secures online commerce.</para><para>But these systems target very specific needs: secure server access and secure online credit card transactions, respectively. Both are concerned with securing human-machine interactions. Much more cryptographic technology specifically targeted at human-to-human interactions needs to be deployed in the coming years to combat the advancing menace of ubiquitous surveillance (which "leads to a quick end to civilization"<footnote id="CHP-11-FNOTE-10"><para>Vernor Vinge, <emphasis>A Deepness in the Sky</emphasis>. Tor Books, 1999.</para></footnote>).</para><para>An easy-to-use, secure webmail system is an enabling technology—it makes possible, for the first time in history, secure and private long-distance communications between individuals all over the globe, who never need meet in person.</para></sect1><sect1 id="hacking_the_civilization" label="11.12"><title>Hacking the Civilization</title><para>This computer of such infinite and subtle complexity that it includes organic life itself in its operational matrix—the Earth, and the civilizations it hosts—can be reprogrammed in powerful ways by simple pieces of code that hack human culture right back, and rewire the operating system of society itself.<indexterm id="idx-CHP-11-0854" significance="normal"><primary>secure communications</primary><secondary>hacking the civilization</secondary></indexterm></para><para>Code has changed the world many times. Consider the medical advances made possible by genetic sequencing software, the impact of business software on large enterprises and small businesses alike, the revolutions enabled by industrial automation software and computer modeling, or the multiple revolutions of the Internet: email, the Web, blogs, social networking services, VoIP…. Clearly, much of the history of our times is the story of software innovation.</para><para>Of course, code, like any technology, can cut both ways, either increasing or decreasing the "returns to violence"<footnote id="CHP-11-FNOTE-11"><para>By "returns to violence," I refer to the social and economic incentives for violating individual rights. As the authors of <emphasis>The Sovereign Individual</emphasis> point out, "The key to understanding how societies evolve is to understand factors that determine the costs and rewards of employing violence."</para></footnote> in society, increasing the efficacy of privacy-violating technology and giving tyrants more effective tools of censorship, on the one hand, or enhancing and promoting individual rights on the other. Code of either sort hacks the very core of human society itself, by altering fundamental social realities such as the tenability of free speech.</para><para>Interestingly, even with a specific technology such as public key cryptography, the implementation chosen can significantly alter cultural realities. For example, a PKI-based implementation reimposes authoritarian properties such as centralized hierarchies and identification requirements on a technology whose entire value arguably lies in its lack of those properties. Despite this, PKI approaches deliver weaker key authentication than does a web-of-trust implementation (which also doesn't dilute other important features of public-key cryptography, such as distributed deployment).</para><para>I think that as the weavers of code, it is to a large extent the ethical responsibility of programmers to seek not only that our code be beautiful in its design and implementation, but also that it be beautiful in its results, in a larger social context. This is why I find freedom code so beautiful. It puts computing technology to the most sublime use: protecting human rights and human life.</para><para>Laws and international human rights treaties can go only so far in protecting individual rights. History has shown that these are far too easy to bypass or ignore. On the other hand, the mathematics of cryptosystems can, when implemented carefully, provide practically impenetrable shields for individual rights and open expression, and can finally set people across the world free to communicate and trade in privacy and liberty.</para><para>Actualizing this global, mathematically protected open society is largely up to us, the gods of the machine.<indexterm id="I_indexterm11_tt253" class="endofrange" startref="idx-CHP-11-0685" significance="normal"><primary>secure communications</primary></indexterm></para></sect1></chapter><chapter id="growing_beautiful_code_in_bioperl" label="12" role=""><title>Growing Beautiful Code in BioPerl</title><para><emphasis>Lincoln Stein</emphasis><indexterm id="idx-CHP-12-0855" significance="normal"><primary>Stein</primary></indexterm></para><para><emphasis>In the past decade, biology has blossomed into an information science</emphasis>. New technologies provide biologists with unprecedented windows into the intricate processes going on inside the cells of animals and plants. DNA sequencing machines allow the rapid readout of complete genome sequences; microarray technologies give snapshots of the complex patterns of gene expression in developing organisms; confocal microscopes produce 3-D movies to track changes in cell architecture as precancerous tissues turn malignant.</para><para>These new technologies routinely generate terabytes of data, all of which must be filtered, stored, manipulated and data-mined. The application of computer science and software engineering to the problems of biological data management is called <emphasis>bioinformatics</emphasis>.<indexterm id="idx-CHP-12-0856" significance="normal"><primary>bioinformatics</primary></indexterm></para><para>Bioinformatics is similar in many ways to software engineering on Wall Street. Like software engineers in the financial sector, bioinformaticians need to be fleet of foot: they have to get applications up and running quickly with little time for requirement analysis and design. Data sets are large and mutable, with shelf lives measured in months, not years. For this reason, most bioinformatics developers favor agile development techniques, such as eXtreme Programming, and toolkits that allow for rapid prototyping and deployment. As in the financial sector, there is also a strong emphasis on data visualization and pattern recognition.</para><sect1 id="bioperl_and_the_biographics_module" label="12.1"><title>BioPerl and the Bio::Graphics Module</title><para>One of the rapid development toolkits developed by and for bioinformaticians is BioPerl, an extensive open source library of reusable code for the Perl programming language. BioPerl provides modules to handle most common bioinformatics problems involving DNA and protein analysis, the construction and analysis of evolutionary trees, the interpretation of genetic data, and, of course, <indexterm id="idx-CHP-12-0857" significance="normal"><primary>genome</primary></indexterm>genome sequence analysis.<indexterm id="idx-CHP-12-0858" significance="normal"><primary>Perl</primary><secondary>BioPerl</secondary></indexterm><indexterm id="idx-CHP-12-0859" significance="normal"><primary>A</primary></indexterm><indexterm class="startofrange" id="idx-CHP-12-0860" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm></para><para>BioPerl allows a software engineer to rapidly create complex pipelines to process, filter, analyze, integrate, and visualize large biological datasets. Because of its extensive testing by the open source community, applications built on top of BioPerl are more likely to work right the first time, and because Perl interpreters are available for all major platforms, applications written with BioPerl will run on Microsoft Windows, Mac OS X, Linux, and Unix machines.</para><para>This chapter discusses Bio::Graphics, BioPerl's genome map rendering module. The problem it addresses is how to visualize a genome and its <indexterm id="idx-CHP-12-0861" significance="normal"><primary>annotation</primary></indexterm>annotations. A genome consists of a set of <indexterm id="idx-CHP-12-0862" significance="normal"><primary>DNA sequences</primary></indexterm>DNA sequences, each a string of the letters [A,G,C,T], which are <indexterm id="idx-CHP-12-0863" significance="normal"><primary>nucleotides (A</primary></indexterm>nucleotides, also known as <indexterm id="idx-CHP-12-0864" significance="normal"><primary>base pairs (bp)</primary></indexterm>base pairs, or <emphasis>bp</emphasis>. Some of the DNA sequence strings can be quite long: for example, the human genome consists of 24 DNA sequence strings, one each for chromosomes 1 through 22, plus the X and Y chromosomes. The longest of these, chromosome 1, is roughly 150,000,000 bp long (150 megabases).<indexterm id="idx-CHP-12-0865" significance="normal"><primary>bp (base pairs)</primary></indexterm></para><para>Hidden inside these DNA sequences are multiple regions that play roles in cell metabolism, reproduction, defense, and signaling. For example, some sections of the chromosome 1 DNA sequence are <indexterm id="idx-CHP-12-0866" significance="normal"><primary>protein-coding genes</primary></indexterm>protein-coding genes. These genes are "transcribed" by the cell into shorter <indexterm id="idx-CHP-12-0867" significance="normal"><primary>RNA sequences</primary></indexterm>RNA sequences that are transported from the cell nucleus into the cytoplasm; these RNA sequences are then translated into proteins responsible for generating energy, moving nutrients into and out of the cell, making the cell membrane, and so on. Other regions of the DNA sequence are <indexterm id="idx-CHP-12-0868" significance="normal"><primary>regulatory DNA</primary></indexterm>regulatory in nature: when a regulatory protein binds to a specific regulatory site, a nearby protein-coding gene is "turned on" and starts to be transcribed. Some regions correspond to parasitic DNA: short regions of sequence that can replicate themselves semiautonomously and hitchhike around on the genome. Still other regions are of unknown significance; we can tell that they're important because they have been conserved among humans and other organisms across long evolutionary intervals, but we don't yet understand what they do.</para><para>Finding and interpreting functionally significant regions of the genome is called <emphasis>annotation</emphasis> and is now the major focus of the genome project. The annotation of a genome typically generates far more data than the raw DNA sequence itself. The whole <indexterm id="idx-CHP-12-0869" significance="normal"><primary>human genome sequence</primary></indexterm>human genome sequence occupies just three gigabytes uncompressed, but its current annotation uses many terabytes (also see <xref linkend="the_design_of_the_gene_sorte"/>).</para><sect2 id="example_of_biographics_output" label="12.1.1"><title>Example of Bio::Graphics Output</title><para>To home in on "interesting" regions of the genome, biologists need to visualize how multiple annotations relate to each other. For example, a putative regulatory region is more likely to be functionally significant if it is spatially close to a protein-coding gene and overlaps with a region that is conserved between evolutionarily distant species.<indexterm id="idx-CHP-12-0870" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>examples of output</secondary></indexterm><indexterm id="idx-CHP-12-0871" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm></para><para>Bio::Graphics allows bioinformatics software developers to rapidly visualize a genome and all its annotations. It can be used in a standalone fashion to generate a static image of a region in a variety of graphics formats (including PNG, JPEG, and SVG), or incorporated into a web or desktop application to provide interactive scrolling, zooming, and data exploration.</para><para><xref linkend="a_sample_image_generated_by_biographics"/> gives an example of an image generated by Bio::Graphics. This image shows a region of the genome of <emphasis>C. elegans</emphasis> (a small soil-dwelling worm) that illustrates several aspects of a <indexterm id="idx-CHP-12-0872" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>examples of output</secondary><tertiary>typical image</tertiary></indexterm>typical image generated by Bio::Graphics. The image is divided vertically into a series of horizontal tracks. The top track consists of a scale that runs horizontally from left to right. The units are in kilobases ("k"), indicating thousands of DNA bases. The region shown begins at just before position 160,000 of the <emphasis>C. elegans</emphasis> chromosome I, and extends to just after position 179,000, covering 20,000 base pairs in toto. There are four annotation tracks, each of which illustrates increasingly complex visualizations.<indexterm id="idx-CHP-12-0873" significance="normal"><primary>C. elegans genome</primary></indexterm></para><figure id="a_sample_image_generated_by_biographics" label="12-1" float="0"><title>A sample image generated by Bio::Graphics</title><mediaobject id="I_mediaobject12_tt254"><imageobject role="print"><imagedata fileref="figs/print/beauty_1201.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1201.png" format="PNG"/></imageobject></mediaobject></figure><para>The original image is brightly colored, but has been reduced to grayscale here for printing. The simplest track is "cDNA for RNAi," which shows the positions of a type of experimental reagent that the research community has created for studying the regulation of <emphasis>C. elegans</emphasis> genes. The image contains a single annotation on the right named <emphasis>yk247c7</emphasis>. It consists of a black rectangle that begins at roughly position 173,500 and extends to roughly 176,000. It corresponds to a physical piece of DNA covering this region, which a researcher can order from a biotech supply company and use experimentally to change the activity of the gene that overlaps it—in this case, F56C11.6.</para><para>The "WABA alignments" track shows slightly more complex information. It visualizes quantitative data arising from comparing this part of the <emphasis>C. elegans</emphasis> genome to similar regions in a different worm. Regions that are highly similar are dark gray. Regions that are weakly similar are light gray. Regions of intermediate similarity are medium gray.</para><para>The "DNA/GC Content" track shows continuously variable quantitative information. This records the ratio of G and C nucleotides to A and T nucleotides across a sliding window of the nucleotide sequence. This ratio correlates roughly with the chances that the corresponding region of the genome contains a protein-coding gene.</para><para>The "Genes" track contains the most complex data: the positions of two protein-coding genes. Each gene has an internal structure that indicates which parts encode protein (dark gray, but blue in the original) and which have other functions (lighter gray). Notice how the coding of the leftmost gene (F56C11.2) corresponds pretty well to the dark-gray, highly similar regions in the WABA alignment track; this is because the protein-coding regions of genes tend to be very strongly conserved across species.</para><para>The gene named F56C11.6 is annotated with a function ("carboxylesterases"), indicating that it is related to a family of proteins responsible for a core part of carbon metabolism. In addition, it is shown with two alternative forms, indicating that it can encode more than one distinct protein. The two alternative forms are grouped together and given a distinct label. Notice that there are numerous alignments beneath this gene; this is a reflection that the gene belongs to a large family of related genes, and each related gene contributes to a different alignment.</para><para>The actual DNA nucleotide sequence is not shown in this representation because it isn't physically possible to squeeze a line of 20,000 base pairs into 800 pixels. However, when viewing smaller segments of a genome, <indexterm id="idx-CHP-12-0874" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics can draw in the actual letters and ornament them (e.g., change their color or highlighting) to show the start and stop positions of interesting <indexterm id="idx-CHP-12-0875" significance="normal"><primary>features (genomic)</primary></indexterm>features.</para></sect2><sect2 id="biographics_requirements" label="12.1.2"><title>Bio::Graphics Requirements</title><para>The job of Bio::Graphics is to take a series of genome annotations (called <emphasis>features</emphasis> in <indexterm id="idx-CHP-12-0876" significance="normal"><primary>Perl</primary><secondary>BioPerl</secondary></indexterm>BioPerl parlance) and output a graphics file formatted according to the programmer's specifications. Each feature has a <indexterm id="idx-CHP-12-0877" significance="normal"><primary>start position (genomic features)</primary></indexterm>start position, an <indexterm id="idx-CHP-12-0878" significance="normal"><primary>end position (genomic features)</primary></indexterm>end position, and a <indexterm id="idx-CHP-12-0879" significance="normal"><primary>direction (genomic features)</primary></indexterm>direction (pointing left, pointing right, or not pointing in either direction). Features may be associated with other attributes such as a name, a description, and a numeric value. Features may also have an internal structure and contain <indexterm id="idx-CHP-12-0880" significance="normal"><primary>subfeatures and sub-subfeatures (genomic features)</primary></indexterm>subfeatures and sub-subfeatures.</para><para>When <indexterm id="idx-CHP-12-0881" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design requirements</secondary></indexterm>designing this library, I had to address the following issues:</para><variablelist><varlistentry><term><emphasis>Open-ended nature of the problem</emphasis></term><listitem><para>There are already a <indexterm id="idx-CHP-12-0882" significance="normal"><primary>annotation</primary><secondary>large number of genome annotation types</secondary></indexterm>large number of genome annotation types, and the number is growing daily. While many annotations can be drawn with simple rectangles of different colors, many of them—particularly the quantitative ones—can be quite complex to represent. Furthermore, different bioinformaticians may want to represent the same annotation type differently; <indexterm id="idx-CHP-12-0883" significance="normal"><primary>collision control</primary><secondary>for overlapping genomic features</secondary></indexterm>for example, there are many different ways of representing genes, each best suited for different circumstances.</para><para>In order to accommodate the open-ended nature of this problem, I wanted to make it easy to add new visual representations to <indexterm id="idx-CHP-12-0884" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics and to extend existing ones. Each representation should be highly configurable; for example, the programmer should be able to exercise exquisite control over the height, weight, boundary color, and fill color of even the simple rectangle. Furthermore, the programmer should be able to alter how each feature is rendered on a case-by-case basis.</para></listitem></varlistentry><varlistentry><term><emphasis>Feature density</emphasis></term><listitem><para>Some genomic features are very dense, whereas others are more sparse (compare the "Genes" and "WABA alignments" tracks in <xref linkend="a_sample_image_generated_by_biographics"/>). Features can also overlap spatially. Sometimes you want overlapping features to partially obscure each other, and sometimes you'd like to practice collision control, shifting the overlapping features up or down vertically to make them distinct. To add to the problem, features can contain subfeatures that themselves overlap, so collision control and spatial layout need to work in a recursive fashion.<indexterm id="idx-CHP-12-0885" significance="normal"><primary>features (genomic)</primary><secondary>density of</secondary></indexterm></para><para>I thought it would be good if collision control could be activated and deactivated in a context-dependent manner. For example, if there are thousands of overlapping features in the region being displayed, collision control might cause a track to become unmanageably busy and should be turned off. The programmer should be able to control at what point this context-sensitive collision control kicks in, or override it entirely.</para></listitem></varlistentry><varlistentry><term><emphasis>Handling scale</emphasis></term><listitem><para>I wanted Bio::Graphics to be able to draw pictures of a highly detailed 500 bp region of the genome, as well as a whole-genome view spanning 150 million nucleotides. To do this, the visual representation of features needs to change intelligently according to the current scale. At a scale of 500 bp, you can show the internal structure of a gene. At a scale of 1,000,000 bp, you can show only the start and end positions of the gene. At a scale of 100,000,000 bp, genes merge into a single black bar, and you should shift to a representation that shows the gene density as an intensity grayscale.<indexterm id="idx-CHP-12-0886" significance="normal"><primary>base pairs (bp)</primary><secondary>handling scale in genomic feature representation</secondary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Useful for interactive web applications</emphasis></term><listitem><para>I wanted Bio::Graphics to be suitable for the backend of an interactive web-based genome browser. In particular, I wanted end users to be able to click on the graphical renditions of features in order to bring up pull-down menus, link to other web pages, view tool tips, and so on. To accomplish this, Bio::Graphics had to be relatively fast so as to generate images in real time. It also had to keep track of the positions of each of its rendered features (and, if necessary, their subfeatures) in order to create an image map that could be passed back to the programmer.<indexterm id="idx-CHP-12-0887" significance="normal"><primary>interactive web applications</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Independence from graphic formats</emphasis></term><listitem><para>I wanted Bio::Graphics to be useful for generating screen-quality, low-resolution images suitable for embedding in a web page, as well as for generating high-resolution, publication-quality images. To do this, the part of Bio::Graphics that handled the logic of the layout had to be separate from the part that generated graphics. Ideally, it should be able to output both pixmap and vector graphics formats.<indexterm id="idx-CHP-12-0888" significance="normal"><primary>graphic formats</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Independence from database schemes</emphasis></term><listitem><para>The bioinformatics community has designed many dozens of database formats for managing genome annotation data, ranging from simple flat files to sophisticated relational databases. For maximum utility, I wanted to avoid tying <indexterm id="idx-CHP-12-0889" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics to any specific database scheme. It should be just as easy to invoke Bio::Graphics to render a genome region described by a flat file as to have it render a segment of a genome described in an Oracle database.<indexterm id="idx-CHP-12-0890" significance="normal"><primary>database schemes</primary></indexterm></para></listitem></varlistentry></variablelist></sect2></sect1><sect1 id="the_biographics_design_process" label="12.2"><title>The Bio::Graphics Design Process</title><para>I'm not enamored of formal design engineering; instead, I typically write out little snippets of pseudocode that describe how I want something to work (a "code story"), play a bit with input and output formats, do a bit of coding, and—if I'm not satisfied with how the system is fitting together—go back and rework the code story. For anything larger than a toy application, I implement little bits of the system and test them out in standalone programs before deciding whether to move forward with that part of the design. I keep my notes in a "stream of consciousness" text file, and commit code to my CVS repository often. I try to make all the code visually appealing and elegant. If it isn't elegant, something's wrong with the design, and I go back to the drawing board.<indexterm class="startofrange" id="idx-CHP-12-0891" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm></para><sect2 id="designing_how_the_developer_interacts_with_the_module" label="12.2.1"><title>Designing How the Developer Interacts with the Module</title><para>My first design task was to figure out the flow of a typical Bio::Graphics application. I started with the code story shown in <indexterm id="idx-CHP-12-0892" significance="normal"><primary>Perl</primary><secondary>BioPerl</secondary></indexterm><xref linkend="basic_story_for_bioperlgraphics_use_pseudocode"/>.<indexterm id="idx-CHP-12-0893" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>developer interaction with the module</tertiary></indexterm></para><example id="basic_story_for_bioperlgraphics_use_pseudocode" label="12-1"><title>Basic story for BioPerl::Graphics use (pseudocode)</title><programlisting format="linespecific">
1 use <indexterm id="idx-CHP-12-0894" significance="normal"><primary>Bio::Graphics::Panel class</primary></indexterm>Bio::Graphics::Panel;

2 @first_set_of_features  = get_features_somehow( );
3 @second_set_of_features = get_more_features_somehow( );

4 $panel_<indexterm id="idx-CHP-12-0895" significance="normal"><primary>object classes (Bio::Graphics)</primary></indexterm>object = Bio::Graphics::Panel-&gt;new(panel_options...)
5 $panel_object-&gt;add_track(\@first_set_of_features,
                           track_options...);
6 $panel_object-&gt;add_track(\@second_set_of_features,
                          track_options...);

7 print $panel_object-&gt;png;
</programlisting></example><para>The code story starts out by bringing in the main Bio::Graphics object class, Bio::Graphics:: Panel (line 1). This object, I reasoned, would hold configuration options for the image as a whole, such as the dimensions of the resulting diagram and its scale (base pairs per pixel), and would be the main object that users interact with.</para><para>The code story continues with two calls to fetch arrays of sequence features (lines 2–3). In order to maintain independence from feature databases, I decided that <indexterm id="idx-CHP-12-0896" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics would operate on lists of features that had already been retrieved from a database. Fortunately, BioPerl already supported a variety of <indexterm id="idx-CHP-12-0897" significance="normal"><primary>BioPerl</primary><secondary>annotation databases</secondary></indexterm>annotation databases via a nicely generic interface. A sequence feature is represented by an interface called Bio::SeqFeatureI, which specifies a set of methods that all sequence features should support. The methods are mostly straightforward; for example, <replaceable>$feature-&gt;</replaceable><literal moreinfo="none">start()</literal> gets the starting position of the feature, <replaceable>$feature-&gt;</replaceable><literal moreinfo="none">end()</literal> gets its end position, and <replaceable>$feature-&gt;</replaceable><literal moreinfo="none">get_SeqFeatures()</literal> gets its sub-features. To retrieve features from a database, BioPerl has an interface called Bio::Seq-Feature::CollectionI, which provides a standard API for retrieving features sequentially or randomly via queries.</para><para>The code story then calls <literal moreinfo="none">Bio::Graphics::Panel-&gt;new()</literal> (line 4), creating a new panel object, and calls <literal moreinfo="none">add_track()</literal> twice (line 5–6). This adds two <indexterm class="startofrange" id="idx-CHP-12-0898" significance="normal"><primary>tracks (Bio::Graphics module)</primary></indexterm>tracks, one each for the first and second sets of features. Each call to <literal moreinfo="none">add_track()</literal> takes an initial argument consisting of a reference to the array of features to add, followed by additional arguments controlling the appearance of the track.</para><para>The last step in the code story is to convert the panel into a PNG file and immediately print the result to standard output.</para><para>Initially this looked like a reasonable story, but as I thought about it further, I realized there were some basic deficiencies in the API. The biggest problem was that it forces the programmer to load all features into memory before beginning to construct the image. However, it is often convenient to read sequence features one at a time from a file or database. Several of the implementations of <indexterm id="idx-CHP-12-0899" significance="normal"><primary>Bio::SeqFeature::CollectionI interface</primary></indexterm>Bio::SeqFeature::CollectionI allow you to do this:</para><programlisting id="I_programlisting12_tt255" format="linespecific">
	$iterator = Bio::SeqFeature::CollectionI-&gt;get_seq_stream(@query_parameters);
	while ($feature = $iterator-&gt;next_seq) {
	    # do something with the feature
	}
</programlisting><para>Another problem was that once you called <literal moreinfo="none">$panel-&gt;add_track()</literal>, you couldn't change the track's configuration settings. However, I could envision situations in which a <indexterm id="idx-CHP-12-0900" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>developer interaction with the module</tertiary></indexterm>developer would want to add a bunch of tracks in advance, and then go back and change an earlier track configuration later.</para><para>Finally, it seemed to me that <literal moreinfo="none">add_track()</literal> was too inflexible, in that it forced the developer to add the tracks in a fixed order (top to bottom). However, there should be a way to insert tracks at arbitrary positions.</para><para>These considerations mandated the creation of a Track object:</para><programlisting id="I_programlisting12_tt256" format="linespecific">
	$track1 = $panel_object-&gt;add_track(\@set_of_gene_features,
	                                       track_options..);
	$track2 = $panel_object-&gt;add_track(\@set_of_variation_features,
	                                      track_options...);
</programlisting><para>One could then add features to an existing track like this:</para><programlisting id="I_programlisting12_tt257" format="linespecific">
	$track1-&gt;add_features(feature1,feature2,feature3....)
</programlisting><para>or change its configuration this way:</para><programlisting id="I_programlisting12_tt258" format="linespecific">
	$track1-&gt;configure(new_options)
</programlisting><para>This led to the alternative code story shown in <xref linkend="basic_story_for_bioperlgraphics_use_pseudocode"/>.</para><example id="story_for_bioperlgraphics_use_with_tracks_pseudocode" label="12-2"><title>Story for BioPerl::Graphics use with tracks (pseudocode)</title><programlisting format="linespecific">
1 use <indexterm id="idx-CHP-12-0901" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics::Panel;

2 $panel_object = Bio::Graphics::Panel-&gt;new(panel_options...)
3 $track1 = $panel_object-&gt;add_track(bump_true,other_track_options...);
4 $track2 = $panel_object-&gt;add_track(bump_true,other_track_options...);

5 $collection = Bio::SeqFeature::CollectionI-&gt;new(@args);
6 $iterator   = $collection-&gt;get_seq_stream(@query_parameters);

7 $genes=0; $variations=0;
8 while ($feature = $iterator-&gt;next_seq) {

9     if ($feature-&gt;method eq 'gene') {
10         $track1-&gt;add_feature($feature);
11         $genes++;

12     } elsif ($feature-&gt;method eq 'variation') {
13         $track2-&gt;add_feature($feature);
14         $variations++;
15     }
16 }

17 $track1-&gt;configure(bump_false) if $genes      &gt; 100;
18 $track2-&gt;configure(bump_false) if $variations &gt; 100;

19 print $panel_object-&gt;png;
</programlisting></example><para>In this version of the story, we first create two tracks without providing any features up front (lines 3–4). We do, however, provide <literal moreinfo="none">add_track()</literal> with a set of options, including a "bump" option that is initially set to true. When <indexterm id="idx-CHP-12-0902" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>designing this story, I posited that a bump option of true would activate collision control, while a bump option of false would turn collision control off.</para><para>We then create a feature collection object using BioPerl; ordinarily this will be connected to a database of some sort and initiate a query (lines 5–6), returning an iterator across the results. We then call <literal moreinfo="none">$iterator-&gt;next_seq</literal> repeatedly to return all features that satisify the query (lines 8–16). For each returned feature, we interrogate its type using a method from Bio::SeqFeatureI called <literal moreinfo="none">method</literal>. If the feature is of type <literal moreinfo="none">gene</literal>, we add it to <literal moreinfo="none">track1</literal> and bump up a counter for genes. If the feature is of type <literal moreinfo="none">variation</literal>, we add it to <literal moreinfo="none">track2</literal> and bump up a different counter.</para><para>After all features are added, we interrogate the number of genes and variations added. If the total number of either feature exceeds 100, we call the corresponding track's <literal moreinfo="none">configure()</literal> method in order to set the bump option to false (17–18). What this achieves is to turn on collision control <indexterm id="idx-CHP-12-0903" significance="normal"><primary>collision control</primary><secondary>for tracks in Bio::Graphics module</secondary></indexterm>for <indexterm id="idx-CHP-12-0904" significance="normal"><primary>tracks (Bio::Graphics module)</primary></indexterm>tracks that contain a manageable number of features, so that overlapping features are moved up and down to avoid covering each other. Tracks with a large number of features, where collision control might create unreasonably tall tracks, have bumping set to false, so that overlapping features can be superimposed.</para><sidebar id="reading_the_code_in_this_chapter" role="missingmanual"><title>READING THE CODE IN THIS CHAPTER</title><para><indexterm id="idx-CHP-12-0905" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics and BioPerl are written in Perl, a language which is deceptively similar to C or Java, but has many cryptic idiosyncrasies. If you don't know Perl, don't sweat it. Just read through the code examples to get a general sense of the logic of the <indexterm id="idx-CHP-12-0906" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>design. To help you understand what's going on, here's a quick <indexterm id="idx-CHP-12-0907" significance="normal"><primary>Perl</primary><secondary>summary of quirkier parts of syntax</secondary></indexterm>summary of the quirkier parts of Perl syntax:</para><variablelist><varlistentry><term><replaceable>$variable_name</replaceable></term><listitem><para>A variable name that starts with a dollar sign ($) is a scalar variable. It holds a single-valued string or number.</para></listitem></varlistentry><varlistentry><term><replaceable>@variable_name</replaceable></term><listitem><para>A variable name that starts with an at-sign (@) is an ordered array. It holds multiple strings or numbers, indexed by their numeric position in the array. When addressing a member of the array, one places the index in square brackets:<indexterm id="idx-CHP-12-0908" significance="normal"><primary>@ (at-sign) in Perl variable names</primary></indexterm></para><programlisting id="I_programlisting12_tt259" format="linespecific">
	$foo[3] = 'element three';
</programlisting><para>There's a $ in front of the variable name because the individual element is scalar.</para><para>Within subroutine and method definitions, a special array named @_ holds the list of arguments passed to the subroutine.</para></listitem></varlistentry><varlistentry><term><replaceable>%variable_name</replaceable></term><listitem><para>A variable name that starts with a percent sign (%) is an <indexterm id="idx-CHP-12-0909" significance="normal"><primary>unordered hash (Perl)</primary></indexterm>unordered hash. It holds multiple strings or numbers (the hash <emphasis>values</emphasis>) indexed by strings (the hash <emphasis>keys</emphasis>). When assigning a list of key/value pairs to a hash, one uses this notation:<indexterm id="idx-CHP-12-0910" significance="normal"><primary>% (percent sign)</primary></indexterm></para><programlisting id="I_programlisting12_tt260" format="linespecific">
	%clade = (monkey=&gt;'mammal',
	          frog=&gt;'amphibian',
	          gazelle=&gt;'mammal');
</programlisting><para>When addressing a member of the hash, one places the key in curly braces:</para><programlisting id="I_programlisting12_tt261" format="linespecific">
	print "The clade of a monkey is ", $clade{monkey};
</programlisting></listitem></varlistentry><varlistentry><term><replaceable>$object-&gt;method('arg1','arg2','arg3')</replaceable></term><listitem><para>The -&gt; arrow indicates an object-oriented <indexterm id="idx-CHP-12-0911" significance="normal"><primary>object-oriented programming</primary><secondary>method call in Perl</secondary></indexterm>method call. The object is stored in the scalar variable <replaceable>$object</replaceable>. The method call takes zero or more arguments.<indexterm id="idx-CHP-12-0912" significance="normal"><primary sortas="&gt; (arrow)">-&gt; (arrow)</primary></indexterm></para><para>If there are no arguments, the parentheses can be omitted, which looks weird to C and Java folk:</para><programlisting id="I_programlisting12_tt262" format="linespecific">
	<replaceable>$object-&gt;method;</replaceable>
</programlisting><para>Within the definition of a method, the object is usually stored in a scalar named <literal moreinfo="none">$self</literal>, although this is a matter of coding style.<indexterm id="I_indexterm12_tt263" class="endofrange" startref="idx-CHP-12-0898" significance="normal"><primary>tracks (Bio::Graphics module)</primary></indexterm></para></listitem></varlistentry></variablelist></sidebar></sect2><sect2 id="setting_options" label="12.2.2"><title>Setting Options</title><para>Up to this point I hadn't figured out how options would be set. I decided that for consistency with the BioPerl coding style, options should be passed as tag/value pairs in the format <replaceable>-option_name=&gt;option_value</replaceable>. For example, the following method call would create a track with feature drawings 10 pixels high, a background color of blue, and collision control <literal moreinfo="none">(bump)</literal> turned on:<indexterm id="idx-CHP-12-0913" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>options, setting</tertiary></indexterm></para><programlisting id="I_programlisting12_tt264" format="linespecific">
	$track1 = $panel_object&gt;add_track(\@features,
	                                  -height    =&gt; 10,
	                                  -bgcolor   =&gt; 'blue',
	                                  -bump      =&gt; 1);
</programlisting><para>Later on, one would be able to change any of these options by calling <literal moreinfo="none">configure()</literal>. This example turns off collision control:</para><programlisting id="I_programlisting12_tt265" format="linespecific">
	$track1&gt;configure(-bump =&gt; 0);
</programlisting><para>Eventually, I extended the power of track <indexterm id="idx-CHP-12-0914" significance="normal"><primary>tracks (Bio::Graphics module)</primary><secondary>configuration options</secondary></indexterm>configuration options by making it possible to use code references (a type of callback) as option values, but the first iteration of the <indexterm id="idx-CHP-12-0915" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>module did not have this feature. I'll discuss it later in this chapter.</para><para>What configuration options should the track object support? I quickly came up with a small number of standard track options, the most important of which was <literal moreinfo="none">glyph</literal>:</para><programlisting id="I_programlisting12_tt266" format="linespecific">
	-glyph =&gt; 'glyph_type'
</programlisting><para>As described earlier, I wanted to be able to support a wide range of visual representations for features. The <literal moreinfo="none">-glyph</literal> option was the end developer's way of accessing this range of representations. For example <literal moreinfo="none">-glyph=&gt;'box'</literal> should render features as simple rectangles, <literal moreinfo="none">-glyph=&gt;'oval'</literal> should render features as appropriately sized ovals, and <literal moreinfo="none">-glyph=&gt;'arrow'</literal> should draw arrows.</para><para>In addition to <literal moreinfo="none">-glyph</literal>, other options included in the original <indexterm id="idx-CHP-12-0916" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>design were:</para><variablelist><varlistentry><term><literal moreinfo="none">-fgcolor</literal></term><listitem><para>Foreground (line) color of features rendered in the track</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">-bgcolor</literal></term><listitem><para>Background (fill) color of features rendered in the track</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">-bump</literal></term><listitem><para>Whether to turn on collision control</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">-label</literal></term><listitem><para>Whether to print each feature's name above it</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">-description</literal></term><listitem><para>Whether to print each feature's description below it</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">-height</literal></term><listitem><para>The height of each feature</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">-key</literal></term><listitem><para>A label for the track as a whole</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">-tkcolor</literal></term><listitem><para>Background color for the track</para></listitem></varlistentry></variablelist><para>I was aware that fancy glyphs might have special-purpose <indexterm id="idx-CHP-12-0917" significance="normal"><primary>Bio::Graphics::Panel class</primary><secondary>configuration options</secondary></indexterm>options that the simple ones wouldn't, so I had to <indexterm id="idx-CHP-12-0918" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>design the code library in such a way that the list of <indexterm id="idx-CHP-12-0919" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>options, setting</tertiary></indexterm>options passed to <literal moreinfo="none">add_track()</literal> was extensible.</para><para>The Panel also needed to take options for such things as the desired image width and the conversion scale between pixels and base pairs. I made up a small number of panelspecific options that included:</para><variablelist><varlistentry><term><literal moreinfo="none">-width</literal></term><listitem><para>Width of the image, in pixels</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">-length</literal></term><listitem><para>Length of the sequence segment, in base pairs</para></listitem></varlistentry></variablelist><para>I could now flesh out the code story to show the specifics of each of the <indexterm id="idx-CHP-12-0920" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics calls, as shown in <xref linkend="detailed_story_for_bioperlgraphics_use_pseudocode"/>.</para><example id="detailed_story_for_bioperlgraphics_use_pseudocode" label="12-3"><title>Detailed story for BioPerl::Graphics use (pseudocode)</title><programlisting format="linespecific">
1 use Bio::Graphics::Panel;

2 $panel_object = Bio::Graphics::Panel&gt;new(-width  =&gt; 800,
                                           -length =&gt; 50000);
3 $track1 = $panel_object-&gt;add_track(-glyph  =&gt; 'box',
                                     -height =&gt; 12,
                                     -bump   =&gt; 1,
                                     -key    =&gt; 'Protein-coding Genes');

4 $track2 = $panel_object-&gt;add_track(-glyph  =&gt; 'triangle',
                                     -height =&gt; 6,
                                     -bump   =&gt; 1,
                                     -key    =&gt; 'Sequence Variants');

5 $collection = Bio::SeqFeature::CollectionI-&gt;new(@args);
6 $iterator   = $collection-&gt;get_seq_stream(@query_parameters);

7 $genes=0; $variations=0;
8 while ($feature = $iterator-&gt;next_seq) {

9     if ($feature-&gt;method eq 'gene') {
10         $track1-&gt;add_feature($feature);
11         $genes++;

12     } elsif ($feature-&gt;method eq 'variation') {
13         $track2-&gt;add_feature($feature);
14         $variations++;
15     }
16 }
17 $track1-&gt;configure(-bump =&gt; 0) if $genes      &gt; 100;
18 $track2-&gt;configure(-bump =&gt; 0) if $variations &gt; 100;

19 print $panel_object-&gt;png;
</programlisting></example></sect2><sect2 id="choosing_object_classes" label="12.2.3"><title>Choosing Object Classes</title><para>The last major <indexterm id="idx-CHP-12-0921" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>design task was selecting the main object classes that the developer would interact with. From the code story, it first seemed that there were two main classes:<indexterm id="idx-CHP-12-0922" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>object classes</tertiary></indexterm><indexterm class="startofrange" id="idx-CHP-12-0923" significance="normal"><primary>object classes (Bio::Graphics)</primary><secondary>choosing</secondary></indexterm></para><variablelist><varlistentry><term><emphasis>Bio::Graphics::Panel</emphasis></term><listitem><para>Objects of this class would represent the entire diagram and would typically be divided into a series of horizontal tracks. <indexterm id="idx-CHP-12-0924" significance="normal"><primary>Bio::Graphics::Panel class</primary></indexterm>Bio::Graphics::Panel would be responsible for positioning each track in its drawing area and for converting feature coordinates (expressed in base pairs) into glyph coordinates (expressed in pixels).<indexterm id="idx-CHP-12-0925" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Bio::Graphics::Track</emphasis></term><listitem><para>Objects of this class would represent the tracks that make up the panel. Tracks would primarily be responsible for positioning and drawing glyphs.<indexterm id="idx-CHP-12-0926" significance="normal"><primary>Bio::Graphics::Track class</primary></indexterm></para></listitem></varlistentry></variablelist><para>What about glyphs? It seemed natural to me that glyphs should be objects and should contain the internal logic for drawing themselves. All glyphs should inherit from a generic <indexterm class="startofrange" id="idx-CHP-12-0927" significance="normal"><primary>Bio::Graphics::Glyph class</primary></indexterm>Bio::Graphics::Glyph object that knew how to do basic drawing. As one called the Track object's <literal moreinfo="none">add_feature()</literal> method, it would create new glyphs by calling the Glyph constructor like this:</para><programlisting id="I_programlisting12_tt267" format="linespecific">
	$glyph = Bio::Graphics::Glyph-&gt;new(-feature=&gt;$feature);
</programlisting><para>Then, when the Track needed to draw itself, it would have a <literal moreinfo="none">draw()</literal> method similar to this:</para><programlisting id="I_programlisting12_tt268" format="linespecific">
	sub draw {
	  @glyphs = $self-&gt;get_list_of_glyphs( );

	  for $glyph (@glyphs) {
	      $glyph-&gt;draw;
	  }

	  # draw other stuff in the track, for example, its label
	}
</programlisting><para>This subroutine starts by fetching a list of the Glyph objects that we created during <literal moreinfo="none">add_feature()</literal>. It then invokes each glyph's <literal moreinfo="none">draw()</literal> method to have it draw itself. Finally, it draws stuff specific to the track, such as the track label.</para><para>As I thought more about Bio::Graphics::Glyph, I realized that they had to embody a bit of cleverness. Recall that a sequence feature can have an internal structure with subfeatures, sub-subfeatures, and so forth, and that each of the components of the internal structure needs to be laid out using collision control, and then drawn according to user preferences. This layout and draw behavior is very glyph-like, and so it seemed to make sense to let glyphs contain subglyphs in parallel to the feature/subfeature structure. The Glyph <literal moreinfo="none">new()</literal> routine would look something like this:</para><programlisting id="I_programlisting12_tt269" format="linespecific">
	sub new {
	  $self = shift; # get self
	  $feature = shift; # get feature
	  for $subfeature ($feature-&gt;get_SeqFeatures) {
	      $subglyph = <indexterm id="idx-CHP-12-0928" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics::Glyph-&gt;new(-feature=&gt;$subfeature);
	      $self-&gt;add_subpart($subglyph);
	  }
	}
</programlisting><para>For each of the feature's subfeatures we create a new subglyph, and add the subglyph to an internal list. Because we call <literal moreinfo="none">new()</literal> recursively, if a subfeature has subfeatures itself, it creates another level of nested glyphs.</para><para>To draw itself and all its subglyphs, a top-level glyph's drawing routine would look something like this:</para><programlisting id="I_programlisting12_tt270" format="linespecific">
	sub draw {
	  @subglyphs = $self-&gt;get_subparts( )

	  for $subglyph (@subglyphs) {
	     $subglyph-&gt;draw;
	  }

	  # draw ourself somehow
	}
</programlisting><para>This bit of pseudocode calls <literal moreinfo="none">get_subparts()</literal> to get all the subglyphs created by our constructor. It loops through each subglyph and calls its <literal moreinfo="none">draw()</literal> methods. The code then does its own drawing.</para><para>At this point, I was struck by the fact that the Glyph <literal moreinfo="none">draw()</literal> pseudocode routine was essentially identical to the Track <literal moreinfo="none">draw()</literal> method shown earlier. I realized that I could unify the two classes by simply arranging for <literal moreinfo="none">add_track()</literal> to create and manage a single internal feature <indexterm id="idx-CHP-12-0929" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>object classes</tertiary></indexterm>object associated with the track. Subsequent calls to <literal moreinfo="none">add_feature()</literal> would in fact add subfeatures to the feature.</para><para>I fooled around with some test code and found out that this worked quite well. In addition to the benefits of removing redundant drawing code, I was able to consolidate all the code dealing with passing and configuring track and glyph options. So, tracks became a <indexterm id="idx-CHP-12-0930" significance="normal"><primary>tracks (Bio::Graphics module)</primary><secondary>subclass of Glyph</secondary></indexterm>subclass of <literal moreinfo="none">Bio::Graphics::Glyph</literal> named <literal moreinfo="none">Bio::Graphics::Glyph::track</literal>, and the Panel's <literal moreinfo="none">add_track()</literal> method ended up looking like this (simplified somewhat):<indexterm id="idx-CHP-12-0931" significance="normal"><primary>Bio::Graphics::Glyph class</primary></indexterm></para><programlisting id="I_programlisting12_tt271" format="linespecific">
	sub add_track {
	   my $self = shift;
	   my $features = shift;
	   my @options = @_;
	   my $top_level_feature = Bio::Graphics::Feature-&gt;new(-type=&gt;'track');
	   my $track_glyph =
	        Bio::Graphics::Glyph::track-&gt;new(\@options);

	   if ($features) {
	      $track_glyph-&gt;add_feature($_) foreach @$features;
	   }

	   $self-&gt;do_add_track($track_glyph);
	   return $track_glyph;
	}
</programlisting><para>To accommodate the very first code story, in which the caller passes a list of features to <literal moreinfo="none">add_track()</literal>, I allow the first argument to be a list of features. In the actual code, I do runtime type checking on the first argument to distinguish a list of features from the first option. This allows the caller to call <literal moreinfo="none">add_track()</literal> either using the style from the first code story:</para><programlisting id="I_programlisting12_tt272" format="linespecific">
	$panel-&gt;add_track(\@list_of_features,@options)
</programlisting><para>or using the style from the second code story:</para><programlisting id="I_programlisting12_tt273" format="linespecific">
	$panel-&gt;add_track(@options)
</programlisting><para><literal moreinfo="none">add_track()</literal> then creates a new feature of type <literal moreinfo="none">track</literal> using a lightweight feature class that I wrote for <indexterm id="idx-CHP-12-0932" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics (this was necessary for performance reasons; the standard BioPerl feature <indexterm id="idx-CHP-12-0933" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>object classes</tertiary></indexterm>objects are memory- and performance-intensive). This class is passed to the constructor for <literal moreinfo="none">Bio::Graphics::Glyph::track</literal>.<indexterm id="idx-CHP-12-0934" significance="normal"><primary>Bio::Graphics::Glyph class</primary></indexterm></para><para>If the list of features was provided, the method loops through the list and calls the track glyph's <literal moreinfo="none">add_feature()</literal> method.</para><para>Lastly, the <literal moreinfo="none">add_track()</literal> method adds the track to an internal list of tracks that have been added to the panel and returns the track glyph to the caller.</para><para>The track's <literal moreinfo="none">add_feature()</literal> method is used to create subglyphs contained within the track. It is called either by the glyph constructor or later on by the developer when he calls <literal moreinfo="none">$track-&gt;add_feature()</literal>. Conceptually, the code looks like this:</para><programlisting id="I_programlisting12_tt274" format="linespecific">
	sub add_feature {
	  my $self = shift;
	  my $feature = shift;
	  my $subglyph = Bio::Graphics::Glyph-&gt;new(-feature=&gt;$feature);
	  $self-&gt;add_subpart($subglyph);
	}
</programlisting><para>I show the constructor for Bio::Graphics::Glyph being called in a hardcoded manner, but in practice there will be many different types of glyphs, so the choice of what subclass of Bio::Graphics::Glyph to create must be done at runtime based on options provided by the user. I discuss how I decided to do this in the next section.</para></sect2><sect2 id="option_processing" label="12.2.4"><title>Option Processing</title><para>The next step in the <indexterm id="idx-CHP-12-0935" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>design process was to figure out how glyphs would be created <indexterm class="startofrange" id="idx-CHP-12-0936" significance="normal"><primary>glyphs (Bio::Graphics module)</primary><secondary>dynamic creation of</secondary></indexterm>dynamically. This was part and parcel of the general problem of handling user-configurable options. Recall from the code stories that I wanted options to be specified at track creation like this:<indexterm id="idx-CHP-12-0937" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>option processing</tertiary></indexterm><indexterm id="I_indexterm12_tt275" class="endofrange" startref="idx-CHP-12-0927" significance="normal"><primary>Bio::Graphics::Glyph class</primary></indexterm><indexterm id="I_indexterm12_tt276" class="endofrange" startref="idx-CHP-12-0923" significance="normal"><primary>object classes (Bio::Graphics)</primary><secondary>choosing</secondary></indexterm></para><programlisting id="I_programlisting12_tt277" format="linespecific">
	$panel-&gt;add_track(-glyph   =&gt; 'arrow',
	                  -fgcolor =&gt; 'blue',
	                  -height  =&gt; 22)
</programlisting><para>This example asks the panel to create a track containing <literal moreinfo="none">arrow</literal> glyphs whose foreground color is blue and whose height is 22 pixels. As decided in the previous section, <literal moreinfo="none">add_track()</literal> will create a hardcoded track glyph of type <literal moreinfo="none">Bio::Graphics::Glyph::track</literal> and pass these <indexterm id="idx-CHP-12-0938" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>option processing</tertiary></indexterm>options to its <literal moreinfo="none">new()</literal> constructor. Later, when the track glyph's <literal moreinfo="none">add_feature()</literal> method is called, it will create a new subglyph for each feature to display.<indexterm id="idx-CHP-12-0939" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm></para><para>However, this leaves three unresolved questions:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>How does the track glyph's <literal moreinfo="none">add_feature()</literal> method figure out what type of subglyph to create?</para><para>We want to create different glyphs to display different types of features based on user preferences. Thus, in the previous example, the user wants to populate the track with a series of <literal moreinfo="none">arrow</literal> glyphs, based on the value of the <literal moreinfo="none">-glyph</literal> option. The pseudocode for <literal moreinfo="none">$track-&gt;add_feature()</literal> in the previous section hardcoded a call to <literal moreinfo="none">Bio::Graphics:: Glyph-&gt;new( )</literal>, but in the production code, we would want to <indexterm id="idx-CHP-12-0940" significance="normal"><primary>glyphs (Bio::Graphics module)</primary><secondary>dynamic creation of</secondary></indexterm>dynamically select the appropriate glyph subclass—for example, <literal moreinfo="none">Bio::Graphics::Glyph::arrow</literal>.</para></listitem><listitem><para>How do these subglyphs know what type of sub-subglyphs to create?</para><para>Recall that features can contain subfeatures, and that each subfeature is represented by a subglyph that is part of the main glyph. In the previous example, the track glyph first created a series of arrow glyphs based on the value of the <literal moreinfo="none">-glyph</literal> option. The arrow glyph was then responsible for creating any subglyphs that it needed; these subglyphs were responsible for creating sub-subglyphs, and so forth. How does the arrow glyph decide what type of subglyph to create?</para></listitem><listitem><para>How are the other options passed to the newly created glyph?</para><para>For instance, what object keeps track of the values for the <literal moreinfo="none">-fgcolor</literal> and <literal moreinfo="none">-height</literal> options in the example?</para></listitem></orderedlist><para>Because choosing the glyph type is a special case of <indexterm id="idx-CHP-12-0941" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>processing configuration options, I decided to attack this problem first. My first thought was that each glyph should have the responsibility of managing its options, but I quickly lost enthusiasm for this idea. Since a track may contain thousands of glyphs, it would be quite inefficient for each one to keep a complete copy of its configuration. I also thought of storing options in the <literal moreinfo="none">Panel</literal> object, but this didn't feel right, since the panel has its own options that are distinct from track-specific options.</para><para>The solution that I came up with was to create a series of glyph "factories," of type <literal moreinfo="none">Bio::Graphics::Glyph::Factory</literal>. Each time a track is created, the <literal moreinfo="none">Panel</literal> creates a corresponding factory initialized with the caller's desired options. Each glyph and subglyph in the track contains a reference to the factory, and makes calls to the factory to get its options. Hence, if the panel has four tracks, there are four <literal moreinfo="none">Bio::Graphics::Glyph::Factory</literal> objects.<indexterm class="startofrange" id="idx-CHP-12-0942" significance="normal"><primary>Bio::Graphics::Glyph::Factory class</primary></indexterm></para><para>Once I came up with the idea of a factory, the problems of how to create the appropriate glyph and subglyph types became easy. The factory stores the user's choice of glyph (e.g., <literal moreinfo="none">arrow</literal>) along with all the other options. The factory has a method named <literal moreinfo="none">make_glyph()</literal> that creates glyphs and subglyphs as needed, using the stored <indexterm id="idx-CHP-12-0943" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>option processing</tertiary></indexterm>option to decide what glyph subclass to use.</para><para>This choice implies that all glyphs contained inside the track share the same class. In other words, if a particular feature contains three nested levels of subfeatures, and the user has selected the <literal moreinfo="none">arrow</literal> glyph to use for the features in the track, then each arrow glyph contains arrow subglyphs, and these contain arrow sub-subglyphs. This sounds like a serious limitation, but it actually makes some sense. Typically, a glyph and its subparts act together, and making them all of the subclass allows one to keep all the relevant code in one place. Furthermore, glyphs can escape this restriction by overriding their <literal moreinfo="none">new()</literal> constructors in order to create subglyphs of whatever type they choose.</para><para>The final <indexterm id="idx-CHP-12-0944" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics::Glyph::<indexterm id="idx-CHP-12-0945" significance="normal"><primary>Factory class (Bio::Graphics::Glyph)</primary></indexterm>Factory class has just a few <indexterm id="idx-CHP-12-0946" significance="normal"><primary>Bio::Graphics::Glyph::Factory class</primary><secondary>methods</secondary></indexterm>methods:</para><variablelist><varlistentry><term><emphasis>The constructor</emphasis></term><listitem><para>The constructor creates a new factory:</para><programlisting id="I_programlisting12_tt278" format="linespecific">
	$factory = <indexterm id="idx-CHP-12-0947" significance="normal"><primary>Bio::Graphics::Glyph::Factory class</primary></indexterm>Bio::Graphics::Glyph::Factory-&gt;new(-options=&gt; \%options, -panel =&gt; $panel);
</programlisting><para>During construction, it takes a list of options passed to it by the panel's <literal moreinfo="none">add_track()</literal> method and stores them internally. The factory can also hold a copy of the panel. I added this so that the factory could provide information about the panel, such as the panel's scale.</para><para>The options are actually passed as a reference to a hash (a Perl dictionary of name/ value pairs). The Panel's <literal moreinfo="none">add_track()</literal> method has the minor duty of turning the list of <replaceable>-option=&gt;$value</replaceable> pairs passed to it into a hash to pass to the factory's <literal moreinfo="none">new()</literal> method.</para></listitem></varlistentry><varlistentry><term><emphasis>The</emphasis> <literal moreinfo="none">option( )</literal> <emphasis>method</emphasis></term><listitem><para>Given an option name, the factory looks up its value and returns it:<indexterm id="idx-CHP-12-0948" significance="normal"><primary>Factory class (Bio::Graphics::Glyph)</primary><secondary>option( ) method</secondary></indexterm></para><programlisting id="I_programlisting12_tt279" format="linespecific">
	<replaceable>$option_value</replaceable> = $factory-&gt;option <replaceable>('option_name')</replaceable>
</programlisting><para> If no option by this name is set, <literal moreinfo="none">option()</literal> looks to see whether there is a default value and returns that.</para></listitem></varlistentry><varlistentry><term><emphasis>The</emphasis> <literal moreinfo="none">make_glyph( )</literal> <emphasis>method</emphasis></term><listitem><para>Given a list of features, the factory creates a list of glyphs of the appropriate class:<indexterm id="idx-CHP-12-0949" significance="normal"><primary>Factory class (Bio::Graphics::Glyph)</primary><secondary>make_glyph( ) method</secondary></indexterm></para><programlisting id="I_programlisting12_tt280" format="linespecific">
	@glyphs = $factory-&gt;make_glyph<replaceable>($feature1,$feature2,$feature3...)</replaceable>
</programlisting></listitem></varlistentry></variablelist><para>Now we'll look at a simplified version of the Bio::Graphics::Glyph::Factory code:</para><programlisting id="I_programlisting12_tt281" format="linespecific">
	1 package Bio::Graphics::Glyph::Factory;

	2 use strict;

	3 my %GENERIC_OPTIONS = (
	4                        bgcolor    =&gt; 'turquoise',
	5                        fgcolor    =&gt; 'black',
	6                        fontcolor  =&gt; 'black',
	7                        font2color =&gt; 'turquoise',
	8                        height     =&gt; 8,
	9                        font       =&gt; 'gdSmallFont',
	10                       glyph      =&gt; 'generic',
	11                       );
	12 sub new {
	13   my $<indexterm id="idx-CHP-12-0950" significance="normal"><primary>Bio::Graphics::Glyph::Factory class</primary></indexterm>class = shift;
	14   my %args  = @_;
	15   my $<indexterm id="idx-CHP-12-0951" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>option processing</tertiary></indexterm>options    = $args{-options};        # the options, as a hash reference
	16   my $panel      = $args{-panel};
	17   return bless {
	18                 options =&gt; $options,
	19                 panel   =&gt; $panel,
	20                 },$class;
	21 }

	22 sub option {
	23   my $self = shift;
	24   my $option_name = shift;
	25   $option_name    = lc $option_name; # all options are lower case
	26   if (exists $self-&gt;{options}{$option_name}) {
	27     return $self-&gt;{options}{$option_name};
	28   } else {
	29     return $GENERIC_OPTIONS{$option_name};
	30   }
	31 }

	32 sub make_glyph {
	33   my $self = shift;
	34   my @result;

	35   my $glyph_type  = $self-&gt;option('glyph');
	36   my $glyph_class = '<indexterm id="idx-CHP-12-0952" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics::Glyph::' . $glyph_type;
	37   eval("require $glyph_class"!) unless $glyph_class-&gt;can('new');

	38   for my $feature (@_) {
	39     my $glyph = $glyph_class-&gt;new(-feature =&gt; $f,
	40                                      -factory =&gt; $self);

	41     push @result,$glyph;

	42   }
	43   return @result;
	44 }

	45 1;
</programlisting><para>I start by declaring the package name and turning on strict type checking (lines 1 and 2).</para><para>I then define a package-specific hash containing some generic glyph options to use as fallback defaults. Among the options are a default background color, a default height, and a default font (lines 3–11).</para><para>The <literal moreinfo="none">new()</literal> constructor reads its arguments from @_ (the Perl subroutine argument list) into a hash named <literal moreinfo="none">%args</literal>. It then looks for two named arguments, <literal moreinfo="none">-options</literal> and <literal moreinfo="none">-panel</literal>. It saves these options into an internal anonymous hash under the keys <literal moreinfo="none">options</literal> and <literal moreinfo="none">panel</literal>, creates the object using the Perl <literal moreinfo="none">bless</literal> function, and returns it (lines 12–21).</para><para>The definition of the <literal moreinfo="none">option()</literal> method occupies lines 22–31. I read the factory object and the requested option name from the subroutine argument list. I then call the built-in <literal moreinfo="none">lc()</literal> function to put the <indexterm id="idx-CHP-12-0953" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>option processing</tertiary></indexterm>option name into lowercase, in order to shield the method's behavior from developers who forget whether an option is named <literal moreinfo="none">-height</literal> or <literal moreinfo="none">-Height</literal>. I look for the existence of a like-named key in the options hash that I created in <literal moreinfo="none">new()</literal>, and if it is present, I return the corresponding value. Otherwise, I use the option name to index into <literal moreinfo="none">%GENERIC_OPTIONS</literal> and return that value. If there is no corresponding key in either the options hash or <literal moreinfo="none">%GENERIC_OPTIONS</literal>, I end up returning an undefined value.</para><para>The <literal moreinfo="none">make_glyph()</literal> method (lines 32–44) demonstrates how Perl can <indexterm id="idx-CHP-12-0954" significance="normal"><primary>glyphs (Bio::Graphics module)</primary><secondary>dynamic creation of</secondary></indexterm>dynamically load a module at runtime. I first look up the desired glyph type by using <literal moreinfo="none">option()</literal> to look up the value of the <literal moreinfo="none">glyph</literal> option. Note that the key/value pair <literal moreinfo="none">glyph=&gt;'generic'</literal> is defined in <literal moreinfo="none">%GENERIC_OPTIONS;</literal> this means that if the programmer neglected to ask for a specific glyph type, <literal moreinfo="none">option()</literal> returns <literal moreinfo="none">generic</literal>.</para><para>I now load the requested glyph <indexterm id="idx-CHP-12-0955" significance="normal"><primary>Bio::Graphics::Glyph::Factory class</primary></indexterm>class if needed. By convention, all <indexterm id="idx-CHP-12-0956" significance="normal"><primary>Bio::Graphics::Glyph class</primary><secondary>subclasses</secondary></indexterm>subclasses of Bio:: Graphics::Glyph are named <literal moreinfo="none">Bio::Graphics::Glyph:</literal><replaceable>subclass_name</replaceable>. The <literal moreinfo="none">generic</literal> glyph has a Perl class of <literal moreinfo="none">Bio::Graphics::Glyph::generic</literal>, the <literal moreinfo="none">arrow</literal> glyph lives in <literal moreinfo="none">Bio::Graphics::Glyph:: arrow</literal>, and so forth. I use a string concatention operation (.) to create the fully qualified class name. I then compile and load this class into memory using <literal moreinfo="none">require $glyph_class</literal>. The call to <literal moreinfo="none">require</literal> is wrapped inside a string and passed to the Perl compiler using <literal moreinfo="none">eval()</literal>. This is done to prevent Perl from trying to invoke <literal moreinfo="none">require()</literal> at the time the Factory definition is compiled. To avoid unnecessary recompilation, I load the class only if I detect that its <literal moreinfo="none">new()</literal> constructor does not already exist, indicating that the class is not yet loaded.<indexterm id="idx-CHP-12-0957" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm></para><para>I loop through each feature passed in the @_ subroutine argument array, invoking the selected glyph class's <literal moreinfo="none">new()</literal> constructor. Each newly created glyph is placed on an array, which I then return to the caller.</para><para>The last line of the module is 1, which ends all Perl modules for mostly historical reasons.</para><para>Notice that the <indexterm id="idx-CHP-12-0958" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>design of the glyph constructor has now been extended so that each glyph is constructed using two named arguments: the feature and the factory object. By passing a copy of the factory, each glyph can get at its relevant options. Here are excerpts of two relevant methods from Bio::Graphics::Glyph:</para><variablelist><varlistentry><term><literal moreinfo="none">factory( )</literal></term><listitem><para>This returns the factory object that was passed to the glyph when it was constructed:<indexterm id="idx-CHP-12-0959" significance="normal"><primary>Bio::Graphics::Glyph class</primary><secondary>factory( ) and option( ) methods</secondary></indexterm></para><programlisting id="I_programlisting12_tt282" format="linespecific">
	sub factory {
	  my $self = shift;
	  return $self-&gt;{factory};
	}
</programlisting></listitem></varlistentry><varlistentry><term><literal moreinfo="none">option( )</literal></term><listitem><para>This is a pass-through method to get the value of a named option:</para><programlisting id="I_programlisting12_tt283" format="linespecific">
	sub option {
	  my $self = shift;
	  my ($option_name) = @_;
	  return $self-&gt;factory-&gt;option($option_name);
	}
</programlisting><para>The glyph calls <literal moreinfo="none">factory()</literal> to get its factory and immediately calls the factory's <literal moreinfo="none">option()</literal> method to get the value of the option specified on the subroutine argument list.<indexterm id="idx-CHP-12-0960" significance="normal"><primary>Factory class (Bio::Graphics::Glyph)</primary></indexterm><indexterm id="idx-CHP-12-0961" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>option processing</tertiary></indexterm></para></listitem></varlistentry></variablelist></sect2><sect2 id="code_example" label="12.2.5"><title>Code Example</title><para>To put it all together, <xref linkend="a_script_that_uses_biographics"/> is a simple illustration of <indexterm id="idx-CHP-12-0962" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics in action. Its output is shown in <xref linkend="the_output_from_example_12-4"/>.<indexterm id="I_indexterm12_tt284" class="endofrange" startref="idx-CHP-12-0942" significance="normal"><primary>Bio::Graphics::Glyph::Factory class</primary></indexterm><indexterm id="I_indexterm12_tt285" class="endofrange" startref="idx-CHP-12-0936" significance="normal"><primary>glyphs (Bio::Graphics module)</primary><secondary>dynamic creation of</secondary></indexterm></para><example id="a_script_that_uses_biographics" label="12-4"><title>A script that uses Bio::Graphics</title><programlisting format="linespecific">
1 #!/usr/bin/perl

2 use strict;

3 use Bio::Graphics; 
4 use Bio::SeqFeature::Generic;
5 my $bsg = 'Bio::SeqFeature::Generic';

6 my $span         = $bsg-&gt;new(-start=&gt;1,-end=&gt;1000);

7 my $test1_feat   = $bsg-&gt;new(-start=&gt;300,-end=&gt;700,
8                                 -display_name=&gt;'Test Feature',
9                                 -source_tag=&gt;'This is only a test');

10 my $test2_feat = $bsg-&gt;new(-start=&gt;650,-end=&gt;800,
11                               -display_name=&gt;'Test Feature 2');

12 my $panel        = Bio::Graphics::Panel-&gt;new(-width=&gt;600,-length=&gt;$span-&gt;length,
13                                                 -pad_left=&gt;12,-pad_right=&gt;12);

14 $panel-&gt;add_track($span,-glyph=&gt;'arrow',-double=&gt;1,-tick=&gt;2);

15 $panel-&gt;add_track([$test1_feat,$test2_feat],
16                      -glyph =&gt; 'box',
17                      -bgcolor =&gt; 'orange',
18                      -font2color =&gt; 'red',
19                      -height =&gt;20,
20                      -label  =&gt; 1,
21                      -description =&gt; 1,
22   );

23 print $panel-&gt;png;
</programlisting></example><figure id="the_output_from_example_12-4" label="12-2" float="0"><title>The output from <xref linkend="a_script_that_uses_biographics"/></title><mediaobject id="I_mediaobject12_tt286"><imageobject role="print"><imagedata fileref="figs/print/beauty_1202.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1202.png" format="PNG"/></imageobject></mediaobject></figure><para>We load the <indexterm id="idx-CHP-12-0963" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics library and one of BioPerl's standard Bio::SeqFeatureI classes, <indexterm id="idx-CHP-12-0964" significance="normal"><primary>Bio::SeqFeature::Generic class</primary></indexterm>Bio::SeqFeature::Generic (lines 3–4). In order to avoid repeatedly typing out the full name of the feature class, we store it in a variable (line 5).<indexterm id="idx-CHP-12-0965" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>script that uses (example)</tertiary></indexterm></para><para>We then create three Bio::SeqFeature::Generic objects. One feature starts at position 1 and ends at position 1000, and will be used to draw a track containing the scale for the image (line 6). Two others will be features in a second track (lines 7–11).</para><para>We create the panel, passing it options that specify its width in pixels, its length in base pairs, and additional whitespace to pad the image with on the left and right (lines 12–13).</para><para>Next, we create a track for the image scale (line 14). It consists of a single feature, contained in the variable <literal moreinfo="none">$span</literal>, and options that select the <literal moreinfo="none">arrow</literal> glyph, make the arrow double-headed <literal moreinfo="none">(-double=&gt;1)</literal>, and print both major and minor tick marks on the arrow <literal moreinfo="none">(-tick=&gt;2)</literal>.</para><para>Now it's time to create a track for the two features, <literal moreinfo="none">$test1_feat</literal> and <literal moreinfo="none">$test2_feat</literal>. We add a second track, this time specifying options to use the <literal moreinfo="none">box</literal> glyph with a background color of orange, a <indexterm id="idx-CHP-12-0966" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>script that uses (example)</tertiary></indexterm>description font color of red, and a height of 20 pixels. We also selectively turn on the printing of the feature name and description (lines 15–22).</para><para>The last step is to call the panel object's <literal moreinfo="none">png()</literal> method to convert it into a PNG graphic, and to print the graphic to standard output where it can be saved to a file or piped to a graphics display program (line 23).</para></sect2><sect2 id="dynamic_options" label="12.2.6"><title>Dynamic Options</title><para>The original Bio::Graphics::Glyph::Factory <indexterm id="idx-CHP-12-0967" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>design was based around the idea of simple static option values. However, as I started working with the first version of Bio::Graphics, I realized that it would be handy to give the developer the ability to compute some options dynamically.<indexterm id="idx-CHP-12-0968" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>dynamic options</tertiary></indexterm></para><para>For example, scattered along the genome are sites on the DNA where <indexterm id="idx-CHP-12-0969" significance="normal"><primary>regulatory protein bound to specific site of the DNA</primary></indexterm>regulatory proteins attach. When a regulatory protein attaches to a specific site of the DNA (a process called "binding"), a nearby gene is typically turned on or off. Some binding sites are strong, while others are weak, and the strength of the DNA/protein <indexterm id="idx-CHP-12-0970" significance="normal"><primary>binding interaction</primary></indexterm>binding interaction is often of great importance to understanding how the regulatory interaction works.</para><para>To create a track showing the <indexterm id="idx-CHP-12-0971" significance="normal"><primary>tracks (Bio::Graphics module)</primary><secondary>positions and relative strengths of DNA/protein binding site</secondary></indexterm>positions and relative strengths of <indexterm id="idx-CHP-12-0972" significance="normal"><primary>DNA/protein binding site</primary></indexterm>DNA/protein binding site features, a developer might want to show a series of rectangles. The start and end of each rectangle would show the span of the feature, and its background (interior) color would show the strength of binding: white for weak, pink for medium, and red for strong. Under the original design the developer could specify the background color for all features in the track like this:</para><programlisting id="I_programlisting12_tt287" format="linespecific">
	@features = get_features_somehow();
	$panel-&gt;add_track(\@features,
	                     -glyph =&gt; 'generic',
	                     -bgcolor =&gt; 'pink');
</programlisting><para>However, this offered no way to set the color on a feature-by-feature basis.</para><para>When I realized this limitation, I went back and extended the API to allow the values of options to be <literal moreinfo="none">CODE</literal> references. These are <indexterm id="idx-CHP-12-0973" significance="normal"><primary>anonymous subroutines (Perl)</primary></indexterm>anonymous subroutines that Perl programmers can define in a variety of ways and are used in much the same way that function pointers are used in C. Here is a revised <literal moreinfo="none">add_track()</literal> call that takes advantage of this facility:</para><programlisting id="I_programlisting12_tt288" format="linespecific">
	$panel-&gt;add_track(\@features,
	                     -glyph =&gt; 'box',
	                     -bgcolor =&gt; sub {
	                           my $feature = shift;
	                           my $score = $feature-&gt;score;
	                           return 'white' if $score &lt; 0.25;
	                           return 'pink' if $score &lt; 0.75;
	                           return 'red';
	                     }
	                   );
</programlisting><para>This works as follows: the value of <literal moreinfo="none">-bgcolor</literal> is an anonymous <literal moreinfo="none">CODE</literal> reference created <indexterm id="idx-CHP-12-0974" significance="normal"><primary>callbacks in Bio::Graphics</primary><secondary>using for each option passed to add_track( )</secondary></indexterm>using the <literal moreinfo="none">sub</literal> keyword without a subroutine name. The code is invoked at runtime each time the glyph wants to access the value of its <literal moreinfo="none">bgcolor</literal> option. The subroutine receives the corresponding feature on its argument array and calls its <literal moreinfo="none">score()</literal> method to get the binding-site strength. Assuming that the binding-site strength is represented as a floating-point number between 0 and 1.0, I return an option value of <literal moreinfo="none">white</literal> if the score is less than 0.25, a value of <literal moreinfo="none">pink</literal> if the score is greater than 0.25 but less than 0.75, and <literal moreinfo="none">red</literal> if it is greater than 0.75. <indexterm id="idx-CHP-12-0975" significance="normal"><primary>Bio::Graphics::Glyph::Factory class</primary><secondary>dynamic option processing</secondary></indexterm><xref linkend="colorizing_the_background_according_to_dynamically_changing_val"/> shows how this might look.</para><figure id="colorizing_the_background_according_to_dynamically_changing_val" label="12-3" float="0"><title>Colorizing the background according to dynamically changing values</title><mediaobject id="I_mediaobject12_tt289"><imageobject role="print"><imagedata fileref="figs/print/beauty_1203.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1203.png" format="PNG"/></imageobject></mediaobject></figure><para>In the end, I made it possible to use code callbacks for every option passed to <literal moreinfo="none">add_track()</literal>, including the <literal moreinfo="none">-glyph</literal> option itself. This gives the end user an amazing amount of flexibility for customizing and extending the library. For example, it greatly simplifies "semantic zooming," or changing the appearance of tracks depending on the size of the region to display. The following callback turns off collision control when the region gets larger than 50,000 bp:</para><programlisting id="I_programlisting12_tt290" format="linespecific">
	-bump =&gt; sub {
	     my ($feature,$option_name,$glyph) = @_; # get all args
	     return $glyph-&gt;panel-&gt;length &lt; 50_000;
	  }
</programlisting><para>Let's now have a look at a simplified version of the revised option-<indexterm id="idx-CHP-12-0976" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>processing code. First, I modified <indexterm id="idx-CHP-12-0977" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics::Glyph::Factory to look like this:</para><programlisting id="I_programlisting12_tt291" format="linespecific">
	# In Bio::Graphics::Glyph::Factory
	sub option {
	  my $self = shift;
	  my ($glyph,$option_name) = @_;
	  $<indexterm id="idx-CHP-12-0978" significance="normal"><primary>Glyph class (Bio::Graphics)</primary><secondary>dynamic option processing</secondary></indexterm>option_name   = lc $option_name; # all options are lowercase
	  my $value;
	  if (exists $self-&gt;{options}{$option_name}) {
	     $value = $self-&gt;{options}{$option_name};
	  } else {
	     $value = $GENERIC_OPTIONS{$option_name};
	  }

	  return $value unless ref $value eq 'CODE';

	  my $feature = $glyph-&gt;feature;
	  my $eval = eval {$value-&gt;($feature,$option_name,$glyph)};
	  warn "Error while evaluating "$option_name' option for glyph $glyph, feature
	$feature: ",$@,"\n"
	      if $@;

	  return defined $eval &amp;&amp; $eval eq '*default*' ?
	  $GENERIC_OPTIONS{$option_name}
	                                               : $eval;
	}
</programlisting><para>The method now takes two arguments rather than one. The first argument is the current glyph, while the second one is the option name as before. Once again, the factory looks first in its hash of track-specific options and then in the defaults hash (<literal moreinfo="none">%GENERIC_OPTIONS</literal>)if the option wasn't named in the track configuration.</para><para>However, additional logic now comes after retrieving the option value. I call Perl's <literal moreinfo="none">ref()</literal> function to look up the data type of the contents of <literal moreinfo="none">$value</literal>. If it is a code reference, <literal moreinfo="none">ref()</literal> returns the string <literal moreinfo="none">CODE</literal>. If I don't get <literal moreinfo="none">CODE</literal>, I just return the value as before. Otherwise, I get the corresponding feature by calling the glyph's <literal moreinfo="none">feature()</literal> method, and then invoke the code reference by using Perl's anonymous code reference invocation syntax:<indexterm id="idx-CHP-12-0979" significance="normal"><primary>ref( ) function (Perl)</primary></indexterm></para><programlisting id="I_programlisting12_tt292" format="linespecific">
	<replaceable>$value-&gt;($feature,$option_name,$glyph)</replaceable>
</programlisting><para>The first argument passed to the callback is the feature, the second is the option name, and the third is the glyph itself.</para><para>Because the callback might cause a runtime error, I defend against this possibility by wrapping the entire call in an <literal moreinfo="none">eval {}</literal> block. In case of a fatal error in the callback, this will return an undefined value and place Perl error diagnostics into the special scalar $@. After invoking the callback, I check whether $@ is nonempty and, if so, print a nonfatal warning.</para><para>The last step is to return the value derived from the callback. I thought it would be useful for the callback to be able to indicate that it wanted to use the default value for the named option. The last line of code simply checks whether the callback returned the string <literal moreinfo="none">*default*</literal> and, if so, returns the value from the defaults hash.</para><para>To accommodate this change in the factory's <literal moreinfo="none">option()</literal> method, I had to make a corresponding change to <literal moreinfo="none">Bio::Graphics::Glyph-&gt;option()</literal>:<indexterm id="idx-CHP-12-0980" significance="normal"><primary>Bio::Graphics::Glyph class</primary><secondary>option( ) method</secondary></indexterm><indexterm id="idx-CHP-12-0981" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm></para><programlisting id="I_programlisting12_tt293" format="linespecific">
	# In Bio::Graphics::Glyph
	sub option {
	  my $self = shift;
	  my ($option_name) = @_;
	  return $self-&gt;factory-&gt;option($self,$option_name);
	}
</programlisting><para>As I worked with callbacks, I found them to be an increasingly useful concept. For example, I realized that callbacks handle semantic zooming very nicely. The gene glyph draws a detailed representation <indexterm id="idx-CHP-12-0982" significance="normal"><primary>callbacks in Bio::Graphics</primary><secondary>usefulness of</secondary></indexterm>of a protein-coding gene's internal structure, which is fine at high magnifications, but doesn't work when viewing very large regions, where the details become so small that they are indistinguishable. However, one can apply a callback to the <literal moreinfo="none">-glyph</literal> option in order to <indexterm id="idx-CHP-12-0983" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary><tertiary>dynamic options</tertiary></indexterm>dynamically select the simple rectangular <literal moreinfo="none">box</literal> glyph rather than the <literal moreinfo="none">gene</literal> glyph whenever the gene is smaller than five percent of the displayed region:</para><programlisting id="I_programlisting12_tt294" format="linespecific">
	$panel-&gt;add_track(
	      -glyph =&gt; sub {
	          my ($feature,$panel) = @_;
	          return 'box' if $feature-&gt;length/$panel-&gt;length &lt; 0.05;
	          return 'gene';
	            },
	      -height =&gt; 12,
	      -font2color =&gt; 'red',
	      -label_transcripts =&gt; 1,
	      -label =&gt; 1,
	      -description =&gt; 1,
	     );
</programlisting><para>Note that the callback arguments for the <literal moreinfo="none">-glyph</literal> option are different from other options because this value is needed before the glyph is created. Instead of passing the feature, option name, and glyph, the callback passes the feature and the panel object.</para><para>As it happens, the callback feature became one of the most popular features of <indexterm id="idx-CHP-12-0984" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics. As time went on, I added callbacks liberally to other parts of the API, including when <indexterm id="idx-CHP-12-0985" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm>processing options passed to the Panel constructor, and in the code that decides in what order to sort features from top to bottom.</para><para>On various occasions, users found uses for callbacks that I hadn't <indexterm id="idx-CHP-12-0986" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>anticipated. To give one nice example, I provided a way for users to specify a callback to do some direct drawing on the Panel after it drew its gridlines but before it drew the glyphs. Years later, an enterprising genome biologist figured out how to use this feature to create diagrams that compare the genomes of species whose chromosomes have undergone structural changes relative to one other. The gridline callback draws colored polygons that connect features of one chromosome to the corresponding features in the other (<xref linkend="clever_use_of_biographics_callbacks_allows_related_features_on_"/>).</para><para>There is also a dark side to the Bio::Graphics::Factory story. In my initial burst of enthusiasm, I added a slew of other features to the option-getting and -setting methods that I omitted from the code examples shown here. One feature was the ability to initialize a factory using a web-style cascading stylesheet. Another feature provided detailed information to each callback concerning the current glyph's relationship to other glyphs in its track or to the top-level glyph. In practice, these features have never been used and are now hanging around as dead code.<indexterm id="I_indexterm12_tt295" class="endofrange" startref="idx-CHP-12-0891" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>design process</secondary></indexterm></para><figure id="clever_use_of_biographics_callbacks_allows_related_features_on_" label="12-4" float="0"><title>Clever use of Bio::Graphics callbacks allows related features on two chromosomes to be compared</title><mediaobject id="I_mediaobject12_tt296"><imageobject role="print"><imagedata fileref="figs/print/beauty_1204.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1204.png" format="PNG"/></imageobject></mediaobject></figure></sect2></sect1><sect1 id="extending_biographics" label="12.3"><title>Extending Bio::Graphics</title><para>We'll now look at some of the Bio::Graphics extensions that were added after the initial release. This illustrates how code evolves in response to user input.<indexterm id="idx-CHP-12-0987" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm><indexterm class="startofrange" id="idx-CHP-12-0988" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>extending</secondary></indexterm></para><sect2 id="supporting_web_developers" label="12.3.1"><title>Supporting Web Developers</title><para>One of the objectives of Bio::Graphics was to support <indexterm id="idx-CHP-12-0989" significance="normal"><primary>interactive web applications</primary></indexterm>interactive browsable views of the genome using web-based applications. My basic idea for this was that a CGI script would process a fill-out form indicating the genome to browse and a region to display. The script would make the database connection, process the user's request, find the region or regions of interest, pull out the features in the corresponding region, and pass them to Bio::Graphics. Bio::Graphics would render the image, and the CGI script would incorporate this data into an <literal moreinfo="none">&lt;IMG&gt;</literal> tag for display.<indexterm id="idx-CHP-12-0990" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>supporting web developers</secondary></indexterm></para><para>The one thing missing from this picture was the ability to generate an image map for the generated image. An image map is necessary to support the user's ability to click on a glyph and get more information about it. <indexterm id="idx-CHP-12-0991" significance="normal"><primary>image maps for Bio::Graphics output</primary></indexterm>Image maps also make it possible to make tool tips appear when the user mouses over the glyph and to perform such dynamic HTML tasks as populating a pull-down menu when the user right-clicks on the glyph.</para><para>To support image map generation, the original version of Bio::Graphics had a single method called <literal moreinfo="none">boxes()</literal>. This returned an array containing the glyph bounding rectangles, the features associated with each glyph, and the glyph objects themselves. To generate an image map, developers had to step through this array and generate the image map HTML manually.</para><para>Unfortunately, this was not as easy to do as I hoped it would be, judging from the number of user-support requests I received. So, after some experience writing my own Bio:: Graphics-based genome browser, I added an <literal moreinfo="none">image_and_map()</literal> method to Bio::Graphics:: Panel. Here is a code fragment that illustrates how to use this method:<indexterm id="idx-CHP-12-0992" significance="normal"><primary>Bio::Graphics::Panel class</primary><secondary>image_and_map( ) method</secondary></indexterm></para><programlisting id="I_programlisting12_tt297" format="linespecific">

	$panel = <indexterm id="idx-CHP-12-0993" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics::Panel-&gt;new(@args);
	$panel-&gt;add_track(@args);
	$panel-&gt;add_track(@args);
	...

	($url,$map,$mapname) = $panel-&gt;image_and_map(
	                                -root =&gt; '/var/www/html',
	                                -url  =&gt; '/images',
	                                -link =&gt; sub {
	                                      my $feature = shift;
	                                      my $name = $feature-&gt;display_name;
	                                      return "http://www.google.com/search?q=$name";
	                                 }
	print "&lt;H2&gt;My Genome&lt;/H2&gt;";
	print "&lt;IMG SRC='$url' USEMAP='#$mapname' BORDER='0' /&gt;";
	print $map;
</programlisting><para>We set up a Panel and add tracks to it as before. We then call <literal moreinfo="none">image_and_map()</literal> with three argument/value pairs. The <literal moreinfo="none">-root</literal> argument gives the physical location of the web server's document root—the place where the tree of HTML files starts. <literal moreinfo="none">-url</literal> indicates where, relative to the document root, Bio::Graphics-generated images should be stored. The <literal moreinfo="none">-link</literal> argument is a callback that Bio::Graphics invokes to attach a clickable link to a glyph. In this case, we recover the feature object from the callback's argument list, get the feature's human-readable name by calling <literal moreinfo="none">display_name()</literal>, and generate a Google search link. Several other <literal moreinfo="none">image_and_map()</literal> options can be used to customize and extend the resulting image map.</para><para>The method generates the image and stores it into the filesystem at the location indicated by <literal moreinfo="none">-root</literal> and <literal moreinfo="none">-url</literal>—in this case, <emphasis>/var/www/html/images</emphasis>. It then returns a three-member result list consisting of a URL for the generated image, the HTML for the image map, and the name of the image map for use in the <literal moreinfo="none">&lt;IMG&gt;</literal> tag. We then simply print the appropriate fragments of HTML to use the image and its map.</para><para>To date there are two <indexterm id="idx-CHP-12-0994" significance="normal"><primary>web-based genome browsers based on Bio::Graphics</primary></indexterm>web-based <indexterm id="idx-CHP-12-0995" significance="normal"><primary>genome browsers</primary></indexterm>genome browsers based on Bio::Graphics. The one that I wrote, called <indexterm id="idx-CHP-12-0996" significance="normal"><primary>GBrowse</primary></indexterm>GBrowse (<ulink url="http://www.gmod.org/gbrowse"/>), is now widely used to display a large number of genomes ranging from bacteria to man. However, it was written in 2002 before Ajax-based asynchronous page refreshes were invented; one moves along the genome by clicking arrow buttons and waiting for the screen to reload. A new browser that is currently in prototype stage, the <indexterm id="idx-CHP-12-0997" significance="normal"><primary>Ajax Generic Genome Browser</primary></indexterm>Ajax Generic Genome Browser (<ulink url="http://genome.biowiki.org/gbrowse"/>), provides Google Maps-style functionality for the genome. To navigate, one simply grabs the view and slides it.</para></sect2><sect2 id="supporting_publication-quality_images" label="12.3.2"><title>Supporting Publication-Quality Images</title><para>Another original requirement was support for multiple graphics formats. To satisfy this, I designed Bio::Graphics to use the Perl <indexterm id="idx-CHP-12-0998" significance="normal"><primary>Perl</primary><secondary>GD library</secondary></indexterm>GD library for its low-level graphics calls. This library, which is based on Tom Boutell's <emphasis>libgd</emphasis> (<ulink url="http://www.libgd.org"/>), generates pixmap-based images in a variety of formats, including PNG, JPEG, and GIF.<indexterm id="idx-CHP-12-0999" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>extending</secondary><tertiary>supporting publication-quality images</tertiary></indexterm><indexterm id="idx-CHP-12-1000" significance="normal"><primary>libgd</primary></indexterm></para><para>The Panel object creates and maintains a GD graphics object internally and passes this object to each of its tracks' <literal moreinfo="none">draw()</literal> routines. The tracks, in turn, pass the GD object to their glyphs, and the glyphs to their subglyphs.</para><para>The <literal moreinfo="none">Bio::Graphics::Panel-&gt;png()</literal> method is simply a pass-through to GD's <literal moreinfo="none">png()</literal> method:<indexterm id="idx-CHP-12-1001" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm><indexterm id="idx-CHP-12-1002" significance="normal"><primary>Bio::Graphics::Panel class</primary><secondary>png( ) method</secondary></indexterm></para><programlisting id="I_programlisting12_tt298" format="linespecific">
	# in Bio::Graphics::Panel
	sub png {
	   my $self = shift;
	   my $gd = $self-&gt;gd;
	   return $gd-&gt;png;
	}
</programlisting><para>The <literal moreinfo="none">jpeg()</literal> and <literal moreinfo="none">gif()</literal> methods are similar. The developer also has the option of recovering the raw GD object and calling its <literal moreinfo="none">png()</literal> method:</para><programlisting id="I_programlisting12_tt299" format="linespecific">
	$gd = $panel-&gt;gd;
	print $gd-&gt;png;
</programlisting><para>The advantage of making the internal GD object available to the public interface is that the developer can do additional things with the GD object, such as embedding it in a larger picture or manipulating its colors.</para><para>One consequence of my choice to use GD was that Bio::Graphics was originally limited to the generation of pixmap images. This problem was solved by Todd Harris when he wrote the Perl GD:::<indexterm id="idx-CHP-12-1003" significance="normal"><primary>SVG (Scalable Vector Graphics) images</primary></indexterm>SVG module (<indexterm id="idx-CHP-12-1004" significance="normal"><primary>Bio::Graphics::Panel class</primary><secondary>SVG images</secondary></indexterm><ulink url="http://toddot.net/projects/GD-SVG"/>). <indexterm id="idx-CHP-12-1005" significance="normal"><primary>GD::SVG module (Perl)</primary></indexterm>GD::SVG has the same API as GD, but generates <indexterm id="idx-CHP-12-1006" significance="normal"><primary>Scalable Vector Graphics (SVG) images</primary></indexterm>Scalable Vector Graphics (SVG) images, which can be printed at high resolution without loss of detail, and manipulated in various image-drawing applications such as Adobe Illustrator.</para><para>After I added support for GD::SVG in Bio::Graphics, it became possible to produce SVGs simply by passing an <literal moreinfo="none">-image_class</literal> argument to the Panel constructor:</para><programlisting id="I_programlisting12_tt300" format="linespecific">
	$panel = Bio::Graphics::Panel-&gt;new(-length=&gt;1000,
	                                      -width=&gt;600,
	                                      -image_class =&gt; 'GD::SVG'
	                                     );
	$panel-&gt;add_track.... etc...
	print $panel-&gt;gd-&gt;svg;
</programlisting><para>Internally, the only change I had to make to Bio::Graphics was to process the <literal moreinfo="none">-image_class</literal> option and to load the indicated image library. This allows for forward compatibility with new GD-compatible libraries. For example, if someone writes a GD::PDF that generates PDF-format graphic files, Bio::Graphics will be able to accommodate it.</para></sect2><sect2 id="adding_new_glyphs" label="12.3.3"><title>Adding New Glyphs</title><para>At the time it was first published, Bio::Graphics supported about a dozen simple glyphs, including rectangles, ovals, arrows, the gene glyph, and a glyph that draws protein and DNA sequences. Each of these glyphs had multiple configuration options, leading to a very large number of possible displays. However, this number was still finite, whereas the number of feature types on the genome is potentially infinite. Fortunately, it is relatively easy to add new glyphs, and over time, I and other BioPerl developers have added many new glyphs to <indexterm id="idx-CHP-12-1007" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics. Currently there are nearly 70 glyph types, ranging from whimsical (a Star of David) to sophisticated (a ternary plot for comparing frequencies of sequence variants in multiple populations).<indexterm id="idx-CHP-12-1008" significance="normal"><primary>glyphs (Bio::Graphics module)</primary><secondary>adding new</secondary></indexterm></para><para>The ability to easily extend existing glyphs to create new ones is a valuable feature. I will illustrate this in <xref linkend="the_hourglass_glyph"/> by showing you how to create a new Glyph called <literal moreinfo="none">hourglass</literal>.</para><example id="the_hourglass_glyph" label="12-5"><title>The hourglass glyph</title><programlisting format="linespecific">
1 package Bio::Graphics::Glyph::hourglass;

2 use strict;
3 use base 'Bio::Graphics::Glyph::box';

4 sub draw_component {
5   my $self = shift;
6   my ($gd,$dx,$dy) = @_;
7   my ($left,$top,$right,$bottom) = $self-&gt;bounds($dx,$dy);

8   # draw the hourglass as a polygon
9   my $poly = GD::Polygon-&gt;new;
10   $poly-&gt;addPt($left,$top);
11   $poly-&gt;addPt($right,$bottom);
12   $poly-&gt;addPt($right,$top);
13   $poly-&gt;addPt($left,$bottom);
14   $poly-&gt;addPt($left,$top);
15   $gd-&gt;filledPolygon($poly,$self-&gt;bgcolor);
16   $gd-&gt;polygon($poly,$self-&gt;fgcolor);
17 }

18 1;
</programlisting></example><para>This glyph generates an hourglass (<xref linkend="the_hourglass_glyph_a_twisted_version_of_the_standard_box_glyph"/>). The glyph starts by defining its package name, which by convention must begin with <literal moreinfo="none">Bio::Graphics::Glyph::</literal> (line 1). It then declares that it is inheriting from <literal moreinfo="none">Bio::Graphics::Glyph::box</literal>, which is a simple glyph that draws a rectangle (line 3).<indexterm id="idx-CHP-12-1009" significance="normal"><primary>hourglass glyph (example)</primary></indexterm></para><figure id="the_hourglass_glyph_a_twisted_version_of_the_standard_box_glyph" label="12-5" float="0"><title>The hourglass glyph, a twisted version of the standard box glyph</title><mediaobject id="I_mediaobject12_tt301"><imageobject role="print"><imagedata fileref="figs/print/beauty_1205.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1205.png" format="PNG"/></imageobject></mediaobject></figure><para>The glyph then overrides the inherited <literal moreinfo="none">draw_component()</literal> method (lines 4–17). The <literal moreinfo="none">draw_ component()</literal> method is called by a <literal moreinfo="none">draw()</literal> method of Bio::Graphics::Glyph after setting up the drawing environment. The method receives the GD object along with horizontal and vertical coordinates indicating the position of the glyph relative to its enclosing glyph. We pass the relative coordinates to the inherited <literal moreinfo="none">bounds()</literal> method to convert them into the absolute coordinates of the rectangle enclosing the glyph (line 7).</para><para>Now we actually draw the glyph. We create a polygon using GD's polygon library and add vertices corresponding to the top-left, bottom-right, top-right, and bottom-left corners of the hourglass (lines 9–14). We then pass the polygon object first to the GD object's <literal moreinfo="none">filledPolygon()</literal> method to draw the solid contents of the polygon (line 15), and then to the GD object's <literal moreinfo="none">polygon()</literal> method to draw the outline of the hourglass (line 16). Notice our use of the inherited <literal moreinfo="none">bgcolor()</literal> and <literal moreinfo="none">fgcolor()</literal> methods to get the appropriate colors to use for the fill and the outline.</para><para>This demonstrates the simplicity of adding new glyphs to <indexterm id="idx-CHP-12-1010" significance="normal"><primary>Bio::Graphics module (Perl)</primary></indexterm>Bio::Graphics. In many cases, one can create a new glyph by inheriting from an existing glyph that does almost what one wants, and then modifying one or two methods to customize it.</para></sect2></sect1><sect1 id="conclusions_and_lessons_learned" label="12.4"><title>Conclusions and Lessons Learned</title><para>Designing software to be used by other developers is a challenge. It has to be easy and straightforward to use because developers are just as impatient as everyone else, but it can't be so dumbed-down that it loses functionality. Ideally, a code library must be immediately usable by naïve developers, easily customized by more sophisticated developers, and readily extensible by experts.</para><para>I think Bio::Graphics hits this sweet spot. Developers new to BioPerl can get started right away by writing simple scripts that use familiar BioPerl objects such as Bio::SeqFeature:: Generic. Intermediate developers can customize the library's output by writing callbacks, while the most sophisticated developers can extend the library with custom glyphs.</para><para>Bio::Graphics also illustrates the power of standard interfaces. Because it was designed to render any object that follows BioPerl's <indexterm id="idx-CHP-12-1011" significance="normal"><primary>Bio::SeqFeatureI interface</primary></indexterm>Bio::SeqFeatureI interface, it will work hand-in-hand with any of BioPerl's sequence data access modules. Bio::Graphics can generate diagrams of handcoded sequence features as easily as it can display features read from a flat file, retrieved from a database query, or generated by a web service and transmitted across the network.</para><para>The module also has a few warts, and if I had to reimplement it now, I would have done several things differently. A major issue is the way that <indexterm id="idx-CHP-12-1012" significance="normal"><primary>glyphs (Bio::Graphics module)</primary><secondary>subglyph generation</secondary></indexterm>subglyphs are generated. In the current implementation, if you assign a glyph to a feature and the feature has subfeatures, the subglyphs will all be of the same type as the top-level glyph.</para><para>This has two drawbacks. First, one must use subclassing to create composite glyphs in which the subglyphs reuse code from a previously defined class and the parent glyph is something new. Second, glyph methods always have to be aware of which level of features they are currently rendering. For example, to create a glyph in which the top level is represented as a dotted octagon and the subfeatures are represented as rectangles, the <literal moreinfo="none">draw_component()</literal> routine must be sure to call the glyph's <literal moreinfo="none">level()</literal> method to find out the current nesting level and then draw the appropriate shape. If I were to do it again, I would provide an API to select the right glyph to use at each level of nesting.<indexterm id="I_indexterm12_tt302" class="endofrange" startref="idx-CHP-12-0988" significance="normal"><primary>Bio::Graphics module (Perl)</primary><secondary>extending</secondary></indexterm></para><para>Another annoyance is the box model. Glyphs are allowed to allocate additional space around themselves in order to draw decorations such as arrows, highlights, or labels. They do this by overriding methods called <literal moreinfo="none">pad_left(), pad_right()</literal>, and so on.</para><para>This works fine until you define a new glyph class that inherits from the old one, and you need to adjust the padding for additional decoration. The derived class must be careful to find out how much padding its parent requests (by calling the inherited pad method) and then add its own padding needs to this value. This can get tricky. If I were to do it over, I would simply keep track of where the glyph draws in its <literal moreinfo="none">draw_component()</literal> routine, and increase its bounding rectangle as needed.</para><para>Unfortunately, implementing either of these fixes will change the glyph API in pretty fundamental ways and would require someone, most likely myself, to rewrite all 60+ existing glyph classes in order not to break them. So for the time being, I will accept that the module will always be Pretty Good but will never achieve Perfection. And this is the last, and maybe the best, lesson learned.</para></sect1></chapter><chapter id="the_design_of_the_gene_sorte" label="13" role=""><title>The Design of the Gene Sorte</title><para><emphasis>Jim Kent</emphasis><indexterm id="idx-CHP-13-1013" significance="normal"><primary>Kent</primary></indexterm></para><para><emphasis>This chapter is about a moderate-sized program i wrote called the gene sorter</emphasis>. The size of the Gene Sorter code is larger than the projects described in most of the other chapters, about 20,000 lines in all. Though there are some smaller pieces of the Gene Sorter that are quite nice, for me the real beauty is how easy it is to read, understand, and extend the program as a whole. In this chapter, I'll present an overview of what the Gene Sorter does, highlight some of the more important parts of the code, and then discuss the issues involved in making programs longer than a thousand lines enjoyable and even beautiful to work with.<indexterm class="startofrange" id="idx-CHP-13-1014" significance="normal"><primary>Gene Sorter</primary></indexterm></para><para>The Gene Sorter helps scientists rapidly sift through the roughly 25,000 genes in the human genome to find those most relevant to their research. The program is part of the <ulink url="http://genome.ucsc.edu"/> web site, which also contains many other tools for working with data generated by the Human Genome Project. The Gene Sorter design is simple and flexible. It incorporates many lessons we learned in two previous generations of programs that serve biomedical data over the Web. The program uses CGI to gather input from the user, makes queries into a MySQL database, and presents the results in HTML. About half of the program code resides in libraries shared with other <ulink url="http://genome.ucsc.edu">genome.ucsc.edu</ulink> tools.</para><para>The human genome is a digital code that somehow contains all of the information needed to build a human body, including that most remarkable of organs, the human brain. The information is stored in three billion <indexterm id="idx-CHP-13-1015" significance="normal"><primary>bases of DNA (A</primary></indexterm>bases of DNA. Each base can be an A, C, G, or T. Thus, there are two bits of information per base, or 750 megabytes of information in the genome.</para><para>It is remarkable that the information to build a human being could fit easily into a memory stick in your pocket. Even more remarkably, we know from an evolutionary analysis of many genomes that only about 10 percent of that information is actually needed. The other 90 percent of the genome consists primarily of relics from evolutionary experiments that turned into dead ends, and in the clutter left by virus-like elements known as <emphasis>transposons</emphasis>.<indexterm id="idx-CHP-13-1016" significance="normal"><primary>transposons</primary></indexterm></para><para>Most of the currently functional parts of the genome are found in <indexterm id="idx-CHP-13-1017" significance="normal"><primary>genes</primary></indexterm>genes. Genes consist of regulatory elements that determine how much of the gene product will be made, and the code for the gene product itself. The regulation of genes is often quite complex. Different types of cells use different genes. The same cell type uses different genes in different situations.</para><para>The gene products are diverse, too. A large and important class of genes produce <emphasis>messenger RNA</emphasis> (<indexterm id="idx-CHP-13-1018" significance="normal"><primary>mRNA (messenger RNA)</primary></indexterm>mRNA), which is then translated into proteins. These proteins include the receptors molecules that let the cell sense the environment and interact with other cells, the enzymes that help convert food to more usable forms of energy, and the transcription factors that control the activity of other genes. Though it has not been an easy job, science has identified about 90 percent of the genes in the genome, over 20,000 genes in all.<indexterm id="idx-CHP-13-1019" significance="normal"><primary>messenger RNA (mRNA)</primary></indexterm></para><para>Most scientific research projects are interested in just a few dozen of these genes. People researching a rare genetic disease examine the patterns of inheritance of the disease to link the disease to perhaps a 10,000,000-base region of a single chromosome. In recent years scientists have tried to associate 100,000-base regions with more common diseases such as diabetes that are partly but not entirely genetic in nature.</para><sect1 id="the_user_interface_of_the_gene_sorter" label="13.1"><title>The User Interface of the Gene Sorter</title><para>The Gene Sorter can collect all the known genes in disease-related regions of DNA into a list of candidate genes. This list is displayed in a table, illustrated in <xref linkend="main_page_of_the_gene_sorter"/>, that includes summary information on each gene and hyperlinks to additional information. The candidate list can be filtered to eliminate genes that are obviously not relevant, such as genes expressed only in the kidneys when the viewer is researching a genetic disease of the lungs. The Gene Sorter is also useful in other contexts where one wants to look at more than one gene at once, such as when one is studying genes that are expressed in similar ways or genes that have similar known functions. The Gene Sorter is available currently for the human, mouse, rat, fruit fly, and <emphasis>C. elegans</emphasis> genomes.<indexterm id="idx-CHP-13-1020" significance="normal"><primary>Gene Sorter</primary><secondary>user interface</secondary></indexterm><indexterm id="idx-CHP-13-1021" significance="normal"><primary>Gene Sorter</primary></indexterm></para><para>The controls on the top of the screen specify which version of which genome to use. The table underneath contains one row per gene.</para><figure id="main_page_of_the_gene_sorter" label="13-1" float="0"><title>Main page of the Gene Sorter</title><mediaobject id="I_mediaobject13_tt303"><imageobject role="print"><imagedata fileref="figs/print/beauty_1301.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1301.png" format="PNG"/></imageobject></mediaobject></figure><para>A separate configuration page controls which columns are displayed in the table and how they are displayed. A filter page can be used to filter out genes based on any combination of column values.<indexterm id="idx-CHP-13-1022" significance="normal"><primary>Gene Sorter</primary></indexterm></para><para>The table can be sorted a number of ways. In this case, it is sorted by proximity to the selected gene, SYP. SYP is a gene involved with the release of neurotransmitters.</para></sect1><sect1 id="maintaining_a_dialog_with_the_user_over_the_web" label="13.2"><title>Maintaining a Dialog with the User over the Web</title><para>The <indexterm id="idx-CHP-13-1023" significance="normal"><primary>CGI scripts</primary><secondary>Gene Sorter</secondary></indexterm>Gene Sorter is a CGI script. When the user points her web browser to the Gene Sorter's URL (<ulink url="http://genome.ucsc.edu/cgi-bin/hgNear"/>), the web server runs the script and sends the output over the network. The script's output is an HTML form. When the user hits a button on the form, the web browser sends a URL to the web server that includes the values in the drop-down menus and other controls encoded as a series of <replaceable>variable=value</replaceable> pairs. The web server runs the script once more, passing the <replaceable>variable=value</replaceable> pairs as input. The script then generates a new HTML form in response.<indexterm id="idx-CHP-13-1024" significance="normal"><primary>Gene Sorter</primary><secondary>dialog with user over the Web</secondary></indexterm></para><para>CGI scripts can be written in any language. The Gene Sorter script is actually a moderately large program written in C.</para><para>A CGI script has both <indexterm id="idx-CHP-13-1025" significance="normal"><primary>CGI scripts</primary><secondary>advantages and disadvantages</secondary></indexterm>advantages and disadvantages compared to other programs that interact with users on the desktop. CGI scripts are quite portable and do not need different versions to support users on Windows, Macintosh, and Linux desktops. On the other hand, their interactivity is only modest. Unless one resorts to JavaScript (which introduces serious portability issues of its own), the display will be updated only when the user presses a button and waits a second or two for a new web page. However, for most genomic purposes, CGI provides an acceptably interactive and very standard user interface.</para><para>The <indexterm id="idx-CHP-13-1026" significance="normal"><primary>CGI scripts</primary><secondary>lifetime</secondary></indexterm>lifetime of a <indexterm id="idx-CHP-13-1027" significance="normal"><primary>cookies</primary><secondary>CGI script data storage</secondary></indexterm>CGI script is very limited. It starts in response to the user clicking on something and finishes when it generates a web page. As a consequence, the script can't keep <indexterm id="idx-CHP-13-1028" significance="normal"><primary>CGI scripts</primary><secondary>long-term data storage</secondary></indexterm>long-term information in program variables. For very simple <indexterm id="idx-CHP-13-1029" significance="normal"><primary>variables</primary><secondary>CGI</secondary></indexterm>CGI scripts, all of the necessary information is stored in the <replaceable>variable=value</replaceable> pairs (also known as <emphasis>CGI variables</emphasis>).</para><para>However, for more complex scripts such as the <indexterm id="idx-CHP-13-1030" significance="normal"><primary>Gene Sorter</primary></indexterm>Gene Sorter, this is not sufficient because the script might need to remember the result of a control that the user set several screens back, but the web server sends only the CGI variables corresponding to the controls in the most recently submitted page. Our CGI scripts therefore need a way to store data for the long term.</para><para>There are two mechanisms CGI provides for storing data not visible in a form's controls: <indexterm id="idx-CHP-13-1031" significance="normal"><primary>hidden CGI variables</primary></indexterm>hidden CGI variables and cookies. In a hidden CGI variable, the data is stored in the HTML in the form of <literal moreinfo="none">&lt;INPUT&gt;</literal> <indexterm id="idx-CHP-13-1032" significance="normal"><primary>&lt;INPUT&gt; tags (HTML) of type hidden</primary></indexterm>tags of type <literal moreinfo="none">hidden</literal>. With cookies, the data is stored by the web browser and sent in the HTTP header.</para><para>Cookies were somewhat controversial when they were first released, and some users would disable them. However, cookies can persist for years, while hidden variables disappear as soon as a web page is closed. Neither cookies nor hidden variable can store truly large amounts of data. The exact amount varies between web browsers, but generally it's not safe to try to save more than 4 KB of data via these mechanisms.</para><para>To exploit both cookies and hidden variables, the Gene Sorter team developed a "<indexterm id="idx-CHP-13-1033" significance="normal"><primary>cart object (Gene Sorter)</primary></indexterm>cart" object that integrates the cookie and hidden variable mechanisms with an <indexterm id="idx-CHP-13-1034" significance="normal"><primary>SQL database</primary></indexterm>SQL database. The cart maintains two tables, one associated with a user and one associated with a web session. The tables are of the same format, consisting of a key column, a blob field containing all of the <replaceable>variable=valuepairs</replaceable> in the same format they are passed in the URL, and fields that track the usage times and access counts.</para><para>A <indexterm id="idx-CHP-13-1035" significance="normal"><primary>cookies</primary><secondary>key into user table for Gene Sorter</secondary></indexterm>key into the user table is kept in a persistent cookie, and a <indexterm id="idx-CHP-13-1036" significance="normal"><primary>hidden CGI variables</primary><secondary>key into session table for Gene Sorter</secondary></indexterm>key into the session table is kept in a hidden CGI variable. On startup, the script looks for the <indexterm id="idx-CHP-13-1037" significance="normal"><primary>user key for Gene Sorter</primary></indexterm>user key in a cookie. If it finds it, it loads the associated <replaceable>variable=value</replaceable> pairs into a hash table. If it doesn't find the cookie, it generates a new user key, and the hash table remains empty.</para><para>Next, the script looks for the <indexterm id="idx-CHP-13-1038" significance="normal"><primary>session key</primary></indexterm>session key and loads the variables from it, replacing any variables that are already in the hash. Finally, any new CGI variables are loaded on top of whatever is in hash.</para><para>A series of library routines allows the script to read and write variables in the cart's hash. As the script exits, it updates the database tables with the current contents of the cart. If the user does not have cookies enabled, he will still be able to interact with Gene Sorter during a single session because the session key is not kept in cookies. Separating the session from the user keys also lets the user have the Gene Sorter going in two separate windows, without the two windows interfering with each other. The user level of the cart allows the Gene Sorter to start up in the same place it was last used, even after the user has moved onto another site in the meantime.</para><para>In the <indexterm id="idx-CHP-13-1039" significance="normal"><primary>Gene Sorter</primary><secondary>genome.ucsc.edu implementation</secondary></indexterm><ulink url="http://genome.ucsc.edu">genome.ucsc.edu</ulink> implementation of the <indexterm id="idx-CHP-13-1040" significance="normal"><primary>Gene Sorter</primary></indexterm>Gene Sorter, all of the CGI scripts on the site share the same cart. Thus, the cart contains variables that are even more global than normal program variables. This is often useful. If the user is focusing on the mouse genome rather than the human genome in one of our programs, she probably wants to be using the mouse on other programs as well.</para><para>However, as our programs have grown, to avoid inadvertent <indexterm id="idx-CHP-13-1041" significance="normal"><primary>cart variables (Gene Sorter)</primary><secondary>avoiding name conflicts</secondary></indexterm>name conflicts between cart variables, we have adopted the convention that cart variables (unless they truly are meant to be global) start with the name of the CGI script that uses them. Thus, most of the Gene <indexterm id="idx-CHP-13-1042" significance="normal"><primary>Sorter</primary></indexterm>Sorter's cart variables start with <literal moreinfo="none">hgNear_</literal>. (We use the underline character rather than a period as a separator because the period would interfere with JavaScript.)</para><para>All in all, the cart makes it relatively straightforward for the Gene Sorter to maintain the illusion of continuity to users, even though a separate instance of the program runs on each user click.</para><para>The <indexterm id="idx-CHP-13-1043" significance="normal"><primary>CGI scripts</primary><secondary>short lifetime</secondary></indexterm>short lifetime of a CGI script does have some advantages. In particular, a CGI script does not need to worry much about memory leaks and closing files because these are all cleaned up by the operating system on program exit. This is particularly nice in the C language, which does not have automatic resource management.</para></sect1><sect1 id="a_little_polymorphism_can_go_a_long_way" label="13.3"><title>A Little Polymorphism Can Go a Long Way</title><para>Inside most programs of any flexibility, there is likely to be a <indexterm id="idx-CHP-13-1044" significance="normal"><primary>C language</primary><secondary>polymorphic object</secondary></indexterm>polymorphic object of some sort. The table that takes up most of the main page of the Gene Sorter is composed of a series of <indexterm id="idx-CHP-13-1045" significance="normal"><primary>objects</primary><secondary>polymorphic</secondary></indexterm>polymorphic column objects.<indexterm class="startofrange" id="idx-CHP-13-1046" significance="normal"><primary>Gene Sorter</primary><secondary>polymorphism</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-13-1047" significance="normal"><primary>polymorphism in Gene Sorter</primary></indexterm></para><para>Making polymorphic objects in C is not as easy as it is in more modern object-oriented languages, but it can be done in a relatively straightforward manner using a <literal moreinfo="none">struct</literal> in place of an object, and function pointers in place of polymorphic methods. <xref linkend="the_column_structure_a_polymorphic_object_in_c"/> shows a somewhat abbreviated version of the C code for the column object.</para><example id="the_column_structure_a_polymorphic_object_in_c" label="13-1"><title>The column structure, a polymorphic object in C</title><programlisting format="linespecific">
struct column
/* A column in the big table. The central data structure for
 * hgNear. */
   {
   /* Data set guaranteed to be in each column. */
   struct column *next;   /* Next column in list. */
   char *name;            /* Column name, not seen by user. */
   char *shortLabel;      /* Column label. */
   char *longLabel;       /* Column description. */

   /* -- Methods -- */
   void (*cellPrint)(struct column *col, struct genePos *gp,
        struct sqlConnection *conn);
   /* Print one cell of this column in HTML. */

   void (*labelPrint)(struct column *col);
   /* Print the label in the label row. */
   void (*filterControls)(struct column *col,
        struct sqlConnection *conn);
   /* Print <indexterm id="idx-CHP-13-1048" significance="normal"><primary>polymorphism in Gene Sorter</primary></indexterm>out controls for advanced filter. */

   struct <indexterm id="idx-CHP-13-1049" significance="normal"><primary>Gene Sorter</primary></indexterm>genePos *(*advFilter)(struct column *col,
        struct sqlConnection *conn,
   /* Return list of positions for advanced filter. */

   /* Lookup tables use the next few fields. */
   char *table;                 /* Name of associated table. */
   char *keyField;              /* GeneId field in associated table. */
   char *valField;              /* Value field in associated table. */

   /* Association tables use these as well as the lookup fields. */
   char *queryFull;      /* Query that returns 2 columns key/value. */
   char *queryOne;       /* Query that returns value, given key. */
   char *invQueryOne;    /* Query that returns key, given value. */
   };
</programlisting></example><para>The structure starts with data shared by all types of columns. Next come the <indexterm id="idx-CHP-13-1050" significance="normal"><primary>objects</primary><secondary>polymorphic</secondary></indexterm>polymorphic methods. Finally, there's a section containing type-specific data.</para><para>Each column object contains space for the data of all types of columns. It would be possible, using a union or some related mechanism, to avoid this waste of space. However, this would complicate the use of the type-specific fields, and because there are fewer than 100 columns, the total space saved would be no more than a few kilobytes.</para><para>Most of the functionality of the program resides in the column methods. A column knows how to retrieve data for a particular gene either as a string or as HTML. A column can search for genes where the column data fits a simple search string. The columns also implement the interactive controls to filter data, and the routine to do the filtering itself.</para><para>The columns are created by a factory routine based on information in the <emphasis>columnDb.ra</emphasis> files. An excerpt of one of these files is shown in <xref linkend="a_section_of_a_columndbra_file_containing_metadata_on_the_colum"/>. All <literal moreinfo="none">columnDb</literal> records contain fields describing the column name, user-visible short and long labels, the default location of the column in the table (priority), whether the column is visible by default, and a type field. The type field controls what methods the column has. There may be additional fields, some of which are type-specific. In many cases, the SQL used to query the tables in the database associated with a column is included in the <literal moreinfo="none">columnDb</literal> record, as well as a URL to hyperlink to each item in the column.<indexterm id="idx-CHP-13-1051" significance="normal"><primary>columnDb.ra files</primary></indexterm></para><example id="a_section_of_a_columndbra_file_containing_metadata_on_the_colum" label="13-2"><title>A section of a columnDb.ra file containing metadata on the columns</title><programlisting format="linespecific">
name proteinName
shortLabel UniProt
longLabel UniProt (SwissProt/TrEMBL) Protein Display ID
priority 2.1
visibility off
type association kgXref
queryFull select kgID,spDisplayID from kgXref
queryOne select spDisplayId,spID from kgXref where kgID = '%s'
<indexterm id="idx-CHP-13-1052" significance="normal"><primary>polymorphism in Gene Sorter</primary></indexterm>invQueryOne select kgID from kgXref where spDisplayId = '%s'
search fuzzy
itemUrl http://us.expasy.org/cgi-bin/niceprot.pl?%s

name proteinAcc
shortLabel UniProt Acc
longLabel UniProt (SwissProt/TrEMBL) Protein Accession
priority 2.15
visibility off
type <indexterm id="idx-CHP-13-1053" significance="normal"><primary>lookup type (Gene Sorter columns)</primary></indexterm>lookup kgXref kgID spID
search exact
itemUrl http://us.expasy.org/cgi-bin/niceprot.pl?%s

name refSeq
shortLabel RefSeq
longLabel NCBI RefSeq Gene Accession
priority 2.2
visibility off
type lookup knownToRefSeq name value
search exact
itemUrl http://www.ncbi.nlm.nih.gov/entrez/query.
fcgi?cmd=Search&amp;db=Nucleotide&amp;term=%s&amp;doptcmdl=GenBank&amp;tool=genome.ucsc.edu
</programlisting></example><para>The format of a <emphasis>columnDb.ra</emphasis> file is simple: one field per line, and records separated <indexterm id="idx-CHP-13-1054" significance="normal"><primary>hashes</primary><secondary>constructed by code reading columnDb</secondary></indexterm>by blank lines. Each line begins with the field name, and the remainder of the line is the field value.</para><para>This simple, line-oriented format is used for a lot of the metadata at <ulink url="http://genome.ucsc.edu">genome.ucsc.edu</ulink>. At one point, we considered using indexed versions of these files as an alternative to a relational database (<emphasis>.ra</emphasis> stands for relational alternative). But there are a tremendous number of good tools associated with relational databases, so we decided keep the bulk of our data relational. The <emphasis>.ra</emphasis> files are very easy to read, edit, and parse, though, so they see continued use in applications such as these.</para><para>The <emphasis>columnDb.ra</emphasis> files are arranged in a three-level directory hierarchy. At the root lies information about <indexterm id="idx-CHP-13-1055" significance="normal"><primary>columns (Gene Sorter)</primary></indexterm>columns that appear for all organisms. The mid-level contains information that is organism-specific. As our understanding of a particular organism's genome progresses, we'll have different assemblies of its DNA sequence. The lowest level contains information that is assembly-specific.</para><para>The code that reads a <literal moreinfo="none">columnDb</literal> constructs a hash of hashes, where the outer hash is keyed by the column name and the inner hashes are keyed by the field name. Information at the lower levels can contain entirely new records, or add or override particular fields of records first defined at a higher level.</para><para>Some types of columns correspond very directly to columns in the relational database. The <literal moreinfo="none">lookup</literal> type columns refer to a table that contains an indexed gene ID field with no more than one row per gene ID. The <literal moreinfo="none">type</literal> line contains the table, the gene ID field, and the field displayed by the column. The <literal moreinfo="none">proteinAcc</literal> and <literal moreinfo="none">refSeq</literal> columns in <xref linkend="a_section_of_a_columndbra_file_containing_metadata_on_the_colum"/> are examples of type lookup.</para><para>If the relational table can <indexterm id="idx-CHP-13-1056" significance="normal"><primary>polymorphism in Gene Sorter</primary></indexterm>contain more than one row per gene, its type becomes <literal moreinfo="none">association</literal>. <indexterm id="idx-CHP-13-1057" significance="normal"><primary>associations (Gene Sorter columns)</primary></indexterm>Associations with multiple values for a single gene are displayed as a comma-separated list in the <indexterm id="idx-CHP-13-1058" significance="normal"><primary>Gene Sorter</primary></indexterm>Gene Sorter. Associations include the SQL <indexterm id="idx-CHP-13-1059" significance="normal"><primary>SQL</primary><secondary>code to fetch data for Gene Sorter association columns</secondary></indexterm>code to fetch the data either one gene at a time (<literal moreinfo="none">queryOne</literal>), for all genes (<literal moreinfo="none">queryFull</literal>), or for the genes associated with a particular value (<literal moreinfo="none">invQueryOne</literal>). The <literal moreinfo="none">queryOne</literal> SQL actually returns two values, one to display in the Gene Sorter and another to use in the hyperlink, although these can be the same.</para><para>Most of the columns in the Gene Sorter are of type <literal moreinfo="none">lookup</literal> or <literal moreinfo="none">association</literal>, and given any relational table that is keyed by gene ID, it is a simple matter to make it into Gene Sorter columns.</para><para>Other columns, such as the gene expression columns, are relatively complex. <xref linkend="main_page_of_the_gene_sorter"/> shows a gene expression column as colored boxes underneath the names of various organs such as brain, liver, kidney, etc. The colors indicate how much of the mRNA for the gene is found in these specific organs in comparison to the level of mRNA in the body as a whole. Red indicates a higher-than-average expression, green a lower-than-average expression, and black an average expression level.</para><para>The entire set of gene expression information from fetal brain to testis in <xref linkend="main_page_of_the_gene_sorter"/> is considered a single Gene Sorter column. It's broken into three columns from the HTML table point of view, to provide the gray lines <indexterm id="idx-CHP-13-1060" significance="normal"><primary>cart variables (Gene Sorter)</primary><secondary>communication between column filtering methods</secondary></indexterm>between groups of five organs for better readability.</para></sect1><sect1 id="filtering_down_to_just_the_relevant_genes" label="13.4"><title>Filtering Down to Just the Relevant Genes</title><para><indexterm id="idx-CHP-13-1061" significance="normal"><primary>filters</primary></indexterm>Filters are one of the most powerful features of the gene sorter. Filters can be applied to each of the columns in order to view just the genes relevant to a particular purpose. For instance, a filter on the gene expression column can be used to find genes that are expressed in the brain but not in other tissues. A filter on the genome position can find genes on the X chromosome. A combination of these filters could find brain-specific genes found on the X chromosome. These genes would be particularly interesting to researchers on autism, since that condition appears to be to a fairly strong degree sex-linked.<indexterm id="idx-CHP-13-1062" significance="normal"><primary>gene expression columns (Gene Sorter)</primary><secondary>filtering</secondary></indexterm><indexterm id="idx-CHP-13-1063" significance="normal"><primary>columns (Gene Sorter)</primary><secondary>filtering</secondary></indexterm></para><para>Each column has two filter methods: <literal moreinfo="none">filterControls</literal> to write the HTML for the filter user interface and <literal moreinfo="none">advFilter</literal> to actually run the filter. These two methods communicate with each other through cart variables that use a naming convention that includes the program name, the letters <literal moreinfo="none">as</literal>, and the column name as prefixes to the specific variable name. In this way, different columns of the same type have different cart variables, and filter variables can be distinguished from other variables. A helpful routine named <literal moreinfo="none">cartFindPrefix</literal>, which returns a list of all variables with a given prefix, is heavily used by the filter system.<indexterm id="idx-CHP-13-1064" significance="normal"><primary>filterControls method (Gene Sorter columns)</primary></indexterm><indexterm id="idx-CHP-13-1065" significance="normal"><primary>advFilter method (Gene Sorter columns)</primary></indexterm></para><para>The filters are arranged as a chain. Initially, the program constructs a list of all genes. Next it checks the cart to see whether any filters are set. If so, it calls the filters for each column. The first filter gets the entire gene list as input. Subsequent filters start with the output of the previous filter. The order in which the filters are applied doesn't matter.<indexterm id="I_indexterm13_tt304" class="endofrange" startref="idx-CHP-13-1047" significance="normal"><primary>polymorphism in Gene Sorter</primary></indexterm><indexterm id="I_indexterm13_tt305" class="endofrange" startref="idx-CHP-13-1046" significance="normal"><primary>Gene Sorter</primary><secondary>polymorphism</secondary></indexterm></para><para>The filters are the most speed-critical <indexterm id="idx-CHP-13-1066" significance="normal"><primary>understandable code</primary></indexterm>code in the <indexterm id="idx-CHP-13-1067" significance="normal"><primary>Gene Sorter</primary></indexterm>Gene Sorter. Most of the code is executed on just 50 or 100 <indexterm id="idx-CHP-13-1068" significance="normal"><primary>hashes</primary><secondary>filtered genes in Gene Sorter</secondary></indexterm>genes, but the filters work on tens of thousands. To keep good interactive response time, the filter should spend less than 0.0001 of a second per gene. A modern CPU operates so fast that generally 0.0001s is not much of a limitation. However, a disk seek still takes about 0.005s, so the filter must avoid causing seeks.</para><para>Most filters start by checking the cart to see whether any of their variables are set, and if not, just quickly return the input list unchanged. Next, the filters read the tables associated with a column. Reading the entire table avoids potentially causing a disk seek for each item, and while it is slower if just processing a few genes, it is much faster when processing a large set of genes.</para><para>Genes that pass the filter are put into a hash, keyed by gene ID. Finally, the filter calls a routine named <literal moreinfo="none">weedUnlessInHash</literal> that loops through each gene in the input to see whether it is in the hash and, if so, copies the gene to the output. The net result is a fast and flexible system in a relatively small amount of code.</para></sect1><sect1 id="theory_of_beautiful_code_in_the_large" label="13.5"><title>Theory of Beautiful Code in the Large</title><para>The Gene Sorter is one of the more beautiful programs at the design and code level that I've worked on. Most of the major parts of the system, including the cart, the directory of <emphasis>.ra</emphasis> riles, and the interface to the genomics database, are on their second or third iterations and incorporate lessons we learned from previous programs. The structure of the program's objects nicely parallels the major components of the user interface and the relational databases. The algorithms used are simple but effective, and make good trade-offs between speed, memory usage, and code complexity. The program has had very few bugs compared to most programs its size. Other people are able to come up to speed on the code base and contribute to it relatively quickly.<indexterm class="startofrange" id="idx-CHP-13-1069" significance="normal"><primary>Gene Sorter</primary><secondary>beautiful code</secondary></indexterm></para><para>Programming is a human activity, and perhaps the resource that <indexterm id="idx-CHP-13-1070" significance="normal"><primary>understandable code</primary><secondary>limits of human memory</secondary></indexterm>limits us most when programming is our <indexterm id="idx-CHP-13-1071" significance="normal"><primary>human memory</primary></indexterm>human memory. We can typically keep a half-dozen things in our short-term memory. Any more than that requires us to involve our long-term memory as well. Our long-term memory system actually has an amazingly large capacity, but we enter things into it relatively slowly, and we can't retrieve things from it randomly, only by association.</para><para>While the structure of a program of no more than a few hundred lines can be dictated by algorithmic and machine considerations, the structure of larger programs must be dictated by human considerations, at least if we expect humans to work productively to maintain and extend them in the long term.</para><para>Ideally, everything that you need to understand a piece of code should fit on a single screen. If not, the reader of the code will be forced at best to hop around from screen to screen in hopes of understanding the code. If the code is complex, the reader is likely to have forgotten what is defined on each screen by the time he gets back to the initial screen, and will actually have to <emphasis>memorize</emphasis> large amounts of the code before he can understand any part of it. Needless to say, this will slow down programmers, and many of them will find it frustrating as well.</para><para><indexterm id="idx-CHP-13-1072" significance="normal"><primary>names</primary><secondary>well-chosen</secondary></indexterm>Well-chosen names are very important to making <indexterm id="idx-CHP-13-1073" significance="normal"><primary>Gene Sorter</primary><secondary>beautiful code</secondary></indexterm>code locally <indexterm id="idx-CHP-13-1074" significance="normal"><primary>understandable code</primary></indexterm>understandable. It's OK to have a few local variables (no more than can fit in short-term memory) with one- and two-letter names. All other names should be words, short phrases, or commonly used (and short) abbreviations. In most cases, the reader should be able to tell the purpose of a variable or <indexterm id="idx-CHP-13-1075" significance="normal"><primary>Gene Sorter</primary><secondary>beautiful code</secondary><tertiary>function filtering associations that handles wildcards</tertiary></indexterm>function just from its name.</para><para>These days, with our fancy integrated development environments, the reader can, at the click of a mouse, go from where a symbol is used to where it is defined. However, we want to write our code so that the user needs to go to the symbol definition only when she is curious about the details. We shouldn't force her to follow a couple of hyperlinks to understand each line.</para><para>Names can be too long as well as too short, though most programmers, influenced by the mathematical descriptions of algorithms and such evils as Hungarian notation, err on the short side. It may take some time to come up with a good name, but it is time well spent.</para><para>For a local variable, a <indexterm id="idx-CHP-13-1076" significance="normal"><primary>understandable code</primary><secondary>well-chosen names</secondary></indexterm>well-chosen name may be sufficient documentation. Thus, <xref linkend="the_filter_method_for_association_type_columns_that_handle_wild"/> shows a reasonably nicely done function from the <indexterm id="idx-CHP-13-1077" significance="normal"><primary>Gene Sorter</primary></indexterm>Gene Sorter. It filters associations according to criteria that can contain wildcards. (There is also a simpler, faster method that handles only exact matches.) The code fits on one screen, which is always a virtue in a function, though not always possible.</para><example id="the_filter_method_for_association_type_columns_that_handle_wild" label="13-3"><title>The filter method for association type columns that handle wildcards</title><programlisting format="linespecific">
static struct genePos *wildAssociationFilter(
        struct slName *wildList, boolean orLogic. struct column *col,
        struct sqlConnection *conn, struct genePos *list)
/* Filter associations that match any of a list of wildcards. */
{
/* Group associations by gene ID. */
struct assocGroup *ag = assocGroupNew(16);
struct sqlResult *sr = sqlGetResult(conn, col-&gt;queryFull);
char **row;
while ((row = sqlNextRow(sr)) != NULL)
    assocGroupAdd(ag, row[0], row[1]);
sqlFreeResult(&amp;sr);

/* Look for matching associations and put them on passHash. */
struct hash *passHash = newHash(16); /* Hash of items passing filter */
struct genePos *gp;
for (gp = list; gp != NULL; gp = gp-&gt;next)
    {
    char *key = (col-&gt;protKey ? gp-&gt;protein : gp-&gt;name);
    struct assocList *al = hashFindVal(ag-&gt;listHash, key);
    if (al != NULL)
        {
        if (wildMatchRefs(wildList, al-&gt;list, orLogic))
            hashAdd(passHash, gp-&gt;name, gp);
        }
    }
/* Build up filtered list, clean up, and go home. */
list = weedUnlessInHash(list, passHash);
hashFree(&amp;passHash);
assocGroupFree(&amp;ag);
return list;
}
</programlisting></example><para>The function prototype is followed by a one-sentence comment that summarizes what the function does. The <indexterm id="idx-CHP-13-1078" significance="normal"><primary>Gene Sorter</primary><secondary>beautiful code</secondary></indexterm>code within the function is broken into "paragraphs," each starting with a comment summarizing what the block does in English.</para><para>Programmers can read this function at several different levels of details. For some, the name itself tells them all they need. Others will want to read the opening comment as well. Still others will read all the comments, ignoring the code. Those interested in the full details will read every line.</para><para>Because human memory is so strongly associative, once a reader has read the function at one level of detail, reading it at a higher level will <indexterm id="idx-CHP-13-1079" significance="normal"><primary>Gene Sorter</primary></indexterm>generally be enough to recall the more detailed levels. This happens in part because the higher levels form a framework for organizing your memory of the function even as you are reading the lower levels.</para><para>In general, the larger the programming entity, the more <indexterm id="idx-CHP-13-1080" significance="normal"><primary>documentation</primary></indexterm>documentation it deserves. A variable needs at least a word, a function at least a sentence, and larger entities such as modules or objects perhaps a paragraph. It's very helpful if a program as a whole can have a few pages of <indexterm id="idx-CHP-13-1081" significance="normal"><primary>understandable code</primary><secondary>documentation</secondary></indexterm>documentation providing an overview.</para><para>It's possible to have too much documentation as well as too little. Documentation is of no use if people don't read it, and people tend to avoid reading long text, especially if it is repetitious.</para><para>Humans tend to remember the important things best, though a few people are blessed (or cursed) with a good memory for trivia. The words used in a programming name are important, but whether the style is <replaceable>varName, VarName, varname, var_name, VARNAME, vrblnam</replaceable>, or <replaceable>Variable_Name</replaceable> is not so important. What is important is that a <indexterm id="idx-CHP-13-1082" significance="normal"><primary>names</primary><secondary>single style convention</secondary></indexterm>single convention be adopted and followed consistently, so that the programmer need not waste time and memory remembering which style is used in any particular case.</para><para>Other keys to keeping code <indexterm id="idx-CHP-13-1083" significance="normal"><primary>understandable code</primary></indexterm>understandable are:</para><itemizedlist><listitem><para>Use a <indexterm id="idx-CHP-13-1084" significance="normal"><primary>understandable code</primary><secondary>using scope as local as possible</secondary></indexterm>scope as local as possible. Never use a global variable when an object variable will do, and never use an object variable when a local variable will do.</para></listitem><listitem><para>Minimize <indexterm id="idx-CHP-13-1085" significance="normal"><primary>understandable code</primary><secondary>minimizing side effects</secondary></indexterm>side effects. In particular, avoid <emphasis>altering</emphasis> any variables except the return value in a function. A function that obeys this rule is called "<indexterm id="idx-CHP-13-1086" significance="normal"><primary>reentrant functions</primary></indexterm>reentrant," and is a thing of beauty. Not only is it easy to understand, it is automatically thread-safe and capable of being used recursively. Beyond readability, code with few side effects is easier to reuse in different contexts.</para></listitem></itemizedlist><para>These days, many programmers are well aware of the negative impact of global variables on code reuse. Another thing that can discourage code reuse is dependence on data structures. The object-oriented programming style sometimes can end up backfiring in this regard. If useful code is embedded in an object method, one must construct an object to use the code. For some objects, this task can be pretty complex.</para><para>A function that is not embedded in an object, and which takes as parameters standard data types, is a lot more likely to be used in many different contexts than a method deeply embedded in a complex object hierarchy. For instance, the previously mentioned <literal moreinfo="none">weedUnlessInHash</literal> function, although written for use by the column object in the Gene Sorter, was designed not to depend on being in a column. So, this useful little function may see application in other contexts now as well.</para></sect1><sect1 id="conclusion-id005" label="13.6"><title>Conclusion</title><para>This chapter has been about one of the prettier pieces of code I've written. The program serves a useful purpose for biomedical researchers. The cart system makes it relatively easy to construct an interactive program over the Web, even though it uses a CGI interface. Both the user's model and the programmer's model of the program revolve around the idea of a big table with one row per gene and a variable number of columns that can represent many different types of data.</para><para>Although the Gene Sorter is written in C, the column code is done in a straightforward, polymorphic, object-oriented design. Additional columns can be added by editing simple text files with no additional programming required, and these same files help make it easy for a single version of the program to work on different genomic databases associated with a variety of organisms.</para><para>The design minimizes disk seeks, which continue to be a bottleneck, lagging CPU and memory speeds by a large margin. The code is written to be readable and reusable. I hope you will find some of the principles it is built on useful in your own programs.<indexterm id="I_indexterm13_tt306" class="endofrange" startref="idx-CHP-13-1014" significance="normal"><primary>Gene Sorter</primary></indexterm><indexterm id="I_indexterm13_tt307" class="endofrange" startref="idx-CHP-13-1069" significance="normal"><primary>Gene Sorter</primary><secondary>beautiful code</secondary></indexterm></para></sect1></chapter><chapter id="how_elegant_code_evolves_with_hardware_the_case_of_gaussian_eli" label="14" role=""><title>How Elegant Code Evolves with Hardware The Case of Gaussian Elimination</title><para><emphasis>Jack Dongarra and Piotr Luszczek</emphasis><indexterm id="idx-CHP-14-1087" significance="normal"><primary>elegant code</primary></indexterm><indexterm id="idx-CHP-14-1088" significance="normal"><primary>hardware</primary></indexterm><indexterm class="startofrange" id="idx-CHP-14-1089" significance="normal"><primary>Gaussian elimination</primary></indexterm><indexterm id="idx-CHP-14-1090" significance="normal"><primary>Dongarra</primary></indexterm><indexterm id="idx-CHP-14-1091" significance="normal"><primary>Luszczek</primary></indexterm></para><para><emphasis>The increasing availability of advanced-architecture computers</emphasis>, at affordable costs, has had a significant effect on all spheres <indexterm id="idx-CHP-14-1092" significance="normal"><primary>linear algebra</primary><secondary>core of scientific computing calculations</secondary></indexterm>of scientific computation. In this chapter, we'll show the need for designers of computing algorithms to make expeditious and substantial adaptations to algorithms, in reaction to architecture changes, by closely examining one simple but important algorithm in mathematical <indexterm id="idx-CHP-14-1093" significance="normal"><primary>linear algebra</primary><secondary>software for advanced-architecture computers</secondary></indexterm>software: Gaussian elimination for the solution of linear systems of equations.</para><para>At the <indexterm id="idx-CHP-14-1094" significance="normal"><primary>application level</primary></indexterm>application level, science has to be captured in <indexterm id="idx-CHP-14-1095" significance="normal"><primary>mathematical models</primary></indexterm>mathematical models, which in turn are expressed algorithmically and ultimately encoded as software. At the software level, there is a continuous tension between performance and portability on the one hand, and understandability of the underlying code. We'll examine these issues and look at trade-offs that have been made over time. Linear algebra—in particular, the solution of linear systems of equations—lies at the heart of most calculations in scientific computing. This chapter focuses on some of the recent developments in linear algebra software designed to exploit advanced-architecture computers over the decades.</para><para>There are two broad classes of algorithms: those <indexterm id="idx-CHP-14-1096" significance="normal"><primary>algorithms</primary><secondary>for dense or sparse matrices</secondary></indexterm>for dense matrices and those for <indexterm id="idx-CHP-14-1097" significance="normal"><primary>sparse matrices</primary></indexterm>sparse matrices. A matrix is called <emphasis>sparse</emphasis> if it contains a substantial number of zero elements. For sparse matrices, radical savings in space and execution time can be achieved through specialized <indexterm id="idx-CHP-14-1098" significance="normal"><primary>storage and retrieval of data</primary></indexterm>storage and algorithms. To narrow our discussion and keep it simple, we will look only at the <emphasis>dense matrix problem</emphasis> (a dense matrix is defined as one with few zero elements).<indexterm id="idx-CHP-14-1099" significance="normal"><primary>dense matrix problem</primary></indexterm></para><para>Much of the work in developing linear algebra software for advanced-architecture computers is motivated by the need to solve large problems on the fastest computers available. In this chapter, we'll discuss the development of standards for linear algebra software, the building blocks for software libraries, and aspects of algorithm design as influenced by the opportunities for parallel implementation. We'll explain <indexterm id="idx-CHP-14-1100" significance="normal"><primary>linear algebra</primary><secondary>software for advanced-architecture computers</secondary><tertiary>motivation for development</tertiary></indexterm>motivations for this work, and say a bit about future directions.</para><para>As representative examples of dense matrix routines, we will consider <indexterm id="idx-CHP-14-1101" significance="normal"><primary>Gaussian elimination</primary></indexterm>Gaussian elimination, or <indexterm id="idx-CHP-14-1102" significance="normal"><primary>LU factorization</primary></indexterm>LU factorization. This examination, spanning <indexterm id="idx-CHP-14-1103" significance="normal"><primary>hardware</primary></indexterm>hardware and software advances over the past 30 years, will highlight the most important factors that must be considered in designing linear algebra software for advanced-architecture computers. We use these factorization routines for illustrative purposes not only because they are relatively simple, but also because of their importance in several scientific and engineering applications that make use of boundary element methods. These applications include electromagnetic scattering and computational fluid dynamics problems.</para><para>The past 30 years have seen a great deal of activity in the area of algorithms and software for solving linear algebra problems. The goal of achieving high performance in <indexterm id="idx-CHP-14-1104" significance="normal"><primary>elegant code</primary></indexterm>code that is portable across platforms has largely been realized by the identification of linear algebra kernels, the Basic Linear Algebra Subprograms (<indexterm id="idx-CHP-14-1105" significance="normal"><primary>BLAS (Basic Linear Algebra Subprograms)</primary></indexterm>BLAS). We will discuss the LINPACK, LAPACK, and ScaLAPACK libraries, which are expressed in successive levels of the BLAS. See the section "Further Reading" at the end of this chapter for discussions of these libraries.</para><sect1 id="the_effects_of_computer_architectures_on_matrix_algorithms" label="14.1"><title>The Effects of Computer Architectures on Matrix Algorithms</title><para>The key motivation in the design of efficient linear algebra algorithms for advanced-architecture computers involves the storage and <indexterm id="idx-CHP-14-1106" significance="normal"><primary>retrieval of data</primary></indexterm>retrieval of <indexterm id="idx-CHP-14-1107" significance="normal"><primary>data movement through the memory hierarchy</primary></indexterm>data. Designers wish to minimize the frequency with which data moves between different levels of the memory hierarchy. Once data is in registers or the fastest cache, all processing required for this data should be performed before it gets evicted back to the main memory. Thus, the main algorithmic approach for exploiting both <indexterm id="idx-CHP-14-1108" significance="normal"><primary>vectorization and parallelism</primary></indexterm>vectorization and parallelism in our implementations uses <emphasis>block-partitioned algorithms</emphasis>, particularly in conjunction with highly tuned kernels for performing matrix-vector and matrix-matrix operations (the <indexterm id="idx-CHP-14-1109" significance="normal"><primary>Level-2 BLAS</primary></indexterm>Level-2 and <indexterm id="idx-CHP-14-1110" significance="normal"><primary>Level-3 BLAS</primary></indexterm>Level-3 BLAS). Block partitioning means that the data is divided into blocks, each of which should fit within a cache memory or a vector register file.<indexterm id="idx-CHP-14-1111" significance="normal"><primary>elegant code</primary><secondary>effects of computer architectures on matrix algorithms</secondary></indexterm><indexterm id="idx-CHP-14-1112" significance="normal"><primary>computer architecture</primary></indexterm><indexterm id="idx-CHP-14-1113" significance="normal"><primary>matrix algorithms</primary></indexterm><indexterm id="idx-CHP-14-1114" significance="normal"><primary>block-partitioned algorithms</primary></indexterm></para><para>The <indexterm id="idx-CHP-14-1115" significance="normal"><primary>matrix algorithms</primary><secondary>computer architecture effects on</secondary></indexterm>computer architectures considered in this chapter are:</para><itemizedlist><listitem><para><indexterm id="idx-CHP-14-1116" significance="normal"><primary>vector machines</primary></indexterm>Vector machines</para></listitem><listitem><para>RISC computers <indexterm id="idx-CHP-14-1117" significance="normal"><primary>RISC computers</primary><secondary>with cache hierarchies</secondary></indexterm>with cache hierarchies</para></listitem><listitem><para><indexterm id="idx-CHP-14-1118" significance="normal"><primary>parallel systems with distributed memory</primary></indexterm>Parallel systems with distributed memory</para></listitem><listitem><para><indexterm id="idx-CHP-14-1119" significance="normal"><primary>multi-core systems</primary></indexterm>Multi-core computers</para></listitem></itemizedlist><para>Vector machines were introduced in the late 1970s and early 1980s. They were able in <indexterm id="idx-CHP-14-1120" significance="normal"><primary>multi-core systems</primary><secondary>effects on matrix algorithms</secondary></indexterm>one step to perform a single operation on a relatively large number of operands stored <indexterm id="idx-CHP-14-1121" significance="normal"><primary>chaining</primary><secondary>n vector machines</secondary></indexterm>in vector registers. <indexterm id="idx-CHP-14-1122" significance="normal"><primary>matrix algorithms</primary><secondary>expressing as vector-vector operations</secondary></indexterm>Expressing matrix <indexterm id="idx-CHP-14-1123" significance="normal"><primary>linear algebra</primary><secondary>algorithms recast as matrix-matrix operations</secondary></indexterm>algorithms as vector-vector operations was a natural fit for this type of machine. However, some of the vector designs had a limited ability to load and store the vector registers in main memory. A technique called <emphasis>chaining</emphasis> allowed this limitation to be circumvented by moving data between the registers before accessing main memory. Chaining required <indexterm id="idx-CHP-14-1124" significance="normal"><primary>matrix-vector operations</primary><secondary>recasting linear algebra in terms of</secondary></indexterm>recasting linear algebra in terms of matrix-vector operations.</para><para>RISC computers were introduced in the late 1980s and early 1990s. While their clock rates might have been comparable to those of the vector machines, the computing speed lagged behind due to their lack of vector registers. Another deficiency was their creation of a deep memory hierarchy with multiple levels of cache memory to alleviate the scarcity of band-width that was, in turn, caused mostly by a limited number of memory banks. The eventual success of this architecture is commonly attributed to the right price point and astonishing improvements in performance over time as predicted by Moore's Law. With RISC computers, the <indexterm id="idx-CHP-14-1125" significance="normal"><primary>matrix-matrix operations</primary><secondary>linear algebra algorithms recast as</secondary></indexterm>linear algebra algorithms had to be redone yet again. This time, the formulations had to expose as many matrix-matrix operations as possible, which guaranteed good cache reuse.</para><para>A natural way of achieving even greater performance levels with both vector and RISC processors is by connecting them together with a network and letting them cooperate to solve a problem bigger than would be feasible on just one processor. Many <indexterm id="idx-CHP-14-1126" significance="normal"><primary>hardware</primary></indexterm>hardware configurations followed this path, so the matrix algorithms had to follow yet again as well. It was quickly discovered that good local performance has to be combined with good global partitioning of the matrices and vectors.</para><para>Any trivial divisions of matrix data quickly uncovered scalability problems dictated by so-called <indexterm id="idx-CHP-14-1127" significance="normal"><primary>Amdahl's Law</primary></indexterm>Amdahl's Law: the observation that the time taken by the sequential portion of a computation provides the minimum bound for the entire execution time, and therefore limits the gains achievable from parallel processing. In other words, unless most computations can be done independently, the point of diminishing returns is reached, and adding more processors to the hardware mix will not result in faster processing.</para><para>For the sake of simplicity, the class of multi-core architectures includes both <indexterm id="idx-CHP-14-1128" significance="normal"><primary>symmetric multiprocessing (SMP) machines</primary></indexterm>symmetric multiprocessing (<indexterm id="idx-CHP-14-1129" significance="normal"><primary>SMP (symmetric multiprocessing) machines</primary></indexterm>SMP) and <indexterm id="idx-CHP-14-1130" significance="normal"><primary>single-chip multi-core machines</primary></indexterm>single-chip multi-core machines. This is probably an unfair simplification, as the SMP machines usually have better memory systems. But when applied to matrix algorithms, both yield good performance results with very similar algorithmic approaches: these combine local cache reuse and independent computation with explicit control of data dependences.</para></sect1><sect1 id="a_decompositional_approach" label="14.2"><title>A Decompositional Approach</title><para>At the basis of solutions to <indexterm id="idx-CHP-14-1131" significance="normal"><primary>dense linear systems</primary></indexterm>dense linear systems lies a decompositional approach. The general idea is the following: given a problem involving a matrix <emphasis>A</emphasis>, one factors or decomposes <emphasis>A</emphasis> into a product of simpler matrices from which the problem can easily be solved. This divides the computational problem into two parts: first determine an appropriate decomposition, and then use it in solving the problem at hand.<indexterm id="idx-CHP-14-1132" significance="normal"><primary>decompositional approach to solutions for dense linear systems</primary></indexterm></para><para>Consider the problem of solving the linear system:</para><programlisting id="I_programlisting14_tt308" format="linespecific">
	<replaceable>Ax = b</replaceable>
</programlisting><para>where <emphasis>A</emphasis> is a nonsingular matrix of order <emphasis>n</emphasis>. The decompositional approach begins with the observation that it is possible to factor <emphasis>A</emphasis> in the form:</para><programlisting id="I_programlisting14_tt309" format="linespecific">
	<replaceable>A = LU</replaceable>
</programlisting><para>where <emphasis>L</emphasis> is a lower triangular matrix (a matrix that has only zeros above the diagonal) with ones on the diagonal, and <emphasis>U</emphasis> is upper triangular (with only zeros below the diagonal). During the decomposition process, diagonal elements of <emphasis>A</emphasis> (called <indexterm id="idx-CHP-14-1133" significance="normal"><primary>pivots</primary></indexterm>pivots) are used to divide the elements below the diagonal. If matrix <emphasis>A</emphasis> has a zero pivot, the process will break with division-by-zero error. Also, small values of the pivots excessively amplify the numerical errors of the process. So for numerical stability, the method needs to interchange rows of the matrix or make sure pivots are as large (in absolute value) as possible. This observation leads to a row permutation matrix <emphasis>P</emphasis> and modifies the factored form to:</para><programlisting id="I_programlisting14_tt310" format="linespecific">
	<replaceable>P</replaceable><superscript>T</superscript> <replaceable>A = LU</replaceable>
</programlisting><para>The solution can then be written in the form:</para><programlisting id="I_programlisting14_tt311" format="linespecific">
	<replaceable>x = A</replaceable><superscript>-1</superscript><replaceable>Pb</replaceable>
</programlisting><para>which then suggests the following algorithm for solving the system of equations:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Factor <emphasis>A</emphasis></para></listitem><listitem><para>Solve the system <emphasis>Ly = Pb</emphasis></para></listitem><listitem><para>Solve the system <emphasis>Ux = y</emphasis></para></listitem></orderedlist><para>This approach to <indexterm id="idx-CHP-14-1134" significance="normal"><primary>matrix computations through decomposition</primary></indexterm>matrix computations through decomposition has proven very useful for several reasons. First, the approach separates the computation into two stages: the computation of a decomposition, followed by the use of the decomposition to solve the problem at hand. This can be important, for example, if different right hand sides are present and need to be solved at different points in the process. The matrix needs to be factored only once and reused for the different righthand sides. This is particularly important because the factorization of <emphasis>A</emphasis>, step 1, requires <emphasis>O(n<superscript>3</superscript>)</emphasis> operations, whereas the solutions, steps 2 and 3, require only <emphasis>O(n<superscript>2</superscript>)</emphasis> operations. Another aspect of the algorithm's strength is in storage: the <emphasis>L</emphasis> and <emphasis>U</emphasis> factors do not require extra storage, but can take over the space occupied initially by <emphasis>A</emphasis>.</para><para>For the discussion of coding this algorithm, we present only the computationally intensive part of the process, which is step 1, the factorization of the matrix.</para></sect1><sect1 id="a_simple_version" label="14.3"><title>A Simple Version</title><para>For the first version, we present a straightforward implementation of LU factorization. It consists of <emphasis>n–1</emphasis> steps, where each step introduces more zeros below the diagonal, as shown in <xref linkend="lu_factorization"/>.</para><figure id="lu_factorization" label="14-1" float="0"><title>LU factorization</title><mediaobject id="I_mediaobject14_tt312"><imageobject role="print"><imagedata fileref="figs/print/beauty_1401.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1401.png" format="PNG"/></imageobject></mediaobject></figure><para>A tool often used to teach <indexterm id="idx-CHP-14-1135" significance="normal"><primary>Gaussian elimination</primary></indexterm>Gaussian elimination is <indexterm id="idx-CHP-14-1136" significance="normal"><primary>MATLAB</primary></indexterm>MATLAB. It features a <indexterm id="idx-CHP-14-1137" significance="normal"><primary>scripting language (MATLAB)</primary></indexterm>scripting language (also called <indexterm id="idx-CHP-14-1138" significance="normal"><primary>Gaussian elimination</primary><secondary>MATLAB tool</secondary></indexterm>MATLAB) that makes developing matrix algorithms very simple. The language might seem very unusual to people familiar <indexterm id="idx-CHP-14-1139" significance="normal"><primary>matrix algorithms</primary><secondary>development with MATLAB</secondary></indexterm>with other scripting languages because it is oriented to process multidimensional arrays. The unique features of the language that we use in the example <indexterm id="idx-CHP-14-1140" significance="normal"><primary>elegant code</primary></indexterm>code are:</para><itemizedlist><listitem><para><indexterm id="idx-CHP-14-1141" significance="normal"><primary>transposition operator (')</primary></indexterm>Transposition operator for vectors and matrices: <indexterm id="idx-CHP-14-1142" significance="normal"><primary>' (single quote) transposition operator</primary></indexterm>' (single quote)</para></listitem><listitem><para>Matrix <indexterm id="idx-CHP-14-1143" significance="normal"><primary>indexing</primary></indexterm>indexing specified as:</para><para>— Simple integer values: <literal moreinfo="none">A(m, k)</literal></para><para>— Ranges: <literal moreinfo="none">A(k:n, k)</literal></para><para>— Other matrices: <literal moreinfo="none">A([k m], : )</literal></para></listitem><listitem><para>Built-in <indexterm id="idx-CHP-14-1144" significance="normal"><primary>matrix functions built into MATLAB</primary></indexterm>matrix functions such as <literal moreinfo="none">size</literal> (returns matrix dimensions), <literal moreinfo="none">tril</literal> (returns the lower triangular portion of the matrix), <literal moreinfo="none">triu</literal> (returns the upper triangular portion of the matrix), and <literal moreinfo="none">eye</literal> (returns an identity matrix, which contains only zero entries, except for the diagonal, which is all ones)</para></listitem></itemizedlist><para><xref linkend="simple_variant_matlab_coding"/> shows the <indexterm id="idx-CHP-14-1145" significance="normal"><primary>LU factorization</primary><secondary>simple implementation</secondary></indexterm>simple implementation.</para><example id="simple_variant_matlab_coding" label="14-1"><title>Simple variant (MATLAB coding)</title><programlisting format="linespecific">
function [L,U,p] = lutx(A)
%LUTX  Triangular factorization, textbook version
%   [L,U,p] = lutx(A) produces a unit lower triangular matrix L,
%   an upper triangular matrix U, and a permutation vector p,
%   so that L*U = A(p,:)

[n,n] = size(A);
p = (1:n)';
for k = 1:n-1

   % Find index 'm' of largest element 'r' below diagonal in k-th column
   [r,m] = max(abs(A(k:n,k)));
   m = m+k-1; % adjust 'm' so it becomes a global index

   % Skip <indexterm id="idx-CHP-14-1146" significance="normal"><primary>Gaussian elimination</primary></indexterm>elimination if column is zero
   if (A(m,k) ~= 0)

      % Swap pivot row
      if (m ~= k)
         A([k m],:) = A([m k],:); % swap rows 'k' and 'm' of 'A'
         p([k m]) = p([m k]);     % swap entrix 'k' and 'm' of 'p'
      end

      % Compute multipliers
      i = k+1:n;
      A(i,k) = A(i,k)/A(k,k);

      % Update the remainder of the matrix
      j = k+1:n;
      A(i,j) = A(i,j) - A(i,k)*A(k,j);
    end
 end

 % Separate result
 L = tril(A,-1) + eye(n,n);
 U = triu(A);
</programlisting></example><para>The algorithm presented in <xref linkend="simple_variant_matlab_coding"/> is row-oriented, in the sense that we are taking a scalar multiple of the "pivot" row and adding it to the rows below to introduce zeros below the diagonal. The beauty of the algorithm lies in its similarity to the mathematical notation. Hence, this is the preferred way of teaching the algorithm for the first time so that students can quickly turn formulas into running <indexterm id="idx-CHP-14-1147" significance="normal"><primary>elegant code</primary></indexterm>code.</para><para>This beauty, however, has its price. In the 1970s, <indexterm id="idx-CHP-14-1148" significance="normal"><primary>Fortran</primary></indexterm>Fortran was the language for scientific computations. Fortran stores two-dimensional arrays by column. Accessing the array in a row-wise fashion within the matrix could involve successive memory reference to locations separated from each other by a large increment, depending on the size of the declared array. The situation was further complicated by the operating system's use of memory pages to effectively control memory usage. With a large matrix and a row-oriented algorithm in a Fortran environment, an excessive number of page swaps might be generated in the process of running the software. Cleve Moler pointed this out in the 1970s (see "Further Reading" at the end of this chapter).</para><para>To avoid this situation, one needed simply to interchange the order of the innermost nested loops on <emphasis>i</emphasis> and <emphasis>j</emphasis>. This simple change resulted in more than 30 percent savings in wall-clock time to solve problems of size 200 on an IBM 360/67. Beauty was thus traded for efficiency by using a less obvious ordering of loops and a much more obscure (by today's standard) language.</para></sect1><sect1 id="linpacks_dgefa_subroutine" label="14.4"><title>LINPACK's DGEFA Subroutine</title><para>The performance issues with the MATLAB version of the <indexterm id="idx-CHP-14-1149" significance="normal"><primary>elegant code</primary></indexterm>code continued as, in the mid-1970s, vector architectures became available for scientific computations. Vector architectures exploit pipeline processing <indexterm id="idx-CHP-14-1150" significance="normal"><primary>vector-vector operations</primary><secondary>denoted by Level-1</secondary></indexterm>by running mathematical operations on arrays of data in a simultaneous or pipelined fashion. Most algorithms in linear algebra can be easily vectorized. Therefore, in the late 1970s there was an effort to standardize vector operations for use in scientific computations. The idea was to define some simple, frequently used operations and implement them on various systems to achieve portability and efficiency. This package came to be known as the Level-1 Basic Linear Algebra Subprograms (BLAS) or <indexterm id="idx-CHP-14-1151" significance="normal"><primary>Level-1 BLAS</primary></indexterm>Level-1 BLAS.<indexterm class="startofrange" id="idx-CHP-14-1152" significance="normal"><primary>LINPACK</primary></indexterm></para><para>The term <emphasis>Level-1</emphasis> denotes vector-vector operations. As we will see, Level-2 (matrix-vector operations), and Level-3 (matrix-matrix operations) play important roles as well.</para><para>In the 1970s, the algorithms of dense linear algebra were implemented in a systematic way by the <indexterm class="startofrange" id="idx-CHP-14-1153" significance="normal"><primary>elegant code</primary><secondary>LINPACK DGEFA subroutine</secondary></indexterm>LINPACK project. <indexterm id="idx-CHP-14-1154" significance="normal"><primary>Fortran</primary><secondary>LINPACK package</secondary></indexterm>LINPACK is a collection of Fortran subroutines that analyze and solve linear equations and linear least-squares problems. The package solves linear systems whose matrices are general, banded, symmetric indefinite, symmetric positive definite, triangular, and tridiagonal square. In addition, the package computes the QR and singular value decompositions of rectangular matrices and applies them to least-squares problems.</para><para>LINPACK uses <indexterm id="idx-CHP-14-1155" significance="normal"><primary>column-oriented algorithms (LINPACK)</primary></indexterm>column-oriented algorithms, which increase efficiency by preserving locality of reference. By column orientation, we mean that the LINPACK code always references arrays down columns, not across rows. This is important since Fortran stores arrays in column-major order. This means that as one proceeds down a column of an array, the memory references proceed sequentially through memory. Thus, if a program references an item in a particular block, the next reference is likely to be in the same block.</para><para>The software in LINPACK was kept machine-independent partly through the introduction of the <indexterm id="idx-CHP-14-1156" significance="normal"><primary>BLAS (Basic Linear Algebra Subprograms)</primary><secondary>Level-1 BLAS</secondary></indexterm>Level-1 BLAS routines. Almost all of the computation was done by calling Level-1 BLAS. For each machine, the set of Level-1 BLAS would be implemented in a machine-specific manner to obtain high performance.</para><para><xref linkend="linpack_variant_fortran_coding"/> shows the LINPACK <indexterm id="idx-CHP-14-1157" significance="normal"><primary>LINPACK</primary><secondary>implementation of factorization</secondary></indexterm>implementation of factorization.</para><example id="linpack_variant_fortran_coding" label="14-2"><title>LINPACK variant (Fortran 66 coding)</title><programlisting format="linespecific">
      subroutine dgefa(a,lda,n,ipvt,info)
      integer lda,n,ipvt(1),info
      double precision a(lda,1)
      double precision t
      integer idamax,j,k,kp1,l,nm1
c
c
c     <indexterm id="idx-CHP-14-1158" significance="normal"><primary>Gaussian elimination</primary></indexterm>gaussian elimination with partial pivoting
c
     info = 0
     nm1 = n - 1
     if (nm1 .lt. 1) go to 70
     do 60 k = 1, nm1
        kp1 = k + 1 
c 
c       find l = pivot index
c 
        l = idamax(n-k+1,a(k,k),1) + k - 1
        ipvt(k) = l
c
c       zero pivot implies this column already triangularized
c
        if (a(l,k) .eq. 0.0d0) go to 40
c 
c       interchange if necessary
c
        if (l .eq. k) go to 10
           t = a(l,k)
           a(l,k) = a(k,k)
           a(k,k) = t
  10    continue
c
c       compute multipliers
c
        t = -1.0d0/a(k,k)
        call dscal(n-k,t,a(k+1,k),1)
c       
c       row <indexterm id="idx-CHP-14-1159" significance="normal"><primary>Gaussian elimination</primary></indexterm>elimination with column indexing
c
        do 30 j = kp1, n
           t = a(l,j)
           if (l .eq. k) go to 20
              a(l,j) = a(k,j)
              a(k,j)= t
  20        continue
            call daxpy(n-k,t,a(k+1,k),1,a(k+1,j),1)
  30      continue
       go to 50 
  40   continue
          info = k 
  50   continue
  60 continue
  70 continue
     ipvt(n) = n
     if (a(n,n) .eq. 0.0d0) info = n
     return
     end
</programlisting></example><para>The Level-1 BLAS subroutines DAXPY, DSCAL, and IDAMAX are <indexterm id="idx-CHP-14-1160" significance="normal"><primary>Level-1 BLAS</primary><secondary>use in LINPACK factorization</secondary></indexterm>used in the routine DGEFA. The main difference between <xref linkend="simple_variant_matlab_coding"/> and <indexterm id="idx-CHP-14-1161" significance="normal"><primary>LINPACK</primary></indexterm><xref linkend="linpack_variant_fortran_coding"/> (other than the programming language and the interchange of loop indexes) is the use of routine DAXPY to <indexterm id="idx-CHP-14-1162" significance="normal"><primary>elegant code</primary></indexterm>encode the inner loop of the method.</para><para>It was presumed that the <indexterm id="idx-CHP-14-1163" significance="normal"><primary>BLAS (Basic Linear Algebra Subprograms)</primary></indexterm>BLAS operations would be implemented in an efficient, machine-specific way suitable for the computer on which the subroutines were executed. On a vector computer, this could translate into a simple, single vector operation. This would avoid leaving the optimization up to the compiler and explicitly exposing a performance-critical operation.</para><para>In a sense, then, the beauty of the original <indexterm id="idx-CHP-14-1164" significance="normal"><primary>elegant code</primary></indexterm>code was regained with the use of a new vocabulary to describe the algorithms: the BLAS. Over time, the BLAS became a widely adopted standard and were most likely the first to enforce two key aspects of software: modularity and portability. Again, these are taken for granted today, but at the time they were not. One could have the cake of compact algorithm representation and eat it, too, because the resulting Fortran code was portable.</para><para>Most algorithms in linear algebra can be easily vectorized. However, to gain the most out of such architectures, simple <indexterm id="idx-CHP-14-1165" significance="normal"><primary>vector machines</primary><secondary>vectorization of linear algebra algorithms</secondary></indexterm>vectorization is usually not enough. Some vector computers are limited by having only one path between memory and the vector registers. This creates a bottleneck if a program loads a vector from memory, performs some arithmetic operations, and then stores the results. In order to achieve top performance, the scope of the vectorization must be expanded to facilitate chaining operations together and to minimize data movement, in addition to using vector operations. <indexterm id="idx-CHP-14-1166" significance="normal"><primary>matrix-vector operations</primary><secondary>recasting linear algebra algorithms as</secondary></indexterm>Recasting the algorithms in terms of matrix-vector operations makes it easy for a vectorizing compiler to achieve these goals.</para><para>Thus, as computer architectures became more complex in the design of their memory hierarchies, it became necessary to increase the scope of the BLAS routines from Level-1 to Level-2 and Level-3.</para></sect1><sect1 id="lapack_dgetrf" label="14.5"><title>LAPACK DGETRF</title><para>As mentioned before, the introduction in the late 1970s and early 1980s of vector machines brought about the development of another variant of algorithms for dense linear algebra. This variant was centered on the multiplication of a matrix by a vector. These subroutines were meant to give improved performance over the dense linear algebra sub-routines in <indexterm id="idx-CHP-14-1167" significance="normal"><primary>LINPACK</primary></indexterm>LINPACK, which were based on Level-1 BLAS. Later on, in the late 1980s and early 1990s, with the introduction of RISC-type microprocessors (the "killer micros") and other machines with cache-type memories, we saw the development of <indexterm id="idx-CHP-14-1168" significance="normal"><primary>hardware, evolution of elegant code with</primary><secondary>effects of computer architecture on matrix algorithms</secondary><tertiary>LAPACK DGEFR subroutine</tertiary></indexterm>LAPACK Level-3 algorithms for dense linear algebra. A Level-3 code is typified by the main Level-3 BLAS, which, in this case, is matrix multiplication.<indexterm class="startofrange" id="idx-CHP-14-1169" significance="normal"><primary>elegant code</primary><secondary>LAPACK DGETRF subroutine</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-14-1170" significance="normal"><primary>LAPACK</primary></indexterm><indexterm id="I_indexterm14_tt313" class="endofrange" startref="idx-CHP-14-1152" significance="normal"><primary>LINPACK</primary></indexterm><indexterm id="I_indexterm14_tt314" class="endofrange" startref="idx-CHP-14-1153" significance="normal"><primary>elegant code</primary><secondary>LINPACK DGEFA subroutine</secondary></indexterm></para><para>The original goal of the LAPACK project was to make the widely used <indexterm id="idx-CHP-14-1171" significance="normal"><primary>elegant code</primary><secondary>LINPACK DGEFA subroutine</secondary></indexterm>LINPACK library run efficiently on vector and shared-memory parallel processors. On these machines, LIN-PACK is inefficient because its memory access patterns disregard the multilayered memory hierarchies of the machines, thereby spending too much time moving data instead of doing useful floating-point operations. LAPACK addresses this problem by reorganizing the algorithms to use block matrix operations, such as matrix multiplication, in the innermost loops (see the paper by E. Anderson and J. <indexterm id="idx-CHP-14-1172" significance="normal"><primary>Dongarra</primary></indexterm>Dongarra listed under "Further Reading"). These block operations can be optimized for each architecture to account for its memory hierarchy, and so provide a transportable way to achieve high efficiency on diverse modern machines.</para><para>Here, we use the term "transportable" instead of "portable" because, for fastest possible performance, <indexterm id="idx-CHP-14-1173" significance="normal"><primary>LAPACK</primary></indexterm>LAPACK requires that highly optimized block matrix operations be implemented already on each machine. In other words, the correctness of the <indexterm id="idx-CHP-14-1174" significance="normal"><primary>elegant code</primary></indexterm>code is portable, but high performance is not—if we limit ourselves to a single Fortran source code.</para><para><indexterm id="idx-CHP-14-1175" significance="normal"><primary>elegant code</primary><secondary>LAPACK DGETRF subroutine</secondary></indexterm>LAPACK can be regarded as a successor to LINPACK in terms of functionality, although it doesn't always use the same function-calling sequences. As such a successor, <indexterm id="idx-CHP-14-1176" significance="normal"><primary>hardware, evolution of elegant code with</primary><secondary>effects of computer architecture on matrix algorithms</secondary><tertiary>LAPACK DGEFR subroutine</tertiary></indexterm>LAPACK was a win for the scientific community because it could keep LINPACK's functionality while getting improved use out of new <indexterm id="idx-CHP-14-1177" significance="normal"><primary>hardware</primary></indexterm>hardware.</para><para><xref linkend="lapack_solution_factorization"/> shows the <indexterm id="idx-CHP-14-1178" significance="normal"><primary>LU factorization</primary><secondary>LAPACK solution</secondary></indexterm>LAPACK solution to <indexterm id="idx-CHP-14-1179" significance="normal"><primary>LAPACK</primary><secondary>LU factorization</secondary></indexterm>LU factorization.</para><example id="lapack_solution_factorization" label="14-3"><title>LAPACK solution factorization</title><programlisting format="linespecific">
SUBROUTINE DGETRF( M, N, A, LDA, IPIV, INFO )
      INTEGER            INFO, LDA, M, N
      INTEGER            IPIV( * )
      DOUBLE PRECISION   A( LDA, * )
      DOUBLE PRECISION   ONE
      PARAMETER          ( ONE = 1.0D+0 )
      INTEGER            I, IINFO, J, JB, NB
      EXTERNAL           DGEMM, DGETF2, DLASWP, DTRSM, XERBLA
      INTEGER            ILAENV
      EXTERNAL           ILAENV
      INTRINSIC          MAX, MIN
      INFO = 0
      IF( M.LT.0 ) THEN
         INFO = -1
      ELSE IF( N.LT.0 ) THEN
         INFO = -2
      ELSE IF( LDA.LT.MAX( 1, M ) ) THEN
         INFO = -4
      END IF
      IF( INFO.NE.0 ) THEN
         CALL XERBLA( 'DGETRF', -INFO )
         RETURN
      END IF
      IF( M.EQ.0 .OR. N.EQ.0 ) RETURN
      NB = ILAENV( 1, 'DGETRF', ' ', M, N, -1, -1 )
      IF( NB.LE.1 .OR. NB.GE.MIN( M, N ) ) THEN
         CALL DGETF2( M, N, A, LDA, IPIV, INFO )
      ELSE
         DO 20 J = 1, MIN( M, N ), NB
            JB = MIN( MIN( M, N )-J+1, NB )
*           Factor diagonal and subdiagonal blocks and test for exact
*           singularity.
            CALL DGETF2( M-J+1, JB, A( J, J ), LDA, IPIV( J ), IINFO )
*           Adjust INFO and the pivot indices.
            IF( INFO.EQ.0 .AND. IINFO.GT.0 ) INFO = IINFO + J - 1
            DO 10 I = J, MIN( M, J+JB-1 )
               IPIV( I ) = J - 1 + IPIV( I )
  10        CONTINUE
*           Apply interchanges to columns 1:J-1.
            CALL DLASWP( J-1, A, LDA, J, J+JB-1, IPIV, 1 )
*
            IF( J+JB.LE.N ) THEN
*              Apply interchanges to columns J+JB:N.
               CALL DLASWP( N-J-JB+1, A( 1, J+JB ), LDA, J, J+JB-1, IPIV, 1 )
*              Compute block row of U. 
               CALL <indexterm id="idx-CHP-14-1180" significance="normal"><primary>DTRSM routine</primary></indexterm>DTRSM( 'Left', 'Lower', 'No transpose', 'Unit', JB,
   $                       N-J-JB+1, ONE, A( J, J ), LDA, A( J, J+JB ), LDA )
               IF( J+JB.LE.M ) THEN
*                 Update trailing submatrix.
                  CALL <indexterm id="idx-CHP-14-1181" significance="normal"><primary>DGEMM routine</primary></indexterm>DGEMM( 'No transpose', 'No transpose', M-J-JB+1,
   $                         N-J-JB+1, JB, -ONE, A( J+JB, J ), LDA,
   $                         A( J, J+JB ), LDA, ONE, A( J+JB, J+JB ), LDA )
               END IF
            END IF
  20    CONTINUE
      END IF
      RETURN
      end
</programlisting></example><para>Most of the computational work in the algorithm from <xref linkend="lapack_solution_factorization"/> is contained in three routines:<indexterm id="idx-CHP-14-1182" significance="normal"><primary>LAPACK</primary></indexterm></para><variablelist><varlistentry><term><emphasis>DGEMM</emphasis></term><listitem><para>Matrix-matrix multiplication</para></listitem></varlistentry><varlistentry><term><emphasis>DTRSM</emphasis></term><listitem><para>Triangular solve with multiple righthand sides</para></listitem></varlistentry><varlistentry><term><emphasis>DGETF2</emphasis></term><listitem><para><indexterm id="idx-CHP-14-1183" significance="normal"><primary>NB (block size)</primary></indexterm>Unblocked LU factorization for operations within a block column<indexterm id="idx-CHP-14-1184" significance="normal"><primary>DGETF2 routine</primary></indexterm></para></listitem></varlistentry></variablelist><para>One of the key parameters in the algorithm is the <indexterm id="idx-CHP-14-1185" significance="normal"><primary>block size (NB)</primary></indexterm>block size, called NB here. If NB is too small or too large, poor performance can result—hence the importance of the ILAENV function, whose standard implementation was meant to be replaced by a vendor implementation encapsulating machine-specific parameters upon installation of the <indexterm id="idx-CHP-14-1186" significance="normal"><primary>elegant code</primary><secondary>LAPACK DGETRF subroutine</secondary></indexterm>LAPACK library. At any given point of the algorithm, NB columns or rows are exposed to a well-optimized Level-3 BLAS. If NB is 1, the algorithm is equivalent in performance and memory access patterns to the LINPACK's version.</para><para>Matrix-matrix operations offer the proper level of <indexterm id="idx-CHP-14-1187" significance="normal"><primary>matrix-matrix operations</primary><secondary>modularity for performance and transportability</secondary></indexterm>modularity for performance and transportability across a wide range of computer architectures, including parallel systems with memory hierarchy. This enhanced performance is primarily due to a greater opportunity for <indexterm id="idx-CHP-14-1188" significance="normal"><primary>reusing data to reduce memory traffic</primary></indexterm>reusing data. There are numerous ways to accomplish this reuse of data to reduce memory traffic and to increase the ratio of floating-point operations to <indexterm id="idx-CHP-14-1189" significance="normal"><primary>data movement through the memory hierarchy</primary></indexterm>data movement through the memory hierarchy. This improvement can bring a three-to ten-fold improvement in performance on modern computer architectures.</para><para>The jury is still out concerning the productivity of writing and reading the <indexterm id="idx-CHP-14-1190" significance="normal"><primary>LAPACK</primary></indexterm>LAPACK <indexterm id="idx-CHP-14-1191" significance="normal"><primary>elegant code</primary></indexterm>code: how hard is it to generate the code from its mathematical description? The use of vector notation in LINPACK is arguably more natural than <indexterm id="idx-CHP-14-1192" significance="normal"><primary>elegant code</primary><secondary>LAPACK DGETRF subroutine</secondary></indexterm>LAPACK's matrix formulation. The mathematical formulas that describe algorithms are usually more complex if only matrices are used, as opposed to mixed vector-matrix notation.</para></sect1><sect1 id="recursive_lu" label="14.6"><title>Recursive LU</title><para>Setting the block size parameter for the <indexterm id="idx-CHP-14-1193" significance="normal"><primary>hardware, evolution of elegant code with</primary><secondary>effects of computer architecture on matrix algorithms</secondary><tertiary>LAPACK DGEFR subroutine</tertiary></indexterm>LAPACK's LU might seem like a trivial matter at first. But in practice, it requires a lot of tuning for various precisions and matrix sizes. Many users end up leaving the setting unchanged, even if the tuning has to be done only once at installation. This problem is exacerbated by the fact that not just one but many LAPACK routines use a blocking parameter.<indexterm class="startofrange" id="idx-CHP-14-1194" significance="normal"><primary>elegant code</primary><secondary>recursive LU</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-14-1195" significance="normal"><primary>LU factorization</primary><secondary>recursive</secondary></indexterm></para><para>Another issue with LAPACK's formulation of LU is the factorization of tall and narrow panels of columns performed by the DGETF2 routine. It uses Level-1 BLAS and was found to become a <indexterm id="idx-CHP-14-1196" significance="normal"><primary>DGETF2 routine</primary><secondary>bottleneck in computers with faster processors</secondary></indexterm>bottleneck as the processors became faster throughout the 1990s without corresponding increases in memory bandwidth.</para><para>A solution came from a rather unlikely direction: divide-and-conquer recursion. In place of LAPACK's looping constructs, the newer <indexterm id="idx-CHP-14-1197" significance="normal"><primary>divide and conquer strategy</primary><secondary>recursive LU algorithm</secondary></indexterm>recursive LU algorithm splits the work in half, factorizes the left part of the matrix, updates the rest of the matrix, and factorizes the right part. The use of Level-1 BLAS is reduced to an acceptable minimum, and most of the calls to Level-3 BLAS operate on larger portions of the matrix than LAPACK's algorithm. And, of course, the block size does not have to be tuned anymore.</para><para><indexterm class="startofrange" id="idx-CHP-14-1198" significance="normal"><primary>hardware</primary><secondary>recursive LU</secondary></indexterm>Recursive LU <indexterm id="idx-CHP-14-1199" significance="normal"><primary>Fortran</primary><secondary>required use of Fortran 90 with recursive LU</secondary></indexterm>required the use of Fortran 90, which was the first Fortran standard to allow recursive subroutines. A side effect of using Fortran 90 was the increased importance of the LDA parameter, the leading dimension of A. It allows more flexible use of the subroutine, as well as performance tuning for cases when matrix dimension <replaceable>m</replaceable> would cause memory bank conflicts that could significantly reduce available memory bandwidth.</para><para>The Fortran 90 compilers use the LDA parameter to avoid copying the data into a contiguous buffer when calling external routines, such as one of the BLAS. Without LDA, the compiler has to assume the worst-case scenario when input matrix <replaceable>a</replaceable> is not contiguous and needs to be copied to a temporary contiguous buffer so the call to BLAS does not end up with an out-of-bands memory access. With LDA, the compiler passes array pointers to BLAS without any copies.</para><para><xref linkend="recursive_variant_fortran_coding"/> shows recursive <indexterm class="startofrange" id="idx-CHP-14-1200" significance="normal"><primary>recursion</primary><secondary>LU factorization</secondary></indexterm>LU factorization.<indexterm id="I_indexterm14_tt315" class="endofrange" startref="idx-CHP-14-1170" significance="normal"><primary>LAPACK</primary></indexterm><indexterm id="I_indexterm14_tt316" class="endofrange" startref="idx-CHP-14-1169" significance="normal"><primary>elegant code</primary><secondary>LAPACK DGETRF subroutine</secondary></indexterm></para><example id="recursive_variant_fortran_coding" label="14-4"><title>Recursive variant (Fortran 90 coding)</title><programlisting format="linespecific">
      recursive subroutine rdgetrf(m, n, a, lda, ipiv, info)
      implicit none

      integer, intent(in) :: m, n, lda
      double precision, intent(inout) :: a(lda,*)
      integer, intent(out) :: ipiv(*)
      integer, intent(out) :: info

      integer :: mn, nleft, nright, i
      double precision :: tmp

      double precision :: pone, negone, zero
      parameter (pone=1.0d0)
      parameter (negone=-1.0d0)
      parameter (zero=0.0d0)

      intrinsic min

      integer idamax
      external dgemm, dtrsm, dlaswp, idamax, dscal

      mn = min(m, n)

      if (mn .gt. 1) then
         nleft = mn / 2
         nright = n - nleft

         call rdgetrf(m, nleft, a, lda, ipiv, info)

         if (info .ne. 0) return
         call dlaswp(nright, a(1, nleft+1), lda, 1, nleft, ipiv, 1)

         call dtrsm('L', 'L', 'N', 'U', nleft, nright, pone, a, lda,
    $         a(1, nleft+1), lda)

         call dgemm('N', 'N', m-nleft, nright, nleft, negone,
    $         a(nleft+1,1) , lda, a(1, nleft+1), lda, pone,
    $         a(nleft+1, nleft+1), lda)

         call rdgetrf(m - nleft, nright, a(nleft+1, nleft+1), lda,
    $         ipiv(nleft+1), info)
         if (info .ne. 0) then
            info = info + nleft
            return
         end if

         do i =nleft+1, m
            ipiv(i) = ipiv(i) + nleft
         end do

         call dlaswp(nleft, a, lda, nleft+1, mn, ipiv, 1)

      else if (mn .eq. 1) then
         i  = idamax(m, a, 1)
         ipiv(1) = i
         tmp = a(i, 1)

         if (tmp .ne. zero .and. tmp .ne. -zero) then
            call dscal(m, pone/tmp, a, 1)
            a(i,1) = a(1,1)
            a(1,1) = tmp
         else
            info = 1
         end if

      end if

      return
      end
</programlisting></example><para>There is a certain degree of elegance in the <indexterm id="idx-CHP-14-1201" significance="normal"><primary>LU factorization</primary><secondary>recursive</secondary></indexterm>recursive variant. No loops are exposed in the routine. Instead, the algorithm is driven by the recursive nature of the method (see the paper by F. G. Gustavson listed under "Further Reading").</para><para> The <indexterm id="idx-CHP-14-1202" significance="normal"><primary>Recursive LU Algorithm</primary></indexterm>Recursive LU Algorithm consists of four basic steps, illustrated in <xref linkend="recursive_lu_factorization"/>:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Split the matrix into two rectangles (<emphasis>m * n/2</emphasis>); if the left part ends up being only a single column, scale it by the <indexterm id="idx-CHP-14-1203" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>reciprocal of the pivot and return.</para></listitem><listitem><para>Apply the <emphasis>LU</emphasis> algorithm to the left part.</para></listitem><listitem><para>Apply transformations to the right part (perform the triangular solve A<emphasis>12</emphasis> =L-<emphasis>1</emphasis>A<emphasis>12</emphasis> and matrix multiplication A<subscript><emphasis>22</emphasis></subscript>=A<subscript><emphasis>22</emphasis></subscript>–A<subscript><emphasis>21</emphasis></subscript>*A<subscript><emphasis>12</emphasis></subscript>).</para></listitem><listitem><para>Apply the LU algorithm to the right part.</para></listitem></orderedlist><figure id="recursive_lu_factorization" label="14-2" float="0"><title>Recursive LU factorization</title><mediaobject id="I_mediaobject14_tt317"><imageobject role="print"><imagedata fileref="figs/print/beauty_1402.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1402.png" format="PNG"/></imageobject></mediaobject></figure><para>Most of the work is performed in the matrix multiplications, which operate on successive matrices of size <emphasis>n/2, n/4, n/8</emphasis>, etc. The implementation in <xref linkend="recursive_variant_fortran_coding"/> can show about a 10 percent improvement in performance over the LAPACK implementation given in <xref linkend="lapack_solution_factorization"/>.<indexterm id="idx-CHP-14-1204" significance="normal"><primary>elegant code</primary><secondary>recursive LU</secondary></indexterm></para><para>In a sense, any of the previous renditions of the LU algorithm could be considered a step backward in terms of <indexterm id="idx-CHP-14-1205" significance="normal"><primary>elegant code</primary></indexterm>code elegance. But divide-and-conquer recursion was a tremendous leap forward (even dismissing the modest performance gains). The recursive algorithm for matrix factorization can now be taught to students alongside other recursive algorithms, such as various kinds of sorting methods.</para><para>By changing just the size of matrix parts, it is possible to achieve the same memory access pattern as in LINPACK or LAPACK. Setting <literal moreinfo="none">nleft</literal> to 1 makes the code operate on vectors, just as in LINPACK, whereas setting <literal moreinfo="none">nleft</literal> to NB&gt;1 makes it behave like LAPACK's blocked code. In both cases, the original recursion deteriorates from divide-and-conquer to the tail kind. The behavior of such variations of the recursive algorithm can be studied alongside a Quicksort algorithm with various partitioning schemes of the sorted array.</para><para>Finally, we leave as an exercise to the reader to try to mimic the <indexterm id="idx-CHP-14-1206" significance="normal"><primary>elegant code</primary><secondary>recursive LU</secondary></indexterm>recursive <indexterm id="idx-CHP-14-1207" significance="normal"><primary>elegant code</primary></indexterm>code without using recursion and without explicitly handling the <indexterm id="idx-CHP-14-1208" significance="normal"><primary>LU factorization</primary><secondary>recursive</secondary></indexterm>recursive call stack—an important problem to solve if the Fortran compiler cannot handle recursive functions or subroutines.</para></sect1><sect1 id="scalapack_pdgetrf" label="14.7"><title>ScaLAPACK PDGETRF</title><para>LAPACK is designed to be highly efficient on vector processors, high-performance "super-scalar" workstations, and shared-memory multiprocessors. LAPACK can also be used sat-isfactorily on all types of scalar machines (PCs, workstations, and mainframes). However, LAPACK in its present form is less likely to give good performance on other types of parallel architectures—for example, massively parallel Single Instruction Multiple Data (SIMD) machines, or Multiple Instruction Multiple Data (MIMD) distributed-memory machines. The ScaLAPACK effort was intended to adapt LAPACK to these new architectures.<indexterm class="startofrange" id="idx-CHP-14-1209" significance="normal"><primary>elegant code</primary><secondary>ScaLAPACK PDGETRF</secondary></indexterm></para><para>By creating the ScaLAPACK software library, we extended the LAPACK library to scalable MIMD, distributed-memory, concurrent computers. For such machines, the memory hierarchy includes the off-processor memory of other processors, in addition to the hierarchy of registers, cache, and local memory on each processor.</para><para>Like LAPACK, the ScaLAPACK routines are based on block-partitioned algorithms in order to minimize the frequency of data movement between different levels of the memory hierarchy. The fundamental building blocks of the <indexterm id="idx-CHP-14-1210" significance="normal"><primary>BLAS (Basic Linear Algebra Subprograms)</primary><secondary>ScaLAPACK library</secondary></indexterm>ScaLAPACK library are distributed-memory versions of the <indexterm id="idx-CHP-14-1211" significance="normal"><primary>Level-2 BLAS</primary></indexterm>Level-2 and <indexterm id="idx-CHP-14-1212" significance="normal"><primary>Level-3 BLAS</primary></indexterm>Level-3 BLAS, and a set of Basic Linear Algebra Communication Subprograms (<indexterm id="idx-CHP-14-1213" significance="normal"><primary>BLACS (Basic Linear Algebra Communication Subprograms)</primary></indexterm>BLACS) for communication tasks that arise frequently in parallel linear algebra computations. In the ScaLAPACK routines, all interprocessor communication occurs within the distributed BLAS and the BLACS, so the source code of the top software layer of ScaLAPACK looks very similar to that of LAPACK.</para><para>The <indexterm class="startofrange" id="idx-CHP-14-1214" significance="normal"><primary>LU factorization</primary><secondary>ScaLAPACK solution</secondary></indexterm>ScaLAPACK solution to <indexterm class="startofrange" id="idx-CHP-14-1215" significance="normal"><primary>recursion</primary><secondary>LU factorization</secondary></indexterm>LU factorization is shown in <xref linkend="scalapack_variant_fortran_coding"/>.<indexterm id="I_indexterm14_tt318" class="endofrange" startref="idx-CHP-14-1194" significance="normal"><primary>elegant code</primary><secondary>recursive LU</secondary></indexterm><indexterm id="I_indexterm14_tt319" class="endofrange" startref="idx-CHP-14-1198" significance="normal"><primary>hardware</primary><secondary>recursive LU</secondary></indexterm><indexterm id="I_indexterm14_tt320" class="endofrange" startref="idx-CHP-14-1195" significance="normal"><primary>LU factorization</primary><secondary>recursive</secondary></indexterm><indexterm id="I_indexterm14_tt321" class="endofrange" startref="idx-CHP-14-1200" significance="normal"><primary>recursion</primary><secondary>LU factorization</secondary></indexterm></para><example id="scalapack_variant_fortran_coding" label="14-5"><title>ScaLAPACK variant (Fortran 90 coding)</title><programlisting format="linespecific">
     SUBROUTINE PDGETRF( M, N, A, IA, JA, DESCA, IPIV, INFO )
      INTEGER            BLOCK_CYCLIC_2D, CSRC_, CTXT_, DLEN_, DTYPE_,
     $                   LLD_, MB_, M_, NB_, N_, RSRC_
      PARAMETER          ( BLOCK_CYCLIC_2D = 1, DLEN_ = 9, DTYPE_ = 1,
     $                     CTXT_ = 2, M_ = 3, N_ = 4, MB_ = 5, NB_ = 6,
     $                     RSRC_ = 7, CSRC_ = 8, LLD_ = 9 )
      DOUBLE PRECISION   ONE
      PARAMETER          ( ONE = 1.0D+0 )
      CHARACTER          COLBTOP, COLCTOP, ROWBTOP
      INTEGER            I, ICOFF, ICTXT, IINFO, IN, IROFF, J, JB, JN,
     $                   MN, MYCOL, MYROW, NPCOL, NPROW
      INTEGER            IDUM1( 1 ), IDUM2( 1 )
      EXTERNAL           BLACS_GRIDINFO, CHK1MAT, IGAMN2D, PCHK1MAT, PB_TOPGET,
     $                   PB_TOPSET, PDGEMM, PDGETF2, PDLASWP, PDTRSM, PXERBLA
      INTEGER            ICEIL
      EXTERNAL           ICEIL
      INTRINSIC          MIN, MOD
*     Get grid parameters
      ICTXT = DESCA( CTXT_ )
      CALL BLACS_GRIDINFO( ICTXT, NPROW, NPCOL, MYROW, MYCOL )
*     Test the input parameters
      INFO = 0 
      IF( NPROW.EQ.-1 ) THEN
         INFO = -(600+CTXT_)
      ELSE
         CALL CHK1MAT( M, 1, N, 2, IA, JA, DESCA, 6, INFO )
         IF( INFO.EQ.0 ) THEN
            IROFF = MOD( IA-1, DESCA( MB_ ) )
            ICOFF = MOD( JA-1, DESCA( NB_ ) )
            IF( IROFF.NE.0 ) THEN
               INFO = -4
            ELSE IF( ICOFF.NE.0 ) THEN 
               INFO = -5 
           ELSE IF( DESCA( MB_ ).NE.DESCA( NB_ ) ) THEN 
              INFO = -(600+NB_)
           END IF 
        END IF 
        CALL PCHK1MAT( M, 1, N, 2, IA, JA, DESCA, 6, 0, IDUM1, IDUM2, INFO )
     END IF
     IF( INFO.NE.0 ) THEN 
        CALL PXERBLA( ICTXT, '<indexterm id="idx-CHP-14-1216" significance="normal"><primary>elegant code</primary><secondary>ScaLAPACK PDGETRF</secondary></indexterm>PDGETRF', -INFO )
        RETURN
     END IF
     IF( DESCA( M_ ).EQ.1 ) THEN
        IPIV( 1 ) = 1
        RETURN
     ELSE IF( M.EQ.0 .OR. N.EQ.0 ) THEN
        RETURN 
     END IF
*    Split-ring topology for the communication along process rows
     CALL PB_TOPGET( ICTXT, 'Broadcast', 'Rowwise', ROWBTOP )
     CALL PB_TOPGET( ICTXT, 'Broadcast', '<indexterm id="idx-CHP-14-1217" significance="normal"><primary>ScaLAPACK</primary><secondary>LU factorization</secondary></indexterm>Columnwise', COLBTOP )
     CALL PB_TOPGET( ICTXT, 'Combine', 'Columnwise', COLCTOP )
     CALL PB_TOPSET( ICTXT, 'Broadcast', 'Rowwise', 'S-ring' )
     CALL PB_TOPSET( ICTXT, 'Broadcast', 'Columnwise', ' ' )
     CALL PB_TOPSET( ICTXT, 'Combine', 'Columnwise', ' ' )
*    Handle the first block of columns separately
     MN = MIN( M, N )
     IN = MIN( ICEIL( IA, DESCA( MB_ ) )*DESCA( MB_ ), IA+M-1 )
     JN = MIN( ICEIL( JA, DESCA( NB_ ) )*DESCA( NB_ ), JA+MN-1 )
     JB = JN - JA + 1
*    Factor diagonal and subdiagonal blocks and test for exact
*    singularity.
     CALL PDGETF2( M, JB, A, IA, JA, DESCA, IPIV, INFO )
     IF( JB+1.LE.N ) THEN
*       Apply interchanges to columns JN+1:JA+N-1.
        CALL PDLASWP('Forward', 'Rows', N-JB, A, IA, JN+1, DESCA, IA, IN, IPIV )
*       Compute block row of U.
        CALL PDTRSM( 'Left', 'Lower', 'No transpose', 'Unit', JB,
    $                N-JB, ONE, A, IA, JA, DESCA, A, IA, JN+1, DESCA )
*
        IF( JB+1.LE.M ) THEN
*          Update trailing submatrix.
           CALL PDGEMM( 'No transpose', 'No transpose', M-JB,N-JB, JB,
    $                   -ONE, A, IN+1, JA, DESCA, A, IA, JN+1, DESCA,
    $                   ONE, A, IN+1, JN+1, DESCA )
        END IF
     END IF
*    Loop over the remaining blocks of columns.
     DO 10 J = JN+1, JA+MN-1, DESCA( NB_ )
        JB = MIN( MN-J+JA, DESCA( NB_ ) )
        I = IA + J - JA
*
*       Factor diagonal and subdiagonal blocks and test for exact
*       singularity. 
*
        CALL PDGETF2( M-J+JA, JB, A, I, J, DESCA, IPIV, IINFO ) 
*
        IF( INFO.EQ.0 .AND. IINFO.GT.0 ) INFO = IINFO + J - JA
*

*       Apply interchanges to columns JA:J-JA.
*
        CALL PDLASWP('Forward', 'Rowwise', J-JA, A, IA, JA, DESCA, I,I+JB-1, IPIV)
        IF( J-JA+JB+1.LE.N ) THEN
*          Apply interchanges to columns J+JB:JA+N-1.
           CALL PDLASWP( 'Forward', 'Rowwise', N-J-JB+JA, A, IA, J+JB,
    $                    DESCA, I, I+JB-1, IPIV )
*          Compute block row of U.
           CALL PDTRSM( 'Left', 'Lower', 'No transpose', 'Unit', JB,
    $                   N-J-JB+JA, ONE, A, I, J, DESCA, A, I, J+JB,
    $                   DESCA )
           IF( J-JA+JB+1.LE.M ) THEN
*             Update trailing submatrix.
              CALL PDGEMM( 'No transpose', 'No transpose', M-J-JB+JA,
    $                      N-J-JB+JA, JB, -ONE, A, I+JB, J, DESCA, A,
    $                      I, J+JB,  DESCA, ONE, A, I+JB, J+JB, DESCA )
           END IF 
        END IF
  10 CONTINUE
     IF( INFO.EQ.0 ) INFO = MN + 1
     CALL IGAMN2D(ICTXT, 'Rowwise', ' ', 1, 1, INFO, 1, IDUM1,IDUM2, -1,-1, MYCOL)
     IF( INFO.EQ.MN+1 ) INFO = 0
     CALL PB_TOPSET( ICTXT, 'Broadcast', 'Rowwise', ROWBTOP )
     CALL PB_TOPSET( ICTXT, 'Broadcast', 'Columnwise', COLBTOP )
     CALL PB_TOPSET( ICTXT, 'Combine', 'Columnwise', COLCTOP ) 
     RETURN 
     END
</programlisting></example><para>In order to simplify the design of <indexterm id="idx-CHP-14-1218" significance="normal"><primary>elegant code</primary><secondary>ScaLAPACK PDGETRF</secondary></indexterm>ScaLAPACK, and because the BLAS have proven to be very useful tools outside LAPACK, we chose to build a <indexterm class="startofrange" id="idx-CHP-14-1219" significance="normal"><primary>Parallel BLAS (PBLAS)</primary></indexterm>Parallel BLAS, or <indexterm class="startofrange" id="idx-CHP-14-1220" significance="normal"><primary>PBLAS (Parallel BLAS)</primary></indexterm>PBLAS (described in the paper by Choi et al. listed under "Further Reading"), whose interface is as similar to the BLAS as possible. This decision has permitted the <indexterm id="idx-CHP-14-1221" significance="normal"><primary>LU factorization</primary><secondary>ScaLAPACK solution</secondary></indexterm>ScaLAPACK <indexterm id="idx-CHP-14-1222" significance="normal"><primary>elegant code</primary></indexterm>code to be quite similar, and sometimes nearly identical, to the analogous LAPACK code.<indexterm id="I_indexterm14_tt322" class="endofrange" startref="idx-CHP-14-1214" significance="normal"><primary>LU factorization</primary><secondary>ScaLAPACK solution</secondary></indexterm><indexterm id="I_indexterm14_tt323" class="endofrange" startref="idx-CHP-14-1215" significance="normal"><primary>recursion</primary><secondary>LU factorization</secondary></indexterm></para><para>It was our aim that the <indexterm id="idx-CHP-14-1223" significance="normal"><primary>PBLAS (Parallel BLAS)</primary></indexterm>PBLAS would provide a distributed memory standard, just as the BLAS provided a shared memory standard. This would simplify and encourage the development of high-performance and portable <indexterm id="idx-CHP-14-1224" significance="normal"><primary>Parallel BLAS (PBLAS)</primary></indexterm>parallel numerical software, as well as providing manufacturers with just a small set of routines to be optimized. The acceptance of the PBLAS requires reasonable compromises between competing goals of functionality and simplicity.</para><para>The PBLAS operate on matrices distributed in a two-dimensional block cyclic layout. Because such a data layout requires many parameters to fully describe the distributed matrix, we have chosen a more object-oriented approach and encapsulated these parameters in an integer <indexterm id="idx-CHP-14-1225" significance="normal"><primary>array descriptors</primary></indexterm>array called an <emphasis>array descriptor</emphasis>. An array descriptor includes:</para><itemizedlist><listitem><para>The descriptor type</para></listitem><listitem><para>The BLACS context (a virtual space for messages that is created to avoid collisions between logically distinct messages)</para></listitem><listitem><para>The number of rows in the distributed matrix</para></listitem><listitem><para>The number of columns in the distributed matrix</para></listitem><listitem><para>The row block size</para></listitem><listitem><para>The column block size</para></listitem><listitem><para>The process row over which the first row of the matrix is distributed</para></listitem><listitem><para>The process column over which the first column of the matrix is distributed</para></listitem><listitem><para>The leading dimension of the local array storing the local blocks</para></listitem></itemizedlist><para>By using this descriptor, a call to a PBLAS routine is very similar to a call to the corresponding BLAS routine:</para><programlisting id="I_programlisting14_tt324" format="linespecific">
	CALL DGEMM ( TRANSA, TRANSB, M, N, K, ALPHA,
	             A( IA, JA ), LDA,
	             B( IB, JB ), LDB, BETA,
	             C( IC, JC ), LDC )

	CALL PDGEMM( TRANSA, TRANSB, M, N, K, ALPHA,
	             A, IA, JA, DESC_A,
	             B, JB, DESC_B, BETA,
	             C, IC, JC, DESC_C )
</programlisting><para>DGEMM computes <emphasis>C = BETA * C + ALPHA * op( A ) * op( B )</emphasis>, where <emphasis>op(A)</emphasis> is either <emphasis>A</emphasis> or its transpose depending on <emphasis>TRANSA, op(B)</emphasis> is similar, <emphasis>op(A) is M-by-K</emphasis>, and <emphasis>op(B)</emphasis> is <emphasis>K-by-N</emphasis>. <emphasis>PDGEMM</emphasis> is the same, with the exception of the way submatrices are specified. To pass the submatrix starting at <emphasis>A(IA,JA)</emphasis> to <emphasis>DGEMM</emphasis>, for example, the actual argument corresponding to the formal argument <emphasis>A</emphasis> is simply <emphasis>A(IA,JA). PDGEMM</emphasis>, on the other hand, needs to understand the global storage scheme of <emphasis>A</emphasis> to extract the correct submatrix, so <emphasis>IA</emphasis> and <emphasis>JA</emphasis> must be passed in separately.</para><para><emphasis>DESC_A</emphasis> is the array descriptor for <emphasis>A</emphasis>. The parameters describing the matrix operands <emphasis>B</emphasis> and <emphasis>C</emphasis> are analogous to those describing <emphasis>A</emphasis>. In a truly object-oriented environment, matrices and <emphasis>DESC_A</emphasis> would be synonymous. However, this would require language support and detract from portability.</para><para>Using message passing and scalable algorithms from the <indexterm id="idx-CHP-14-1226" significance="normal"><primary>elegant code</primary><secondary>ScaLAPACK PDGETRF</secondary></indexterm>ScaLAPACK library makes it possible to factor matrices of arbitrarily increasing size, given machines with more processors. By design, the library computes more than it communicates, so for the most part, data stays locally for processing and travels only occasionally across the interconnect network.</para><para>But the number and types of messages exchanged between processors can sometimes be hard to manage. The context associated with every distributed matrix lets implementations use separate "universes" for message passing. The use of separate communication contexts by distinct libraries (or distinct library invocations) such as the <indexterm id="idx-CHP-14-1227" significance="normal"><primary>PBLAS (Parallel BLAS)</primary></indexterm>PBLAS insulates communication internal to the library from external communication. When more than one descriptor array is present in the argument list of a routine in the PBLAS, the individual BLACS context entries must be equal. In other words, the PBLAS do not perform "inter-context" operations.</para><para>In the performance sense, ScaLAPACK did to LAPACK what LAPACK did to LINPACK: it broadened the range of <indexterm id="idx-CHP-14-1228" significance="normal"><primary>hardware</primary></indexterm>hardware where LU factorization (and other <indexterm id="idx-CHP-14-1229" significance="normal"><primary>elegant code</primary></indexterm>codes) could run efficiently. In terms of code elegance, the ScaLAPACK's changes were much more drastic: the same mathematical operation now required large amounts of tedious work. Both the users and the library writers were now forced into explicitly controlling data storage intricacies, because data locality became paramount for performance. The victim was the readability of the code, despite efforts to modularize the code according to the best software engineering practices of the day.</para></sect1><sect1 id="multithreading_for_multi-core_systems" label="14.8"><title>Multithreading for Multi-Core Systems</title><para>The advent of multi-core chips brought about a fundamental shift in the way software is produced. Dense linear algebra is no exception. The good news is that LAPACK's LU factorization runs on a multi-core system and can even deliver a modest increase of performance if <indexterm class="startofrange" id="idx-CHP-14-1230" significance="normal"><primary>LU factorization</primary><secondary>multithreaded</secondary></indexterm>multithreaded BLAS are used. In technical terms, this is the <indexterm id="idx-CHP-14-1231" significance="normal"><primary>fork-join model of computation</primary></indexterm>fork-join model of computation: each call to BLAS (from a single main thread) forks a suitable number of threads, which perform the work on each core and then join the main thread of computation. The fork-join model implies a synchronization point at each join operation.<indexterm class="startofrange" id="idx-CHP-14-1232" significance="normal"><primary>elegant code</primary><secondary>multithreading for multi-core systems</secondary></indexterm><indexterm id="I_indexterm14_tt325" class="endofrange" startref="idx-CHP-14-1219" significance="normal"><primary>Parallel BLAS (PBLAS)</primary></indexterm><indexterm id="I_indexterm14_tt326" class="endofrange" startref="idx-CHP-14-1220" significance="normal"><primary>PBLAS (Parallel BLAS)</primary></indexterm><indexterm id="I_indexterm14_tt327" class="endofrange" startref="idx-CHP-14-1209" significance="normal"><primary>elegant code</primary><secondary>ScaLAPACK PDGETRF</secondary></indexterm></para><para>The bad news is that the LAPACK's fork-join algorithm gravely impairs scalability even on small multi-core computers that do not have the memory systems available in SMP systems. The inherent scalability flaw is the heavy synchronization in the fork-join model (only a single thread is allowed to perform the significant computation that occupies the critical section of the code, leaving other threads idle) that results in lock-step execution and prevents hiding of inherently sequential portions of the code behind <indexterm id="idx-CHP-14-1233" significance="normal"><primary>Parallel BLAS (PBLAS)</primary></indexterm>parallel ones. In other words, the threads are forced to perform the same operation on different data. If there is not enough data <indexterm id="idx-CHP-14-1234" significance="normal"><primary>elegant code</primary><secondary>multithreading for multi-core systems</secondary></indexterm>for some threads, they will have to stay idle and wait for the rest of the threads that perform useful work on their data. Clearly, another version of the LU algorithm is needed such that would allow threads to stay busy all the time by possibly making them perform different operations during some portion of the execution.</para><para>The <indexterm id="idx-CHP-14-1235" significance="normal"><primary>LU factorization</primary><secondary>multithreaded</secondary></indexterm>multithreaded version of the algorithm recognizes the existence of a so-called <emphasis>critical path</emphasis> in the algorithm: a portion of the <indexterm id="idx-CHP-14-1236" significance="normal"><primary>elegant code</primary></indexterm>code whose execution depends on previous calculations and can block the progress of the algorithm. The LAPACK's LU does not treat this critical portion of the code in any special way: the DGETF2 subroutine is called by a single thread and doesn't allow much parallelization even at the BLAS level. While one thread calls this routine, the other ones wait idly. And since the performance of DGETF2 is bound by memory bandwidth (rather than processor speed), this bottleneck will exacerbate scalability problems as systems with more cores are introduced.<indexterm id="idx-CHP-14-1237" significance="normal"><primary>critical path</primary></indexterm></para><para>The multithreaded version of the algorithm attacks this problem head-on by introducing the notion of <indexterm id="idx-CHP-14-1238" significance="normal"><primary>look-ahead computations</primary></indexterm>look-ahead: calculating things ahead of time to avoid potential stagnation in the progress of the computations. This of course requires additional synchronization and bookkeeping not present in the previous versions—a trade-off between code complexity and performance. Another aspect of the multithreaded code is the use of recursion in the panel factorization. It turns out that the use of recursion can give even greater performance benefits for tall panel matrices than it does for the square ones.</para><para><xref linkend="factorization_for_multithreaded_execution_c_code"/> shows a factorization suitable for multithreaded execution.</para><example id="factorization_for_multithreaded_execution_c_code" label="14-6"><title>Factorization for multithreaded execution (C code)</title><programlisting format="linespecific">
void SMP_dgetrf(int n, double *a, int lda, int *ipiv, int pw,
                            int tid, int tsize, int *pready,ptm *mtx, ptc *cnd) {
  int pcnt, pfctr, ufrom, uto, ifrom, p;
  double *pa = a, *pl, *pf, *lp;

  pcnt = n / pw; /* number of panels */

  pfctr = tid + (tid ? 0 : tsize); /* first panel that should be factored by this
                     thread after the very first panel (number 0) gets factored */

  /* this is a pointer to the last panel */
  lp = a + (size_t)(n - pw) * (size_t)lda;

  /* for each panel (that is used as source of updates) */
  for (ufrom = 0; ufrom &lt; pcnt; ufrom++, pa += (size_t)pw * (size_t)(lda + 1)){
    p = ufrom * pw; /* column number */

  /* if the panel to be used for updates has not been factored yet; 'ipiv'
     does not be consulted, but it is to possibly avoid accesses to 'pready'*/
  if (! ipiv[p + pw - 1] || ! pready[ufrom]) {

    if (ufrom % tsize == tid) { /* if this is this thread's panel */
      pfactor( n - p, pw, pa, lda, ipiv + p, pready, ufrom, mtx, cnd );
    } else if (ufrom &lt; pcnt - 1) { /* if this is not the last panel */
      LOCK( mtx );
      while (! pready[ufrom]) { WAIT( cnd, mtx ); }
      UNLOCK( mtx );
    }
  }
  /* <indexterm id="idx-CHP-14-1239" significance="normal"><primary>elegant code</primary><secondary>multithreading for multi-core systems</secondary></indexterm>for each panel to be updated */
  for (uto = first_panel_to_update( ufrom, tid, tsize ); uto &lt; pcnt;
       uto += tsize) {
    /* if there are still panels to factor by this thread and preceding panel
       has been factored; test to 'ipiv' could be skipped but is in there to
       decrease number of accesses to 'pready' */
    if (pfctr &lt; pcnt &amp;&amp; ipiv[pfctr * pw - 1] &amp;&amp; pready[pfctr - 1]) {
      /* for each panel that has to (still) update panel 'pfctr' */
      for (ifrom = ufrom + (uto &gt; pfctr ? 1 : 0); ifrom &lt; pfctr; ifrom++) {
        p = ifrom * pw;
        pl = a + (size_t)p * (size_t)(lda + 1);
        pf = pl + (size_t)(pfctr - ifrom) * (size_t)pw * (size_t)lda;
        pupdate( n - p, pw, pl, pf, lda, p, ipiv, lp );
      }
      p = pfctr * pw;
      pl = a + (size_t)p * (size_t)(lda + 1);
      pfactor( n - p, pw, pl, lda, ipiv + p, pready, pfctr, mtx, cnd );
      pfctr += tsize; /* move to this thread's next panel */
    }

    /* if panel 'uto' hasn't been factored (if it was, it certainly has been
       updated, so no update is necessary) */
    if (uto &gt; pfctr || ! ipiv[uto * pw]) {
      p = ufrom * pw;
      pf = pa + (size_t)(uto - ufrom) * (size_t)pw * (size_t)lda;
      pupdate( n - p, pw, pa, pf, lda, p, ipiv, lp );
    }
  }
}
</programlisting></example><para>The algorithm is the same for each thread (the SIMD paradigm), and the matrix data is partitioned among threads in a cyclic manner using panels with <literal moreinfo="none">pw</literal> columns in each panel (except maybe the last). The <literal moreinfo="none">pw</literal> parameter corresponds to the blocking parameter NB of LAPACK. The difference is the logical assignment of panels (blocks of columns) to threads. (Physically, all panels are equally accessible because the <indexterm id="idx-CHP-14-1240" significance="normal"><primary>elegant code</primary></indexterm>code operates in a shared memory regimen.) The benefits of blocking in a thread are the same as they were in LAPACK: better cache reuse and less stress on the memory bus. Assigning a portion of the matrix to a thread seems an artificial requirement at first, but it simplifies the code and the bookkeeping data structures; most importantly, it provides better memory affinity. It turns out that multi-core chips are not symmetric in terms of memory access bandwidth, so minimizing the number of reassignments of memory pages to cores directly benefits performance.</para><para>The standard components of LU factorization are represented by the <literal moreinfo="none">pfactor()</literal> and <literal moreinfo="none">pupdate()</literal> functions. As one might expect, the former factors a panel, whereas the latter updates a panel using one of the previously factored panels.</para><para>The main loop makes each thread iterate over each panel in turn. If necessary, the panel is factored by the owner thread while other threads wait (if they happen to need this panel <indexterm id="idx-CHP-14-1241" significance="normal"><primary>elegant code</primary><secondary>multithreading for multi-core systems</secondary></indexterm>for their updates).</para><para>The look-ahead logic is inside the nested loop (prefaced by the comment <literal moreinfo="none">for each panel to be updated</literal>) that replaces DGEMM or PDGEMM from previous algorithms. Before each thread updates one of its panels, it checks whether it's already feasible to factor its first unfactored panel. This minimizes the number of times the threads have to wait because each thread constantly attempts to eliminate the potential bottleneck.</para><para>As was the case for ScaLAPACK, the <indexterm id="idx-CHP-14-1242" significance="normal"><primary>LU factorization</primary><secondary>multithreaded</secondary></indexterm>multithreaded version detracts from the inherent elegance of the LAPACK's version. Also in the same spirit, performance is the main culprit: LAPACK's <indexterm id="idx-CHP-14-1243" significance="normal"><primary>elegant code</primary></indexterm>code will not run efficiently on machines with ever-increasing numbers of cores. Explicit control of execution threads at the LAPACK level rather than the BLAS level is critical: parallelism cannot be encapsulated in a library call. The only good news is that the code is not as complicated as ScaLAPACK's, and efficient BLAS can still be put to a good use.</para></sect1><sect1 id="a_word_about_the_error_analysis_and_operation_count" label="14.9"><title>A Word About the Error Analysis and Operation Count</title><para>The key aspect of all of the implementations presented in this chapter is their numerical properties.<indexterm id="idx-CHP-14-1244" significance="normal"><primary>error analysis</primary></indexterm></para><para>It is acceptable to forgo elegance in order to gain performance. But numerical stability is of vital importance and cannot be sacrificed because it is an inherent part of the algorithm's correctness. While these are serious considerations, there is some consolation to follow. It may be surprising to some readers that all of the algorithms presented are the same, even though it's virtually impossible to make each excerpt of code produce exactly the same output for exactly the same inputs.</para><para>When it comes to repeatability of results, the vagaries of floating-point representation may be captured in a rigorous way by <emphasis>error bounds</emphasis>. One way of expressing the numerical robustness of the previous algorithms is with the following formula:<indexterm id="idx-CHP-14-1245" significance="normal"><primary>error bounds</primary></indexterm></para><programlisting id="I_programlisting14_tt328" format="linespecific">
	||r||/||A|| ≤ ||e|| ≤ ||A<superscript>-1</superscript>|| ||r||
</programlisting><para>where error <emphasis>e = x – y</emphasis> is the difference between the computed solution <literal moreinfo="none">y</literal> and the correct solution <literal moreinfo="none">x</literal>, and <literal moreinfo="none">r</literal>= <emphasis>Ay – b</emphasis> is a so-called "residual." The previous formula basically says that the size of the error (the parallel bars surrounding a value indicate a norm—a measure of absolute size) is as small as warranted by the quality of the matrix <emphasis>A</emphasis>. Therefore, if the matrix is close to being singular in numerical sense (some entries are so small that they might as well be considered to be zero), the algorithms will not give an accurate answer. But, otherwise, a relatively good quality of result can be expected.<indexterm id="I_indexterm14_tt329" class="endofrange" startref="idx-CHP-14-1232" significance="normal"><primary>elegant code</primary><secondary>multithreading for multi-core systems</secondary></indexterm><indexterm id="I_indexterm14_tt330" class="endofrange" startref="idx-CHP-14-1230" significance="normal"><primary>LU factorization</primary><secondary>multithreaded</secondary></indexterm></para><para>Another feature that is common to all the versions presented is the <indexterm id="idx-CHP-14-1246" significance="normal"><primary>operation count</primary></indexterm>operation count: they all perform 2/3n<superscript>3</superscript> floating-point multiplications and/or additions. The order of these operations is what differentiates them. There are algorithms that increase the amount of floating-point work to save on memory traffic or network transfers (especially for distribute-memory parallel algorithms). But because the algorithms shown in this chapter have the same operation count, it is valid to compare them for performance. The computational rate (number of floating-point operations per second) may be used instead of the time taken to solve the problem, provided that the matrix size is the same. But comparing computational rates is sometimes better because it allows a comparison of algorithms when the matrix sizes differ. For example, a sequential algorithm on a single processor can be directly compared with a parallel one working on a large cluster on a much bigger matrix.</para></sect1><sect1 id="future_directions_for_research" label="14.10"><title>Future Directions for Research</title><para>In this chapter, we have looked at the evolution of the design of a simple but important algorithm in computational science. The changes over the past 30 years have been necessary to follow the lead of the advances in computer architectures. In some cases, these changes have been simple, such as interchanging loops. In other cases, they have been as complex as the introduction of recursion and look-ahead computations. In each case, however, the <indexterm id="idx-CHP-14-1247" significance="normal"><primary>elegant code</primary></indexterm>code's ability to efficiently utilize the memory hierarchy is the key to high performance on a single processor as well as on shared and distributed memory systems.<indexterm id="idx-CHP-14-1248" significance="normal"><primary>elegant code</primary><secondary>future directions for research</secondary></indexterm></para><para>The essence of the problem is the dramatic increase in complexity that software developers have had to confront, and still do. Dual-core machines are already common, and the number of cores is expected to roughly double with each processor generation. But contrary to the assumptions of the old model, programmers will not be able to consider these cores independently (i.e., multi-core is <emphasis>not</emphasis> "the new SMP") because they share on-chip resources in ways that separate processors do not. This situation is made even more complicated by the other nonstandard components that future architectures are expected to deploy, including the mixing of different types of cores, <indexterm id="idx-CHP-14-1249" significance="normal"><primary>hardware</primary></indexterm>hardware accelerators, and memory systems.</para><para>Finally, the proliferation of widely divergent design ideas shows that the question of how to best combine all these new resources and components is largely unsettled. When combined, these changes produce a picture of a future in which programmers will have to overcome software design problems vastly more complex and challenging than those in the past in order to take advantage of the much higher degrees of concurrency and greater computing power that new architectures will offer.</para><para>So, the bad news is that none of the presented code will work efficiently someday. The good news is that we have learned various ways to mold the original simple rendition of the algorithm to meet the ever-increasing challenges of hardware designs.</para></sect1><sect1 id="further_reading" label="14.11"><title>Further Reading</title><itemizedlist><listitem><para><emphasis>LINPACK User's Guide</emphasis>7, J. J. Dongarra, J. R. Bunch, C. B. Moler, and G. W. Stewart, SIAM: Philadelphia, 1979, ISBN 0-89871-172-X.</para></listitem><listitem><para><emphasis>LAPACK Users' Guide</emphasis>, Third Edition, E. Anderson, Z. Bai, C. Bischof, S. Blackford, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammaring, A. McKenney, and D. Sorensen, SIAM: Philadelphia, 1999, ISBN 0-89871-447-8.</para></listitem><listitem><para><emphasis>ScaLAPACK Users' Guide</emphasis>, L. S. Blackford, J. Choi, A. Cleary, E. D'Azevedo, J. Demmel, I. Dhillon, J. Dongarra, S. Hammarling, G. Henry, A. Petitet, K. Stanley, D. Walker, and R. C. Whaley, SIAM Publications, Philadelphia, 1997, ISBN 0-89871-397-8.</para></listitem><listitem><para>"Basic Linear Algebra Subprograms for FORTRAN usage," C. L. Lawson, R. J. Hanson, D. Kincaid, and F. T. Krogh, <emphasis>ACM Trans. Math. Soft., Vol. 5</emphasis>, pp. 308–323, 1979.</para></listitem><listitem><para>"An extended set of FORTRAN Basic Linear Algebra Subprograms," J. J. Dongarra, J. Du Croz, S. Hammarling, and R. J. Hanson, <emphasis>ACM Trans. Math. Soft., Vol. 14</emphasis>, pp. 1–17, 1988.</para></listitem><listitem><para>"A set of Level 3 Basic Linear Algebra Subprograms," J. J. Dongarra, J. Du Croz, I. S. Duff, and S. Hammarling, <emphasis>ACM Trans. Math. Soft., Vol. 16</emphasis>, pp. 1–17, 1990.</para></listitem><listitem><para><emphasis>Implementation Guide for</emphasis> LAPACK, E. Anderson and J. Dongarra, UT-CS-90-101, April 1990.</para></listitem><listitem><para><emphasis>A Proposal for a Set of Parallel Basic Linear Algebra Subprograms</emphasis>, J. Choi, J. Dongarra, S. Ostrouchov, A. Petitet, D. Walker, and R. C. Whaley, UT-CS-95-292, May 1995.</para></listitem><listitem><para><emphasis>LAPACK Working Note 37: Two Dimensional Basic Linear Algebra Communication Subprograms</emphasis>, J. Dongarra and R. A. van de Geijn, University of Tennessee Computer Science Technical Report, UT-CS-91-138, October 1991.</para></listitem><listitem><para>"Matrix computations with Fortran and paging," Cleve B. Moler, <emphasis>Communications of the ACM</emphasis>, 15(4), pp. 268–270, 1972.</para></listitem><listitem><para><emphasis>LAPACK Working Note 19: Evaluating Block Algorithm Variants in LAPACK</emphasis>, E. Anderson and J. Dongarra, University of Tennessee Computer Science Technical Report, UT-CS-90-103, April 1990.</para></listitem><listitem><para>"Recursion leads to automatic variable blocking for dense linear-algebra algorithms," Gustavson, F. G. <emphasis>IBM J. Res. Dev</emphasis>. Vol. 41, No. 6 (Nov. 1997), pp. 737–756.<indexterm id="I_indexterm14_tt331" class="endofrange" startref="idx-CHP-14-1089" significance="normal"><primary>Gaussian elimination</primary></indexterm></para></listitem></itemizedlist></sect1></chapter><chapter id="the_long-term_benefits_of_beautiful_design" label="15" role=""><title>The Long-Term Benefits of Beautiful Design</title><para><emphasis>Adam Kolawa</emphasis><indexterm id="idx-CHP-15-1250" significance="normal"><primary>Kolawa</primary></indexterm></para><para><emphasis>Some algorithms for seemingly straightforward and simple</emphasis> <indexterm id="idx-CHP-15-1251" significance="normal"><primary>mathematical equations vs. computed solutions</primary></indexterm>mathematical equations are actually extremely difficult to implement. For instance, rounding problems can compromise accuracy, some mathematical equations can cause values to exceed the range of a floating-point value on the system, and some algorithms (notably the classic Fourier Transform) take much too long if done in a brute-force fashion. Furthermore, different sets of data work better with different algorithms. Consequently, beautiful <indexterm id="idx-CHP-15-1252" significance="normal"><primary>beautiful code</primary><secondary>code that works accurately and efficiently</secondary></indexterm>code and beautiful mathematics are not necessarily one and the same.</para><para>The programmers who wrote the code for the CERN mathematical library recognized the difference between mathematical equations and <indexterm id="idx-CHP-15-1253" significance="normal"><primary>computed solutions vs. mathematical equations</primary></indexterm>computed solutions: the difference between theory and practice. In this chapter, I will explore the beauty in a few of the programming strategies that they used to bridge that gap.</para><sect1 id="my_idea_of_beautiful_code" label="15.1"><title>My Idea of Beautiful Code</title><para>My idea of beautiful code stems from my belief that the ultimate purpose of code is to work. In other words, code should accurately and efficiently perform the task that it was designed to complete, in such a way that there are no ambiguities as to how it will behave.</para><para>I find beauty in code that I can trust—code that I am confident will produce results that are correct and applicable to my problem. What I am defining here as my first criterion of beautiful code is code that I can use and reuse without any shred of doubt in the code's ability to deliver results. In other words, my primary concern is not what the code looks like, but what I can do with it.</para><para>It's not that I don't appreciate the beauty in code's implementation details; I do indeed, and I will discuss criteria and examples of code's inner beauty later in this chapter. My point here is that when code satisfies my somewhat nontraditional notion of beauty in utility, it's rarely necessary to look at its implementation details. Such code promotes what I believe to be one of the most important missions in the industry: the ability to share code with others, without requiring them to analyze the code and figure out exactly how it works. Beautiful code is like a beautiful car. You rarely need to open it up to look at its mechanics. Rather, you enjoy it from the outside and trust that it will drive you where you want to go.</para><para>For code to be enjoyed in this way, it must be designed so that it's clear how it should be used, easy to understand how you can apply it to solve your own problems, and easy to verify if you are using it correctly.</para></sect1><sect1 id="introducing_the_cern_library" label="15.2"><title>Introducing the CERN Library</title><para>I believe that the mathematical library developed by CERN (European Organization for Nuclear Research) is a prime example of beautiful code. The code in this library performs algebraic operations, integrates functions, solves differential equations, and solves a lot of physics problems. It was written over 30 years ago and has been widely used over the years. The linear algebra part of the CERN Library evolved into the LAPACK library, which is the code that I will discuss here. The LAPACK library is currently developed by multiple universities and organizations.<indexterm id="idx-CHP-15-1254" significance="normal"><primary>CERN library</primary></indexterm></para><para>I have used this code since I was young, and I am still fascinated by it. The beauty of this code is that it contains many complicated mathematical algorithms that are very well tested and difficult to reproduce. You can reuse it and rely on it without having to worry about whether it works.</para><para>The library's high accuracy and reliability are why—even after all these years—it remains the mathematical library of choice for anyone who needs to accurately and reliably solve equations. There are other mathematical libraries available, but they can't compete with the CERN library's proven reliability and accuracy.</para><para>The first part of this chapter discusses this code's outer beauty: the things that make it so accurate and reliable that developers want to reuse it and the elements that make this reuse as simple as possible. The second part explores the inner beauty of its implementation details.</para></sect1><sect1 id="outer_beauty" label="15.3"><title>Outer Beauty</title><para>If you've ever tried to solve a system of linear equations or perform an equally complicated mathematical operation, you know that many times the code you write to achieve this does not deliver the correct results. One of the greatest problems with mathematical libraries is that rounding errors and floating-point operations lead to solution instabilities and incorrect results.<indexterm class="startofrange" id="idx-CHP-15-1255" significance="normal"><primary>CERN library</primary><secondary>outer beauty of code</secondary></indexterm></para><para>If you design a mathematical library, you need to carefully define the range in which each algorithm will work. You need to write each algorithm in such a way that it will adhere to these conditions, and you also need to write it in such a way that the rounding errors will cancel out. This can be very complicated.</para><para>In the CERN library, the algorithms are specified in a very precise way. Basically, if you look at any routine, you will notice that it has a description of what it is going to do. It really doesn't matter in which language the routine is written. In fact, these routines were written in Fortran but have interfaces that allow them to be called from almost any other place. That's also a beautiful thing. In some sense, the routine is a black box: you don't care what goes on inside, only that it delivers the appropriate results for your inputs. It carefully defines what every routine is doing, under which conditions it is working, what input data it accepts, and what constraints must be put on the input data in order to get the correct answer.</para><para>For example, let's look at the LAPACK library's <indexterm class="startofrange" id="idx-CHP-15-1256" significance="normal"><primary>SGBSV routine (LAPACK library)</primary></indexterm>SGBSV routine, which solves a system of linear equations for a banded matrix. If you try to solve a system of linear equations numerically, you use different algorithms. Different algorithms operate better in different domains, and you need to know the structure of the matrix to choose the best one. For instance, you would want to use one algorithm to solve the problem if you had a banded matrix (a matrix where most of the elements are around the diagonal), and a different one if you had a sparse matrix (a matrix that has a lot of zeros and few numbers).</para><para>Because different routines are optimized for different situations, the best routine to use really depends on the matrix structure that you have. However, in order to understand the range of this, you need to understand how to input data to these routines. Sometimes you input data in the form of a matrix. Sometimes—for instance, with a banded matrix— you send it like a very narrow array. Each of these routines and their requirements are described very clearly in the library:</para><programlisting id="I_programlisting15_tt332" format="linespecific">
	     SUBROUTINE SGBSV( N, KL, KU, NRHS, AB, LDAB, IPIV, B, LDB, INFO )
	*
	* -- LAPACK driver routine (version 2.0) --
	*    Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
	*    Courant Institute, Argonne National Lab, and Rice University
	*    March 31, 1993
	*
	*    .. Scalar Arguments ..
	     INTEGER            INFO, KL, KU, LDAB, LDB, N, NRHS
	*    ..

	*    .. Array Arguments ..
	     INTEGER            IPIV( * )
	     REAL               AB( LDAB, * ), B( LDB, * )
	*    ..
	*
	* Purpose
	* =======
	*
	* <indexterm id="idx-CHP-15-1257" significance="normal"><primary>SGBSV routine (LAPACK library)</primary></indexterm>SGBSV computes the solution to a real system of linear equations
	* A * X = B, where A is a band matrix of order N with KL subdiagonals
	* and KU superdiagonals, and X and B are N-by-NRHS matrices.
	*
	* The LU decomposition with partial pivoting and row interchanges is
	* used to factor A as A = L * U, where L is a product of permutation
	* and unit lower triangular matrices with KL subdiagonals, and U is
	* upper triangular with KL+KU superdiagonals. The factored form of A
	* is then used to solve the system of equations A * X = B.
	*
	* Arguments
	* =========
	*
	* N        (input) INTEGER
	*          The number of linear equations, i.e., the order of the
	*          matrix A. N &gt;= 0.
	*
	* KL       (input) INTEGER
	*          The number of subdiagonals within the band of A. KL &gt;= 0.
	*
	* KU       (input) INTEGER
	*          The number of superdiagonals within the band of A. KU &gt;= 0.
	*
	* NRHS     (input) INTEGER
	*          The number of right hand sides, i.e., the number of columns
	*          of the matrix B. NRHS &gt;= 0.
	*
	* AB       (input/output) REAL array, dimension (LDAB,N)
	*          On entry, the matrix A in band storage, in rows KL+1 to
	*          2*KL+KU+1; rows 1 to KL of the array need not be set.
	*          The j-th column of A is stored in the j-th column of the
	*          array AB as follows:
	*          AB(KL+KU+1+i-j,j) = A(i,j) for max(1,j-KU)&lt;=i&lt;=min(N,j+KL)
	*          On exit, details of the factorization: U is stored as an
	*          upper triangular band matrix with KL+KU superdiagonals in
	*          rows 1 to KL+KU+1, and the multipliers used during the
	*          factorization are stored in rows KL+KU+2 to 2*KL+KU+1.
	*          See below for further details.
	*
	* LDAB     (input) INTEGER
	*          The leading dimension of the array AB. LDAB &gt;= 2*KL+KU+1.
	*
	* IPIV     (output) INTEGER array, dimension (N)
	*          The pivot indices that define the permutation matrix P;
	*          row i of the matrix was interchanged with row IPIV(i).
	*
	* B        (input/output) REAL array, dimension (LDB,NRHS)
	*          On entry, the N-by-NRHS right hand side matrix B.
	*          On exit, if INFO = 0, the N-by-NRHS solution matrix X.
	*
	* LDB      (input) INTEGER
	*          The leading dimension of the array B. LDB &gt;= max(1,N).
	*
	* INFO     (output) INTEGER
	*          = 0: successful exit
	*          &lt; 0: if INFO = -i, the i-th argument had an illegal value
	*          &gt; 0: if INFO = i, U(i,i) is exactly zero. The factorization
	*               has been completed, but the factor U is exactly
	*               singular, and the solution has not been computed.
	*
	* Further Details
	* ===============
	*
	* The band storage scheme is illustrated by the following example, when
	* M = N = 6, KL = 2, KU = 1:
	*
	* On entry:                       On exit:
	*
	*     *   *   *   +   +   +           *   *   *   u14   u25   u36
	*     *   *   +   +   +   +           *   *  u13  u24   u35   u46
	*     *  a12 a23 a34 a45 a56          *  u12 u23  u34   u45   u56
	*    a11 a22 a33 a44 a55 a66         u11 u22 u33  u44   u55   u66
	*    a21 a32 a43 a54 a65  *          m21 m32 m43  m54   m65    *
	*    a31 a42 a53 a64  *   *          m31 m42 m53  m64    *     *
	*
	* Array elements marked * are not used by the <indexterm id="idx-CHP-15-1258" significance="normal"><primary>SGBSV routine (LAPACK library)</primary></indexterm>routine; elements marked
	* + need not be set on entry, but are required by the routine to store
	* elements of U because of fill-in resulting from the row interchanges.
	*
	* =====================================================================
	*
	*   .. External Subroutines ..
	    EXTERNAL SGBTRF,   SGBTRS, XERBLA
	*   ..
	*   .. Intrinsic Functions ..
	    INTRINSIC          MAX
	*   ..
	*   .. Executable Statements ..
	*
	*   Test the input parameters.	
	*
	    INFO = 0
	    IF( N.LT.0 ) THEN
	       INFO = -1
	    ELSE IF( KL.LT.0 ) THEN
	       INFO = -2
	    ELSE IF( KU.LT.0 ) THEN
	       INFO = -3
	    ELSE IF( NRHS.LT.0 ) THEN
	       INFO = -4
	    ELSE IF( LDAB.LT.2*KL+KU+1 ) THEN
	       INFO = -6
	    ELSE IF( LDB.LT.MAX( N, 1 ) ) THEN
	       INFO = -9
	    END IF
	    IF( INFO.NE.0 ) THEN
	       CALL XERBLA( 'SGBSV ', -INFO )
	       RETURN
	    END IF
	*
	*   Compute the LU factorization <indexterm id="idx-CHP-15-1259" significance="normal"><primary>memory</primary><secondary>conservation of</secondary></indexterm>of the band matrix A.
	*
	    CALL SGBTRF ( N, N, KL, KU, AB, LDAB, IPIV, INFO )
	    IF( INFO.EQ.0 ) THEN
	*
	*      Solve the system A*X = B, overwriting B with X.
	*
	       CALL SGBTRS( 'No transpose', N, KL, KU, NRHS, AB, LDAB, IPIV,
	   $                B, LDB, INFO )
	    END IF
	    RETURN
	*
	*   End of SGBSV
	*
	    END
</programlisting><para>One of the first things to notice in the code for the <indexterm id="idx-CHP-15-1260" significance="normal"><primary>SGBSV routine (LAPACK library)</primary></indexterm>SGBSV routine is that it starts with a long comment that describes the routine's purpose and use. In fact, the comment is exactly the same as the manual page for that routine. Having the <indexterm id="idx-CHP-15-1261" significance="normal"><primary>comments</primary><secondary>presenting full documentation for purpose of a routine</secondary></indexterm>full documentation of the routine's usage in the code is important because it connects the routine's internal structure with its usage. In many other cases, I have found that the manual description and code documentation have nothing in common. I think this practice of marrying the two is one thing that makes code beautiful.</para><para>Following the initial comments, the algorithm that the routine uses is <indexterm id="idx-CHP-15-1262" significance="normal"><primary>algorithms</primary><secondary>detailed in routine's description</secondary></indexterm>detailed in the routine's description. This helps anyone using the code to understand what the code will do and how it should react. Next comes a detailed description of the arguments, with their ranges explicitly specified.</para><para>The <literal moreinfo="none">AB</literal> argument is an interesting one to consider. This argument contains the elements of the matrix <literal moreinfo="none">A</literal>. Because the matrix is banded, it contains a lot of zero values, which are not clustered close to the diagonal. In <indexterm id="idx-CHP-15-1263" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>principle, the input to the routine could be presented as a two-dimensional array of the dimensions of the matrix. However, this would be a waste of memory space. Instead, the <literal moreinfo="none">AB</literal> argument contains only nonzero elements of the matrix next to its diagonal.</para><para>The format of the <literal moreinfo="none">AB</literal> argument not only conserves memory space, but also has another purpose. In this routine, the algorithm is using the properties of the system of equations to solve the problem in a more efficient way. This means that the algorithm relies on the user to provide the correct matrix type as an input. If the <literal moreinfo="none">AB</literal> argument contains all the elements of the matrix, one or more of the elements outside the band could accidentally be set to nonzero. This could lead to errors in the solution. The format chosen for <literal moreinfo="none">AB</literal> makes it impossible to make this mistake. This was done on purpose, and it contributes to the code's <indexterm id="idx-CHP-15-1264" significance="normal"><primary>CERN library</primary><secondary>outer beauty of code</secondary></indexterm>beauty.</para><para>The <literal moreinfo="none">AB</literal> argument also plays another role: it serves as an output argument as well as an input argument. In this context, the design solves a different problem. By having the routine reuse the space that the original program allocated, the developers <indexterm id="idx-CHP-15-1265" significance="normal"><primary>scalability</primary><secondary>of beautiful code</secondary></indexterm>of this code ensured that the routine would work as long as the original program had sufficient memory. If it had been written so that the routine needed additional memory allocation, then it might not run if the system was unable to allocate more memory. This can be especially problematic when there is a really large system of equations, and the routine needs a significant amount of memory space in which it can operate. The sample code is immune to such problems because it was written so that the routine can return the solution as long as the original program has sufficient memory space to store the problem. This is very beautiful.</para><para>Before I move on to the other arguments, I want to discuss this issue further. I have seen a lot of code written in my lifetime. Very often, developers write code and unconsciously place intrinsic <indexterm id="idx-CHP-15-1266" significance="normal"><primary>restrictions built into code</primary></indexterm>restrictions on it. Most commonly, they restrict the size of the problem that can be solved. This occurs as a result of the following thought process:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>I have something to write.</para></listitem><listitem><para>I'll write it fast so I can see if it works.</para></listitem><listitem><para>Once it works, I will generalize it for the real problem.</para></listitem></orderedlist><para>This process prompts developers to build restrictions into code, which very often leads to difficult-to-find errors that may take years to clean. During this process, developers commonly place explicit or implicit restrictions on the size of the problem they may solve. For example, an explicit restriction may be the definition of a large data space, which should be large enough for all the problems. This is bad and relatively easy to spot. An implicit restriction may be improper usage of dynamic memory—for instance, writing code so that once the problem is presented to the code, the program dynamically allocates the space and solves the problem. For large problems, this can create out-of-memory errors and significantly impact performance. The performance penalty stems from the program's reliance on the operating system's paging utility. If the algorithm is computationally intensive and needs data from many different chunks of memory, the program will fall into constant paging and execute very slowly.</para><para>Another example of this type of problem manifests itself in programs that use database systems. If such a program is written in the manner I just described, it could start constantly accessing the database when it is operating on the data. The programmer might think that the program's operations are trivial and fast, but they are actually very inefficient because they contain calls to the database.</para><para>So what is the lesson here? When writing beautiful code, one needs to think about its <indexterm id="idx-CHP-15-1267" significance="normal"><primary>beautiful code</primary><secondary>scalability</secondary></indexterm>scalability. Contrary to popular belief, scalability does not come from code optimization; rather, it comes from using the right algorithm. Code profiling can provide hints about symptoms of <indexterm id="idx-CHP-15-1268" significance="normal"><primary>performance</primary><secondary>poor design as root cause of problems</secondary></indexterm>poor performance, but the root cause of performance issues can generally be traced back to design issues. The <indexterm id="idx-CHP-15-1269" significance="normal"><primary>SGBSV routine (LAPACK library)</primary></indexterm>SGBSV routine is designed so that it does not have this performance problem, and that is another thing that makes it beautiful.</para><para>Looking now at the other input arguments, it becomes clear that the same <indexterm id="idx-CHP-15-1270" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>principle that applied to the <literal moreinfo="none">AB</literal> array also applies to the others.</para><para>The final argument, <literal moreinfo="none">INFO</literal>, is the error <indexterm id="idx-CHP-15-1271" significance="normal"><primary>errors</primary><secondary>communication mechanism in LAPACK SGBSV routine</secondary></indexterm>communication mechanism. It is interesting to see how the diagnostics are presented to the <indexterm id="idx-CHP-15-1272" significance="normal"><primary>memory</primary><secondary>use of (LAPACK SGBSV routine)</secondary></indexterm>user. It is possible that the system <indexterm id="idx-CHP-15-1273" significance="normal"><primary>testing</primary><secondary>importance of test programs</secondary></indexterm>of equations does not have a solution, and this case is also reported here. Notice that the <literal moreinfo="none">INFO</literal> argument reports failure as well as success, and that it provides diagnostics to help you identify the problem.</para><para>This is something often lacking in code written today. Nowadays, code is commonly written to handle positive use cases: it is written to perform the actions detailed in the specification. With the sample code, this means that the code will work fine if the solution for the system of equations exists. However, reality is messy. In real life, code can break, and code dumps core or throw exceptions when it is presented with a system of equations that lacks a solution. This is a common case of failure to specify requirements about unexpected usages.</para><para>Many systems today are programmed to do as little as possible; then—once they are in use—they are "fixed" to do the things nobody initially anticipated they would need to do. A similar problem is the failure to specify requirements about how to gracefully handle errors and other unexpected situations. Such a response to exceptional circumstances is critical to application reliability and should be treated as a fundamental functionality requirement.</para><para>When writing code to a specification, developers need to recognize that <indexterm id="idx-CHP-15-1274" significance="normal"><primary>specifications for code</primary></indexterm>specifications are usually incomplete. The developer must have a deep understanding of the problem at hand so that she can extend the specification with the additional use cases and unexpected usages that need to be implemented in order for the code to perform in an intelligent way. Our sample <indexterm id="idx-CHP-15-1275" significance="normal"><primary>SGBSV routine (LAPACK library)</primary></indexterm>routine is one example of what happens when such careful consideration is applied. This routine will either do the job, or it will tell you that it cannot do it—it won't crash on you. This is beautiful.</para><para>Next, let's look at the routine's <literal moreinfo="none">Further Details</literal> section. This section describes how the memory is used and makes it obvious that the space is used as the scratch space during internal operations. This is a good example of beautifully implemented code, so I'll be discussing this in the next section, "Inner Beauty."</para><para>Another example of the code's <indexterm id="idx-CHP-15-1276" significance="normal"><primary>CERN library</primary><secondary>outer beauty of code</secondary></indexterm>outer beauty is that many routines in the CERN library provide simple <indexterm id="idx-CHP-15-1277" significance="normal"><primary>beautiful code</primary><secondary>test and example programs</secondary></indexterm>test and <indexterm id="idx-CHP-15-1278" significance="normal"><primary>example programs</primary></indexterm>example programs. This is very important for beautiful code. You should be able to tell whether the code is doing what it's supposed to be doing in your application. The developers of this library have written test programs that show you how the library is being called for specific data. You can use these test programs to verify whether you are going to get the correct results for your data, thus building your confidence in the library.</para><para>The beautiful design here is that the tests not only tell you under which conditions you can use the routines, but also give you a validation example that allows you to build confidence and know what's going on—without really looking into the code.<indexterm id="I_indexterm15_tt333" class="endofrange" startref="idx-CHP-15-1256" significance="normal"><primary>SGBSV routine (LAPACK library)</primary></indexterm><indexterm id="I_indexterm15_tt334" class="endofrange" startref="idx-CHP-15-1255" significance="normal"><primary>CERN library</primary><secondary>outer beauty of code</secondary></indexterm></para></sect1><sect1 id="inner_beauty" label="15.4"><title>Inner Beauty</title><para>Now, let's start looking at the code's <indexterm id="idx-CHP-15-1279" significance="normal"><primary>SGBSV routine (LAPACK library)</primary><secondary>implementation details</secondary></indexterm>implementation details.<indexterm class="startofrange" id="idx-CHP-15-1280" significance="normal"><primary>CERN library</primary><secondary>inner beauty of code</secondary></indexterm></para><sect2 id="beauty_in_brevity_and_simplicity" label="15.4.1"><title>Beauty in Brevity and Simplicity</title><para>I believe that beautiful code is short code, and I find that lengthy, complicated code is generally quite ugly. The SGBSV routine is a prime example of the beauty of short code. It begins with a quick verification of the consistency of the input arguments, then continues with two calls that logically follow the mathematical algorithm.<indexterm id="idx-CHP-15-1281" significance="normal"><primary>understandable code</primary><secondary>brevity and simplicity of code</secondary></indexterm><indexterm id="idx-CHP-15-1282" significance="normal"><primary>brevity in code</primary></indexterm><indexterm id="idx-CHP-15-1283" significance="normal"><primary>simplicity in code</primary></indexterm></para><para>From the first glance, it is obvious what this code is doing: it begins <indexterm id="idx-CHP-15-1284" significance="normal"><primary>code reuse</primary><secondary>promoted by good design and clear</secondary></indexterm>by performing LU factorization with the SGBTRF routine, then solves the system with the SGBTRS routine. This code is very easy to read. There's no need to pore over hundreds of lines of code to understand what the code does. The main task is split into two subtasks, and the subtasks are pushed into a <indexterm id="idx-CHP-15-1285" significance="normal"><primary>subsystem</primary></indexterm>subsystem.</para><para>Note that the subsystem adheres to the same design assumptions regarding memory usage as the main system. This is a very important and beautiful aspect of the design.</para><para>The routines from the subsystem are reused in different "<indexterm id="idx-CHP-15-1286" significance="normal"><primary>driver routines</primary></indexterm>driver" routines (the SGBSV routine is called a driver routine). This creates a hierarchical system that encourages code reuse. This is beautiful, too. Code reuse significantly reduces the effort required for code development, testing, and maintenance. In fact, it is one of the best ways to increase developers' productivity and reduce their stress. The problem is that reuse is typically difficult. Very often, code is so complicated and difficult to read that developers find it easier to rewrite code from scratch than to reuse somebody else's code. Good design and clear, concise code are vital to promoting code reuse.</para><para>Unfortunately, much of the code written today falls short in this respect. Nowadays, most of the code written has an <indexterm id="idx-CHP-15-1287" significance="normal"><primary>inheritance structure</primary></indexterm>inheritance structure, which is encouraged in the hope that it will bring clarity to the code. However, I must admit that I've spent hours on end staring at a few lines of such code…and still could not <indexterm id="idx-CHP-15-1288" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>decipher what it was supposed to do. This is not beautiful code; it is bad code with a convoluted design. If you cannot tell what the code does by glancing at the naming conventions and several code lines, then the code is too complicated.</para><para>Beautiful code should be easy to understand. I hate reading code that was written to show off the developer's knowledge of the language, and I shouldn't need to go through 25 files before I can really understand what a piece of it is really doing. The code does not necessarily need to be commented, but its purpose should be explicit, and there should be no ambiguity in each operation. The problem with the new code being written today—especially in the C++ language—is that developers use so much inheritance and <indexterm id="idx-CHP-15-1289" significance="normal"><primary>overloading</primary></indexterm>overloading that it's almost impossible to tell what the code is really doing, why it's doing it, and whether it's correct. To figure this out, you need to understand all of the hierarchy of <indexterm id="idx-CHP-15-1290" significance="normal"><primary>C++</primary><secondary>inheritance and overloading</secondary></indexterm>inheritance and overloading. If the operation is some kind of complicated overloaded operation, this code is not beautiful to me.</para></sect2><sect2 id="beauty_in_frugality" label="15.4.2"><title>Beauty in Frugality</title><para>My next criterion for beautiful code is that you can tell that a lot of thought went into how the code will be running on the computer. What I'm trying to say is that beautiful code never forgets that it will be running on a computer, and that a computer has limitations. As I said earlier in this chapter, computers have limited speed, sometimes operate better on floating-point numbers or integer numbers, and have finite amounts of memory. Beautiful code must consider these limitations of reality. Quite often, people writing code assume that memory is infinite, computer speed is infinite, and so on. This is not beautiful code; it's arrogant code. Beautiful code is frugal about things like memory use and reuses memory whenever possible.<indexterm id="idx-CHP-15-1291" significance="normal"><primary>CERN library</primary><secondary>inner beauty of code</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-15-1292" significance="normal"><primary>frugality in beautiful code</primary></indexterm></para><para>For example, let's look at the LU decomposition subroutine <indexterm class="startofrange" id="idx-CHP-15-1293" significance="normal"><primary>LAPACK</primary><secondary>SGBTRF routine</secondary></indexterm>SGBTRF, which is in the second level of subroutines. To save space, I removed the initial comments in the header and other excepts that I do not directly discuss (you can view the complete subroutine at <indexterm class="startofrange" id="idx-CHP-15-1294" significance="normal"><primary>LU factorization</primary><secondary>LAPACK SGBTRF routine</secondary></indexterm><ulink url="http://www.netlib.org/lapack/explore-html/sgbtrf.f.html"/>):</para><programlisting id="I_programlisting15_tt335" format="linespecific">
	     SUBROUTINE SGBTRF( M, N, KL, KU, AB, LDAB, IPIV, INFO )
	*
	* -- LAPACK routine (version 2.0) --
	*    Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
	*    Courant Institute, Argonne National Lab, and Rice University
	*    February 29, 1992
	<userinput moreinfo="none">.
	.
	.
	Initial comments, description of parameters
	.
	,
	,</userinput>

	*     Test the input parameters.
	*
	      INFO = 0
	      IF( M.LT.0 ) THEN

	<userinput moreinfo="none">.
	.
	.
	Checking parameters
	.
	.
	.</userinput>

	           CALL XERBLA( 'SGBTRF', -INFO )
	         RETURN
	      END IF
	*
	*     Quick return if possible
	*
	      IF( M.EQ.0 .OR. N.EQ.0 )
	     $   RETURN
	*
	*     <indexterm id="idx-CHP-15-1295" significance="normal"><primary>frugality in beautiful code</primary></indexterm>Determine the block size for this environment
	*
	      NB = ILAENV( 1, '<indexterm id="idx-CHP-15-1296" significance="normal"><primary>LAPACK</primary><secondary>SGBTRF routine</secondary></indexterm>SGBTRF', ' ', M, N, KL, KU )
	*
	*     The block size must not exceed the limit set by the size of the
	*     local arrays WORK13 and WORK31.
	*
	      NB = MIN( NB, NBMAX )
	*
	      IF( NB.LE.1 .OR. NB.GT.KL ) THEN
	*
	*        Use unblocked code
	*
	         CALL SGBTF2( M, N, KL, KU, AB, LDAB, IPIV, INFO )
	      ELSE
	*
	*        Use blocked code
	*
	*        Zero the superdiagonal elements of the work array WORK13
	*
	         DO 20 J = 1, NB
	            DO 10 I = 1, J - 1
	               WORK13( I, J ) = ZERO
	  10        CONTINUE
	  20     CONTINUE
	*
	*        Zero the subdiagonal elements of the work array WORK31
	*
	         DO 40 J = 1, NB
	            DO 30 I = J + 1, NB
	               WORK31( I, J ) = ZERO
	  30        CONTINUE
	  40     CONTINUE	
	*
	*        Gaussian elimination with partial pivoting
	*
	*        Set fill-in elements in columns KU+2 to KV to zero
	*
	         DO 60 J = KU + 2, MIN( KV, N )
	            DO 50 I = KV - J + 2, KL
	               AB( I, J ) = ZERO
	  50        CONTINUE
	  60     CONTINUE
	*
	*        JU is the index of the last column affected by the current
	*        stage of the factorization
	*
	         JU = 1
	*
	         DO 180 J = 1, MIN( M, N ), NB
	            JB = MIN( NB, MIN( M, N )-J+1 )
	*
	*           The active part of the matrix is partitioned
	*
	*               A11 A12 A13
	*               A21 A22 A23
	*               A31 A32 A33
	*
	*            Here A11, A21 and A31 denote the current block of JB columns
	*            which is about to be factorized. The number of rows <indexterm id="idx-CHP-15-1297" significance="normal"><primary>frugality in beautiful code</primary></indexterm>in the
	*            partitioning are JB, I2, I3 respectively, and the numbers
	*            of columns are JB, J2, J3. The superdiagonal elements of A13
	*            and the subdiagonal elements of A31 lie outside the band.
	*
	             I2 = MIN( KL-JB, M-J-JB+1 )
	             I3 = MIN( JB, M-J-KL+1 )
	*
	*            J2 and J3 are computed after JU has been updated.
	*
	*            Factorize the current block of JB columns
	*
	             DO 80 JJ = J, J + JB - 1
	*
	*               Set fill-in elements in column JJ+KV to zero
	*
	                IF( JJ+KV.LE.N ) THEN
	                   DO 70 I = 1, KL
	                      AB( I, JJ+KV ) = ZERO
	   70              CONTINUE
	                END IF
	*
	*               Find pivot and test for singularity. KM is the number of
	*               subdiagonal elements in the current column.
	*
	                KM = MIN( KL, M-JJ )
	                JP = ISAMAX( KM+1, AB( KV+1, JJ ), 1 )
	                IPIV( JJ ) = JP + JJ - J
	                IF( AB( KV+JP, JJ ).NE.ZERO ) THEN
	                   JU = MAX( JU, MIN( JJ+KU+JP-1, N ) )
	                   IF( JP.NE.1 ) THEN
	*
	*                     Apply interchange to columns J to J+JB-1
	*
	                      IF( JP+JJ-1.LT.J+KL ) THEN
	*
	                         CALL SSWAP( JB, AB( KV+1+JJ-J, J ), LDAB-1,
	   $                                 AB( KV+JP+JJ-J, J ), LDAB-1 )
	                      ELSE
	*
	*                        The interchange affects columns J to JJ-1 of A31
	*                        which are stored in the work array WORK31
	*
	                         CALL SSWAP( JJ-J, AB( KV+1+JJ-J, J ), LDAB-1,
	   $                                 WORK31( JP+JJ-J-KL, 1 ), LDWORK )
	                         CALL SSWAP( J+JB-JJ, AB( KV+1, JJ ), LDAB-1,
	   $                                AB( KV+JP, JJ ), LDAB-1 )
	                      END IF
	                   END IF
	*
	*                  Compute multipliers
	*
	                        CALL SSCAL( KM, ONE / AB( KV+1, JJ ), AB( KV+2, JJ ),
	  $                                 1 )
	*
	<userinput moreinfo="none">.
	.
	.
	Continue direct solution
	.
	.
	.</userinput>
	  170      CONTINUE
	  180   CONTINUE
	     END IF
	*
	     RETURN
	*
	*    End of <indexterm id="idx-CHP-15-1298" significance="normal"><primary>LAPACK</primary><secondary>SGBTRF routine</secondary></indexterm>SGBTRF
	*
	     END
</programlisting><para>Again, the subroutine starts with argument verification and then proceeds to the problem solution. This is followed by an optimization <indexterm id="idx-CHP-15-1299" significance="normal"><primary>memory</primary><secondary>check looking at problem size and memory of computer</secondary></indexterm>check, which looks at the problem size to determine whether it can be solved in the "cache" arrays <literal moreinfo="none">WORK13</literal> and <literal moreinfo="none">WORK31</literal>, or whether it needs to be sent to a lower level for more complicated operations. This is an excellent example of code that is built realistically, for a computer with inherent limitations. The work array can be adjusted for the standard memory of the computer that is solving the problem; in problems with a small enough size, this can prevent performance penalties from possible paging. Problems above that size are so large that that the performance penalty cannot be avoided.</para></sect2><sect2 id="beauty_in_flow" label="15.4.3"><title>Beauty in Flow</title><para>The previous problem solution provides a step-by-step representation of the algorithm. Reading this code is almost like reading a book, since it is so easy to follow. The parts of the problem that are common to other algorithms are reused, and the parts that would complicate the code are passed to <indexterm id="idx-CHP-15-1300" significance="normal"><primary>subroutines</primary></indexterm>subroutines. The result is a very clear, understandable flow.<indexterm id="idx-CHP-15-1301" significance="normal"><primary>CERN library</primary><secondary>inner beauty of code</secondary><tertiary>beauty in flow</tertiary></indexterm><indexterm id="idx-CHP-15-1302" significance="normal"><primary>CERN library</primary><secondary>inner beauty of code</secondary></indexterm><indexterm id="idx-CHP-15-1303" significance="normal"><primary>flow in beautiful code</primary></indexterm></para><para>Each step in the flow corresponds to the mathematical expression. At each step, the code describes what a lower system is expected to do and calls that lower system. The main routine, which is a driver routine, branches into lower routines, each of which branches into more lower routines, and so on. This flow is represented in <indexterm id="idx-CHP-15-1304" significance="normal"><primary>divide and conquer strategy</primary><secondary>logical subdivision of tasks into subroutines</secondary></indexterm><xref linkend="logical_subdivision_of_tasks_into_subroutines"/>.</para><para>This is an excellent example of how to apply the "divide and conquer" <indexterm id="idx-CHP-15-1305" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>principle to code design. Every time you move to a lower step, there is a smaller problem to conquer, and you can focus on well-defined circumstances that make the code smaller and better focused. If the problem fits in the computer's memory, the algorithm will solve it directly, as I discussed previously. If not, it goes to the next level of subroutines, and so on.<indexterm id="I_indexterm15_tt336" class="endofrange" startref="idx-CHP-15-1292" significance="normal"><primary>frugality in beautiful code</primary></indexterm><indexterm id="I_indexterm15_tt337" class="endofrange" startref="idx-CHP-15-1293" significance="normal"><primary>LAPACK</primary><secondary>SGBTRF routine</secondary></indexterm><indexterm id="I_indexterm15_tt338" class="endofrange" startref="idx-CHP-15-1294" significance="normal"><primary>LU factorization</primary><secondary>LAPACK SGBTRF routine</secondary></indexterm></para><figure id="logical_subdivision_of_tasks_into_subroutines" label="15-1" float="0"><title>Logical subdivision of tasks into subroutines</title><mediaobject id="I_mediaobject15_tt339"><imageobject role="print"><imagedata fileref="figs/print/beauty_1501.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1501.png" format="PNG"/></imageobject></mediaobject></figure><para>As a result, very computation-intensive routines can be written in assembly language and then optimized for the architecture. Another benefit of this design is that many people can work on the code simultaneously because each subroutine is independent and so well defined.</para></sect2></sect1><sect1 id="conclusion-id006" label="15.5"><title>Conclusion</title><para>In sum, I believe that beautiful code must be short, explicit, frugal, and written with consideration for reality. However, I think that the true test of beauty—for code as well as art—is whether the work stands the test of time. Lots of code has been written over the years, but little of it was still in use even several years after it was written. That the CERN library code is still in use more than 30 years after it was written confirms that it is truly beautiful.<indexterm id="I_indexterm15_tt340" class="endofrange" startref="idx-CHP-15-1280" significance="normal"><primary>CERN library</primary><secondary>inner beauty of code</secondary></indexterm></para></sect1></chapter><chapter id="the_linux_kernel_driver_model_the_benefits_of_working_together" label="16" role=""><title>The Linux Kernel Driver Model: The Benefits of Working Together</title><para><emphasis>Greg Kroah-Hartman</emphasis><indexterm class="startofrange" id="idx-CHP-16-1306" significance="normal"><primary>Linux kernel</primary></indexterm><indexterm id="idx-CHP-16-1307" significance="normal"><primary>Kroah-Hartman</primary></indexterm></para><para><emphasis>The linux kernel driver model attempts to create a system-wide tree</emphasis> of all different types of <indexterm id="idx-CHP-16-1308" significance="normal"><primary>devices (on Linux)</primary></indexterm>devices managed by the operating system. The core data structures and code used to do this have changed over the years from a very simplistic system meant for handling a few <indexterm id="idx-CHP-16-1309" significance="normal"><primary>Linux kernel</primary><secondary>devices</secondary></indexterm>devices to a highly scalable system that can control every different type of device that the real world needs to interact with.</para><para>As the Linux kernel has evolved over the years, handling more and more different types of devices,<footnote id="CHP-16-FNOTE-1"><para>Linux now supports more different types of devices and processors than any other operating system ever has in the history of computing.</para></footnote> the core of the kernel has had to change and evolve in order to come up with easier and more manageable ways to handle the range of device types.</para><para>Almost all devices consist of two different portions: the physical portion that defines how the operating system talks to the device (be it through the PCI bus, SCSI bus, ISA bus, USB bus, etc.) and the virtual portion that defines how the operating system presents the device to the user so that it can be operated properly (keyboard, mouse, video, sound, etc.). Through the 2.4 kernel releases, each physical portion of devices was controlled by a bus-specific portion of code. This bus code was responsible for a wide range of different tasks, and each individual bus code had no interaction with any other bus code.</para><para><indexterm id="idx-CHP-16-1310" significance="normal"><primary>databases</primary><secondary>in operating system kernel for device naming</secondary></indexterm>In 2001, Pat Mochel was working on solving the issue of <indexterm id="idx-CHP-16-1311" significance="normal"><primary>Linux kernel</primary><secondary>power management for devices</secondary></indexterm>power management in the <indexterm id="idx-CHP-16-1312" significance="normal"><primary>Linux kernel</primary></indexterm>Linux kernel. He came to realize that in order to shut down or power up individual <indexterm id="idx-CHP-16-1313" significance="normal"><primary>device structure (Linux)</primary></indexterm>devices properly, the kernel had to <indexterm id="idx-CHP-16-1314" significance="normal"><primary>devices (on Linux)</primary><secondary>no proper handling in persistent manner</secondary></indexterm>know the linkages between the different <indexterm id="idx-CHP-16-1315" significance="normal"><primary>Linux kernel</primary><secondary>device handling in persistent manner</secondary></indexterm>devices. For example, a USB disk drive should be shut down before the PCI controller card for the USB controller is shut down, in order to properly save the data on the device. To solve this issue, the kernel needed to know the tree of all devices in the system, showing what device controlled what other device, and the order in which everything was connected.</para><para>Around the same time, I was running into another device-related problem: Linux did not properly handle devices in a persistent manner. I wanted my two USB printers to always have the same name, no matter which one was turned on first, or the order in which they were discovered by the Linux kernel.</para><para>Some other operating systems have solved this issue by placing a small <indexterm id="idx-CHP-16-1316" significance="normal"><primary>operating systems</primary><secondary>database or devfs to handle device naming</secondary></indexterm>database in the kernel to handle device naming, or have attempted to export all possible unique characteristics of a device through a <emphasis>devfs</emphasis> type of filesystem<footnote id="CHP-16-FNOTE-2"><para><emphasis>devfs</emphasis> is one way for an operating system to show users all the different devices that are available to be used. It does this by showing all of the different device names, and sometimes a limited relationship between those devices.</para></footnote> that can be used to directly access the device. For Linux, placing a database inside the kernel was not going to be an acceptable solution. Also, the Linux's <emphasis>devfs</emphasis> filesystem implementation contained a number of well-known and incurable race conditions, preventing almost all Linux distributions from relying on it. The <emphasis>devfs</emphasis> solution also forced a specific naming policy on the user. Although some people considered this an advantage, it went against the published Linux device-naming standard, and did not allow anyone to use a different naming policy if they so desired.<indexterm id="idx-CHP-16-1317" significance="normal"><primary>devfs filesystem</primary></indexterm><indexterm id="idx-CHP-16-1318" significance="normal"><primary>Linux kernel</primary><secondary>devfs</secondary></indexterm></para><para>Pat and I realized that both of our problems could be solved by a <indexterm id="idx-CHP-16-1319" significance="normal"><primary>Linux kernel</primary><secondary>unified driver and device model</secondary></indexterm>unified driver and device model within the Linux kernel. Such a unified model was not a new idea by any means, as other operating systems had embodied such unified models in the past. Now it was time for Linux to do the same. Such a model would allow for the creation of a tree of all devices and also allow a userspace program outside the kernel to handle persistent device naming of any device, in any way that the user desired.</para><para>This chapter will describe the evolution of the data structures and supporting functions inside the Linux kernel to do this work, and how this evolution caused changes that could have never been <indexterm id="idx-CHP-16-1320" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>anticipated by anyone at the beginning of the development process.</para><sect1 id="humble_beginnings" label="16.1"><title>Humble Beginnings</title><para>To start with, a simple structure, <literal moreinfo="none">struct device</literal>, was created as the "base" class for all devices in the kernel. This structure started out looking like the following:<indexterm id="idx-CHP-16-1321" significance="normal"><primary>devices (on Linux)</primary><secondary>struct device as base class</secondary></indexterm></para><programlisting id="I_programlisting16_tt341" format="linespecific">
	struct device {
	        struct list_head node;           /* node in sibling list */
	        struct list_head children;
	        struct device *parent;
	        char   name[DEVICE_NAME_SIZE];   /* descriptive ascii string */
	        char   bus_id[BUS_ID_SIZE];      /* position on parent bus */

	        spinlock_t       lock;           /* lock for the device to ensure two
	                                            different layers don't access it at
	                                            the same time. */
	        atomic_t         refcount;       /* refcount to make sure the device
	                                          * persists for the right amount of time */

	        struct driver_dir_entry * dir;

	        struct device_driver *driver;    /* which driver has allocated this
	                                            device */
	        void            *driver_data;    /* data private to the driver */
	        void            *platform_data;  /* Platform-specific data (e.g. ACPI,
	                                            BIOS data relevant to device */

	       u32             current_state;    /* Current operating state. In
	                                            ACPI-speak, this is D0-D3, D0
	                                            being fully functional, <indexterm class="startofrange" id="idx-CHP-16-1322" significance="normal"><primary>structures</primary><secondary>inheritance and manipulation on Linux kernel</secondary></indexterm>and D3
	                                            being off. */

	      unsigned char *saved_state;        /* saved device state */
	};
</programlisting><para>Every time this structure was created and registered with the kernel driver core, a new entry in a virtual filesystem was created that showed the device and any different attributes it contained. This allowed all devices in the system to be shown to userspace, in the order in which they were connected. This virtual filesystem is now called <emphasis>sysfs</emphasis> and can be seen on a <indexterm id="idx-CHP-16-1323" significance="normal"><primary>Linux kernel</primary></indexterm>Linux machine in the <emphasis>/sys/devices</emphasis> directory. An example of this structure showing a few <indexterm id="idx-CHP-16-1324" significance="normal"><primary>PCI and USB devices in Linux sysfs</primary></indexterm>PCI and USB devices follows:<indexterm id="idx-CHP-16-1325" significance="normal"><primary>sysfs (Linux)</primary></indexterm></para><programlisting id="I_programlisting16_tt342" format="linespecific">
	<userinput moreinfo="none">$ tree -d /sys/devices/</userinput>
	/sys/devices/pci0000:00/
	|-- 0000:00:00.0
	|-- 0000:00:02.0
	|-- 0000:00:07.0
	|-- 0000:00:1b.0
	|   |-- card0
	|   |   |-- adsp
	|   |   |-- audio
	|   |   |-- controlC0
	|   |   |-- dsp
	|   |   |-- mixer
	|   |   |-- pcmC0D0c
	|   |   |-- pcmC0D0p
	|   |   |-- pcmC0D1p
	|   |   `-- subsystem -&gt; ../../../../class/sound
	|   `-- driver -&gt; ../../../bus/pci/drivers/HDA Intel
	|-- 0000:00:1c.0
	|   |-- 0000:00:1c.0:pcie00
	|   |-- 0000:00:1c.0:pcie02
	|   |-- 0000:00:1c.0:pcie03
	|   |-- 0000:01:00.0
	|   | `-- driver -&gt; ../../../../bus/pci/drivers/sky2
	|   `-- driver -&gt; ../../../bus/pci/drivers/pcieport-driver
	|-- 0000:00:1d.0
	|   |-- driver -&gt; ../../../bus/pci/drivers/uhci_hcd
	|   `-- usb2
	|       |-- 2-0:1.0
	|       |   |-- driver -&gt; ../../../../../bus/usb/drivers/hub
	|       |   |-- subsystem -&gt; ../../../../../bus/usb
	|       |   `-- usbdev2.1_ep81
	|       |-- driver -&gt; ../../../../bus/usb/drivers/usb
	|       `-- usbdev2.1_ep00
	|-- 0000:00:1d.2
	|   |-- driver -&gt; ../../../bus/pci/drivers/uhci_hcd
	|   `-- usb4
	|       |-- 4-0:1.0
	|       |   |-- driver -&gt; ../../../../../bus/usb/drivers/hub
	|       |   `-- usbdev4.1_ep81
	|       |-- 4-1
	|       |   |-- 4-1:1.0
	|       |   |   |-- driver -&gt; ../../../../../../bus/usb/drivers/usbhid
	|       |   |   `-- usbdev4.2_ep81
	|       |   |-- driver -&gt; ../../../../../bus/usb/drivers/usb
	|       |   |-- power
	|       |   `-- usbdev4.2_ep00
	|       |-- 4-2
	|       |   |-- 4-2.1
	|       |   |   |-- 4-2.1:1.0
	|       |   |   |   |-- driver -&gt; ../../../../../../../bus/usb/drivers/usbhid
	|       |   |   |   `-- usbdev4.4_ep81
	|       |   |   |-- 4-2.1:1.1
	|       |   |   |   |-- driver -&gt; ../../../../../../../bus/usb/drivers/usbhid
	|       |   |   |   `-- usbdev4.4_ep82
	|       |   |   |-- driver -&gt; ../../../../../../bus/usb/drivers/usb
	|       |   |   `-- usbdev4.4_ep00
	|       |   |-- 4-2.2
	|       |   |   |-- 4-2.2:1.0
	|       |   |   |   |-- driver -&gt; ../../../../../../../bus/usb/drivers/usblp
	|       |   |   |   |-- usbdev4.5_ep01
	|       |   |   |   `-- usbdev4.5_ep81
	|       |   |   |-- driver -&gt; ../../../../../../bus/usb/drivers/usb
	|       |   |   `-- usbdev4.5_ep00
	|       |   |-- 4-2:1.0
	|       |   |   |-- driver -&gt; ../../../../../../bus/usb/drivers/hub
	|       |   | `-- usbdev4.3_ep81
	|       |   |-- driver -&gt; ../../../../../bus/usb/drivers/usb
	|       |   `-- usbdev4.3_ep00
	|       |-- driver -&gt; ../../../../bus/usb/drivers/usb
	|       `-- usbdev4.1_ep00
	...
</programlisting><para>To use this structure, it is required that you embed it within another structure, causing the new structure to "inherit," in a sense, from the base structure:</para><programlisting id="I_programlisting16_tt343" format="linespecific">
	struct usb_interface {
	        struct usb_interface_descriptor *altsetting;
	
	        int act_altsetting;             /* active alternate setting */
	        int num_altsetting;             /* number of alternate settings*/
	        int max_altsetting;             /* total memory allocated */
	        struct usb_driver *driver;      /* driver */
	        struct device dev;              /* interface specific device info */
	};
</programlisting><para>The driver core operates by passing <indexterm id="idx-CHP-16-1326" significance="normal"><primary>Linux kernel</primary><secondary>unified driver and device model</secondary><tertiary>around</tertiary></indexterm>around <indexterm id="idx-CHP-16-1327" significance="normal"><primary>C language</primary><secondary>pointers</secondary></indexterm>pointers <indexterm id="idx-CHP-16-1328" significance="normal"><primary>pointers</primary><secondary>to a struct device (on Linux)</secondary></indexterm>to a <literal moreinfo="none">struct device</literal>, operating on the basic fields that are in that structure <indexterm id="idx-CHP-16-1329" significance="normal"><primary>structures</primary><secondary>inheritance and manipulation on Linux kernel</secondary></indexterm>and thus are common to all types of devices. When the pointer is handed off to the bus-specific code for various functions, it needs to be converted to the real type of structure that contains it. To handle this conversion, the bus-specific code casts the pointer back to the original structure, based on where it is in memory. This is accomplished by the following fun macro:</para><programlisting id="I_programlisting16_tt344" format="linespecific">
	#define <indexterm id="idx-CHP-16-1330" significance="normal"><primary>container_of macro</primary></indexterm>container_of(ptr, type, member) ({                      \
	        const typeof( ((type *)0)-&gt;member ) *__mptr = (ptr); \
	        (type *)( (char *)__mptr - <indexterm id="idx-CHP-16-1331" significance="normal"><primary>offsetof macro</primary></indexterm>offsetof(type,member) );})
</programlisting><para>This macro deserves some explanation, for those not up on their pointer arithmetic in the C language. To take an example, the previous <literal moreinfo="none">struct usb_interface</literal> could convert a pointer to the <literal moreinfo="none">struct device</literal> member of the structure back to the original pointer through:<indexterm id="idx-CHP-16-1332" significance="normal"><primary>usb_interface structure (Linux)</primary></indexterm></para><programlisting id="I_programlisting16_tt345" format="linespecific">
	int probe(struct device *d) {
	        struct usb_interface *intf;

	        intf = container_of(d, struct usb_interface, dev);

	    ...
	}
</programlisting><para>where <literal moreinfo="none">d</literal> is a pointer to a <literal moreinfo="none">struct device</literal>.</para><para>Expanding the <literal moreinfo="none">container_of</literal> macro just shown creates the following code:</para><programlisting id="I_programlisting16_tt346" format="linespecific">
	intf = ({
	   const typeof( ((struct usb_interface *)0)-&gt;dev) *__mptr = d;
	  (struct usb_interface *)( (char *)__mptr - offsetof(struct usb_interface, dev));
	});
</programlisting><para>To understand this, remember that <literal moreinfo="none">dev</literal> is a member of the <literal moreinfo="none">struct usb_interface</literal> structure. The first line of the macro sets up a pointer that points to the <literal moreinfo="none">struct device</literal> passed to the code. The second line of the macro finds the real location in memory of the <literal moreinfo="none">struct usb_ interface</literal> that we want to access.</para><para>So, with the type of the <literal moreinfo="none">dev</literal> structure known, the macro can be reduced to:</para><programlisting id="I_programlisting16_tt347" format="linespecific">
	intf = ({
	    const struct device *__mptr = d;
	    (struct usb_interface *)( (char *)__mptr - offsetof(struct usb_interface, dev));
	});
</programlisting><para>Based on the definition of the <literal moreinfo="none">struct usb_interface</literal> recently shown, the <literal moreinfo="none">dev</literal> variable is probably placed 16 bytes into the structure on a 32-bit processor. This is automatically calculated by the compiler with the <literal moreinfo="none">offsetof</literal> macro. Replacing this information in the macro now yields:</para><programlisting id="I_programlisting16_tt348" format="linespecific">
	intf = ({
	    const struct device *__mptr = d;
	    (struct usb_interface *)( (char *)__mptr - 16));
	});
</programlisting><para>The <literal moreinfo="none">container_of</literal> macro has now been reduced to simple <indexterm id="idx-CHP-16-1333" significance="normal"><primary>usb_interface structure (Linux)</primary><secondary>pointer</secondary></indexterm>pointer arithmetic, subtracting 16 from the original pointer to get to the desired <literal moreinfo="none">struct usb_interface</literal> pointer. The compiler does this quickly at <indexterm id="idx-CHP-16-1334" significance="normal"><primary>pointers</primary><secondary>runtime type checking lacking on Linux kernel</secondary></indexterm>runtime.</para><para>With this very simple method, the <indexterm id="idx-CHP-16-1335" significance="normal"><primary>Linux kernel</primary></indexterm>Linux kernel allows normal C structures to be inherited <indexterm id="idx-CHP-16-1336" significance="normal"><primary>structures</primary><secondary>inheritance and manipulation on Linux kernel</secondary></indexterm>and manipulated in very powerful ways. Well, very powerful as long as you know exactly what you are doing.</para><para>If you notice, there is no runtime <indexterm id="idx-CHP-16-1337" significance="normal"><primary>type checking for pointers</primary></indexterm>type checking to ensure that the pointer that was originally passed as a <literal moreinfo="none">struct device</literal> really was of the <literal moreinfo="none">struct usb_interface</literal> type. Traditionally, most systems that do this kind of pointer manipulation also have a field in the <indexterm id="idx-CHP-16-1338" significance="normal"><primary>structures</primary><secondary>base structure field defining pointer type</secondary></indexterm>base structure that defines the type of the pointer being manipulated, to catch sloppy programming errors. It also allows for code to be written to dynamically determine the type of the pointer and do different things with it based on the type.</para><para>The Linux kernel developers made the decision to do none of this checking or type definition. These types of checks can catch basic programming errors at the initial time of development, but allow programmers to create hacks that can have much more subtle problems later on that can't be easily caught.</para><para>The lack of runtime checking forces the developers who are manipulating these pointers to be absolutely sure they know exactly what type of pointer they are manipulating and passing around the system. Sure, at moments, a developer really wishes that there would be some way to determine what type of <literal moreinfo="none">struct device</literal> he is staring at, but the feeling eventually passes when the problem is properly debugged.</para><para>Is this <indexterm id="idx-CHP-16-1339" significance="normal"><primary>beautiful code</primary><secondary>lack of type checking in Linux kernel</secondary></indexterm>lack of type checking good enough to be called "beautiful code"? After working with it for over five years, yes, I think it is. It keeps easy hacks from springing up within the kernel and forces everyone to be very exact in their logic, never falling back on any checks for types that might prevent bugs from happening later.</para><para>I should note here that only a relatively small number of developers—those who code up subsystems for common buses—work on these parts of the kernel, and that they are expected to develop considerable expertise; that is why no hand-holding in the form of type-checking is done here.</para><para>With this method of <indexterm id="idx-CHP-16-1340" significance="normal"><primary>C language</primary><secondary>structures</secondary><tertiary>inheriting and manipulating in Linux kernel</tertiary></indexterm>inheriting the basic <literal moreinfo="none">struct device</literal> structure, all the different driver subsystems were unified during the 2.5 kernel development process. They now shared the common core code, which allowed the kernel to show users how all devices were interconnected. This enabled the creation of tools such as <literal moreinfo="none">udev</literal>, which does persistent device naming in a small userspace program, and power management tools, which can walk the tree of devices and shut devices down in the proper order.<indexterm id="idx-CHP-16-1341" significance="normal"><primary>udev tool (Linux)</primary></indexterm><indexterm id="I_indexterm16_tt349" class="endofrange" startref="idx-CHP-16-1322" significance="normal"><primary>structures</primary><secondary>inheritance and manipulation on Linux kernel</secondary></indexterm></para></sect1><sect1 id="reduced_to_even_smaller_bits" label="16.2"><title>Reduced to Even Smaller Bits</title><para>As the <indexterm id="idx-CHP-16-1342" significance="normal"><primary>structures</primary><secondary>in multithreaded programs</secondary></indexterm>initial driver core rework was happening, another kernel developer, Al Viro, was working on fixing a number of issues regarding <indexterm class="startofrange" id="idx-CHP-16-1343" significance="normal"><primary>object reference counting in Linux kernel virtual filesystem layer</primary></indexterm>object reference counting in the virtual filesystem layer.</para><para>The main problem with structures in <indexterm id="idx-CHP-16-1344" significance="normal"><primary>multithreaded programs in C</primary></indexterm>multithreaded programs written in the C language is that it's very hard to determine when it is safe to free up any memory used by a structure. The <indexterm id="idx-CHP-16-1345" significance="normal"><primary>Linux kernel</primary></indexterm>Linux kernel is a massively multithreaded program that must properly handle hostile users as well as large numbers of processors all running at the same time. Because of this, <indexterm id="idx-CHP-16-1346" significance="normal"><primary>device structure (Linux)</primary><secondary>reference counting</secondary></indexterm>reference counting on any structure that can be found by more than one thread is a necessity.</para><para>The <literal moreinfo="none">struct device</literal> structure was one such reference-counted structure. It had a single field that was used to determine when it was safe to free the structure:</para><programlisting id="I_programlisting16_tt350" format="linespecific">
	atomic_t          refcount;
</programlisting><para>When the structure was initialized, this field was set to 1. Whenever any code wished to use the structure, it had to first increment the reference count by calling the function <literal moreinfo="none">get_ device</literal>, which checked that the reference count was valid and incremented the reference count of the structure:</para><programlisting id="I_programlisting16_tt351" format="linespecific">
	static inline void get_device(struct device * dev)
	{
	        BUG_ON(!atomic_read(&amp;dev-&gt;refcount));
	        atomic_inc(&amp;dev-&gt;refcount);
	}
</programlisting><para>Similarly, when a thread was finished with the structure, it decremented the reference count by calling <literal moreinfo="none">put_device</literal>, which was a bit more complex:</para><programlisting id="I_programlisting16_tt352" format="linespecific">
	void put_device(struct device * dev)
	{
	        if (!atomic_dec_and_lock(&amp;dev-&gt;refcount,&amp;device_lock))
	                return;

	    ...

	        /* Tell the driver to clean up after itself.
	         * Note that we likely didn't allocate the device,
	         *so this is the driver's chance to free that up...
	         */
	        if (dev-&gt;driver &amp;&amp; dev-&gt;driver-&gt;remove)
	                 dev-&gt;driver-&gt;remove(dev,REMOVE_FREE_RESOURCES);
	}
</programlisting><para>This function decremented the reference count and then, if it was the last user of the object, would tell the object to clean itself up and call a function that was previously set up to free it from the system.</para><para>Al Viro liked the unification of the <literal moreinfo="none">struct device</literal> structure, the virtual filesystem that showed all of the different devices and how they were <indexterm id="idx-CHP-16-1347" significance="normal"><primary>structures</primary><secondary>in multithreaded programs</secondary></indexterm>linked together, and the automatic <indexterm id="idx-CHP-16-1348" significance="normal"><primary>C language</primary><secondary>structures</secondary><tertiary>reference counting</tertiary></indexterm>reference counting. The only problem was that his virtual filesystem core did not work on "devices," nor did it have "drivers" that would attach to these <indexterm id="idx-CHP-16-1349" significance="normal"><primary>object reference counting in Linux kernel virtual filesystem layer</primary></indexterm>objects. So, he decided to refactor things a bit and make the code simpler.</para><para>Al convinced Pat to create something called <literal moreinfo="none">struct kobject</literal>. This structure had the basic properties of the <literal moreinfo="none">struct device</literal> structure, but was smaller and did not have the "driver" and "device" relationship. It contained the following fields:<indexterm id="idx-CHP-16-1350" significance="normal"><primary>kobject structure (Linux)</primary></indexterm></para><programlisting id="I_programlisting16_tt353" format="linespecific">
	struct kobject {
	        char                 name[KOBJ_NAME_LEN];
	        atomic_t             refcount;
	        struct list_head     entry;
	        struct kobject       *parent;
	        struct subsystem     *subsys;
	        struct dentry        *dentry;
	};
</programlisting><para>This structure is a type of empty object. It has only the very basic ability to be reference-counted and to be inserted into a hierarchy of objects. The <literal moreinfo="none">struct device</literal> structure could now include this smaller <literal moreinfo="none">struct kobject</literal> "base" structure to inherit all of its functionality:</para><programlisting id="I_programlisting16_tt354" format="linespecific">
	struct device {
	        struct list_head g_list;      /* node in depth-first order list */
	        struct list_head node;        /* node in sibling list */
	        struct list_head bus_list;    /* node in bus's list */
	        struct list_head driver_list;
	        struct list_head children;
	        struct list_head intf_list;
	        struct device *parent;

	        struct kobject kobj;
	        char    bus_id[BUS_ID_SIZE];  /* position on parent bus */

	...
	}
</programlisting><para>The <literal moreinfo="none">container_of</literal> macro is used to cast <indexterm id="idx-CHP-16-1351" significance="normal"><primary>container_of macro</primary><secondary>casting back from core kobject to main struct device</secondary></indexterm>back from the core <literal moreinfo="none">kobject</literal>, to the main <literal moreinfo="none">struct device:</literal></para><programlisting id="I_programlisting16_tt355" format="linespecific">
	#define to_dev(obj) container_of(obj, struct device, kobj)
</programlisting><para>During this development process, many other people were increasing the robustness of the <indexterm id="idx-CHP-16-1352" significance="normal"><primary>Linux kernel</primary></indexterm>Linux kernel by allowing it to scale up to larger and larger numbers of processors all running in the same system image.<footnote id="CHP-16-FNOTE-3"><para>The current record for the number of processors with Linux running in a single system image is 4096 processors, so the scalability work has succeeded.</para></footnote> Because of this, many other developers were adding reference counts to their structures to properly handle their memory usage. Each developer had to duplicate the ability to initialize, increment, decrement, and clean up the structure. So it was decided that this simple functionality could be taken from the <literal moreinfo="none">struct kobject</literal> and made into its own structure. Thus was the <literal moreinfo="none">struct kref</literal> structure born:<indexterm id="idx-CHP-16-1353" significance="normal"><primary>structures</primary><secondary>in multithreaded programs</secondary></indexterm><indexterm id="idx-CHP-16-1354" significance="normal"><primary>Linux kernel</primary><secondary>unified driver and device model</secondary><tertiary>object reference counting in virtual filesystem layer</tertiary></indexterm><indexterm id="idx-CHP-16-1355" significance="normal"><primary>C language</primary><secondary>structures</secondary><tertiary>reference counting</tertiary></indexterm><indexterm id="idx-CHP-16-1356" significance="normal"><primary>kref structure (Linux)</primary></indexterm></para><programlisting id="I_programlisting16_tt356" format="linespecific">
	struct kref {
	        atomic_t refcount;
	};
</programlisting><para><literal moreinfo="none">struct kref</literal> has only three simple functions: <literal moreinfo="none">kref_init</literal> to initialize the reference count, <literal moreinfo="none">kref_get</literal> to increment the reference count, and <literal moreinfo="none">kref_put</literal> to decrement the reference count. The first two functions are very simple; it is the last one that's a bit interesting:</para><programlisting id="I_programlisting16_tt357" format="linespecific">
	int kref_put(struct kref *kref, void (*release)(struct kref *kref))
	{
	        WARN_ON(release == NULL);
	        WARN_ON(release == (void (*)(struct kref *))kfree);

	       if (atomic_dec_and_test(&amp;kref-&gt;refcount)) {
	               release(kref);
	               return 1; 
	      }
	      return 0; 
	}
</programlisting><para>The <literal moreinfo="none">kref_put</literal> function has two parameters: a pointer to the <literal moreinfo="none">struct kref</literal> whose reference count you wish to decrement, and a pointer to the function that you wish to have called if this was the last reference held on the object.</para><para>The first two lines of the function were added a while after the <literal moreinfo="none">struct kref</literal> was added to the kernel, as a number of programmers were trying to get around the reference counting by passing in either no pointer to a release function or, when they realized that the kernel would complain about that, a pointer to the basic <literal moreinfo="none">kfree</literal> function. (Sad to say, but even these two checks are not enough these days. Some programmers have taken to just creating empty release functions that do not do anything, as they are trying to ignore the reference count altogether. Unfortunately, C doesn't have a simple way to determine whether a pointer to a function really does anything within that function; otherwise, that check would be added to <literal moreinfo="none">kref_put</literal>, too.)</para><para>After these two checks are made, the reference count is atomically decremented, and if this is the last reference, the release function is called and 1 is returned. If this is not the last reference on the object, <literal moreinfo="none">0</literal> is returned. This return value is used just to determine whether the caller was the last holder of the object, not whether the object is still in memory (it can't guarantee that the object still exists because someone else might come in and release it after the call returns).</para><para>With the creation of <literal moreinfo="none">struct kref</literal>, the <literal moreinfo="none">struct kobject</literal> structure was <indexterm id="idx-CHP-16-1357" significance="normal"><primary>kobject structure (Linux)</primary><secondary>changed to use struct kref</secondary></indexterm>changed to use it:</para><programlisting id="I_programlisting16_tt358" format="linespecific">
	struct kobject {
	        char             name[KOBJ_NAME_LEN];
	        struct kref      kref;
	  ...
	};
</programlisting><para>With all of these different <indexterm id="idx-CHP-16-1358" significance="normal"><primary>usb_interface structure (Linux)</primary><secondary>structures embedded within other structures</secondary></indexterm>structures embedded <indexterm id="idx-CHP-16-1359" significance="normal"><primary>structures</primary><secondary>in multithreaded programs</secondary></indexterm>within other structures, the result is that the original <literal moreinfo="none">struct usb_interface</literal> described earlier now contains a <literal moreinfo="none">struct device</literal>, which contains a <literal moreinfo="none">struct kobject</literal>, which contains a <literal moreinfo="none">struct kref</literal>. And who said it was hard to do object-oriented programming in the C language.…<indexterm id="idx-CHP-16-1360" significance="normal"><primary>object reference counting in Linux kernel virtual filesystem layer</primary></indexterm></para></sect1><sect1 id="scaling_up_to_thousands_of_devices" label="16.3"><title>Scaling Up to Thousands of Devices</title><para>As <indexterm id="idx-CHP-16-1361" significance="normal"><primary>Linux kernel</primary></indexterm>Linux runs on everything from cellphones, radio-controlled helicopters, desktops, and servers to 73 percent of the world's largest supercomputers, scaling the driver model was very important and always in the backs of our minds. As development progressed, it was nice to see that the basic structures used to hold devices, <literal moreinfo="none">struct kobject</literal> and <literal moreinfo="none">struct devices</literal>, were relatively small. The number of devices connected to most systems is directly proportional to the size of the system. So small, embedded systems had only a few—one to ten— different devices connected and in their device tree. Larger "enterprise" systems had many more devices connected, but these systems also had a lot of memory to spare, so the increased number of devices was still only a very small proportion of the kernel's overall <indexterm id="idx-CHP-16-1362" significance="normal"><primary>device structure (Linux)</primary><secondary>memory usage</secondary></indexterm>memory usage.<indexterm id="idx-CHP-16-1363" significance="normal"><primary>Linux kernel</primary><secondary>unified driver and device model</secondary><tertiary>scaling up to thousands of devices</tertiary></indexterm></para><para>This comfortable scaling model, unfortunately, was found to be completely false when it came to one class of "enterprise" system, the s390 mainframe computer. This computer could run Linux in a virtual partition (up to 1,024 instances at the same time on a single machine) and had a huge number of different storage devices connected to it. Overall, the system had a lot of memory, but each virtual partition would have only a small slice of that memory. Each virtual partition wanted to see all different storage devices (20,000 could be typical), while only being allocated a few hundred megabytes of RAM.</para><para>On these systems, the device tree was quickly found to suck up a huge percentage of memory that was never released back to the user processes. It was time to put the driver model on a diet, and some very smart IBM kernel developers went to work on the problem.</para><para>What the developers found was initially surprising. It turned out that the main <literal moreinfo="none">struct device</literal> structure was only around 160 bytes (for a 32-bit processor). With 20,000 devices in the system, that amounted to only 3 to 4 MB of RAM being used, a very manageable usage of memory. The big memory hog was the RAM-based filesystem mentioned earlier, sysfs, which showed all of these devices to userspace. For every device, <emphasis>sysfs</emphasis> created both a <literal moreinfo="none">struct inode</literal> and a <literal moreinfo="none">struct dentry</literal>. These are both fairly heavy structures, with the <literal moreinfo="none">struct inode</literal> weighing in around 256 bytes and <literal moreinfo="none">struct dentry</literal> about 140 bytes.<footnote id="CHP-16-FNOTE-4"><para>Both of these structures have since been shrunk, and therefore are smaller in current kernel versions.</para></footnote><indexterm id="idx-CHP-16-1364" significance="normal"><primary>inode structure (Linux)</primary></indexterm><indexterm id="idx-CHP-16-1365" significance="normal"><primary>dentry structure (Linux)</primary></indexterm><indexterm id="I_indexterm16_tt359" class="endofrange" startref="idx-CHP-16-1343" significance="normal"><primary>object reference counting in Linux kernel virtual filesystem layer</primary></indexterm></para><para>For every <literal moreinfo="none">struct device</literal>, at least one <literal moreinfo="none">struct dentry</literal> and one <literal moreinfo="none">struct inode</literal> were being created. Generally, many different copies of these filesystem structures were created, one for every virtual file per device in the system. As an example, a single block device would create about 10 different virtual files, so that meant that a single structure of 160 bytes would end up using 4 KB. In a system of 20,000 devices, about 80 MB were wasted on the virtual filesystem. This memory was consumed by the kernel, unable to be used by any user programs, even if they never wanted to look at the information stored in <emphasis>sysfs</emphasis>.</para><para>The solution for this was to rewrite the <emphasis>sysfs</emphasis> code to put these <literal moreinfo="none">struct inode</literal> and <literal moreinfo="none">struct dentry</literal> structures in the kernel's caches, creating them on the fly when the filesystem was accessed. The solution was just a matter of dynamically creating the directories and files on the fly as a user walked through the tree, instead of preallocating everything when the device was originally created. Because these structures are in the main caches of the kernel, if memory pressure is placed on the system by userspace programs, or other parts of the kernel, the caches are freed and the memory is returned to those who need it at the time. This was all done by touching the backend <emphasis>sysfs</emphasis> code, and not the main <literal moreinfo="none">struct device</literal> structures.</para></sect1><sect1 id="small_objects_loosely_joined" label="16.4"><title>Small Objects Loosely Joined</title><para>The Linux driver model shows how the C language can be used to create a heavily object-oriented model of code by creating numerous small objects, all doing one thing well. These objects can be embedded in other objects, all without any runtime type identification, creating a very powerful and flexible object tree. And based on the real-world usage of these objects, their memory footprint is minimal, allowing the Linux kernel to be flexible enough to work from the same code base for tiny embedded systems up to the largest supercomputers in the world.</para><para>The development of this model also shows two very interesting and powerful aspects of the way Linux kernel development works.</para><para>First, the process is very iterative. As the requirements of the kernel change, and the systems on which it runs also change, the developers have found ways to abstract different parts of the model to make it more efficient where it is needed. This is responding to a basic evolutionary need of the system to survive in these environments.</para><para>Second, the history of device handling shows that the process is extremely collaborative. Different developers come up independently with ideas for improving and extending different aspects of the kernel. Through the source code, others can then see the goals of the developers exactly as they describe them, and then help change the code in ways the original developers never considered. The end result is something that meets the goals of many different developers by finding a common solution that would not have been seen by any one individual.</para><para>These two characteristics of development have helped Linux evolve into the most flexible and powerful operating system ever created. And they ensure that as long as this type of development continues, Linux will remain this way.<indexterm id="I_indexterm16_tt360" class="endofrange" startref="idx-CHP-16-1306" significance="normal"><primary>Linux kernel</primary></indexterm></para></sect1></chapter><chapter id="another_level_of_indirection" label="17" role=""><title>Another Level of Indirection</title><para><emphasis>Diomidis Spinellis</emphasis><indexterm id="idx-CHP-17-1366" significance="normal"><primary>Spinellis</primary></indexterm></para><para><emphasis>All problems in computer science can be solved by another level of indirection</emphasis>," is a famous quote attributed to Butler <indexterm id="idx-CHP-17-1367" significance="normal"><primary>Lampson</primary></indexterm>Lampson, the scientist who in 1972 envisioned the modern personal computer. The quote rings in my head on various occasions: when I am forced to talk to a secretary instead of the person I wish to communicate with, when I first travel east to Frankfurt in order to finally fly west to Shanghai or Bangalore, and—yes—when I examine a complex system's source code.</para><para>Let's start this particular journey by considering the problem of a typical operating system that supports disparate filesystem formats. An operating system may use data residing on its <indexterm id="idx-CHP-17-1368" significance="normal"><primary>Linux</primary><secondary>native filesystem</secondary></indexterm>native filesystem, a CD-ROM, or a <indexterm id="idx-CHP-17-1369" significance="normal"><primary>USB sticks</primary></indexterm>USB stick. These storage devices may, in turn, employ <indexterm id="idx-CHP-17-1370" significance="normal"><primary>operating systems</primary><secondary>supporting different filesystems</secondary></indexterm>different filesystem organizations: NTFS or ext3fs for a Windows or Linux <indexterm id="idx-CHP-17-1371" significance="normal"><primary>Windows operating systems</primary><secondary>native filesystem</secondary></indexterm>native filesystem, ISO-9660 for the CD-ROM, and, often, the legacy <indexterm id="idx-CHP-17-1372" significance="normal"><primary>FAT-32 filesystem for the USB stick</primary></indexterm>FAT-32 filesystem for the USB stick. Each filesystem uses different data structures for managing free space, for storing file metadata, and for organizing files into directories. Therefore, each filesystem requires different code for each operation on a file (<literal moreinfo="none">open, read, write, seek, close, delete</literal>, and so on).</para><sect1 id="from_code_to_pointers" label="17.1"><title>From Code to Pointers</title><para>I grew up in an era where different computers more often than not had incompatible filesystems, forcing me <indexterm id="idx-CHP-17-1373" significance="normal"><primary>pointers</primary><secondary>to vop_vector structure</secondary></indexterm>to transfer data from one machine to another over serial links. Therefore, the ability to read on my PC a flash card written on my camera never ceases to amaze me. Let's consider how the operating system would structure the code for accessing the different filesystems. One approach would be to employ a <literal moreinfo="none">switch</literal> statement for each operation. Consider as an example a hypothetical <indexterm id="idx-CHP-17-1374" significance="normal"><primary>FreeBSD operating system</primary><secondary>implementation of read system call</secondary></indexterm>implementation of the <literal moreinfo="none">read</literal> system call under the <indexterm id="idx-CHP-17-1375" significance="normal"><primary>additional levels of indirection</primary><secondary>operating system supporting different</secondary><tertiary>FreeBSD implementation of read system call</tertiary></indexterm>FreeBSD operating system. Its kernel-side interface would look as follows:<indexterm id="idx-CHP-17-1376" significance="normal"><primary>filesystems</primary><secondary>code to access filesystems</secondary></indexterm></para><programlisting id="I_programlisting17_tt361" format="linespecific">
	int VOP_READ(
	        struct vnode *vp,          /* File to read from */
	        struct uio *uio,           /* Buffer specification */
	        int ioflag,                /* I/O-specific flags */
	        struct ucred *cred)        /* User's credentials */
	{
	    /* Hypothetical implementation */
	       switch (vp-&gt;filesystem) {
	       case FS_NTFS:               /* NTFS-specific code */
	       case FS_ISO9660:            /* ISO-9660-specific code */
	       case FS_FAT32:              /* FAT-32-specific code */
	    /* [...] */
	    }
	}
</programlisting><para>This approach would bundle together code for the various filesystems, limiting modularity. Worse, adding support for a new filesystem type would require modifying the code of each system call implementation and recompiling the kernel. Moreover, adding a processing step to all the operations of a filesystem (for example, the mapping of remote user credentials) would also require the error-prone modification of each operation with the same boilerplate code.</para><para>As you might have guessed, our task at hand calls for some <indexterm id="idx-CHP-17-1377" significance="normal"><primary>additional levels of indirection</primary></indexterm>additional levels of indirection. Consider how the FreeBSD operating system—a code base I admire for the maturity of its engineering—solves these problems. Each filesystem defines the operations that it supports as functions and then initializes a <literal moreinfo="none">vop_vector</literal> structure with pointers to them. Here are some fields of the <literal moreinfo="none">vop_vector</literal> structure:<indexterm id="idx-CHP-17-1378" significance="normal"><primary>vop_vector structure (FreeBSD)</primary></indexterm></para><programlisting id="I_programlisting17_tt362" format="linespecific">
	struct vop_vector {
	         struct vop_vector *vop_default;
	         int (*vop_open)(struct vop_open_args *);
	         int (*vop_access)(struct vop_access_args *);
</programlisting><para>and here is how the <indexterm id="idx-CHP-17-1379" significance="normal"><primary>ISO-9660 filesystem</primary></indexterm>ISO-9660 filesystem initializes the structure:</para><programlisting id="I_programlisting17_tt363" format="linespecific">
	struct vop_vector cd9660_vnodeops = {
	        .vop_default =          &amp;default_vnodeops,
	        .vop_open =             cd9660_open,
	        .vop_access =           cd9660_access,
	        .vop_bmap =             cd9660_bmap,
	        .vop_cachedlookup =     cd9660_lookup,
	        .vop_getattr =          cd9660_getattr, 
	        .vop_inactive =         cd9660_inactive,
	        .vop_ioctl =            cd9660_ioctl,]
	        .vop_lookup =           vfs_cache_lookup, 
	        .vop_pathconf =         cd9660_pathconf,
	        .vop_read =             cd9660_read,
	        .vop_readdir =          cd9660_readdir,
	        .vop_readlink =         cd9660_readlink, 
	        .vop_reclaim =          cd9660_reclaim,
	        .vop_setattr =          cd9660_setattr,
	        .vop_strategy =         cd9660_strategy,
	};
</programlisting><para>(The <literal moreinfo="none">.field = value</literal> syntax is a nifty C99 feature that allows fields of a structure to be initialized in an arbitrary order and in a readable way.) Note that although the complete <literal moreinfo="none">vop_vector</literal> structure contains 52 fields, only 16 are defined in the preceding code. As an example, the <literal moreinfo="none">vop_write</literal> field is left undefined (getting a value of <literal moreinfo="none">NULL</literal>) because writing to files is not supported on ISO-9660 <indexterm id="idx-CHP-17-1380" significance="normal"><primary>CD-ROMs</primary></indexterm>CD-ROMs. Having initialized one such structure for every filesystem type (see the bottom of <xref linkend="layers_of_indirection_in_the_freebsd_implementation_of_the_read"/>), it is then easy to tie this structure to the administrative data associated with each file handle. Then, in the FreeBSD kernel, the <indexterm id="idx-CHP-17-1381" significance="normal"><primary>FreeBSD operating system</primary><secondary>implementation of read system call</secondary><tertiary>filesystem-independent part</tertiary></indexterm>filesystem-independent part of the read system call implementation appears simply as (see <xref linkend="layers_of_indirection_in_the_freebsd_implementation_of_the_read"/>):</para><programlisting id="I_programlisting17_tt364" format="linespecific">
	struct vop_vector *vop;

	     rc = vop-&gt;vop_read(a);
</programlisting><figure id="layers_of_indirection_in_the_freebsd_implementation_of_the_read" label="17-1" float="0"><title>Layers of indirection in the FreeBSD implementation of the read system call</title><mediaobject id="I_mediaobject17_tt365"><imageobject role="print"><imagedata fileref="figs/print/beauty_1701.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1701.png" format="PNG"/></imageobject></mediaobject></figure><para>So, when reading from a CD <indexterm id="idx-CHP-17-1382" significance="normal"><primary>layering of filesystems</primary><secondary>on FreeBSD</secondary></indexterm>containing an ISO-9660 filesystem, the previous call through a pointer would actually result in a call to the function <literal moreinfo="none">cd9660_read;</literal> in effect:</para><programlisting id="I_programlisting17_tt366" format="linespecific">
	rc = cd9660_read(a);
</programlisting></sect1><sect1 id="from_function_arguments_to_argument_pointers" label="17.2"><title>From Function Arguments to Argument Pointers</title><para>Most <indexterm id="idx-CHP-17-1383" significance="normal"><primary>Unix-related operating systems</primary></indexterm>Unix-related operating systems, such as <indexterm class="startofrange" id="idx-CHP-17-1384" significance="normal"><primary>additional levels of indirection</primary><secondary>FreeBSD using indirection to abstract read function arguments</secondary></indexterm>FreeBSD, Linux, and Solaris, use <indexterm id="idx-CHP-17-1385" significance="normal"><primary>pointers</primary><secondary>function pointers</secondary></indexterm>function pointers to isolate the implementation of a filesystem from the code that accesses its contents. Interestingly, <indexterm class="startofrange" id="idx-CHP-17-1386" significance="normal"><primary>filesystems</primary><secondary>FreeBSD use of indirection to abstract read function arguments</secondary></indexterm>FreeBSD also employs indirection to abstract the read function's arguments.<indexterm class="startofrange" id="idx-CHP-17-1387" significance="normal"><primary>function arguments abstracted to argument pointers</primary></indexterm></para><para>When I first encountered the call <literal moreinfo="none">vop-&gt;vop_read(a)</literal>, shown in the previous section, I asked myself what that a argument was and what happened to the original four arguments of the hypothetical implementation of the <literal moreinfo="none">VOP_READ</literal> function we saw earlier. After some digging, I found that the kernel uses another level of indirection to layer filesystems on top of each other to an arbitrary depth. This layering allows a filesystem to offer some services (such as translucent views, compression, and encryption) based on the services of another underlying filesystem. Two mechanisms work cleverly together to support this feature: one allows a single bypass function to modify the arguments of any <literal moreinfo="none">vop_vector</literal> function, while another allows all undefined <literal moreinfo="none">vop_vector</literal> functions to be redirected to the underlying filesystem layer.</para><para>You can see both mechanisms in action in <xref linkend="example_of_filesystem_layering"/>. The figure illustrates three file-systems layered on top of one another. On top lies the <emphasis>umapfs</emphasis> filesystem, which the system administrator mounted in order to map user credentials. This is valuable if the system where this particular disk was created used different user IDs. For instance, the administrator might want user ID 1013 on the underlying filesystem to appear as user ID 5325.<indexterm id="idx-CHP-17-1388" significance="normal"><primary>umapfs filesystem</primary></indexterm></para><figure id="example_of_filesystem_layering" label="17-2" float="0"><title>Example of filesystem layering</title><mediaobject id="I_mediaobject17_tt367"><imageobject role="print"><imagedata fileref="figs/print/beauty_1702.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1702.png" format="PNG"/></imageobject></mediaobject></figure><para>Beneath the top filesystem lies the <indexterm id="idx-CHP-17-1389" significance="normal"><primary>Berkeley Fast Filesystem (ffs)</primary></indexterm>Berkeley Fast Filesystem (<emphasis>ffs</emphasis>), the time- and space-efficient filesystem used by default in typical <indexterm id="idx-CHP-17-1390" significance="normal"><primary>additional levels of indirection</primary><secondary>FreeBSD using indirection to abstract read function arguments</secondary></indexterm>FreeBSD installations. The <emphasis>ffs</emphasis> in turn, for most of its operations, relies on the code of the original 4.2 BSD filesystem implementation <emphasis>ufs</emphasis>.<indexterm id="idx-CHP-17-1391" significance="normal"><primary>vop_vector structure (FreeBSD)</primary><secondary>filesystem layering support</secondary></indexterm><indexterm id="idx-CHP-17-1392" significance="normal"><primary>ffs (Berkeley Fast Filesystem)</primary></indexterm><indexterm id="idx-CHP-17-1393" significance="normal"><primary>ufs filesystem (BSD 4.2)</primary></indexterm></para><para>In the example shown in the figure, most system calls pass through a common bypass <indexterm id="idx-CHP-17-1394" significance="normal"><primary>function arguments abstracted to argument pointers</primary></indexterm>function in <emphasis>umapfs</emphasis> that maps the user credentials. Only a few system calls, such as <literal moreinfo="none">rename</literal> and <literal moreinfo="none">getattr</literal>, have their own implementations in <emphasis>umapfs</emphasis>. The ffs layer provides optimized implementations of read and <literal moreinfo="none">write;</literal> both rely on a filesystem layout that is more efficient than the one employed by <emphasis>ufs</emphasis>. Most other operations, such as <literal moreinfo="none">open, close, getattr, setatr</literal>, and <literal moreinfo="none">rename</literal>, are handled in the traditional way. Thus, a <literal moreinfo="none">vop_default</literal> entry in the <emphasis>ffs</emphasis> <literal moreinfo="none">vop_vector</literal> structure directs all those functions to call the underlying <emphasis>ufs</emphasis> implementations. For example, a <literal moreinfo="none">read</literal> system call will pass through <literal moreinfo="none">umapfs_bypass</literal> and <literal moreinfo="none">ffs_read</literal>, whereas a <literal moreinfo="none">rename</literal> call will pass through <literal moreinfo="none">umapfs_rename</literal> and<literal moreinfo="none"> ufs_rename</literal>.</para><para>Both mechanisms, the bypass and the default, pack the four arguments into a single structure to provide commonality between the different filesystem functions, and also support the groundwork for the bypass function. This is a beautiful design pattern that is easily overlooked within the intricacies of the C code required to implement it.</para><para>The four arguments are packed into a single structure, which as its first field (<literal moreinfo="none">a_gen.a_desc</literal>) contains a description of the structure's contents (<literal moreinfo="none">vop_read_desc</literal>, in the following code). As you can see in <xref linkend="layers_of_indirection_in_the_freebsd_implementation_of_the_read"/><indexterm id="idx-CHP-17-1395" significance="normal"><primary>filesystems</primary><secondary>FreeBSD use of indirection to abstract read function arguments</secondary></indexterm>, a <literal moreinfo="none">read</literal> system call on a file in the FreeBSD kernel will trigger a call to <literal moreinfo="none">vn_read</literal>, which will set up the appropriate lowl-evel arguments and call <literal moreinfo="none">VOP_READ</literal>. This will pack the arguments and call <literal moreinfo="none">VOP_READ_APV</literal>, which finally calls <literal moreinfo="none">vop-&gt;vop_read</literal> and thereby the actual filesystem read function:</para><programlisting id="I_programlisting17_tt368" format="linespecific">
	struct vop_read_args {
	        struct vop_generic_args a_gen;
	        struct vnode *a_vp;
	        struct uio *a_uio;
	        int a_ioflag;
	        struct ucred *a_cred;
	};
	static _ _inline int VOP_READ(
	        struct vnode *vp,
	        struct uio *uio,
	        int ioflag,
	        struct ucred *cred)
	{
	        struct vop_read_args a;

	        a.a_gen.a_desc = &amp;vop_read_desc;
	        a.a_vp = vp;
	        a.a_uio = uio;
	        a.a_ioflag = ioflag;
	        a.a_cred = cred;
	        return (VOP_READ_APV(vp-&gt;v_op, &amp;a));
	}
</programlisting><para>This same elaborate dance is performed for calling all other <literal moreinfo="none">vop_vector</literal> <indexterm id="idx-CHP-17-1396" significance="normal"><primary>function arguments abstracted to argument pointers</primary></indexterm>functions (<literal moreinfo="none">stat, write, open, close</literal>, and so on). The <literal moreinfo="none">vop_vector</literal> structure also contains a <indexterm id="idx-CHP-17-1397" significance="normal"><primary>vop_vector structure (FreeBSD)</primary><secondary>pointer to a bypass function</secondary></indexterm>pointer to a <literal moreinfo="none">bypass</literal> function. This function gets the packed arguments and, after possibly performing some modifications on them (such as, perhaps, mapping <indexterm id="idx-CHP-17-1398" significance="normal"><primary>filesystems</primary><secondary>FreeBSD use of indirection to abstract read function arguments</secondary></indexterm>user credentials from one administrative domain to another) passes control to the appropriate underlying function for the specific call through the <literal moreinfo="none">a_desc</literal> field.</para><para>Here is an excerpt of how the <emphasis>nullfs</emphasis> filesystem implements the bypass function. The <emphasis>nullfs</emphasis> filesystem just duplicates a part of an existing filesystem into another location of the global filesystem namespace. Therefore, for most of its operations, it can simply have its <literal moreinfo="none">bypass</literal> function call the corresponding function of the underlying filesystem:<indexterm id="idx-CHP-17-1399" significance="normal"><primary>nullfs filesystem</primary></indexterm></para><programlisting id="I_programlisting17_tt369" format="linespecific">
	#define VCALL(c) ((c)-&gt;a_desc-&gt;vdesc_call(c))
	int
	null_bypass(struct vop_generic_args *ap)
	{
	    /* ... */
	      error = VCALL(ap);
</programlisting><para>In the preceding code, the macro <literal moreinfo="none">VCALL(ap)</literal> will bump the <emphasis>vnode</emphasis> operation that called <literal moreinfo="none">null_bypass</literal> (for instance <literal moreinfo="none">VOP_READ_APV)</literal> one filesystem level down. You can see this trick in action in <xref linkend="routing_system_calls_through_a_bypass_function"/>.</para><figure id="routing_system_calls_through_a_bypass_function" label="17-3" float="0"><title>Routing system calls through a bypass function</title><mediaobject id="I_mediaobject17_tt370"><imageobject role="print"><imagedata fileref="figs/print/beauty_1703.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1703.png" format="PNG"/></imageobject></mediaobject></figure><para>In addition, the <literal moreinfo="none">vop_vector</literal> contains a field named <literal moreinfo="none">default</literal> that is a <indexterm id="idx-CHP-17-1400" significance="normal"><primary>vop_vector structure (FreeBSD)</primary><secondary>pointer to vop_vector structure of underlying filesystem layer</secondary></indexterm>pointer to the <literal moreinfo="none">vop_vector</literal> structure of the underlying filesystem layer. Through that field, if a filesystem doesn't implement some functionality, the request is passed on to a lower level. By <indexterm id="idx-CHP-17-1401" significance="normal"><primary>vop_vector structure (FreeBSD)</primary><secondary>populating bypass and default fields</secondary></indexterm>populating the <literal moreinfo="none">bypass</literal> and the <literal moreinfo="none">default</literal> fields of its <literal moreinfo="none">vop_vector</literal> structure, a filesystem can choose among:</para><itemizedlist><listitem><para>Handling an incoming request on its own</para></listitem><listitem><para>Bypassing the request to a lower-level filesystem after modifying some arguments</para></listitem><listitem><para>Directly calling the lower-level filesystem</para></listitem></itemizedlist><para>In my mind, I visualize this as bits sliding down the ramps, kickers, and spinners of an elaborate pinball machine. The following example from the read system call implementation shows how the system locates the <indexterm id="idx-CHP-17-1402" significance="normal"><primary>function arguments abstracted to argument pointers</primary></indexterm>function to call:</para><programlisting id="I_programlisting17_tt371" format="linespecific">
	int
	VOP_READ_APV(struct {	vop_vector	*vop, struct vop_read_args *a)
	{

	   [...]
	     /*
	 * Drill down the <indexterm class="startofrange" id="idx-CHP-17-1403" significance="normal"><primary>filesystems</primary><secondary>filesystem layers</secondary></indexterm>filesystem layers to find one
	 * that implements the function or a bypass
	 */
	while (vop != NULL &amp;&amp;
	            vop-&gt;vop_read == NULL &amp;&amp; vop-&gt;vop_bypass == NULL)
	                 vop = vop-&gt;vop_default;
	      /* Call the function or the bypass */
	        if (vop-&gt;vop_read != NULL)
	                 rc = vop-&gt;vop_read(a);
	        else 
	                 rc = vop-&gt;vop_bypass(&amp;a-&gt;a_gen);
</programlisting><para>Elegantly, at the bottom of all <indexterm id="idx-CHP-17-1404" significance="normal"><primary>operating systems</primary><secondary>supporting different filesystems</secondary><tertiary>filesystem layers</tertiary></indexterm>filesystem layers lies a filesystem that returns the Unix "operation not supported" error (<literal moreinfo="none">EOPNOTSUPP</literal>) for any function that wasn't implemented by the filesystems layered on top of it. This is our pinball's drain:</para><programlisting id="I_programlisting17_tt372" format="linespecific">
	#define VOP_EOPNOTSUPP ((void*)(uintptr_t)vop_eopnotsupp)

	struct vop_vector default_vnodeops = {
	        .vop_default =          NULL,
	        .vop_bypass =           VOP_EOPNOTSUPP,
	}

	int
	vop_eopnotsupp(struct vop_generic_args *ap)
	{
	          return (EOPNOTSUPP);
	}
</programlisting></sect1><sect1 id="from_filesystems_to_filesystem_layers" label="17.3"><title>From Filesystems to Filesystem Layers</title><para>For a concrete example of filesystem <indexterm class="startofrange" id="idx-CHP-17-1405" significance="normal"><primary>layering of filesystems</primary></indexterm>layering, consider the case where you mount on your computer a remote filesystem <indexterm id="idx-CHP-17-1406" significance="normal"><primary>additional levels of indirection</primary><secondary>FreeBSD using indirection to abstract read function arguments</secondary></indexterm>using the <indexterm id="idx-CHP-17-1407" significance="normal"><primary>NFS (Network File System)</primary></indexterm>NFS (Network File System) protocol. Unfortunately, in your case, the user and group identifiers on the remote system don't match those used on your computer. However, by <indexterm id="idx-CHP-17-1408" significance="normal"><primary>umapfs filesystem</primary><secondary>interposing over NFS implementation</secondary></indexterm>interposing a <emphasis>umapfs</emphasis> filesystem over the actual NFS implementation, we can specify through external files the correct user and group mappings. <xref linkend="routing_system_calls_through_a_bypass_function"/> illustrates how some operating system kernel function calls first get routed through the bypass function of <emphasis>umpafs</emphasis>—<literal moreinfo="none">umap_bypass</literal>—before continuing their journey to the corresponding NFS client functions.<indexterm id="idx-CHP-17-1409" significance="normal"><primary>operating systems</primary><secondary>supporting different filesystems</secondary><tertiary>filesystem layers</tertiary></indexterm><indexterm id="I_indexterm17_tt373" class="endofrange" startref="idx-CHP-17-1387" significance="normal"><primary>function arguments abstracted to argument pointers</primary></indexterm><indexterm id="I_indexterm17_tt374" class="endofrange" startref="idx-CHP-17-1384" significance="normal"><primary>additional levels of indirection</primary><secondary>FreeBSD using indirection to abstract read function arguments</secondary></indexterm><indexterm id="I_indexterm17_tt375" class="endofrange" startref="idx-CHP-17-1386" significance="normal"><primary>filesystems</primary><secondary>FreeBSD use of indirection to abstract read function arguments</secondary></indexterm></para><para>In contrast to the <literal moreinfo="none">null_bypass</literal> function, the implementation <indexterm id="idx-CHP-17-1410" significance="normal"><primary>layering of filesystems</primary></indexterm>of <literal moreinfo="none">umap_bypass</literal> actually does some work before making a call to the underlying layer. The <literal moreinfo="none">vop_generic_args</literal> structure passed as its argument contains a description of the actual arguments for each <emphasis>vnode</emphasis> operation:<indexterm id="idx-CHP-17-1411" significance="normal"><primary>vop_generic_args structure (FreeBSD)</primary></indexterm></para><programlisting id="I_programlisting17_tt376" format="linespecific">
	/*
	 * A generic structure.
	 * This can be used by bypass routines to identify generic arguments.
	 */
	struct vop_generic_args {
	       struct <indexterm id="idx-CHP-17-1412" significance="normal"><primary>vnodeop_desc structure</primary></indexterm>vnodeop_desc *a_desc;
	       /* other random data follows, presumably */
	};

	/*
	 * This structure describes the vnode operation taking place.
	 */
	struct vnodeop_desc {
	       char    *vdesc_name;            /* a readable name for debugging */
	       int      vdesc_flags;           /* VDESC_* flags */
	       vop_bypass_t    *vdesc_call;    /* Function to call */

	       /*
	        * These ops are used by bypass routines to map and locate arguments.
	        * Creds and procs are not needed in bypass routines, but sometimes
	        * they are useful to (for example) transport layers.
	        * Nameidata is useful because it has a cred in it.
	        */
	       int     *vdesc_vp_offsets;     /* list ended by VDESC_NO_OFFSET */
	       int      vdesc_vpp_offset      /* return vpp location */
	       int      vdesc_cred_offset;    /* cred location, if any */
	       int      vdesc_thread_offset   /* thread location, if any *
	       int      vdesc_componentname_offset; /* if any */ 
	};
</programlisting><para>For instance, the <literal moreinfo="none">vnodeop_desc</literal> structure for the arguments passed to the <literal moreinfo="none">vop_read</literal> operation is the following:</para><programlisting id="I_programlisting17_tt377" format="linespecific">
	struct vnodeop_desc vop_read_desc = {
	        "vop_read",
	        0,
	        (vop_bypass_t *)VOP_READ_AP,
	        vop_read_vp_offsets,
	        VDESC_NO_OFFSET,
	        VOPARG_OFFSETOF(struct vop_read_args,a_cred),
	        VDESC_NO_OFFSET,
	        VDESC_NO_OFFSET,
	};
</programlisting><para>Importantly, apart from the name of the function (used for debugging purposes) and the underlying function to call (<literal moreinfo="none">VOP_READ_AP</literal>), the structure contains in its <literal moreinfo="none">vdesc_cred_offset</literal> field the location of the user credential data field (<literal moreinfo="none">a_cred</literal>) within the read call's arguments. By using this field, <literal moreinfo="none">umap_bypass</literal>can map the credentials of <emphasis>any</emphasis> vnode operation with the following code:</para><programlisting id="I_programlisting17_tt378" format="linespecific">
	if (descp-&gt;vdesc_cred_<indexterm id="idx-CHP-17-1413" significance="normal"><primary>layering of filesystems</primary></indexterm>offset != VDESC_NO_OFFSET) {
	        credpp = VOPARG_OFFSETTO(struct ucred**,
	            descp-&gt;vdesc_cred_offset, ap);
	        /* Save old values */
	        savecredp = (*credpp);
	        if (savecredp != NOCRED)
	               (*credpp) = crdup(savecredp);
	        credp = *credpp;
	        /* Map all ids in the credential structure. */
	        umap_mapids(vp1-&gt;v_mount, credp);
	}
</programlisting><para>What we have here is a case of data describing the format of other data: a redirection in terms of data abstraction. This <emphasis>metadata</emphasis> allows the credential mapping code to manipulate the arguments of arbitrary system calls.<indexterm id="idx-CHP-17-1414" significance="normal"><primary>metadata in filesystem layering</primary></indexterm></para></sect1><sect1 id="from_code_to_a_domain-specific_language" label="17.4"><title>From Code to a Domain-Specific Language</title><para>You may have noticed that some of the code associated with the implementation of the read system call, such as the packing of its arguments into a structure or the logic for calling the appropriate function, is highly stylized and is probably repeated in similar forms for all 52 other interfaces. Another implementation detail, which we have not so far discussed and which can keep me awake at nights, concerns <indexterm id="idx-CHP-17-1415" significance="normal"><primary>locking</primary></indexterm>locking.</para><para>Operating systems must ensure that various processes running concurrently don't step on each other's toes when they modify data without coordination between them. On modern <indexterm id="idx-CHP-17-1416" significance="normal"><primary>multithreaded</primary></indexterm>multithreaded, multi-core processors, ensuring data consistency by maintaining one mutual exclusion lock for all critical operating system structures (as was the case in older operating system implementations) would result in an intolerable drain on performance. Therefore, <indexterm id="idx-CHP-17-1417" significance="normal"><primary>operating systems</primary><secondary>locks for critical operating system structures</secondary></indexterm>locks are nowadays held over fine-grained objects, such as a user's credentials or a single buffer. Furthermore, because obtaining and releasing locks can be expensive operations, ideally once a lock is held it should not be released if it will be needed again in short order. These locking specifications can best be described through preconditions (what the state of a lock must be before entering a function) and postconditions (the state of the lock at a function's exit).</para><para>As you can imagine, programming under those constraints and verifying the code's correctness can be hellishly complicated. Fortunately for me, another level of indirection can be used to bring some sanity into the picture. This indirection handles both the redundancy of packing code and the fragile locking requirements.<indexterm id="I_indexterm17_tt379" class="endofrange" startref="idx-CHP-17-1405" significance="normal"><primary>layering of filesystems</primary></indexterm><indexterm id="I_indexterm17_tt380" class="endofrange" startref="idx-CHP-17-1403" significance="normal"><primary>filesystems</primary><secondary>filesystem layers</secondary></indexterm></para><para>In the FreeBSD kernel, the <indexterm id="idx-CHP-17-1418" significance="normal"><primary>FreeBSD operating system</primary><secondary>interface functions and data structures</secondary></indexterm>interface functions and data structures we've examined, such as <literal moreinfo="none">VOP_READ_AP, VOP_READ_APV</literal>, and <literal moreinfo="none">vop_read_desc</literal>, aren't directly written in C. Instead, a domain-specific language is used to specify the types of each call's arguments and their locking pre- and postconditions. Such an implementation style always raises my pulse, because the productivity boost it gives can be enormous. Here is an excerpt from the read system call specification:</para><programlisting id="I_programlisting17_tt381" format="linespecific">
	#
	#% read          vp     L L L
	#
	vop_read {
	        IN struct <indexterm id="idx-CHP-17-1419" significance="normal"><primary>vnode call interface</primary></indexterm>vnode *vp;
	        INOUT struct uio *uio;
	        IN int ioflag;
	        IN struct ucred *cred;
	};
</programlisting><para><indexterm id="idx-CHP-17-1420" significance="normal"><primary>awk programming language</primary><secondary>creations from FreeBSD read system call specification</secondary></indexterm>From specifications such as the above, an <emphasis>awk</emphasis> script creates:</para><itemizedlist><listitem><para>C <indexterm id="idx-CHP-17-1421" significance="normal"><primary>C language</primary><secondary>code packing function arguments into a single structure</secondary></indexterm>code for packing the arguments of the functions into a single structure</para></listitem><listitem><para>Declarations for the structures <indexterm id="idx-CHP-17-1422" significance="normal"><primary>structures</primary><secondary>holding packed function arguments</secondary></indexterm>holding the packed arguments and the functions doing the work</para></listitem><listitem><para>Initialized data specifying the contents of the packed argument structures</para></listitem><listitem><para>The boilerplate C code we saw used for implementing filesystem layers</para></listitem><listitem><para><indexterm id="idx-CHP-17-1423" significance="normal"><primary>assertions verifying the state of locks</primary></indexterm>Assertions for verifying the state of the locks when the function enters and exits</para></listitem></itemizedlist><para>In the FreeBSD version 6.1 implementation of the <emphasis>vnode</emphasis> call interface, all in all, 588 lines of domain-specific code expand into 4,339 lines of C code and declarations.</para><para>Such <indexterm id="idx-CHP-17-1424" significance="normal"><primary>C language</primary><secondary>compilation from specialized high-level domain-specific language to</secondary></indexterm>compilation from a specialized high-level domain-specific language into C is quite common in the computing field. For example, the input to the <indexterm id="idx-CHP-17-1425" significance="normal"><primary>lex (lexical analyzer generator)</primary></indexterm>lexical analyzer generator <emphasis>lex</emphasis> is a file that maps regular expressions <indexterm id="idx-CHP-17-1426" significance="normal"><primary>regular expressions</primary><secondary>mapping into actions with lex</secondary></indexterm>into actions; the input to the parser generator <emphasis>yacc</emphasis> is a language's grammar and corresponding production rules. Both systems (and their descendants <emphasis>flex</emphasis> and <emphasis>bison</emphasis>) generate C <indexterm id="idx-CHP-17-1427" significance="normal"><primary>C language</primary><secondary>code implementing filesystem layers</secondary></indexterm>code implementing the high-level specifications. A more extreme case involves the early implementations of the C++ programming language. These consisted of a preprocessor, <emphasis>cfront</emphasis>, that would compile C++ code into C.<indexterm id="idx-CHP-17-1428" significance="normal"><primary>yacc (parser generator)</primary></indexterm><indexterm id="idx-CHP-17-1429" significance="normal"><primary>flex</primary></indexterm><indexterm id="idx-CHP-17-1430" significance="normal"><primary>bison</primary></indexterm><indexterm id="idx-CHP-17-1431" significance="normal"><primary>C++</primary><secondary>cfront preprocessor</secondary></indexterm></para><para>In all these cases, C is used as a portable assembly language. When used appropriately, domain-specific languages increase the code's expressiveness and thereby programmer productivity. On the other hand, a gratuitously used obscure domain-specific language can make a system more difficult to comprehend, debug, and maintain.</para><para>The <indexterm id="idx-CHP-17-1432" significance="normal"><primary>locking</primary><secondary>handling of locking assertions</secondary></indexterm>handling of locking assertions deserves more explanation. For each argument, the code lists the state of its lock for three instances: when the function is entered, when the function exits successfully, and when the function exits with an error—an elegantly clear separation of concerns. For example, the preceding specification of the <literal moreinfo="none">read</literal> call indicated that the <literal moreinfo="none">vp</literal> argument should be locked in all three cases. More complex scenarios are also possible. The following code excerpt indicates that the <literal moreinfo="none">rename</literal> call arguments <literal moreinfo="none">fdvp</literal> and <literal moreinfo="none">fvp</literal> are always unlocked, but the argument <literal moreinfo="none">tdvp</literal> has a process-exclusive lock when the routine is called. All arguments should be unlocked when the function terminates:</para><programlisting id="I_programlisting17_tt382" format="linespecific">
	# 
	#% rename      fdvp    U U U
	#% rename      fvp     U U U
	#% rename      tdvp    E U U
	#
</programlisting><para>The locking specification is used to instrument the C code with assertions at the function's entry, the function's normal exit, and the function's error exit. For example, the code at the entry point of the <literal moreinfo="none">rename</literal> function contains the following assertions:</para><programlisting id="I_programlisting17_tt383" format="linespecific">
	ASSERT_VOP_UNLOCKED(a-&gt;a_fdvp, "VOP_RENAME");
	ASSERT_VOP_UNLOCKED(a-&gt;a_fvp, "VOP_RENAME");
	ASSERT_VOP_ELOCKED(a-&gt;a_tdvp, "VOP_RENAME");
</programlisting><para>Although assertions, such as the preceding one, don't guarantee that the code will be bug-free, they do at least provide an early-fail indication that will diagnose errors during system testing, before they destabilize the system in a way that hinders debugging. When I read complex code that lacks assertions, it's like watching acrobats performing without a net: an impressive act where a small mistake can result in considerable grief.</para></sect1><sect1 id="multiplexing_and_demultiplexing" label="17.5"><title>Multiplexing and Demultiplexing</title><para>As you can see back in <xref linkend="layers_of_indirection_in_the_freebsd_implementation_of_the_read"/>, the processing of the <indexterm id="idx-CHP-17-1433" significance="normal"><primary>Unix operating system</primary><secondary>read system call variants</secondary></indexterm>read system call doesn't start from <literal moreinfo="none">VOP_READ. VOP_READ</literal> is actually called from <literal moreinfo="none">vn_read</literal>, which itself is called through a function pointer.<indexterm id="idx-CHP-17-1434" significance="normal"><primary>additional levels of indirection</primary><secondary>multiplexing and demultiplexing</secondary></indexterm></para><para>This level of indirection is used for another purpose. The Unix operating system and its derivatives treat all <indexterm id="idx-CHP-17-1435" significance="normal"><primary>Unix operating system</primary><secondary>input and output sources</secondary></indexterm>input and output sources uniformly. Thus, instead of having separate system calls for reading from, say, a file, a socket, or a pipe, the <literal moreinfo="none">read</literal> system call can read from any of those I/O abstractions. I find this design both elegant and useful; I've often relied on it, using tools in ways their makers couldn't have <indexterm id="idx-CHP-17-1436" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>anticipated. (This statement says more about the age of the tools I use than my creativity.)</para><para>The indirection appearing in the middle of <xref linkend="layers_of_indirection_in_the_freebsd_implementation_of_the_read"/> is the mechanism FreeBSD uses for providing this <indexterm id="idx-CHP-17-1437" significance="normal"><primary>FreeBSD operating system</primary><secondary>high-level I/O abstraction independence</secondary></indexterm>high-level <indexterm id="idx-CHP-17-1438" significance="normal"><primary>I/O abstraction independence on FreeBSD</primary></indexterm>I/O abstraction independence. Associated with each file descriptor is a function pointer leading to the code that will service the particular request: <literal moreinfo="none">pipe_read</literal> for pipes, <literal moreinfo="none">soo_read</literal> for sockets, <literal moreinfo="none">mqf_read</literal> for POSIX message queues, <literal moreinfo="none">kqueue_read</literal> for kernel event queues, and, finally, <literal moreinfo="none">vn_read</literal> for actual files.</para><para>So far, in our example, we have encountered two instances where <indexterm id="idx-CHP-17-1439" significance="normal"><primary>function pointers</primary></indexterm>function pointers are used to dispatch a request to different functions. Typically, in such cases, a function pointer is used to demultiplex a single request to multiple potential providers. This use of indirection is so common that it forms an important element of object-oriented languages, in the form of <indexterm id="idx-CHP-17-1440" significance="normal"><primary>dynamic dispatch</primary></indexterm>dynamic dispatch to various subclass methods. To me, the manual implementation of <indexterm id="idx-CHP-17-1441" significance="normal"><primary>object-oriented (OO) programming languages</primary><secondary>dynamic dispatch to various subclass methods</secondary></indexterm>dynamic dispatch in a procedural language like C is a distinguishing mark of an expert programmer. (Another is the ability to write a structured program in assembly language or Fortran.)</para><para>Indirection is also often introduced as a way to factor common functionality. Have a look at the top of <xref linkend="layers_of_indirection_in_the_freebsd_implementation_of_the_read"/>. Modern Unix systems have four variants of the vanilla <literal moreinfo="none">read</literal> system call. The system call variants starting with <literal moreinfo="none">p (pread, preadv)</literal> allow the specification of a file position together with the call. The variants ending with a <literal moreinfo="none">v (readv, preadv)</literal> allow the specification of a <indexterm id="idx-CHP-17-1442" significance="normal"><primary>vector of I/O requests</primary></indexterm>vector of I/O requests instead of a single one. Although I consider this proliferation of system calls inelegant and against the spirit of Unix, applications programmers seem to depend on them for squeezing every bit of performance out of the Web or database servers they implement.</para><para>All these calls share some common code. The FreeBSD implementation introduces indirection through <indexterm id="idx-CHP-17-1443" significance="normal"><primary>additional levels of indirection</primary></indexterm>additional functions in order to avoid code duplication. The function <literal moreinfo="none">kern_preadv</literal> handles the common parts of the positional system call variants, while <literal moreinfo="none">kern_readv</literal> handles the remaining two system calls. The functionality common in all four is handled by another function, <literal moreinfo="none">dofileread</literal>. In my mind, I can picture the joy developers got from factoring out the code common to those functions by introducing more levels of indirection. I always feel elated if, after committing a refactoring change, the lines I add are less than the lines I remove.<indexterm id="idx-CHP-17-1444" significance="normal"><primary>FreeBSD operating system</primary><secondary>interface functions and data structures</secondary><tertiary>read system call</tertiary></indexterm></para><para>The journey from our call to a read function in our user-level program to the movement of a disk head to fetch our data from a platter is a long and tortuous one. In our description, we haven't considered what happens above the kernel layer (<indexterm id="idx-CHP-17-1445" significance="normal"><primary>virtual machines</primary></indexterm>virtual machines, <indexterm id="idx-CHP-17-1446" significance="normal"><primary>buffering</primary></indexterm>buffering, <indexterm id="idx-CHP-17-1447" significance="normal"><primary>data representation</primary></indexterm>data representation), or what happens when a filesystem handles a request (buffering again, device drivers, data representation). Interestingly, there's a pleasant symmetry between the two ends we haven't covered: both involve <indexterm id="idx-CHP-17-1448" significance="normal"><primary>hardware interfaces</primary></indexterm>hardware interfaces (virtual machines, such as the JVM at the top, and real interfaces at the bottom), buffering (to minimize system calls at the top, and to optimize the hardware's performance at the bottom), and data representation (to interact with the user's locale at the top, and to match the physical layer's requirements at the bottom). It seems that indirection is everywhere we care to cast our eyes. In the representative chunk we've looked at, nine levels of function calls, two indirections through function pointers, and a domain-specific language provided us with a representative view of its power.</para></sect1><sect1 id="layers_forever" label="17.6"><title>Layers Forever?</title><para>We could continue looking at more code examples forever, so it is worth bringing our discussion to an end by noting that Lampson attributes the aphorism that started our exploration (all problems in computer science can be solved by another level of indirection) to David <indexterm id="idx-CHP-17-1449" significance="normal"><primary>Wheeler</primary></indexterm>Wheeler, the inventor of the subroutine. Significantly, Wheeler completed his quote with another phrase: "But that usually will create another problem." Indeed, indirection and <indexterm id="idx-CHP-17-1450" significance="normal"><primary>layering and indirection</primary></indexterm>layering add space and time overhead, and can obstruct the code's comprehensibility.</para><para>The time and space overhead is often unimportant, and should rarely concern us. In most cases, the delays introduced by an extra pointer lookup or subroutine call are insignificant in the greater scheme of things. In fact, nowadays the tendency in modern programming languages is for some operations to always happen through a level of <indexterm id="idx-CHP-17-1451" significance="normal"><primary>C#</primary><secondary>indirection in</secondary></indexterm>indirection in order to provide an additional measure of flexibility. Thus, for example, in <indexterm id="idx-CHP-17-1452" significance="normal"><primary>lookup table</primary><secondary>Java instance method calls dispatched through</secondary></indexterm>Java and C#, almost all accesses to objects go through one pointer indirection, to allow for automatic garbage collection. Also, in Java, almost all calls to <indexterm id="idx-CHP-17-1453" significance="normal"><primary>instance method calls in Java</primary></indexterm>instance methods are dispatched through a lookup table, in order to allow inheriting classes to override a method at runtime.</para><para>Despite these overheads that burden all object accesses and method calls, both platforms are doing fine in the marketplace, thank you very much. In other cases, compilers optimize away the indirection we developers put in our code. Thus, most compilers detect cases where calling a function is more expensive than substituting its code inline, and automatically perform this inlining.</para><para>Then again, when we're operating at the edge of performance, indirection can be a burden. One trick that developers trying to feed gigabit network interfaces use to speed up their code is to combine functionality of different levels of the network stack, collapsing some layers of abstraction. But these are extreme cases.</para><para>On the other hand, the effect that indirection has on the comprehensibility of our code is a very important concern, because over the last 50 years, in contrast to the dizzying increases in CPU speeds, the ability of humans to understand code hasn't improved much. Therefore, the proponents of agile processes advise us to be especially wary when introducing layering to handle some vague, unspecified requirements we imagine might crop up in the future rather than today's concrete needs. As Bart Smaalders quipped when discussing performance anti-patterns: "Layers are for cakes, not for software."</para></sect1></chapter><chapter id="pythons_dictionary_implementation_being_all_things_to_all_peopl" label="18" role=""><title>Python's Dictionary Implementation: Being All Things to All People</title><para><emphasis>Andrew Kuchling</emphasis><indexterm id="idx-CHP-18-1454" significance="normal"><primary>python command (Mac OS and Linux)</primary></indexterm><indexterm id="idx-CHP-18-1455" significance="normal"><primary>Kuchling</primary></indexterm></para><para><emphasis>Dictionaries are a fundamental data type in the python programming language</emphasis>. Like <emphasis>awk's</emphasis> associative arrays and Perl's hashes, <indexterm class="startofrange" id="idx-CHP-18-1456" significance="normal"><primary>Python</primary><secondary>dictionaries</secondary></indexterm>dictionaries store a mapping of unique keys to values. <indexterm id="idx-CHP-18-1457" significance="normal"><primary>dictionaries</primary><secondary>basic operations on</secondary></indexterm>Basic operations on a dictionary include:<indexterm id="idx-CHP-18-1458" significance="normal"><primary>dictionaries</primary></indexterm><indexterm id="idx-CHP-18-1459" significance="normal"><primary>key/value pairs</primary><secondary>Python dictionaries</secondary></indexterm></para><itemizedlist><listitem><para>Adding a new key/value pair</para></listitem><listitem><para>Retrieving the value corresponding to a particular key</para></listitem><listitem><para>Removing existing pairs</para></listitem><listitem><para>Looping over the keys, values, or key/value pairs</para></listitem></itemizedlist><para>Here's a brief example of using a dictionary at the Python interpreter prompt. (To try out this example, you can just run the <emphasis>python</emphasis> command on Mac OS and most Linux distributions. If Python isn't already installed, you can <indexterm id="idx-CHP-18-1460" significance="normal"><primary>Python</primary><secondary>download site</secondary></indexterm>download it from <ulink url="http://www.python.org"/>.)</para><para>In the following interactive session, the &gt;&gt;&gt; signs represent the Python interpreter's prompts, and <literal moreinfo="none">d</literal> is the name of the dictionary I'm playing with:</para><programlisting id="I_programlisting18_tt384" format="linespecific">
	&gt;&gt;&gt; <userinput moreinfo="none">d = {1: 'January', 2: 'February',
	... 'jan': 1, 'feb': 2, 'mar': 3}</userinput>
	{'jan': 1, 1: 'January', 2: 'February', 'mar': 3, 'feb': 2}
	&gt;&gt;&gt; <userinput moreinfo="none">d['jan'], d[1]</userinput>
	(1, 'January')
	&gt;&gt;&gt; <userinput moreinfo="none">d[12]</userinput>
	Traceback (most recent call last):
	  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
	KeyError: 12
	&gt;&gt;&gt; <userinput moreinfo="none">del d[2]</userinput>
	&gt;&gt;&gt; <userinput moreinfo="none">for k, v in d.items(): print k,v</userinput> # Looping over all pairs.
	jan 1
	1 January
	mar 3
	&gt;feb 2
	...
</programlisting><para>Two things to note about <indexterm id="idx-CHP-18-1461" significance="normal"><primary>identifiers</primary><secondary>Python</secondary></indexterm>Python's dictionary type are:</para><itemizedlist><listitem><para>A single dictionary can contain <indexterm id="idx-CHP-18-1462" significance="normal"><primary>dictionaries</primary><secondary>keys and values of different data types in single dictionary</secondary></indexterm>keys and values of several different data types. It's legal to store the <indexterm id="idx-CHP-18-1463" significance="normal"><primary>dictionaries</primary><secondary>keys not ordered</secondary></indexterm>keys <literal moreinfo="none">1, 3+4j</literal> (a complex number), and <literal moreinfo="none">"abc"</literal> (a string) in the same dictionary. Values retain their type; they aren't all converted to strings.</para></listitem><listitem><para>Keys are <indexterm id="idx-CHP-18-1464" significance="normal"><primary>keys</primary><secondary>Python dictionaries collisions</secondary><tertiary>not ordered</tertiary></indexterm>not ordered. Methods such as <literal moreinfo="none">.values()</literal> that return the entire contents of a dictionary will return the data in some arbitrary arrangement, not ordered by value or by insertion time.</para></listitem></itemizedlist><para>It's important that retrieval of keys be a very fast operation, so dictionary-like types are usually implemented as hash tables. For the <indexterm id="idx-CHP-18-1465" significance="normal"><primary>dictionaries</primary><secondary>C implementation of Python</secondary></indexterm>C implementation of Python (henceforth referred to as <indexterm id="idx-CHP-18-1466" significance="normal"><primary>CPython</primary></indexterm>CPython), <indexterm id="idx-CHP-18-1467" significance="normal"><primary>dictionaries</primary></indexterm>dictionaries are even more pivotal because they underpin several other language features. For example, classes and class instances use a dictionary to store their attributes:</para><programlisting id="I_programlisting18_tt385" format="linespecific">
	&gt;&gt;&gt; obj = MyClass()          # Create a class instance
	&gt;&gt;&gt; obj.name = 'object'      # Add a .name attribute
	&gt;&gt;&gt; obj.id = 14              # Add a .id attribute
	&gt;&gt;&gt; obj._ _dict_ _            # Retrieve the underlying dictionary
	{'name': 'object', 'id': 14}
	&gt;&gt;&gt; obj._ _dict_ _['id'] = 12 # Store a new value in the dictionary
	&gt;&gt;&gt; obj.id                   # Attribute is changed accordingly
	12
</programlisting><para><indexterm id="idx-CHP-18-1468" significance="normal"><primary>dictionaries</primary><secondary>representing module contents</secondary></indexterm>Module contents are also represented as a dictionary, most notably the <literal moreinfo="none">_ _builtin_ _</literal> module that contains built-in identifiers such as <literal moreinfo="none">int</literal> and <literal moreinfo="none">open</literal>. Any expression that uses such built-ins will therefore result in a few dictionary lookups. Another use of <indexterm id="idx-CHP-18-1469" significance="normal"><primary>Python</primary><secondary>dictionaries</secondary></indexterm>dictionaries is to pass <indexterm id="idx-CHP-18-1470" significance="normal"><primary>dictionaries</primary><secondary>passing keyword arguments to a function</secondary></indexterm>keyword arguments to a function, so a dictionary could potentially be created and destroyed on every function call. This internal use of the dictionary type means that any running <indexterm id="idx-CHP-18-1471" significance="normal"><primary>performance</primary><secondary>Python dictionary implementation and</secondary></indexterm>Python program has many dictionaries active at the same time, even if the user's program code doesn't explicitly use a dictionary. It's therefore important that dictionaries can be created and destroyed quickly and not use an overly large amount of memory.<indexterm id="idx-CHP-18-1472" significance="normal"><primary>_ _builtin_ _ module (Python)</primary></indexterm></para><para>The implementation of dictionaries in Python teaches several lessons about performance-critical code. First, one has to trade off the advantages of an optimization against the overhead it adds in space or calculation time. There were places where the Python developers found that a relatively naïve implementation was better in the long run than an extra optimization that seemed more appealing at first. In short, it often pays to keep things simple.</para><para>Second, real-life benchmarking is critical; only that way can you discover what's really worth doing.</para><sect1 id="inside_the_dictionary" label="18.1"><title>Inside the Dictionary</title><para><indexterm id="idx-CHP-18-1473" significance="normal"><primary>dictionaries</primary></indexterm>Dictionaries are represented by a C structure, <literal moreinfo="none">PyDictObject</literal>, defined in <emphasis>Include/dictobject.h</emphasis>. Here's a schematic of the structure representing a small dictionary mapping <literal moreinfo="none">"aa", "bb", "cc", …, "mm"</literal> to the integers 1 to 13:<indexterm id="idx-CHP-18-1474" significance="normal"><primary>PyDictObject structure</primary></indexterm></para><programlisting id="I_programlisting18_tt386" format="linespecific">
	int ma_fill         13
	int ma_used         13
	int ma_mask         31

	PyDictEntry ma_table[]:
	[0]: aa, 1                  hash(aa) == -1549758592, -1549758592 &amp; 31 = 0
	[1]: ii, 9                  hash(ii) == -1500461680, -1500461680 &amp; 31 = 16	
	[2]: null, null
	[3]: null, null 
	[4]: null, null
	[5]: jj, 10                 hash(jj) == 653184214, 653184214 &amp; 31 = 22
	[6]: bb, 2                  hash(bb) == 603887302, 603887302 &amp; 31 = 6
	[7]: null, null 
	[8]: cc, 3                  hash(cc) == -1537434360, -1537434360 &amp; 31 = 8
	[9]: null, null
	[10]: dd, 4                 hash(dd) == 616211530, 616211530 &amp; 31 = 10
	[11]: null, null
	[12]: null, null
	[13]: null, null
	[14]: null, null 
	[15]: null, null
	[16]: gg, 7                 hash(gg) == -1512785904, -1512785904 &amp; 31 = 16
	[17]: ee, 5                 hash(ee) == -1525110136, -1525110136 &amp; 31 = 8
	[18]: hh, 8                 hash(hh) == 640859986, 640859986 &amp; 31 = 18
	[19]: null, null
	[20]: null, null
	[21]: kk, 11                hash(kk) == -1488137240, -1488137240 &amp; 31 = 8
	[22]: ff, 6                 hash(ff) == 628535766, 628535766 &amp; 31 = 22
	[23]: null, null
	[24]: null, null
	[25]: null, null
	[26]: null, null
	[27]: null, null
	[28]: null, null
	[29]: ll, 12                hash(ll) == 665508394, 665508394 &amp; 31 = 10
	[30]: mm, 13                hash(mm) == -1475813016, -1475813016 &amp; 31 = 8 
	[31]: null, null
</programlisting><para>The <literal moreinfo="none">ma_</literal>prefix in the field names comes from the word <emphasis>mapping</emphasis>, Python's term for data types that provide key/value lookups. The fields in the structure are:<indexterm id="idx-CHP-18-1475" significance="normal"><primary>mapping (Python)</primary></indexterm></para><variablelist><varlistentry><term><literal moreinfo="none">ma_used</literal></term><listitem><para>Number of slots occupied by keys (in this case, 13).</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">ma_fill</literal></term><listitem><para>Number of slots occupied by keys or by dummy entries (also 13).</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">ma_mask</literal></term><listitem><para><indexterm id="idx-CHP-18-1476" significance="normal"><primary>hash tables</primary><secondary>bitmask representing size in PyDictObject structure</secondary></indexterm>Bitmask representing the size of the hash table. The hash table contains <literal moreinfo="none">ma_mask+1</literal> slots—in this case, 32. The number of slots in the table is always a power of 2, so this value is always of the form 2<superscript>n</superscript>–1 for some <emphasis>n</emphasis>, and therefore consists of <emphasis>n</emphasis> set bits.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">ma_table</literal></term><listitem><para>Pointer to an array of <literal moreinfo="none">PyDictEntry</literal> structures. <literal moreinfo="none">PyDictEntry</literal> contains pointers to:<indexterm id="idx-CHP-18-1477" significance="normal"><primary>PyDictEntry structure</primary></indexterm><indexterm id="idx-CHP-18-1478" significance="normal"><primary>pointers</primary><secondary>PyDictEntry structures</secondary></indexterm></para><itemizedlist><listitem><para>The key object</para></listitem><listitem><para>The value object</para></listitem><listitem><para>A cached copy of the key's hash code</para></listitem></itemizedlist><para>The hash value is cached for the sake of speed. When searching for a key, the exact hash values can be quickly compared before performing a slower, full equality comparison of the keys. Resizing a dictionary also requires the hash value for each key, so caching the value saves having to rehash all the keys when resizing.</para></listitem></varlistentry></variablelist><para>We don't keep track directly of the number of slots in the table, but derive it instead as needed from <literal moreinfo="none">ma_mask</literal>. When looking up the entry for a key, <literal moreinfo="none">slot = hash &amp; mask</literal> is used to figure out the initial slot for a particular hash value. For instance, the hash function for the first entry generated a hash of –1549758592, and –1549758592 mod 31 is 0, so the entry is stored in slot 0.</para><para>Because the mask is needed so often, we store it instead of the number of slots. It's easy to calculate the number of slots by adding 1, and we never need to do so in the most speed-critical sections of code.</para><para><literal moreinfo="none">ma_fill</literal> and <literal moreinfo="none">ma_used</literal> are updated as objects are added and deleted. <literal moreinfo="none">ma_used</literal> is the number of keys present in the dictionary; adding a new key increases it by 1, and deleting a key decreases it by 1. To delete a key, we make the appropriate slot point to a dummy key; <literal moreinfo="none">ma_fill</literal> therefore remains the same when a key is deleted, but may increase by 1 when a new key is added. (<literal moreinfo="none">ma_fill</literal> is never decremented, but will be given a new value when a dictionary is resized.)</para></sect1><sect1 id="special_accommodations" label="18.2"><title>Special Accommodations</title><para>When trying to be all things to all people—a time- and memory-efficient data type for Python users, an internal data structure used as part of the interpreter's implementation, and a readable and maintainable code base for Python's developers—it's necessary to complicate a pure, theoretically elegant implementation with special-case code for particular cases… but not too much.</para><sect2 id="a_special-case_optimization_for_small_hashes" label="18.2.1"><title>A Special-Case Optimization for Small Hashes</title><para>The <literal moreinfo="none">PyDictObject</literal> also contains space for an eight-slot hash table. Small <indexterm id="idx-CHP-18-1479" significance="normal"><primary>dictionaries</primary></indexterm>dictionaries with five elements or fewer can be stored in this table, saving the time cost of an extra <literal moreinfo="none">malloc()</literal> call. This also improves cache locality; for example, <literal moreinfo="none">PyDictObject</literal> structures <indexterm id="idx-CHP-18-1480" significance="normal"><primary>keys</primary><secondary>Python dictionaries collisions</secondary><tertiary>looking up</tertiary></indexterm>occupy 124 bytes of space when using x86 GCC and therefore can fit into two 64-byte cache lines. The <indexterm id="idx-CHP-18-1481" significance="normal"><primary>Python</primary><secondary>dictionaries</secondary></indexterm>dictionaries used for keyword arguments most commonly have one to three keys, so this optimization helps improve function-call performance.<indexterm id="idx-CHP-18-1482" significance="normal"><primary>dictionaries</primary><secondary>special-case optimization for small hashes</secondary></indexterm></para></sect2><sect2 id="when_special-casing_is_worth_the_overhead" label="18.2.2"><title>When Special-Casing Is Worth the Overhead</title><para>As previously explained, a single dictionary can contain keys of several different data types. In most <indexterm id="idx-CHP-18-1483" significance="normal"><primary>Java</primary><secondary>Python implementation (Jython)</secondary></indexterm>Python programs, the dictionaries underlying class instances and modules have only strings as keys. It's natural to wonder whether a specialized dictionary object that only accepted strings as keys might provide benefits. Perhaps a special-case data type would be useful and make the interpreter run faster?<indexterm id="idx-CHP-18-1484" significance="normal"><primary>Python</primary><secondary>dictionaries</secondary><tertiary>special-casing</tertiary></indexterm><indexterm id="idx-CHP-18-1485" significance="normal"><primary>dictionaries</primary><secondary>special-casing</secondary></indexterm></para><sect3 id="the_java_implementation_another_special-case_optimization" label="18.2.2.1"><title>The Java implementation: another special-case optimization</title><para>In fact, there <emphasis>is</emphasis> a <indexterm id="idx-CHP-18-1486" significance="normal"><primary>string-specialized dictionary type</primary></indexterm>string-specialized dictionary type in <indexterm id="idx-CHP-18-1487" significance="normal"><primary>Jython</primary></indexterm>Jython (<ulink url="http://www.jython.org"/>), an implementation of Python in Java. Jython has an <literal moreinfo="none">org.python.org.PyStringMap</literal> class used only for dictionaries in which all keys are strings; it is used for the <literal moreinfo="none">_ _dict_ _</literal> dictionary underpinning class instances and modules. Jython code that creates a dictionary for user code employs a different class, <literal moreinfo="none">org.python.core.PyDictionary</literal>, a heavyweight object that uses a <literal moreinfo="none">java.util.Hashtable</literal> to store its contents and does extra indirection to allow <literal moreinfo="none">PyDictionary</literal> to be subclassed.<indexterm id="idx-CHP-18-1488" significance="normal"><primary>PyStringMap class (Jython)</primary></indexterm></para><para>Python's language definition doesn't allow users to replace the internal<literal moreinfo="none">_ _dict_ _</literal> dictionaries by a different data type, making the overhead of supporting subclassing unnecessary. For Jython, having a specialized string-only dictionary type makes sense.</para></sect3><sect3 id="the_c_implementation_selecting_the_storage_function_dynamically" label="18.2.2.2"><title>The C implementation: selecting the storage function dynamically</title><para>CPython does <emphasis>not</emphasis> have a specialized dictionary type, as Jython does. Instead, it employs a different trick: an individual dictionary uses a string-only function until a search for non-string data is requested, and then a more general function is used. The implementation is simple. <literal moreinfo="none">PyDictObject</literal> contains one field, <literal moreinfo="none">ma_lookup</literal>, that's a pointer to the function used to look up keys:<indexterm id="idx-CHP-18-1489" significance="normal"><primary>PyDictObject structure</primary><secondary>ma_lookup field</secondary></indexterm><indexterm id="idx-CHP-18-1490" significance="normal"><primary>CPython</primary><secondary>selecting storage function dynamically</secondary></indexterm></para><programlisting id="I_programlisting18_tt387" format="linespecific">
	struct PyDictObject {
	    ...
	    PyDictEntry *(*ma_lookup)(PyDictObject *mp, PyObject *key, long hash);
	};
</programlisting><para><literal moreinfo="none">PyObject</literal> is the C structure that represents any Python data object, containing basic fields such as a reference count and a pointer to a type object. Specific types such as <literal moreinfo="none">PyIntObject</literal> and <literal moreinfo="none">PyStringObject</literal> extend the structure with additional fields as necessary. The dictionary implementation calls <literal moreinfo="none">(dict-&gt;ma_lookup)(dict, key, hash)</literal> to find a key; <literal moreinfo="none">key</literal> is a pointer to the <literal moreinfo="none">PyObject</literal> representing the key, and <literal moreinfo="none">hash</literal> is the hash value derived for the key.<indexterm id="idx-CHP-18-1491" significance="normal"><primary>PyObject structure</primary></indexterm><indexterm id="idx-CHP-18-1492" significance="normal"><primary>PyIntObject type</primary></indexterm><indexterm id="idx-CHP-18-1493" significance="normal"><primary>PyStringObject type</primary></indexterm><indexterm id="idx-CHP-18-1494" significance="normal"><primary>structures</primary><secondary>PyObject</secondary></indexterm></para><para><literal moreinfo="none">ma_lookup</literal> is initially set to <literal moreinfo="none">lookdict_string</literal>, a function that assumes that both the <indexterm id="idx-CHP-18-1495" significance="normal"><primary>hash tables</primary><secondary>keys hashing to same slot</secondary></indexterm>keys in the dictionary and the key being searched for are strings represented as Python's standard <literal moreinfo="none">PyStringObject</literal> type. <literal moreinfo="none">lookdict_string</literal> can therefore take a few shortcuts. One shortcut is that string-to-string <indexterm id="idx-CHP-18-1496" significance="normal"><primary>comparison operators</primary></indexterm>comparisons never raise exceptions, so some unnecessary error checking can be skipped. Another is that there's no need to check for rich comparisons on the object; arbitrary Python data types can provide their own separate versions of &lt;, &gt;, &lt;=, &gt;=, ==, and !=, but the standard string type has no such special cases.</para><para>If a nonstring key is encountered, either because it's used as a dictionary key or the program makes an attempt to search for it, the <literal moreinfo="none">ma_lookup</literal> field is changed to point to the more general <literal moreinfo="none">lookdict</literal> function. <literal moreinfo="none">lookdict_string</literal> checks the type of its input and changes <literal moreinfo="none">ma_lookup</literal> if necessary, then calls the chosen function to obtain a correct answer. (CPython trivia: this means that a dictionary with only string keys will become slightly slower if you issue <literal moreinfo="none">d.get(1)</literal>, even though the search can't possibly succeed. All subsequent code in the program that refers to the dictionary will also go through the more general function and incur a slight slowdown.) Subclasses of <literal moreinfo="none">PyStringObject</literal> have to be treated as nonstrings because the subclass might define a new equality test.</para></sect3></sect2></sect1><sect1 id="collisions" label="18.3"><title>Collisions</title><para>For any hash table implementation, an important decision is what to do when two keys hash to the same slot. One approach is <emphasis>chaining</emphasis> (see <ulink url="http://en.wikipedia.org/wiki/Hash_table#Chaining"/>): each slot is the head of a linked list containing all the items that hash to that slot. Python doesn't take this approach because creating linked lists would require allocating memory for each list item, and memory allocations are relatively slow operations. Following all the linked-list pointers would also probably reduce cache locality.<indexterm id="idx-CHP-18-1497" significance="normal"><primary>dictionaries</primary><secondary>collisions</secondary></indexterm><indexterm id="idx-CHP-18-1498" significance="normal"><primary>chaining</primary></indexterm><indexterm id="idx-CHP-18-1499" significance="normal"><primary>collisions in Python dictionaries</primary></indexterm></para><para>The alternative approach is <emphasis>open addressing</emphasis> (see <ulink url="http://en.wikipedia.org/wiki/Hash_table#Open_addressing"/>): if the first slot <literal moreinfo="none">i</literal> that is tried doesn't contain the key, other slots are tried in a fixed pattern. The simplest pattern is called <emphasis>linear probing</emphasis>: if slot <literal moreinfo="none">i</literal> is full, try <literal moreinfo="none">i+1, i+2, i+3</literal>, and so on, wrapping around to slot 0 when the end of the table is reached. Linear probing would be wasteful in Python because many programs use consecutive integers as keys, resulting in blocks of filled slots. Linear probing would frequently scan these blocks, resulting in poor performance. Instead, Python uses a more complicated pattern:<indexterm id="idx-CHP-18-1500" significance="normal"><primary>open addressing</primary></indexterm><indexterm id="idx-CHP-18-1501" significance="normal"><primary>linear probing</primary></indexterm></para><programlisting id="I_programlisting18_tt388" format="linespecific">
	/* Starting slot */
	slot = hash;

	/* Initial perturbation value */
	perturb = hash;
	while (&lt;slot is full&gt; &amp;&amp; &lt;item in slot doesn't equal the key&gt;) {
	    slot = (5*slot) + 1 + perturb;
	    perturb &gt;&gt;= 5;
	}
</programlisting><para>In the C code, <literal moreinfo="none">5*slot</literal> is written using <indexterm id="idx-CHP-18-1502" significance="normal"><primary>bit shifts for collisions in Python dictionaries</primary></indexterm>bit shifts and addition as <literal moreinfo="none">(slot&lt;&lt;2) + slot</literal>. The perturbation factor <literal moreinfo="none">perturb</literal> starts out as the full hash code; its bits are then progressively shifted downward 5 bits at a time. This shift ensures that every bit in the hash code will affect the probed slot index fairly quickly. Eventually the perturbation factor becomes zero, and the pattern becomes simply <literal moreinfo="none">slot=(5*slot)+1</literal>. This eventually generates every integer between 0 and <literal moreinfo="none">ma_mask</literal>, so the search is guaranteed to eventually find either the key (on a search operation) or an empty slot (on an insert operation).</para><para>The shift value of 5 bits was chosen by experiment; 5 bits minimized collisions slightly better than 4 or 6 bits, though the difference wasn't significant. Earlier versions of this code used more complicated operations such as multiplication or division, but though these versions had excellent collision statistics, the calculation ran slightly more slowly. (The extensive comments in <emphasis>Objects/dictobject.c</emphasis> discuss the history of this optimization in more detail.)</para></sect1><sect1 id="resizing" label="18.4"><title>Resizing</title><para>The size of a dictionary's hash table needs to be adjusted as keys are added. The code aims to keep the table two-thirds full; if a dictionary is holding <emphasis>n</emphasis> keys, the table must have at least <emphasis>n/</emphasis> (2/3) slots. This ratio is a trade-off: filling the table more densely results in more collisions when searching for a key, but uses less memory and therefore fits into cache better. Experiments have been tried where the 2/3 ratio is adjusted depending on the size of the dictionary, but they've shown poor results; every insert operation has to check whether the dictionary needed to be resized, and the complexity that the check adds to the insert operation slows things down.<indexterm id="idx-CHP-18-1503" significance="normal"><primary>hash tables</primary><secondary>resizing for Python dictionaries</secondary></indexterm><indexterm id="idx-CHP-18-1504" significance="normal"><primary>dictionaries</primary><secondary>resizing</secondary></indexterm></para><sect2 id="determining_the_new_table_size" label="18.4.1"><title>Determining the New Table Size</title><para>When a dictionary needs to be resized, how should the new size be determined? For small- or medium-size <indexterm id="idx-CHP-18-1505" significance="normal"><primary>dictionaries</primary></indexterm>dictionaries with 50,000 keys or fewer, the new size is <literal moreinfo="none">ma_used*4</literal>. Most Python programs that work with large <indexterm id="idx-CHP-18-1506" significance="normal"><primary>Python</primary><secondary>dictionaries</secondary></indexterm>dictionaries build up the dictionary in an initial phase of processing, and then look up individual keys or loop over the entire contents. Quadrupling the dictionary size like this keeps the dictionary sparse (the fill ratio starts out at 1/4) and reduces the number of resize operations performed during the build phase. Large dictionaries with more than 50,000 keys use <literal moreinfo="none">ma_used*2</literal> to avoid consuming too much memory for empty slots.<indexterm id="idx-CHP-18-1507" significance="normal"><primary>dictionaries</primary><secondary>resizing</secondary><tertiary>determining new table size</tertiary></indexterm></para><para>On deleting a key from a dictionary, the slot occupied by the key is changed to point to a dummy key, and the <literal moreinfo="none">ma_used</literal> count is updated, but the number of full slots in the table isn't checked. This means dictionaries are never resized on deletion. If you build a large dictionary and then delete many keys from it, the dictionary's hash table may be larger than if you'd constructed the smaller dictionary directly. This usage pattern is quite infrequent, though. Keys are almost never deleted from the many small <indexterm id="idx-CHP-18-1508" significance="normal"><primary>dictionaries</primary></indexterm>dictionaries used for objects and for passing function arguments. Many <indexterm id="idx-CHP-18-1509" significance="normal"><primary>Python</primary></indexterm>Python programs will build a dictionary, work with it for a while, and then discard the whole dictionary. Therefore, very few Python programs will encounter high memory usage because of the no-resize-on-deletion policy.</para></sect2><sect2 id="a_memory_trade-off_thats_worth_it_the_free_list" label="18.4.2"><title>A Memory Trade-Off That's Worth It: The Free List</title><para>Many dictionary instances are used by Python itself to hold the <indexterm id="idx-CHP-18-1510" significance="normal"><primary>keyword arguments in function calls (Python dictionaries)</primary></indexterm>keyword arguments in <indexterm id="idx-CHP-18-1511" significance="normal"><primary>function calls</primary></indexterm>function calls. These are therefore created very frequently and have a very short lifetime, being destroyed when the function returns. An effective optimization when facing a high creation rate and short lifetime is to recycle unused data structures, reducing the number of <literal moreinfo="none">malloc()</literal> and <literal moreinfo="none">free()</literal> calls.</para><para>Python therefore maintains a <literal moreinfo="none">free_dicts</literal> array of <indexterm id="idx-CHP-18-1512" significance="normal"><primary>structures</primary><secondary>dictionary structures no longer in use</secondary></indexterm>dictionary structures no longer in use. In Python 2.5, this array is 80 elements long. When a new <literal moreinfo="none">PyDictObject</literal> is required, a pointer is taken from <literal moreinfo="none">free_dicts</literal> and the structure is reused. <indexterm id="idx-CHP-18-1513" significance="normal"><primary>Python</primary><secondary>dictionaries</secondary></indexterm>Dictionaries are added to the array when deletion is requested; if <literal moreinfo="none">free_dicts</literal> is full, the structure is simply freed.<indexterm id="idx-CHP-18-1514" significance="normal"><primary>free_dicts array (Python)</primary></indexterm></para></sect2></sect1><sect1 id="iterations_and_dynamic_changes" label="18.5"><title>Iterations and Dynamic Changes</title><para>A common use case is looping through the contents of a dictionary. The <literal moreinfo="none">keys(), values()</literal>, and <literal moreinfo="none">items()</literal> methods return lists containing all of the keys, values, or key/value pairs in the dictionary. To conserve memory, the user can call the <literal moreinfo="none">iterkeys(), itervalues()</literal>, and <literal moreinfo="none">iteritems()</literal> methods instead; they return an iterator object that returns elements one by one. But when these iterators are used, Python has to forbid any statement that adds or deletes an entry in the dictionary during the loop.<indexterm id="idx-CHP-18-1515" significance="normal"><primary>dictionaries</primary><secondary>iterations and dynamic changes</secondary></indexterm><indexterm id="idx-CHP-18-1516" significance="normal"><primary>iterations through Python dictionaries</primary></indexterm></para><para>This restriction turns out to be fairly easy to enforce. The iterator records the number of items in the dictionary when an <literal moreinfo="none">iter*()</literal> method is first called. If the size changes, the iterator raises a <literal moreinfo="none">RuntimeError</literal> exception with the message <literal moreinfo="none">dictionary changed size during iteration</literal>.</para><para>One special case that modifies a dictionary while looping over it is code that assigns a new value for the same key:</para><programlisting id="I_programlisting18_tt389" format="linespecific">
	for k, v in d.iteritems():
	    d[k] = d[k] + 1
</programlisting><para>It's convenient to avoid raising a <literal moreinfo="none">RuntimeError</literal> exception during such operations. Therefore, the C function that handles dictionary insertion, <literal moreinfo="none">PyDict_SetItem()</literal>, guarantees not to resize the dictionary if it inserts a key that's already present. The <literal moreinfo="none">lookdict()</literal> and <literal moreinfo="none">lookdict_ string</literal> search functions support this feature by the way they report failure (not finding the searched-for key): on failure, they return a pointer to the empty slot where the searched-for key would have been stored. This makes it easy for <literal moreinfo="none">PyDict_SetItem</literal> to store the new value in the returned slot, which is either an empty slot or a slot known to be occupied by the same key. When the new value is recorded in a slot already occupied by the same key, as in <literal moreinfo="none">d[k]=d[k]+1</literal>, the dictionary's size isn't checked for a possible resize operation, and the <literal moreinfo="none">RuntimeError</literal> is avoided. Code such as the previous example therefore runs without an exception.<indexterm id="idx-CHP-18-1517" significance="normal"><primary>PyDict_SetItem( ) function</primary></indexterm><indexterm id="idx-CHP-18-1518" significance="normal"><primary>lookdict( ) and lookdict_string search functions</primary></indexterm></para></sect1><sect1 id="conclusion-id007" label="18.6"><title>Conclusion</title><para>Despite the many features and options presented by Python dictionaries, and their widespread use internally, the CPython implementation is still mostly straightforward. The optimizations that have been done are largely algorithmic, and their effects on collision rates and on benchmarks have been tested experimentally where possible. To learn more about the dictionary implementation, the source code is your best guide. First, read the <emphasis>Objects/dictnotes.txt</emphasis> file at <ulink url="http://svn.python.org/view/python/trunk/Objects/dictnotes.txt?view=markup"/> for a discussion of the common use cases for dictionaries and of various possible optimizations. (Not all the approaches described in the file are used in the current code.) Next, read the <emphasis>Objects/dictobject.c</emphasis> source file at <ulink url="http://svn.python.org/view/python/trunk/Objects/dictobject.c?view=markup"/>.</para><para>You can get a good understanding of the issues by reading the comments and taking an occasional clarifying glance at the code.</para></sect1><sect1 id="acknowledgments-id001" label="18.7"><title>Acknowledgments</title><para>Thanks to Raymond Hettinger for his comments on this chapter. Any errors are my own.<indexterm id="I_indexterm18_tt390" class="endofrange" startref="idx-CHP-18-1456" significance="normal"><primary>Python</primary><secondary>dictionaries</secondary></indexterm></para></sect1></chapter><chapter id="multidimensional_iterators_in_numpy" label="19" role=""><title>Multidimensional Iterators in NumPy</title><para><emphasis>Travis E. Oliphant</emphasis><indexterm class="startofrange" id="idx-CHP-19-1519" significance="normal"><primary>NumPy (Python)</primary></indexterm><indexterm id="idx-CHP-19-1520" significance="normal"><primary>Oliphant</primary></indexterm></para><para><emphasis>Numpy is an optional package for the python language</emphasis> that provides a powerful <indexterm id="idx-CHP-19-1521" significance="normal"><primary>N-dimensional</primary></indexterm>N-dimensional array object. An <emphasis>N</emphasis>-dimensional array is a data structure that uses <emphasis>N</emphasis> integers, or indices, to access individual elements. It is a useful model for a wide variety of data processed by a computer.<indexterm class="startofrange" id="idx-CHP-19-1522" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm></para><para>For example, a <indexterm id="idx-CHP-19-1523" significance="normal"><primary>one-</primary></indexterm>one-dimensional array can store the samples of a sound wave, a <indexterm id="idx-CHP-19-1524" significance="normal"><primary>two-dimensional arrays</primary></indexterm>two-dimensional array can store a grayscale image, a <indexterm id="idx-CHP-19-1525" significance="normal"><primary>three-dimensional arrays</primary></indexterm>three-dimensional array can store a color image (with one of the dimensions having a length of 3 or 4), and a four-dimensional array can store the value of pressure in a room during a concert. Even higher-dimensional <indexterm id="idx-CHP-19-1526" significance="normal"><primary>one-dimensional arrays</primary></indexterm>arrays are often useful.</para><para>NumPy provides an environment for the mathematical and structural manipulation of arrays of arbitrary dimensions. These manipulations are at the heart of much scientific, engineering, and multimedia code that routinely deals with large amounts of data. Being able to perform these mathematical and structural manipulations in a high-level language can considerably simplify the development and later reuse of these algorithms.</para><para><indexterm id="idx-CHP-19-1527" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy provides an assortment of mathematical calculations that can be done on arrays, as well as providing very simple syntax for structural operations. As a result, Python (with <indexterm id="idx-CHP-19-1528" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy) can be successfully used for the development of significant and fast-performing engineering and scientific code.</para><para>One feature that allows fast structural manipulation is that <indexterm id="idx-CHP-19-1529" significance="normal"><primary>NumPy (Python)</primary><secondary>accessing any region of an array using slicing</secondary></indexterm>any subregion of a NumPy array can be selected using the concept of <emphasis>slicing</emphasis>. In Python, a slice is defined by a starting index, a stopping index, and a stride, using the notation <literal moreinfo="none">start:stop:stride</literal> (inside square brackets).<indexterm id="idx-CHP-19-1530" significance="normal"><primary>slicing</primary></indexterm></para><para>For example, suppose we want to crop and shrink a 656x498 image to a 160x120 image by selecting a region in the middle of the image. If the image is <indexterm id="idx-CHP-19-1531" significance="normal"><primary>images held in NumPy array</primary></indexterm>held in the NumPy array, <literal moreinfo="none">im</literal>, this operation can be performed using:</para><programlisting id="I_programlisting19_tt391" format="linespecific">
	im2=im[8:-8:4, 9:-9:4]
</programlisting><para>An important feature of NumPy, however, is that the new image selected in this way actually shares data with the underlying image. A copy is not performed. This can be an important optimization when calculating with large data sets where indiscriminate copying can <indexterm id="idx-CHP-19-1532" significance="normal"><primary>for loops</primary><secondary>looping over N-dimensional arrays</secondary></indexterm>overwhelm the computing resources.</para><sect1 id="key_challenges_in_n-dimensional_array_operations" label="19.1"><title>Key Challenges in N-Dimensional Array Operations</title><para>In order to provide fast implementations of all mathematical operations, NumPy implements loops (in C) that work quickly over an array or several arrays of any number of dimensions. Writing such generic code that works quickly on arrays of arbitrary dimension can be a mind-stretching task. It may be easy to write a <literal moreinfo="none">for</literal> loop to process all the elements of a one-dimensional array, or two nested <literal moreinfo="none">for</literal> loops to process all the elements of a two-dimensional array. Indeed, if you know ahead of time how many dimensions the array consists of, you can use the right number of <literal moreinfo="none">for</literal> loops to directly loop over all of the elements of the array. But how do you write a general <literal moreinfo="none">for</literal>loop that will process all of the elements of an <emphasis>N</emphasis>-dimensional array when <emphasis>N</emphasis> can be an arbitrary integer?<indexterm id="idx-CHP-19-1533" significance="normal"><primary>N-dimensional arrays</primary><secondary>key challenges in operations</secondary></indexterm><indexterm id="idx-CHP-19-1534" significance="normal"><primary>NumPy (Python)</primary><secondary>N-dimensional array operations</secondary></indexterm><indexterm id="idx-CHP-19-1535" significance="normal"><primary>C language</primary><secondary>N-dimensional arrays</secondary></indexterm></para><para>There are two basic solutions to this problem. One solution is to use recursion by thinking about the problem in terms of a recursive case and a base case. Thus, if <literal moreinfo="none">copy_ND(a, b, N)</literal> is a function that copies an <literal moreinfo="none">N</literal>-dimensional array pointed to by <literal moreinfo="none">b</literal> to another N-dimensional array pointed to by <literal moreinfo="none">a</literal>, a simple recursive implementation might look like:</para><programlisting id="I_programlisting19_tt392" format="linespecific">
	if (N==0)
	    copy memory from b to a
	    return
	set up ptr_to_a and ptr_to_b
	for n=0 to size of first dimension of a and b
	    copy_ND(ptr_to_a, ptr_to_b, N-1)
	    add stride_a[0] to ptr_to_a and stride_b[0] to ptr_b
</programlisting><para>Notice the use of the single <literal moreinfo="none">for</literal> loop and the check for the base case that stops the recursion when <emphasis>N</emphasis> reaches 0.</para><para>It is not always easy to think about how to write every algorithm as a recursive algorithm, even though the code just shown can often be used as a starting model. <indexterm id="idx-CHP-19-1536" significance="normal"><primary>performance</primary><secondary>recursion and</secondary></indexterm>Recursion also requires the <indexterm id="idx-CHP-19-1537" significance="normal"><primary>NumPy (Python)</primary><secondary>use of iteration for N-dimensional algorithms</secondary></indexterm>use of a function call at each <indexterm id="idx-CHP-19-1538" significance="normal"><primary>iteration</primary></indexterm>iteration of the loop. So it can be all too easy for recursion to create slow code, unless some <indexterm id="idx-CHP-19-1539" significance="normal"><primary>optimization</primary><secondary>base-case optimization for recursive code</secondary></indexterm>base-case optimization is performed (such as stopping when <emphasis>N</emphasis>==1 and doing the memory copy in a <literal moreinfo="none">for</literal> loop locally).</para><para>Most languages will not do that kind of optimization automatically, so an elegant-looking recursive solution might end up looking much more contrived by the time optimizations are added.</para><para>In addition, many algorithms require the storage of intermediate information that will be used during later recursions. For example, what if the maximum or minimum value in the array must be tracked? Typically, such values become part of the recursive call structure and are passed along as arguments in the recursive call. In the end, each algorithm that uses recursion must be written in a slightly different way. Thus, it is hard to provide the programmer with additional simplifying tools for recursive solutions.</para><para>Instead of using recursion, <indexterm id="idx-CHP-19-1540" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy uses iteration to accomplish most of its <emphasis>N</emphasis>-dimensional algorithms. Every recursive solution can be written using an iterative solution. <indexterm id="idx-CHP-19-1541" significance="normal"><primary>Python</primary><secondary>iterators</secondary></indexterm>Iterators are an abstraction that simplifies thinking about these algorithms. Therefore, using iterators, <emphasis>N</emphasis>-dimensional routines can be developed that run quickly, while the code can still be read and understood using a single looping structure.</para><para>An iterator is an abstract concept that encapsulates the idea of walking through all of the elements of an array with just one loop. In <indexterm id="idx-CHP-19-1542" significance="normal"><primary>for loops</primary><secondary>Python iterators as predicates</secondary></indexterm>Python itself, iterators are objects that can be used as the predicate of any <literal moreinfo="none">for</literal> loop. For example:</para><programlisting id="I_programlisting19_tt393" format="linespecific">
	for x in iterobj:
	    process(x)
</programlisting><para>will run the function <literal moreinfo="none">process</literal> on all of the elements of <literal moreinfo="none">iterobj</literal>. The most important requirement of <literal moreinfo="none">iterobj</literal> is that it has some way to get its "next" element. Thus, the concept of an iterator refocuses the problem of looping over all the elements of a data structure to one of finding the next element.</para><para>In order to understand how iterators are implemented and used in <indexterm id="idx-CHP-19-1543" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy, it is crucial to have at least some conception of how NumPy views the memory in an <emphasis>N</emphasis>-dimensional array. The next section should clarify this point.</para></sect1><sect1 id="memory_models_for_an_n-dimensional_array" label="19.2"><title>Memory Models for an N-Dimensional Array</title><para>The simplest model for an <emphasis>N</emphasis>-dimensional array in computer memory can be used whenever all of the elements of the array are sitting next to each other in a contiguous segment. Under such circumstances, getting to the next element of the array is as simple as adding a fixed constant to a pointer to the memory location of the current data pointer. As a result, an iterator for contiguous memory arrays requires just adding a fixed constant to the current data pointer. Therefore, if every <emphasis>N</emphasis>-dimensional array in NumPy were contiguous, discussing iterators would be rather uninteresting.<indexterm id="idx-CHP-19-1544" significance="normal"><primary>memory models for N-dimensional array</primary></indexterm></para><para>The beauty of the iterator abstraction is that it allows us to think about processing and manipulating <indexterm id="idx-CHP-19-1545" significance="normal"><primary>noncontiguous arrays</primary></indexterm>noncontiguous arrays with the same ease as contiguous arrays. Noncontiguous arrays arise in <indexterm id="idx-CHP-19-1546" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy because an array can be created that is a "view" of some other contiguous memory area. This new array may not itself be contiguous.</para><para>For example, consider a three-dimensional array, <literal moreinfo="none">a</literal>, that is contiguous in memory. With <indexterm id="idx-CHP-19-1547" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy, you can create another array consisting of a subset of this larger array using Python's slicing notation. Thus, the statement <literal moreinfo="none">b=a[::2, 3:, 1::3]</literal> returns another NumPy array consisting of every other element in the first dimension, all elements starting at the fourth element (with zero-based indexing) in the second dimension, and every third element starting at the second element in the third dimension. This new array is not a copy of the memory at those locations; it is a view of the original array and shares memory with it. But this new array cannot be represented as a contiguous chunk of memory.</para><para>A two-dimensional illustration should further drive home the point. <xref linkend="a_two-dimensional_array_slice_and_its_linear_representation_in_"/> shows a contiguous, two-dimensional, 4 x 5 array with memory locations labeled from 1 through 20. Above the representation of the 4 x 5 array is a linear representation of the memory for the array as the computer might see it. If <literal moreinfo="none">a</literal> represents the full memory block, <literal moreinfo="none">b=a[1:3, 1:4]</literal> represents the shaded region (memory locations 7, 8, 9, 12, 13, and 14). As emphasized in the linear representation, these memory locations are not contiguous.</para><figure id="a_two-dimensional_array_slice_and_its_linear_representation_in_" label="19-1" float="0"><title>A two-dimensional array slice and its linear representation in memory</title><mediaobject id="I_mediaobject19_tt394"><imageobject role="print"><imagedata fileref="figs/print/beauty_1901.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_1901.png" format="PNG"/></imageobject></mediaobject></figure><para>NumPy's general memory model for an <emphasis>N</emphasis>-dimensional array supports the creation of these kinds of noncontiguous views of arrays. It is made possible by attaching to the array a sequence of integers that represent the values for the "striding" through each dimension.</para><para>The stride value for a particular dimension specifies how many bytes must be skipped to get from one element of the array to another along the associated dimension, or axis. This stride value can even be negative, indicating that the next element in the array is obtained by moving backward in memory. The extra complication of the (potentially) arbitrary striding means that constructing an iterator to handle the generic case is more difficult.</para></sect1><sect1 id="numpy_iterator_origins" label="19.3"><title>NumPy Iterator Origins</title><para>Loops that traverse all the elements of an array in compiled code are an essential feature that <indexterm id="idx-CHP-19-1548" significance="normal"><primary>beautiful code</primary><secondary>NumPy iterators</secondary></indexterm>NumPy offers the Python programmer. The use of an iterator makes it relatively easy to write these loops in a straightforward and readable way that works for the most general (arbitrarily strided) arrays supported by <indexterm id="idx-CHP-19-1549" significance="normal"><primary>iterators</primary><secondary>NumPy</secondary></indexterm>NumPy. The iterator abstraction is an example in my mind of beautiful code because it allows simple expression of a simple idea, even though the underlying implementation details might actually be complicated. This kind of beautiful code does not just drop into existence, but it is often the result of repeated attempts to solve a set of similar problems until a general solution crystallizes.<indexterm id="idx-CHP-19-1550" significance="normal"><primary>NumPy (Python)</primary></indexterm><indexterm id="idx-CHP-19-1551" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator origins</secondary></indexterm></para><para>My first attempt at writing a general-purpose, <emphasis>N</emphasis>-dimensional looping construct occurred around 1997 when I was trying to write code for both an <emphasis>N</emphasis>-dimensional convolution and a general-purpose arraymap that would perform a Python function on every element of an <emphasis>N</emphasis>-dimensional array.</para><para>The solution I arrived at then (though not formalized as an iterator) was to keep track of a C array of integers as indices for the <emphasis>N</emphasis>-dimensional array. Iteration meant incrementing this <emphasis>N</emphasis>-index counter with special code to wrap the counter back to zero and increment the next counter by 1 when the index reached the size of the array in a particular dimension.</para><para>While writing <indexterm id="idx-CHP-19-1552" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy eight years later, I became more aware of the concept of, and use of, iterator objects in Python. I thus considered adapting the arraymap code as a formal iterator. In the process, I studied how Peter Vevreer (author of <indexterm id="idx-CHP-19-1553" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>SciPy's <emphasis>ndimage</emphasis> package) accomplished <emphasis>N</emphasis>-dimensional looping and discovered an iterator very similar to what I had already been using. With this boost in confidence, I formalized the iterator, applying ideas from <emphasis>ndimage</emphasis> to the basic structural elements contained in the arraymap and <emphasis>N</emphasis>-dimensional convolution code.</para></sect1><sect1 id="iterator_design" label="19.4"><title>Iterator Design</title><para>As described previously, an iterator is an abstract concept that encapsulates the idea of walking through each element of an array. The basic pseudocode for an iterator-based loop used <indexterm class="startofrange" id="idx-CHP-19-1554" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary></indexterm>in NumPy is:<indexterm class="startofrange" id="idx-CHP-19-1555" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary></indexterm></para><programlisting id="I_programlisting19_tt395" format="linespecific">
	set up iterator
	  (including pointing the current value to the first value in the array)
	while iterator not done:
	    <replaceable>process the current value</replaceable>
	point the current value to the next value
</programlisting><para>Everything but <replaceable>process the current value </replaceable>must be handled by the iterator and deserves discussion. As a result, there are basically three parts to the <indexterm id="idx-CHP-19-1556" significance="normal"><primary>Python</primary><secondary>NumPy</secondary><tertiary>iterator design</tertiary></indexterm>iterator design:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Moving to the next value</para></listitem><listitem><para>Termination</para></listitem><listitem><para>Setup</para></listitem></orderedlist><para>These will each be discussed separately. The design considerations that went into <indexterm id="idx-CHP-19-1557" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy's <indexterm id="idx-CHP-19-1558" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary></indexterm>iterators included making the overhead for using them inside of a loop as small as possible and making them as fast as possible.</para><sect2 id="iterator_progression" label="19.4.1"><title>Iterator Progression</title><para>The first decision is the order in which the elements will be taken. Although one could conceive of an iterator with no guarantee of the order in which the elements are taken, it is useful most of the time for the programmer to know the order. As a result, iterators <indexterm id="idx-CHP-19-1559" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary></indexterm>in NumPy follow a specific order. The order is obtained using a relatively simple approach patterned after simple counting (with wrap-around) using a tuple of digits. Let a tuple of <emphasis>N</emphasis> integers represent the current position in the array, with <emphasis>(0,…,0)</emphasis> representing the first element of the <emphasis>n</emphasis><subscript>1</subscript> x <emphasis>n</emphasis><subscript>2</subscript> x … x <emphasis>n<subscript>N</subscript></emphasis> array, and (<emphasis>n</emphasis><subscript>1</subscript>−1, <emphasis>n</emphasis><subscript>2</subscript>−1,…, <emphasis>n<subscript>N</subscript>−1)</emphasis> representing the last element.<indexterm id="idx-CHP-19-1560" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary><tertiary>iterator progression</tertiary></indexterm><indexterm id="idx-CHP-19-1561" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary><tertiary>progression</tertiary></indexterm></para><para>This tuple of integers represents an <emphasis>N</emphasis>-digit counter. The next position is found by incrementing the last digit by one. If, during this process, the <emphasis>i<superscript>th</superscript></emphasis> digit reaches <emphasis>n<subscript>i</subscript></emphasis>, it is set to 0, and the <emphasis>(i</emphasis>−1)<emphasis><superscript>th</superscript></emphasis> digit is incremented by 1.</para><para>For example, the counting for a 3 x 2 x 4 array would proceed as follows:</para><simplelist type="vert"><member>(0,0,0) (0,0,1) (0,0,2) (0,0,3) (0,1,0) (0,1,1) (0,1,2) (0,1,3) (1,0,0) … (2,1,2) (2,1,3)</member></simplelist><para>The next increment would produce <literal moreinfo="none">(0,0,0)</literal>, and the iterator would be set up to start all over again.</para><para>This counter is the essence of the <indexterm id="idx-CHP-19-1562" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy iterator. The way it is incremented plays an important part in the iterator implementation. As a result, the implementation of the counter will be discussed in a subsequent section. Assuming that this counter that specifies the current position in the array is available, a pointer to the current value in the array can always be obtained by multiplying the integers of the counter by the stride values defined with the array, yielding the number of bytes to add to the memory address of the first element of the array.</para><para>For example, if <literal moreinfo="none">data</literal> is a pointer to the start of the array, <literal moreinfo="none">counter</literal> is the counter (or coordinate) array, and strides is an array of <literal moreinfo="none">stride</literal> values, the following operations:</para><programlisting id="I_programlisting19_tt396" format="linespecific">
	currptr = (char *)data;
	for (i=0; i&lt;N; i++) currptr += counter[i]*strides[i];
</programlisting><para>set <literal moreinfo="none">currptr</literal> to the (first byte of the) current value of the array.</para><para>In fact, rather than compute this multiplication every time a pointer to the current value is needed, the implementation can keep track of the pointer at the same time that it keeps track of the counter, making adjustments every time the counter is altered. For example, when the <emphasis>i<superscript>th</superscript></emphasis> index of the counter is incremented by 1, <literal moreinfo="none">currptr</literal> is incremented by <literal moreinfo="none">strides[i]</literal>. When the <emphasis>i<superscript>th</superscript></emphasis> index is reset to 0, this is the same as subtracting <emphasis>n<subscript>i</subscript></emphasis>−1 from the current index, and therefore the memory address of the current value of the array should be decremented by <emphasis>(n<subscript>i</subscript></emphasis>−1) −<literal moreinfo="none">strides[i]</literal>.</para><para>For the general case, the <indexterm id="idx-CHP-19-1563" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary></indexterm>iterator <indexterm id="idx-CHP-19-1564" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary></indexterm>maintains the counter specifying the position in the array along with a pointer to the current value. In the case of an array whose elements are all next to each other in memory, keeping track of this counter is unnecessary extra work because the memory address of the current value of the array can be maintained just by incrementing its value by the size of each element in the array when the next value is desired.</para></sect2><sect2 id="iterator_termination" label="19.4.2"><title>Iterator Termination</title><para>Another important aspect of the iterator (especially when it is used in a loop) is figuring out when the iterator is finished and how to signal that information. The most general approach to signaling is to attach a flag variable to the iterator that is checked each time around the loop, and set when there are no more elements to iterate through.<indexterm id="idx-CHP-19-1565" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary><tertiary>iterator termination</tertiary></indexterm><indexterm id="idx-CHP-19-1566" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary><tertiary>termination</tertiary></indexterm></para><para>One possible way to set this flag would be to look for the transition in the first-dimension counter from <emphasis>n</emphasis><subscript>1</subscript>−1 to 0. The problem with this approach is that it requires a temporary variable to store the last counter value, so it doesn't work for contiguous arrays, which do not keep track of the counter.</para><para>The easiest thing to do, however, is just remember that a particular number (<emphasis>n</emphasis>1 x…x <emphasis>nN</emphasis>) of iterations will take place given the size of the array. This number can be stored in the iterator structure. Then, during each iterator stage, this number can be decremented. When it reaches 0, the iterator should terminate.</para><para><indexterm id="idx-CHP-19-1567" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy uses a slight modification of this countdown. In order to preserve the total number of iterations as another piece of information, as well as to keep a running counter of the total number of iterations so far, <indexterm id="idx-CHP-19-1568" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy uses an integer counter that counts <emphasis>up</emphasis> from zero. The iteration terminates when this number reaches the total number of elements.</para></sect2><sect2 id="iterator_setup" label="19.4.3"><title>Iterator Setup</title><para>When the iterator is created, the size of the underlying array must be computed and stored. In addition, the integer counter must be set to 0, and the coordinate counter must be initialized to <literal moreinfo="none">(0,0,…,0)</literal>. Finally, NumPy determines whether the iterator can be based on simple contiguous memory and sets a flag to remember the answer.<indexterm id="idx-CHP-19-1569" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary><tertiary>iterator setup</tertiary></indexterm><indexterm id="idx-CHP-19-1570" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary><tertiary>setup</tertiary></indexterm></para><para>In order to speed up the "back-tracking step" that occurs whenever an index in the counter moves from <emphasis>n<subscript>i</subscript></emphasis>−1 to 0, the product of <emphasis>(n<subscript>i</subscript></emphasis>−1) x<literal moreinfo="none">strides[i]</literal> is precalculated and stored for each index. In addition to avoid repeatedly computing <emphasis>n<subscript>i</subscript></emphasis>−1, this is also precomputed and stored in the structure.</para><para>While it is doubtful that there is any speed increase in storing this easily computed quantity, it is still very useful to have the dimensions of the array stored in the iterator structure. In the same manner, it is useful to have information about strides stored directly in the iterator, along with a variable tracking how many dimensions the underlying array has. With the dimensions and strides of the array stored in the iterator, modifications to how the array is interpreted later can be easily accomplished by modifying these values in the <indexterm id="idx-CHP-19-1571" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary></indexterm>iterator and not <indexterm id="idx-CHP-19-1572" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary></indexterm>in the underlying array itself. This is especially useful in implementing <emphasis>broadcasting</emphasis>, which makes arrays that are not shaped the same appear as if they were shaped the same (as will be explained later).</para><para>Finally, an array of precomputed factors is stored to simplify the calculations involved in the one-to-one mapping between the single integer counter into the array and its <emphasis>N</emphasis>-index counterpart. For example, every item in the array can be referenced by a single integer <emphasis>k</emphasis> between 0 and <emphasis>n</emphasis><subscript>1</subscript> x … x <emphasis>nN</emphasis>−<subscript>1</subscript>−<superscript>1</superscript> or by a tuple of integers: <emphasis>(k</emphasis>1,…,<emphasis>kN)</emphasis>. The relationship can be defined by <emphasis>l</emphasis><subscript>1</subscript>=<emphasis>k</emphasis> and:</para><para><mediaobject id="I_mediaobject19_tt397"><imageobject role="print"><imagedata fileref="figs/print/equation7.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation7.png" format="PNG"/></imageobject></mediaobject></para><para><mediaobject id="I_mediaobject19_tt398"><imageobject role="print"><imagedata fileref="figs/print/equation8.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation8.png" format="PNG"/></imageobject></mediaobject></para><para>Going back the other way, the relationship is:</para><para><mediaobject id="I_mediaobject19_tt399"><imageobject role="print"><imagedata fileref="figs/print/equation9.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation9.png" format="PNG"/></imageobject></mediaobject></para><para>The terms within the parentheses of the previous equation are precomputed and stored in the iterator as an array of factors, to facilitate mapping back and forth between the two ways of thinking about the <emphasis>N</emphasis>-dimensional index.</para></sect2><sect2 id="iterator_counter_tracking" label="19.4.4"><title>Iterator Counter Tracking</title><para>Code for keeping track of the <emphasis>N</emphasis>-dimensional index counter is fairly straightforward. A distinction must be made between the case when the iterator will simply add 1 to the last index and when wrapping might occur. Whenever wrapping occurs, it has the potential to cause other indices to wrap as well. Therefore, there must be some kind of <literal moreinfo="none">for</literal> loop to handle all the altered indices.<indexterm id="idx-CHP-19-1573" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary><tertiary>iterator counter tracking</tertiary></indexterm></para><para>A straightforward approach is to start at the end of the counter, or coordinate, array and work backward. At each index position, the code checks to see whether the coordinate is currently smaller than <emphasis>n<subscript>i</subscript></emphasis>−1. If it is, it just adds 1 to that coordinate position and adds <literal moreinfo="none">strides[i]</literal> to the memory address of the current value pointer. Whenever this happens, the <literal moreinfo="none">for</literal> loop can break early, and the counter increment is done.</para><para>If the <emphasis>i<superscript>th</superscript></emphasis> coordinate is greater than or equal to <emphasis>n<subscript>i</subscript></emphasis>−1, it needs to be reset to 0 and (<emphasis>n<subscript>i</subscript></emphasis>−1)x<literal moreinfo="none">strides[i]</literal> must be subtracted from the memory address of the current value pointer (to move back to the beginning of that dimension). In this case, the previous index position is checked.</para><para>All the necessary <indexterm id="idx-CHP-19-1574" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary></indexterm>information can be represented in a structure we'll call <literal moreinfo="none">it</literal>. The contents are:</para><variablelist><varlistentry><term><literal moreinfo="none">coords</literal></term><listitem><para>The coordinate index, <emphasis>N</emphasis></para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">dims_m1</literal></term><listitem><para>The index of the highest element <emphasis>n<subscript>i</subscript></emphasis>−1 for each dimension</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">strides</literal></term><listitem><para>The stride in each dimension</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">backstrides</literal></term><listitem><para>The amount to move back in order to return from the end of each dimension to the beginning: (<emphasis>n<subscript>i</subscript></emphasis>−1) x <literal moreinfo="none">strides[i]</literal></para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">nd_m1</literal></term><listitem><para>The number of dimensions</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">currptr</literal></term><listitem><para>A pointer to memory for the current position in the array</para></listitem></varlistentry></variablelist><para>The code for the counter-tracking can then be written in C as follows:</para><programlisting id="I_programlisting19_tt400" format="linespecific">
	for (i=it-&gt;nd_m1; i&gt;=0; i--) {
	    if (it-&gt;coords[i] &lt; it-&gt;dims_m1[i]) {
	        it-&gt;coords[i]++;
	        it-&gt;dataptr += it-&gt;strides[i];
	        break;
	    }
	    else {
	        it-&gt;coords[i] = 0;
	        it-&gt;dataptr -= it-&gt;backstrides[i];
	    }
	}
</programlisting><para>This implementation uses the <literal moreinfo="none">break</literal> statement and a <literal moreinfo="none">for</literal> loop. We could instead have used a <literal moreinfo="none">while</literal> statement and a flag indicating whether to continue looping:</para><programlisting id="I_programlisting19_tt401" format="linespecific">
	done = 0;
	i = it-&gt;nd_m1;
	while (!done || i&gt;=0) {
	    if (it-&gt;coords[i] &lt; it-&gt;dims_m1[i]) {
	       it-&gt;coords[i]++;
	       it-&gt;dataptr += it-&gt;strides[i];
	       done = 1;
	    }
	    else {
	         it-&gt;coords[i] = 0;
	         it-&gt;dataptr -= it-&gt;backstrides[i];
	    }
	    i--;
	}
</programlisting><para>Part of the reason I chose the <literal moreinfo="none">for</literal> loop implementation is that the <literal moreinfo="none">while</literal> loop looks a lot like the <literal moreinfo="none">for</literal> loop (<indexterm id="idx-CHP-19-1575" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary></indexterm><indexterm id="idx-CHP-19-1576" significance="normal"><primary>in PyArrayIterObject</primary></indexterm>initialize counter, check against a value, decrement the counter), anyway. I typically reserve <literal moreinfo="none">while</literal> loops for situations where the iteration requires more than a single iteration index. A bigger reason for choosing the <literal moreinfo="none">for</literal> loop version, however, is that this code snippet implementing the counter increment will be used as a macro inside of every <indexterm id="idx-CHP-19-1577" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary></indexterm>iterator loop. I wanted to avoid defining the extra variable <literal moreinfo="none">done</literal>.</para></sect2><sect2 id="iterator_structure" label="19.4.5"><title>Iterator Structure</title><para>We are now in a position to understand the entire structure of the <indexterm id="idx-CHP-19-1578" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy iterator. It's represented as the following <literal moreinfo="none">struct</literal> in C:<indexterm id="idx-CHP-19-1579" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary><tertiary>iterator structure</tertiary></indexterm><indexterm id="idx-CHP-19-1580" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary><tertiary>structure</tertiary></indexterm></para><programlisting id="I_programlisting19_tt402" format="linespecific">
	typedef struct {
	    PyObject_HEAD
	    int nd_m1;
	    npy_intp index, size;
	    npy_intp coords[NPY_MAXDIMS];
	    npy_intp dims_m1[NPY_MAXDIMS];
	    npy_intp strides[NPY_MAXDIMS];
	    npy_intp backstrides[NPY_MAXDIMS];
	    npy_intp factors[NPY_MAXDIMS];
	    PyArrayObject *ao;
	    char *dataptr;
	    npy_bool contiguous;
	} <indexterm id="idx-CHP-19-1581" significance="normal"><primary>PyArrayIterObject structure</primary></indexterm>PyArrayIterObject;
</programlisting><para>The arrays in this structure (<literal moreinfo="none">coords, dims_m1, strides, backstrides</literal>, and <literal moreinfo="none">factors</literal>) are fixed-size arrays with dimensions controlled by the <literal moreinfo="none">NPY_MAXDIMS</literal> constant. This choice was made to simplify memory management. However, it does limit the number of dimensions that can be used. It could easily be handled differently by dynamically allocating the needed memory when the iterator is created; such a change would not alter the fundamental behavior.</para><para>The <literal moreinfo="none">npy_intp</literal> variables are integers just large enough to hold a pointer for the platform. <literal moreinfo="none">npy_bool</literal> is a flag that should be either TRUE or FALSE. The <literal moreinfo="none">PyObject_HEAD</literal> part of the structure contains the required portion that all Python objects must contain.</para><para>All of the variables have been explained before, but for clarity they are:</para><variablelist><varlistentry><term><literal moreinfo="none">nd_m1</literal></term><listitem><para>One less than the number of dimensions of the array: <emphasis>N</emphasis>−1.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">index</literal></term><listitem><para>A running counter indicating which element the iterator is currently at in the array. This counter runs from 0 to <literal moreinfo="none">size</literal>−1.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">size</literal></term><listitem><para>The total number of elements in the array: <emphasis>n</emphasis><subscript>1</subscript> x <emphasis>n</emphasis><subscript>2</subscript> x…x <emphasis>n<subscript>N</subscript></emphasis>.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">coords</literal></term><listitem><para>An array of <emphasis>N</emphasis> integers providing the counter, or the <emphasis>N</emphasis>-dimensional location of the current element.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">dims_m1</literal></term><listitem><para>An array of <emphasis>N</emphasis> <indexterm id="idx-CHP-19-1582" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary></indexterm>integers providing one less than the number of elements along each dimension: <emphasis>n</emphasis>1−<subscript>1</subscript>, <emphasis>n</emphasis><subscript>2</subscript>−<superscript>1</superscript>,…, <emphasis>n<subscript>N</subscript></emphasis>−<superscript>1</superscript>.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">strides</literal></term><listitem><para>An array of <emphasis>N</emphasis> integers providing the number of bytes to skip when advancing to the next element in a particular dimension.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">backstrides</literal></term><listitem><para>An array of <emphasis>N</emphasis> integers providing the number of bytes to subtract when the internal index counter rolls from <emphasis>n<subscript>i</subscript></emphasis>−1 to 0 in a particular dimension.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">factors</literal></term><listitem><para>An array of factors useful in rapidly calculating the mapping between the one-dimensional index and the <emphasis>N</emphasis>-dimensional <literal moreinfo="none">coords</literal> array. This array is needed only if <literal moreinfo="none">PyArray_ITER_GOTO1D</literal> is called.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">ao</literal></term><listitem><para>A pointer to the underlying array this <indexterm id="idx-CHP-19-1583" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary></indexterm>iterator is built from.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">datapr</literal></term><listitem><para>A pointer to the (first byte of) the current value of the array.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">contiguous</literal></term><listitem><para>TRUE (1) if this iterator is for a contiguous array and FALSE (0) if otherwise. This is the same as <literal moreinfo="none">(ao-&gt;flags &amp; NPY_C_CONTIGUOUS)</literal>. It's much simpler to find the next element in the array each time when the array is contiguous, so it is worth checking for.</para></listitem></varlistentry></variablelist></sect2></sect1><sect1 id="iterator_interface" label="19.5"><title>Iterator Interface</title><para>The iterator is implemented in <indexterm id="idx-CHP-19-1584" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy using a combination of macros and function calls. An iterator is created using the C-API function call <literal moreinfo="none">it=PyArray_IterNew(ao)</literal>. The check for iterator termination can be accomplished using the macro <literal moreinfo="none">PyArray_ITER_NOTDONE(it)</literal>. Finally, the next position in the iterator is accomplished using <literal moreinfo="none">PyArray_ITER_NEXT(it)</literal>, which is a macro to ensure that it occurs inline (avoiding the function call). Ideally, this macro would be an inline function because it is sufficiently complicated. However, because <indexterm id="idx-CHP-19-1585" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy is written to ANSI C, which does not define inline functions, a macro is used. Finally, the pointer to the first byte of the current value can be obtained using <literal moreinfo="none">PyArray_ITER_DATA(it)</literal>, which avoids referencing the structure member <literal moreinfo="none">dataptr</literal> directly (allowing for future name changes to the structure members).<indexterm id="idx-CHP-19-1586" significance="normal"><primary>iterators</primary><secondary>iterator interface in NumPy</secondary></indexterm></para><para>An example of the <indexterm id="idx-CHP-19-1587" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator interface</secondary></indexterm>iterator interface is the following code snippet, which computes the largest value in an <emphasis>N</emphasis>-dimensional array. We assume that the array is named <literal moreinfo="none">ao</literal>, has elements of type <literal moreinfo="none">double</literal>, and is correctly aligned:<indexterm id="I_indexterm19_tt403" class="endofrange" startref="idx-CHP-19-1554" significance="normal"><primary>iterators</primary><secondary>designing in NumPy</secondary></indexterm><indexterm id="I_indexterm19_tt404" class="endofrange" startref="idx-CHP-19-1555" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator design</secondary></indexterm></para><programlisting id="I_programlisting19_tt405" format="linespecific">
	#include &lt;float.h&gt;
	double *currval, maxval=-DBL_MAX;
	PyObject *it;
	it = PyArray_IterNew(ao);
	while (PyArray_ITER_NOTDONE(it)) {
	    currval = (double *)PyArray_ITER_DATA(it);
	    if (*currval &lt; maxval) maxval = *currval;
	    PyArray_ITER_NEXT(it);
	}
</programlisting><para>This code shows how relatively easy it is to construct a loop for a noncontiguous, <emphasis>N</emphasis>-dimensional array using the iterator structure. The simplicity of this code also illustrates the elegance of iterator abstraction. Notice how similar the code is to the simple iterator pseudocode shown at the beginning of the earlier section "Iterator Design." Consider also that this code works for arrays of arbitrary dimensions and arbitrary strides in each dimension, and you begin to appreciate the beauty of the multidimensional iterator.</para><para>The iterator-based code is fast for both contiguous and noncontiguous arrays. However, the fastest contiguous-array loop is still something like:</para><programlisting id="I_programlisting19_tt406" format="linespecific">
	double *currval, maxval=-MAX_DOUBLE;
	int size;
	currval = (double *)PyArray_DATA(ao);
	size = PyArray_SIZE(ao);
	while (size--) {
	     if (*currval &gt; maxval) maxval = *currval;
	     currval += 1;
	}
</programlisting><para>The real benefit of the <indexterm id="idx-CHP-19-1588" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy iterator is that it allows programmers to write contiguous-like code that is still fairly fast without worrying about whether their arrays are contiguous. It should be remembered that forcing a contiguous algorithm has performance costs as well <indexterm class="startofrange" id="idx-CHP-19-1589" significance="normal"><primary>iterators</primary><secondary>use in NumPy</secondary></indexterm>because noncontiguous data must be copied to another array for processing.</para><para>The speed difference between the <indexterm id="idx-CHP-19-1590" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy iterator solution and the fastest contiguous-case solution could be largely eliminated if a remaining problem with the current NumPy iterator interface could be fixed. The problem is that the <literal moreinfo="none">PyArray_ITER_NEXT</literal> macro checks each time through the loop whether the iterator can use the simplified contiguous approach. Ideally, this check should be made only once outside of the loop, and then a single approach to finding the next value should be used inside the loop. However, this kind of interface is a bit messy to implement in C. It would require two different macros similar to <literal moreinfo="none">ITER_NEXT</literal> and two different <literal moreinfo="none">while</literal> loops. As a result, nothing to this effect was implemented in NumPy at the time of the writing of this chapter. People wishing to get the small speed gain available for contiguous cases are assumed to be knowledgeable enough to write the simple loop themselves (bypassing the iterator entirely).</para></sect1><sect1 id="iterator_use" label="19.6"><title>Iterator Use</title><para>A good abstraction proves its worth when it makes coding simpler under diverse conditions, or when it ends up being useful in ways that were originally unintended. Both of these affirmations of value are definitely true of the NumPy iterator object. With only slight modifications, the original simple NumPy iterator has become a workhorse for implementing other NumPy features, such as iteration over all but one dimension and iteration over multiple arrays at the same time. In addition, when we had to quickly <indexterm class="startofrange" id="idx-CHP-19-1591" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator use</secondary></indexterm>add</para><para>some enhancements to the code for generating random numbers and for broadcast-based copying, the existence of the <indexterm id="idx-CHP-19-1592" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator use</secondary></indexterm>iterator and its extensions made implementation much easier.</para><sect2 id="iteration_over_all_but_one_dimension" label="19.6.1"><title>Iteration Over All But One Dimension</title><para>A common motif in <indexterm id="idx-CHP-19-1593" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy is to gain speed by concentrating optimizations on the loop over a single dimension where simple striding can be assumed. Then an iteration strategy that iterates over all but the last dimension is <indexterm id="idx-CHP-19-1594" significance="normal"><primary>iterators</primary><secondary>use in NumPy</secondary></indexterm>used. This was the approach introduced by <indexterm id="idx-CHP-19-1595" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy's predecessor, Numeric, to implement the math functionality.<indexterm id="idx-CHP-19-1596" significance="normal"><primary>iterators</primary><secondary>use in NumPy</secondary><tertiary>iteration over all but one dimension</tertiary></indexterm></para><para>In NumPy, a slight modification to the NumPy iterator makes it possible to use this basic strategy in any code. The modified iterator is returned from the constructor as follows:</para><programlisting id="I_programlisting19_tt407" format="linespecific">
	it = PyArray_IterAllButAxis(array, &amp;dim).
</programlisting><para>The <literal moreinfo="none">PyArray_IterAllButAxis</literal> function takes a NumPy array and the address of an integer representing the dimension to remove from the iteration. The integer is passed by reference (the <literal moreinfo="none">&amp;</literal> operator) because if the dimension is specified as −1, the function determines which dimension to remove from iteration and places the number of that dimension in the argument. When the input dimension is −1, the routine chooses the dimension with the smallest nonzero stride.</para><para>Another choice for the dimension to remove might have been the dimension with the largest number of elements. That choice would minimize the number of outer loop iterations and reserve the most elements for the presumably fast inner loop. The problem with that choice is that getting information in and out of memory is often the slowest part of an algorithm on general-purpose processors.</para><para>As a result, the choice made by NumPy is to make sure that the inner loop is proceeding with data that is as close together as possible. Such data is more likely to be accessed more quickly during the speed-critical inner loop.</para><para>The iterator is modified by:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Dividing the iteration size by the length of the dimension being removed.</para></listitem><listitem><para>Setting the number of elements in the selected dimension to 1 (so the array storing one less than the total number is set to 0): <literal moreinfo="none">dims_m1[i]=0</literal>.</para></listitem><listitem><para>Setting the backstrides entry for that dimension to 0 so that the continual rewrapping of the counter in the given dimension back to 0 will never alter the data pointer.</para></listitem><listitem><para>Resetting the contiguous flag to 0 because processing will not be contiguous in memory (each iteration has to skip an entire dimension of the array).</para></listitem></orderedlist><para>The altered iterator is returned by the function. It can now be used everywhere an iterator was previously used. Each time through the loop, the iterator will point to the first element of the selected dimension of the array.</para></sect2><sect2 id="multiple_iterations" label="19.6.2"><title>Multiple Iterations</title><para>Another common task in <indexterm id="idx-CHP-19-1597" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy is to iterate over several arrays in concert. For example, the implementation of array addition requires iterating over both arrays using a connected <indexterm id="idx-CHP-19-1598" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator use</secondary></indexterm>iterator so that the output array is the sum of each element of the first array multiplied by each element of the second array. This can be accomplished using a different iterator for each of the input elements and an iterator for the output array in the normal fashion.<indexterm id="idx-CHP-19-1599" significance="normal"><primary>iterators</primary><secondary>use in NumPy</secondary><tertiary>multiple iterations</tertiary></indexterm></para><para>Alternatively, <indexterm id="idx-CHP-19-1600" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy provides a multi-iterator object that can simplify dealing with several iterators at once. This multi-iterator object also handles the <indexterm id="idx-CHP-19-1601" significance="normal"><primary>broadcasting (in NumPy)</primary></indexterm>broadcasting functionality of NumPy automatically. <emphasis>Broadcasting</emphasis> is the name given to the feature in NumPy that allows arrays with different shapes to be <indexterm id="idx-CHP-19-1602" significance="normal"><primary>iterators</primary><secondary>use in NumPy</secondary></indexterm>used together in operations that are supposed to work element-by-element. For example, broadcasting allows a (4,1)-shaped array to be added to a (3)-shaped array resulting in a (4,3)-shaped array. Broadcasting also allows simultaneous iteration over a (4,1)-shaped array, a (3)-shaped array, and a (5,1,1)-shaped array to produce a broadcasted iteration covering the elements of a (5,4,3)-shaped array.</para><para>The rules of broadcasting are:</para><itemizedlist><listitem><para>Arrays with fewer dimensions are treated as occupying the last dimensions of an array that has the full number of dimensions, so that all arrays have the same number of dimensions. The new, initial dimensions are filled in with 1s.</para></listitem><listitem><para>The length of each dimension in the final broadcast shape is the greatest length of that dimension in any of the arrays.</para></listitem><listitem><para>For each dimension, all inputs must either have the same number of elements as the broadcast result or a 1 as the number of elements.</para></listitem><listitem><para>Arrays with a single element in a particular dimension act as if that element were virtually copied to all positions during the iteration. In effect, the element is "broadcast" to the additional positions.</para></listitem></itemizedlist><para>The key to the implementation of broadcasting consists of surprisingly simple modifications to the array iterators. With these alterations, standard iterator loops can be used to implement the resulting calculations in a straightforward way. The modifications needed are changes to the shape of the iterators (not the underlying array) and changes to the strides and backstrides. The shape stored in the iterator is changed to match the broadcast shape. The strides and backstrides for broadcast dimensions are changed to 0. With a stride of 0, the standard iterator does not actually move the data pointer to the element in memory as the index in that dimension proceeds. This creates the desired effect of broadcasting without actually copying the memory.</para><para>The following code illustrates usage of the multi-iterator object:</para><programlisting id="I_programlisting19_tt408" format="linespecific">
	PyObject *multi;
	PyObject *in1, *in2;
	double *i1p, *i2p, *op;
	/* get in1 and in2 (assumed to be arrays of NPY_DOUBLE) */
	/* first argument is the number of input arrays; the
	   next (variable number of) arguments are the
	   array objects */
	multi = PyArray_MultiNew(2, in1, in2);
	/* construct output array */
	out = PyArray_SimpleNew(PyArray_MultiIter_NDIM(multi),
	                        PyArray_MultiIter_DIMS(multi),
	                        NPY_DOUBLE);
	op = PyArray_DATA(out);
	while(PyArray_MultiIter_NOTDONE(multi)) {
	    /* get (pointers to) the current value in each array */
	    i1p = PyArray_MultiIter_DATA(multi, 0);
	    i2p = PyArray_MultiIter_DATA(multi, 1);
	    /* perform the operation for this element */
	    *op = *ip1 + *ip2
	    op += 1; /* Advance output array pointer */
	    /* Advance all the input <indexterm id="idx-CHP-19-1603" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator use</secondary></indexterm>iterators */
	    PyArray_MultiIter_NEXT(multi);
	}
</programlisting><para>The code is very similar to a standard iterator loop, except the multi-iterator handles adjustments of the input iterators to accomplish <indexterm id="idx-CHP-19-1604" significance="normal"><primary>broadcasting (in NumPy)</primary></indexterm>broadcasting, as well as incrementing all the other input iterators. This code handles the broadcasting automatically as part of the iterator processing, so that the addition of a (3,1)-shaped array to a (4)-shaped one will produce a (3,4)-shaped output array.</para></sect2><sect2 id="anecdotes" label="19.6.3"><title>Anecdotes</title><para>The <indexterm id="idx-CHP-19-1605" significance="normal"><primary>NumPy (Python)</primary></indexterm>NumPy iterator is <indexterm id="idx-CHP-19-1606" significance="normal"><primary>iterators</primary><secondary>use in NumPy</secondary></indexterm>used throughout the <indexterm id="idx-CHP-19-1607" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm>NumPy code base to simplify the construction of <emphasis>N</emphasis>-dimensional loops. Having the iterator available allowed me to code algorithms for more general (noncontiguous) arrays. Normally, the difficulty of thinking about how to handle the noncontiguous arrays would have convinced me to just force an array to be contiguous (by making a new copy if necessary) and then use an easy looping algorithm. The existence of the NumPy iterator allowed me to write much more general code that is still as readable, with a very minor cost in speed for arrays that are actually contiguous. This slight disadvantage is offset by the very great decrease in memory requirements for arrays that are noncontiguous. The improved productivity in writing such loops is sufficient to justify the existence of the NumPy iterator.<indexterm id="idx-CHP-19-1608" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator use</secondary><tertiary>anecdotes</tertiary></indexterm><indexterm id="idx-CHP-19-1609" significance="normal"><primary>iterators</primary><secondary>use in NumPy</secondary><tertiary>anecdotes</tertiary></indexterm></para><para>However, it is NumPy's encapsulation for broadcasting where the utility of the abstraction really shines. It shone particularly bright when the multi-iterator allowed me to enhance the random-number generators of NumPy to deal with arrays of parameters pertaining to the random number generators. The change took about two hours with only a few lines of code.</para><para>The <indexterm id="idx-CHP-19-1610" significance="normal"><primary>random-number generator facility of NumPy</primary></indexterm>random-number generator facility of NumPy was written by Robert Kern. He was not familiar with the C broadcasting API that had only been recently added. As a result, the original implementation required all parameters used to specify the random numbers to be scalar values (i.e., the value of 𝛂 for an exponential distribution).</para><para>This was an unfortunate restriction. It is quite common to need an array of random numbers drawn from a particular distribution where different parts of the array should have different parameters. For instance, a programmer might need a matrix of random numbers drawn from the exponential distribution where each row of numbers should be sampled using a different value of 𝛂. To allow arrays of parameters, the bulk of the change was to use the multi-iterator loop (with its built-in broadcasting facility) and fill in the output array with the random samples.</para><para>Another opportunity to use the iterator surfaced when the code that copied data from one array to another needed to be altered to copy in a manner consistent with NumPy's definition of broadcasting. Previously, an array was copied over to another using the standard iterator. The only shape checking done was to ensure that the destination array got filled only once. If the destination ran out of elements, its iterator started over again. Eventually, it became clear that this was not the desired copying behavior because it basically implemented a different kind of "broadcasting" (as long as the total number of elements of one array was a multiple of another, any array could be copied into any other array regardless of shape). The kind of data replication that resulted from this copy command was inconsistent with the definition of broadcasting used in other places in NumPy. It became clear that it needed to be changed. Again, the multi-iterators and its built-in concept of iterator broadcasting was a useful abstraction because it allowed me to write the code to accomplish the copy (including size checking) very quickly with only very few lines of actual new code.</para></sect2></sect1><sect1 id="conclusion-id008" label="19.7"><title>Conclusion</title><para>The iterator object in NumPy is an example of a coding abstraction that simplifies programming. Since its construction in 2005, it has been extremely useful in writing <emphasis>N</emphasis>-dimensional algorithms that work on general NumPy arrays regardless of whether or not they are contiguous in memory or actually represent noncontiguous <emphasis>N</emphasis>-dimensional slices of some other contiguous chunk of memory. In addition, simple modifications to the iterator have made it much simpler to implement some of the more difficult ideas of NumPy, such as optimizing loops (looping over all but the least-striding dimension) and broadcasting.</para><para>Iterators are a beautiful abstraction because they save valuable programmer attention in the implementation of a complicated algorithm. This has been true in NumPy as well. The NumPy implementation of a standard array iterator has made general-purpose code much more pleasant to write and debug, and it has allowed the encapsulation and exposure of some of the important (but hard-to-write) internal features of NumPy, such as broadcasting.<indexterm id="I_indexterm19_tt409" class="endofrange" startref="idx-CHP-19-1519" significance="normal"><primary>NumPy (Python)</primary></indexterm><indexterm id="I_indexterm19_tt410" class="endofrange" startref="idx-CHP-19-1589" significance="normal"><primary>iterators</primary><secondary>use in NumPy</secondary></indexterm><indexterm id="I_indexterm19_tt411" class="endofrange" startref="idx-CHP-19-1591" significance="normal"><primary>NumPy (Python)</primary><secondary>iterator use</secondary></indexterm><indexterm id="I_indexterm19_tt412" class="endofrange" startref="idx-CHP-19-1522" significance="normal"><primary>Python</primary><secondary>NumPy</secondary></indexterm></para></sect1></chapter><chapter id="a_highly_reliable_enterprise_system_for_nasas_mars_rover_missio" label="20" role=""><title>A Highly Reliable Enterprise System for NASA's Mars Rover Mission</title><para><emphasis>Ronald Mak</emphasis><indexterm id="idx-CHP-20-1611" significance="normal"><primary>Mak</primary></indexterm></para><para><emphasis>How often do you hear that beauty is in the eye of the beholder?</emphasis> In our case, the beholder was NASA's Mars Exploration Rover mission, and it had very strict requirements that the mission's software systems be functional, reliable, and robust. Oh, and the software also had to be completed on schedule—Mars would not accept any excuses for schedule slips. When NASA talks about meeting "launch windows," it means it in more ways than one!</para><para>This chapter describes the design and development of Collaborative Information Portal, or <indexterm id="idx-CHP-20-1612" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP, which is a large enterprise information system developed at NASA and used by mission managers, engineers, and scientists worldwide.</para><para>Martians have zero tolerance for ugly software. For CIP, the notion of beauty is not so much about elegant algorithms or programs that you can stand back and admire. Rather, beauty is embodied in a complex software structure built by master builders who knew just where to pound in the nails. Large applications can be beautiful in ways that small programs often are not. This is due both to increased necessity and to greater opportunity—large applications often have to do things that small programs don't need to. We'll take a look at CIP's overall Java-based service-oriented architecture, and then, by focusing on one of its services as a case study, examine some code snippets and study some of the nails that enable the system to meet the functionality, reliability, and robustness requirements.</para><para>As you can <indexterm id="idx-CHP-20-1613" significance="normal"><primary>middleware</primary><secondary>in multitiered service-oriented architecture</secondary></indexterm>imagine, software used on NASA space missions must be highly reliable. Missions are expensive, and years of planning and many millions of dollars cannot be jeopardized by faulty programs. The most difficult part of the software work, of course, is to debug and patch software used onboard a spacecraft that is millions of miles from Earth. But even ground-based systems must be reliable; nobody wants a software bug to interrupt mission operations or cause the loss of valuable data.</para><para>There is a bit of irony in writing about beauty for this type of software. In a <indexterm id="idx-CHP-20-1614" significance="normal"><primary>multitiered service-oriented architecture</primary></indexterm>multitiered service-oriented architecture, the services are implemented in a middleware tier that resides on a server. (We developed shared reusable components in the middleware, which greatly reduced development time.) The middleware decouples the client applications from the backend data sources; in other words, an application doesn't have to know where and how the data it needs is stored. Client applications <indexterm id="idx-CHP-20-1615" significance="normal"><primary>Mak</primary></indexterm>make remote service requests to the middleware and then receive responses that contain the requested data. When all the middleware services are doing their jobs well, the end users of the enterprise system should not even know that their client applications are making remote service requests. When the middleware is operating smoothly, users should believe that they are directly accessing the data sources and that all the data processing is happening locally on their workstations or laptops. Therefore, the more successful the middleware is, the less visible it becomes. Beautiful middleware should be invisible!</para><sect1 id="the_mission_and_the_collaborative_information_portal" label="20.1"><title>The Mission and the Collaborative Information Portal</title><para>The primary goal of the <indexterm id="idx-CHP-20-1616" significance="normal"><primary>Mars Exploration Rover (MER) mission and</primary></indexterm>Mars Exploration Rover, or MER, mission is to discover whether liquid water once flowed on the Martian surface. In June and July 2003, NASA launched two identical rovers to Mars to operate as robotic geologists. In January 2004, after separate seven-month journeys, they landed on opposite sides of the planet.</para><para>Each rover is solar-powered and can drive itself over the surface. Each one has scientific instruments such as spectrometers mounted at the end of an articulated arm. The arm has a drill and a microscopic imager to examine what's beneath the surface of rocks. Each rover has several cameras and antennas to send data and images back to earth (see <xref linkend="a_mars_rover_image_courtesy_of_jpl"/>).</para><para>Unmanned NASA missions are a combination of hardware and software. Different software packages onboard each Mars rover control its operation autonomously and in response to remote commands issued from mission control at NASA's Jet Propulsion Laboratory (JPL) near Pasadena, California. Earth-based software packages at mission control enable the mission managers, engineers, and scientists to download and analyze the information sent by the rovers, to plan and develop new command sequences to send to the rovers, and to collaborate with each other.</para><para>At the NASA Ames Research Center near Mountain View, California, we designed and developed the Collaborative Information Portal (<indexterm id="idx-CHP-20-1617" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP) for the MER mission. The project team consisted of 10 software engineers and computer scientists. Another nine team members included project managers and the support engineers who took care of QA, software system build, hardware configuration, and bug-tracking tasks.</para><figure id="a_mars_rover_image_courtesy_of_jpl" label="20-1" float="0"><title>A Mars rover (image courtesy of JPL)</title><mediaobject id="I_mediaobject20_tt413"><imageobject role="print"><imagedata fileref="figs/print/beauty_2001.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2001.png" format="PNG"/></imageobject></mediaobject></figure></sect1><sect1 id="mission_needs" label="20.2"><title>Mission Needs</title><para>We designed <indexterm id="idx-CHP-20-1618" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP to meet three primary needs of the MER mission. By satisfying these needs, CIP provides vital "situational awareness" among mission personnel:<indexterm id="idx-CHP-20-1619" significance="normal"><primary>Mars Exploration Rover (MER) mission and</primary><secondary>mission needs</secondary></indexterm></para><variablelist><varlistentry><term><emphasis>Time management</emphasis></term><listitem><para>Keeping everybody synchronized during any large complex mission is critical for success, and MER presented some special time management challenges. Because mission personnel work at locations around the world, CIP displays time in various terrestrial time zones. Because the rovers landed on opposite sides of Mars, there are also two Martian time zones.<indexterm id="idx-CHP-20-1620" significance="normal"><primary>time management (MER mission)</primary></indexterm></para><para>Initially, the mission ran on Mars time, which meant that all scheduled meetings and events (such as data downloads from Mars) were given in the time of one Mars time zone or the other, depending on to which rover the meeting or event pertained. A Martian day is nearly 40 minutes longer than an Earth day, and so relative to Earth time, mission personnel shifted later by that amount of time each day as seen by their families and colleagues who remained on Earth time. This made CIP's time management functions even more important.</para></listitem></varlistentry><varlistentry><term><emphasis>Personnel management</emphasis></term><listitem><para>With two rover teams (one per rover) and some people moving between the teams, keeping track of everybody is another critical function. <indexterm id="idx-CHP-20-1621" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP manages a personnel roster and displays schedules (as Gantt charts) that show who is working where, when, and in what role.<indexterm id="idx-CHP-20-1622" significance="normal"><primary>personnel management (MER mission)</primary></indexterm></para><para><indexterm class="startofrange" id="idx-CHP-20-1623" significance="normal"><primary>beautiful code</primary><secondary>CIP system architecture</secondary></indexterm>CIP also enables some collaboration among mission personnel. They can send out broadcast messages, share analyses of data and image, upload reports, and annotate each other's reports.</para></listitem></varlistentry><varlistentry><term><emphasis>Data management</emphasis></term><listitem><para>Getting data and images from the far reaches of the universe is the key to every NASA planetary and deep space mission, and here, too, CIP plays a major role. An array of terrestrial antennas receive the data and images sent by the Mars rovers, and once on Earth, they are transmitted to JPL to be processed and stored in the mission file servers.<indexterm id="idx-CHP-20-1624" significance="normal"><primary>data management (MER Mission)</primary></indexterm></para><para>Once the mission managers release the processed data and image files, CIP generates metadata that categorizes the files by various criteria, such as which rover instrument generated the data, which camera took the image, at which setting, using what configuration, when and where, etc. CIP users can then search for the data and images by these criteria and download them from the mission file servers over the Internet onto their personal laptops and workstations.</para><para>CIP also implements data security. For example, depending on a user's role (and whether she is a U.S. citizen), certain data and images can be off-limits.</para></listitem></varlistentry></variablelist></sect1><sect1 id="system_architecture" label="20.3"><title>System Architecture</title><para>Code beauty for an <indexterm id="idx-CHP-20-1625" significance="normal"><primary>enterprise system architecture</primary></indexterm>enterprise system is derived partly from architecture, the way the code is put together. Architecture is more than aesthetics. In a large application, architecture determines how the software components interoperate and contributes to overall system reliability.<indexterm id="idx-CHP-20-1626" significance="normal"><primary>robustness</primary><secondary>system architecture</secondary></indexterm></para><para>We implemented CIP using a <indexterm id="idx-CHP-20-1627" significance="normal"><primary>SOA (service-oriented architecture)</primary><secondary>three-tiered</secondary></indexterm>three-tiered service-oriented architecture (SOA). We adhered to industry standards and best practices, and where practicable, we used <indexterm id="idx-CHP-20-1628" significance="normal"><primary>commercial off-the-shelf (COTS) software</primary></indexterm>commercial off-the-shelf (COTS) software. We programmed mostly in Java and used the Java 2 Enterprise Edition (<indexterm id="idx-CHP-20-1629" significance="normal"><primary>J2EE (Java 2 Enterprise Edition)</primary></indexterm>J2EE) standards (see <xref linkend="cips_three-tiered_service-oriented_architecture"/>).</para><para>The <indexterm id="idx-CHP-20-1630" significance="normal"><primary>Java</primary><secondary>client and data tier of CIP</secondary></indexterm>client tier consists mostly of standalone GUI-based Java applications implemented with Swing components and a few web-based applications. A J2EE-compliant application server runs in the middleware and hosts all the services that respond to requests from the client applications. We implemented the services using <indexterm id="idx-CHP-20-1631" significance="normal"><primary>Enterprise JavaBeans (EJBs)</primary></indexterm>Enterprise JavaBeans (<indexterm id="idx-CHP-20-1632" significance="normal"><primary>EJBs (Enterprise JavaBeans)</primary></indexterm>EJBs). The data tier consists of the data sources and data utility programs. Also written in Java, these utilities monitor the file server for the processed data and image files. The utilities generate metadata for the files as soon as they're released by the mission managers.</para><figure id="cips_three-tiered_service-oriented_architecture" label="20-2" float="0"><title>CIP's three-tiered service-oriented architecture</title><mediaobject id="I_mediaobject20_tt414"><imageobject role="print"><imagedata fileref="figs/print/beauty_2002.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2002.png" format="PNG"/></imageobject></mediaobject></figure><para>Using an <indexterm id="idx-CHP-20-1633" significance="normal"><primary>J2EE (Java 2 Enterprise Edition)</primary><secondary>SOA based on</secondary></indexterm>SOA based on J2EE gave us the option to use these well-defined beans (and others) wherever appropriate in the design of a large enterprise application. <indexterm id="idx-CHP-20-1634" significance="normal"><primary>stateless session beans</primary></indexterm>Stateless session beans handle service requests without remembering any state from one request to the next. On the other hand, <indexterm id="idx-CHP-20-1635" significance="normal"><primary>stateful session beans</primary></indexterm>stateful session beans maintain state information for clients and typically manage persisted information that the beans read from and write to a data store. Having multiple options in any design situation is important when developing large complex applications.<indexterm id="idx-CHP-20-1636" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm><indexterm id="idx-CHP-20-1637" significance="normal"><primary>robustness</primary><secondary>system architecture</secondary></indexterm></para><para>In the middleware, we implemented a stateless session bean as a service provider for each service. This was the facade from which we generated a web service that the client applications use to <indexterm id="idx-CHP-20-1638" significance="normal"><primary>Mak</primary></indexterm>make service requests and get back responses. Each service may also access one or more stateful session beans that are business objects supplying any necessary logic that must maintain state between service requests, such as where to read the next block of information from a database in response to a data request. In effect, the stateless beans are often the service dispatchers for the stateful beans that do the actual work.</para><para>There is much beauty in this type of architecture! The architecture embodies some key design <indexterm id="idx-CHP-20-1639" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>principles:</para><variablelist><varlistentry><term><emphasis>Standards-based</emphasis></term><listitem><para>Especially at a research institution (like the NASA Ames Research Center, where we designed and developed <indexterm id="idx-CHP-20-1640" significance="normal"><primary>beautiful code</primary><secondary>CIP system architecture</secondary></indexterm>CIP), there is always a strong temptation to invent something new, even if the result is reinventing the wheel. The MER mission afforded the CIP development team neither the time nor the resources, and our goal was to develop production-quality code for the mission, not necessarily to do research.<indexterm id="idx-CHP-20-1641" significance="normal"><primary>standards-based applications</primary></indexterm></para><para><emphasis>In any large application, the key to success is integration, not coding</emphasis>. The beauty behind adhering to industry standards and best practices is that we did less coding by using COTS components, and because of common interfaces, these components were able to work well with each other. This enabled us to <indexterm id="idx-CHP-20-1642" significance="normal"><primary>Mak</primary></indexterm>make guarantees to the mission managers that we would deliver functional and reliable code on time.<indexterm id="idx-CHP-20-1643" significance="normal"><primary>integration as key to success in large applications</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Loose coupling</emphasis></term><listitem><para>We loosely coupled the client applications and the middleware <indexterm id="idx-CHP-20-1644" significance="normal"><primary>middleware</primary><secondary>services loosely coupled with client applications</secondary></indexterm>services. This meant that once the application programmer and the service programmer agreed on an interface <indexterm id="idx-CHP-20-1645" significance="normal"><primary>web services</primary><secondary>communication between client applications and middleware services</secondary></indexterm>between the two, they could develop their respective code in parallel. Any changes on one side didn't affect the other as long as the interface remained stable. Loose coupling was another major factor that allowed us to complete a large multitiered SOA application on time.<indexterm id="idx-CHP-20-1646" significance="normal"><primary>loose coupling of client applications and middleware services</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Language independence</emphasis></term><listitem><para>The client applications and the middleware services used web services to communicate with each other. The web services protocol is an industry standard that is language independent. Most of the CIP client applications were written in Java, but the middleware also served some C++ and C# applications. Once we got a service to work with a Java client, it was relatively simple to get it to work with another client written in any language that supported web services. This greatly expanded the usefulness and usability of CIP with little extra cost in time or resources.<indexterm id="idx-CHP-20-1647" significance="normal"><primary>language independence in CIP</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Modularity</emphasis></term><listitem><para>The importance of <indexterm id="idx-CHP-20-1648" significance="normal"><primary>modularity in CIP</primary></indexterm>modularity increases exponentially with the size of the application. In CIP, each service is a self-contained middleware component that is independent of the other services. If one service needs to work with another service, it makes a service request of the other service just as if it were a client application. This allowed us to create the services separately and added another dimension of parallelism in our development. Modular services are beautiful artifacts that are often found in large, successful SOA applications.</para><para>In the client tier, the application programs often compounded the services, either combining the results of multiple services or using the results of one service to pass in a request to another service.</para></listitem></varlistentry><varlistentry><term><emphasis>Scalability</emphasis></term><listitem><para><indexterm id="idx-CHP-20-1649" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP usage levels spike whenever mission control releases processed data and image files, especially after an interesting discovery by one of the rovers. We had to ensure that the <indexterm id="idx-CHP-20-1650" significance="normal"><primary>beautiful code</primary><secondary>CIP system architecture</secondary></indexterm>CIP middleware can handle such spikes, particularly when the users are anxious to download and view the latest files. A slowdown or, worse, a crash, at such times would be highly intolerable and highly visible.<indexterm id="idx-CHP-20-1651" significance="normal"><primary>J2EE (Java 2 Enterprise Edition)</primary><secondary>scalability</secondary></indexterm></para><para>One of the beauties of the J2EE infrastructure is how it handles scalability. The application server maintains bean pools, and based on demand, it can automatically create more instances of our stateless session bean service providers. This is a significant "free" J2EE feature that the middleware service developers were happy to accept.</para></listitem></varlistentry><varlistentry><term><emphasis>Reliability</emphasis></term><listitem><para>As a standard that had undergone much vetting by industry, the J2EE infrastructure proved to be extremely reliable. We avoided pushing the envelope of what it was designed to do. So after two years of operation, <indexterm id="idx-CHP-20-1652" significance="normal"><primary>scalability</primary><secondary>CIP</secondary></indexterm>CIP achieved an uptime record of over 99.9 percent.<indexterm id="idx-CHP-20-1653" significance="normal"><primary>reliability of CIP</primary></indexterm></para><para>We went beyond what J2EE intrinsically provided for <indexterm id="idx-CHP-20-1654" significance="normal"><primary>J2EE (Java 2 Enterprise Edition)</primary><secondary>reliability</secondary></indexterm>reliability. As you'll see in the following case study, we pounded a few extra nails into our services to further increase their reliability.</para></listitem></varlistentry></variablelist></sect1><sect1 id="case_study_the_streamer_service" label="20.4"><title>Case Study: The Streamer Service</title><para>You've seen some of the beauty of CIP at the architectural level. It's time to focus on one of its middleware services—the <indexterm class="startofrange" id="idx-CHP-20-1655" significance="normal"><primary>robustness</primary><secondary>streamer service case study</secondary></indexterm>streamer service—as a case study, and examine some of the nails that allowed us to meet the mission's strict functional, reliability, and robustness requirements. You'll see that the nails were not particularly fancy; the beauty was in knowing just where to pound them in.<indexterm class="startofrange" id="idx-CHP-20-1656" significance="normal"><primary>streamer service (CIP)</primary></indexterm></para><sect2 id="functionality" label="20.4.1"><title>Functionality</title><para>One of the MER mission's data management needs is to allow users to download data and image files from the mission file servers located at JPL to their personal workstations and laptops. As described earlier, CIP data-tier utilities generate metadata that allow users to find the files they want based on various search criteria. Users also need to upload files that contain their analysis reports to the servers.<indexterm id="idx-CHP-20-1657" significance="normal"><primary>robustness</primary><secondary>streamer service case study</secondary><tertiary>functionality</tertiary></indexterm><indexterm id="idx-CHP-20-1658" significance="normal"><primary>streamer service (CIP)</primary><secondary>functionality</secondary></indexterm></para><para>CIP's streamer service performs file downloading and uploading. We gave the service that name because it streams the file data securely across the Internet between the mission file servers at JPL and users' local computers. It uses the web services protocol, so client applications can be written in any language that supports the protocol, and these applications are free to devise whatever GUI they deem suitable.<indexterm id="I_indexterm20_tt415" class="endofrange" startref="idx-CHP-20-1623" significance="normal"><primary>beautiful code</primary><secondary>CIP system architecture</secondary></indexterm></para></sect2><sect2 id="service_architecture" label="20.4.2"><title>Service Architecture</title><para>Like each of the other middleware services, the <indexterm id="idx-CHP-20-1659" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamer service <indexterm id="idx-CHP-20-1660" significance="normal"><primary>web services</primary><secondary>use by CIP streamer service for client requests and responses</secondary></indexterm>uses web services to receive client requests and to return responses. Each request is first fielded by the <indexterm id="idx-CHP-20-1661" significance="normal"><primary>robustness</primary><secondary>streamer service case study</secondary></indexterm>streamer service provider, which is implemented by a stateless session bean. The service provider creates a <indexterm id="idx-CHP-20-1662" significance="normal"><primary>file readers and file writers (CIP streamer service)</primary></indexterm>file reader, implemented by a stateful session bean, to do the actual work of downloading the requested file contents to the client. Conversely, the service provider creates a file writer, also implemented by a stateful session bean, to upload file contents (see <xref linkend="the_streamer_service_architecture"/>).<indexterm id="idx-CHP-20-1663" significance="normal"><primary>streamer service (CIP)</primary><secondary>service architecture</secondary></indexterm></para><figure id="the_streamer_service_architecture" label="20-3" float="0"><title>The streamer service architecture</title><mediaobject id="I_mediaobject20_tt416"><imageobject role="print"><imagedata fileref="figs/print/beauty_2003.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2003.png" format="PNG"/></imageobject></mediaobject></figure><para>At any given moment, multiple users can be downloading or uploading files, and any single user can also have several download or upload operations going at once. So, there can be numerous file reader and file writer beans active in the middleware. A single stateless Streamer Service Provider bean handles all the requests, unless the load becomes heavy, at which time the application server can create more provider beans.<indexterm id="idx-CHP-20-1664" significance="normal"><primary>robustness</primary><secondary>streamer service case study</secondary><tertiary>service architecture</tertiary></indexterm></para><para>Why does each file reader and file writer have to be a <emphasis>stateful</emphasis> session bean? Unless the file is small, the streamer service transfers the file contents one block at a time in response to "Read Data Block" or "Write Data Block" requests from the client. (The download block size is configurable on the middleware server. The client application chooses the upload  block size.) From one request to the next, the stateful bean keeps track of the open source or destination file on the mission file servers and the position within the file of the next block to be read or written.</para><para>This is a very simple architecture, but it very effectively handles multiple downloads simultaneously from multiple users. <xref linkend="how_the_two-layer_service_handles_a_file_read"/> shows the sequence of events for downloading a file from the mission file servers to a user's local machine.</para><figure id="how_the_two-layer_service_handles_a_file_read" label="20-4" float="0"><title>How the two-layer service handles a file read</title><mediaobject id="I_mediaobject20_tt417"><imageobject role="print"><imagedata fileref="figs/print/beauty_2004.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2004.png" format="PNG"/></imageobject></mediaobject></figure><para>Note that the <indexterm id="idx-CHP-20-1665" significance="normal"><primary>streamer service (CIP)</primary></indexterm>Streamer Service Provider bean does not maintain any state between service requests. It functions as a rapid service dispatcher that parcels work out to the stateful File Reader beans. Because it doesn't need to track requests or maintain state, it can handle requests intermingled from several client applications. Each File Reader bean maintains state information (where to get the next block of data) for a single client application as the application <indexterm id="idx-CHP-20-1666" significance="normal"><primary>Mak</primary></indexterm>makes multiple "Read Data Block" requests to download a complete file. This architecture enables the <indexterm id="idx-CHP-20-1667" significance="normal"><primary>robustness</primary><secondary>streamer service case study</secondary></indexterm>streamer service to download multiple files to multiple clients simultaneously while providing acceptable throughput for all.</para><para>The sequence of events for a file upload from a user's local machine to the mission file servers is just as straightforward. It's shown in <xref linkend="how_the_two-layer_service_handles_a_file_write"/>.</para><figure id="how_the_two-layer_service_handles_a_file_write" label="20-5" float="0"><title>How the two-layer service handles a file write</title><mediaobject id="I_mediaobject20_tt418"><imageobject role="print"><imagedata fileref="figs/print/beauty_2005.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2005.png" format="PNG"/></imageobject></mediaobject></figure><para>These tables don't show it, but besides a file token, each client request also includes a user token. A client application first obtains a user token when it <indexterm id="idx-CHP-20-1668" significance="normal"><primary>Mak</primary></indexterm>makes a successful login request (with a user name and password) to the middleware's user management service, thus authenticating the user. A user token contains information that identifies a particular user session, including the user's role. It enables the <indexterm id="idx-CHP-20-1669" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamer service to verify that a request is coming from a legitimate user. It checks the user's role to ensure that she has the right to download a particular file. For example, the MER mission disallowed users from foreign (non-U.S.) countries from accessing certain files, and <indexterm id="idx-CHP-20-1670" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP respected all such security restrictions.</para></sect2></sect1><sect1 id="reliability" label="20.5"><title>Reliability</title><para>Reliable code continues to perform well without problems. It rarely crashes, if ever. As you can imagine, code that is on board the Mars rovers must be extremely reliable because making on-site maintenance calls is somewhat difficult. But the MER mission wanted earthbound software used by mission control to be reliable, too. Once the mission was underway, no one wanted software problems to disrupt operations.<indexterm id="idx-CHP-20-1671" significance="normal"><primary>robustness</primary><secondary>streamer service case study</secondary><tertiary>reliability</tertiary></indexterm><indexterm class="startofrange" id="idx-CHP-20-1672" significance="normal"><primary>streamer service (CIP)</primary><secondary>reliability</secondary></indexterm></para><para>As noted earlier, the CIP project took several measures to ensure the intrinsic reliability of the system:</para><itemizedlist><listitem><para>Adhering to industry standards and best practices, including J2EE<indexterm id="I_indexterm20_tt419" class="endofrange" startref="idx-CHP-20-1655" significance="normal"><primary>robustness</primary><secondary>streamer service case study</secondary></indexterm></para></listitem><listitem><para>Using proven COTS software wherever practicable, including a commercial application server from an established middleware vendor</para></listitem><listitem><para>Using a service-oriented architecture with modular services</para></listitem><listitem><para>Implementing simple, straightforward middleware services</para></listitem></itemizedlist><para>We further enhanced <indexterm id="idx-CHP-20-1673" significance="normal"><primary>streamer service (CIP)</primary><secondary>reliability</secondary></indexterm>reliability with extra nails: service <indexterm id="idx-CHP-20-1674" significance="normal"><primary>streamer service (CIP)</primary><secondary>reliability</secondary><tertiary>logging</tertiary></indexterm>logging and monitoring. While these features can be useful for debugging even small programs, they become essential for keeping track of the runtime behavior of large applications.</para><sect2 id="logging" label="20.5.1"><title>Logging</title><para>During development, we used the open source <indexterm id="idx-CHP-20-1675" significance="normal"><primary>Apache Log4J Java package</primary></indexterm>Apache Log4J Java package to log nearly everything that occurred in the middleware services. It was certainly useful for debugging during development. Logging enabled us to write code that was more reliable. Whenever there was a bug, the logs told us what was going on just prior to the problem, and so we were better able to fix the bug.<indexterm id="idx-CHP-20-1676" significance="normal"><primary>streamer service (CIP)</primary><secondary>reliability</secondary><tertiary>logging</tertiary></indexterm></para><para>We originally intended to reduce the logging only to serious messages before <indexterm id="idx-CHP-20-1677" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP went into operation. But we ended up leaving most of the logging on since it had a negligible impact on overall performance. Then we discovered that the logs gave us much useful information not only about what was going on with each service, but also <emphasis>how</emphasis> client applications were using the services. By analyzing the logs (which we called "log mining"), we were able to tune the services for better performance based on empirical data (see "Dynamic Reconfiguration," later in this chapter).</para><para>Here are some code snippets from the <indexterm id="idx-CHP-20-1678" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamer service provider bean that show how we did logging for file downloading. The <literal moreinfo="none">getDataFile( )</literal> method processes each "Get Data File" request (via web services) from the client applications. The method immediately logs the request (lines 15–17), including the user ID of the requester and the filepath of the desired source file:</para><programlisting id="I_programlisting20_tt420" format="linespecific">
1 public class <userinput moreinfo="none">StreamerServiceBean</userinput> implements SessionBean
2 {
3     <userinput moreinfo="none">static {
4         Globals.loadResources("Streamer");
5      };</userinput>
6
7      private static Hashtable readerTable = new Hashtable( );
8      private static Hashtable writerTable = new Hashtable( );
9
10     private static BeanCacheStats cacheStats = Globals.queryStats;
11
12     public FileToken <userinput moreinfo="none">getDataFile</userinput>(AccessToken accessToken, String filePath)
13         throws MiddlewareException
14     {
15         <userinput moreinfo="none">Globals.streamerLogger.info(accessToken.userId( ) +
16                                     ": Streamer.getDataFile("
17                                     + filePath + ")");</userinput>
18         long startTime = System.currentTimeMillis( );
19
20         UserSessionObject.validateToken(accessToken);
21         <userinput moreinfo="none">FileToken fileToken = doFileDownload(accessToken, filePath);
22         cacheStats.incrementTotalServerResponseTime(startTime);</userinput>
23         return fileToken;
24     }
25
</programlisting><para>The <literal moreinfo="none">doFileDownload( )</literal> method creates a new file token (line 30) and file reader bean (line 41), and then calls the reader bean's <literal moreinfo="none">getDataFile( )</literal> method (line 42). The <literal moreinfo="none">cacheStats</literal> field deals with runtime monitoring, which is described later:</para><programlisting id="I_programlisting20_tt421" format="linespecific">
26     private static FileToken <userinput moreinfo="none">doFileDownload</userinput>(AccessToken accessToken,
27                                             String filePath)
28         throws MiddlewareException
29     {
30         <userinput moreinfo="none">FileToken fileToken = new FileToken(accessToken, filePath);</userinput>
31         String    key       = fileToken.getKey( );
32
33         FileReaderLocal reader = null;
34         synchronized (readerTable) {
35             reader = (FileReaderLocal) readerTable.get(key);
36         }
37
38         // Create a file reader bean to start the download.
39         if (reader == null) {
40             try {
41                 <userinput moreinfo="none">reader = registerNewReader(key);
42                 reader.getDataFile(filePath);</userinput>
43
44                 return fileToken;
45             }
46             catch(Exception ex) {
47                 Globals.<indexterm id="idx-CHP-20-1679" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamerLogger.warn("Streamer.doFileDownload("
48                                             + filePath + "): " +
49                                             ex.getMessage( ));
50                 <userinput moreinfo="none">cacheStats.incrementFileErrorCount( );</userinput>
51                 removeReader(key, reader);
52                 throw new MiddlewareException(ex);
53             }
54         }
55         else {
56             throw new MiddlewareException("File already being downloaded: " +
57                                           filePath);
58         }
59     }
60
</programlisting><para>The <literal moreinfo="none">readDataBlock( )</literal> method processes each "Read Data Block" request from the client applications. It looks up the correct file reader bean (line 71) and calls the reader bean's <literal moreinfo="none">readDataBlock( )</literal> method (line 79). At the end of the source file, it removes the file reader bean (line 91):</para><programlisting id="I_programlisting20_tt422" format="linespecific">
61     public DataBlock <userinput moreinfo="none">readDataBlock</userinput>(AccessToken accessToken, FileToken fileToken)
62         throws MiddlewareException
63     {
64         long startTime = System.currentTimeMillis( );
65         UserSessionObject.validateToken(accessToken);
66
67         String key = fileToken.getKey( );
68
69         FileReaderLocal reader = null;
70         synchronized (readerTable) {
71             <userinput moreinfo="none">reader = (FileReaderLocal) readerTable.get(key);</userinput>
72         }
73
74         // Use the reader bean to download the next data block.
75         if (reader != null) {
76             DataBlock block = null;
77
78             try {
79                 <userinput moreinfo="none">block = reader.readDataBlock( );</userinput>
80             }
81             catch(MiddlewareException ex) {
82                 Globals.<indexterm id="idx-CHP-20-1680" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamerLogger.error("Streamer.readDataBlock("
83                                              + key + ")", ex);
84                 <userinput moreinfo="none">cacheStats.incrementFileErrorCount( );</userinput>
85                 removeReader(key, reader);
86                 throw ex;
87             }
88
89             // End of file?
90             if (block == null) {
91                 <userinput moreinfo="none">removeReader(key, reader);</userinput>
92             }
93
94             <userinput moreinfo="none">cacheStats.incrementTotalServerResponseTime(startTime);</userinput>
95             return block;
96         }
97         else {
98             throw new MiddlewareException(
99                 "Download source file not opened: " +
100                fileToken.getFilePath( ));
101        }
102    }
103
</programlisting><para>The <literal moreinfo="none">registerNewReader( )</literal> and <literal moreinfo="none">removeReader( )</literal> methods create and destroy the stateful file reader beans, respectively:</para><programlisting id="I_programlisting20_tt423" format="linespecific">
104    private static FileReaderLocal <userinput moreinfo="none">registerNewReader</userinput>(String key)
105        throws Exception
106    {
107        Context context = MiddlewareUtility.getInitialContext( );
108        Object queryRef = context.lookup("FileReaderLocal");
109
110        // Create the reader service bean and register it.
111        FileReaderLocalHome home = (FileReaderLocalHome)
112            PortableRemoteObject.narrow(queryRef, FileReaderLocalHome.class);
113        FileReaderLocal reader = home.create( );
114
115        synchronized (readerTable) {
116            readerTable.put(key, reader);
117        }
118
119        return reader;
120    }
121
122    private static void <userinput moreinfo="none">removeReader</userinput>(String key, FileReaderLocal reader)
123    {
124        synchronized (readerTable) {
125            readerTable.remove(key);
126        }
127
128        if (reader != null) {
129            try {
130                reader.remove( );
131            }
132            catch(javax.ejb.NoSuchObjectLocalException ex) {
133                // ignore
134            }
135            catch(Exception ex) {
136                Globals.<indexterm id="idx-CHP-20-1681" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamerLogger.error("Streamer.removeReader("
137                                             + key + ")", ex);
138                cacheStats.incrementFileErrorCount( );
139            }
140        }
141    }
142 }
</programlisting><para>Now, here are code snippets from the file reader bean. The <literal moreinfo="none">cacheStats</literal> and <literal moreinfo="none">fileStats</literal> fields are for runtime monitoring, as described later. The <literal moreinfo="none">getDataFile( )</literal> method logs the start of the file download (lines 160–161):</para><programlisting id="I_programlisting20_tt424" format="linespecific">
143 public class <userinput moreinfo="none">FileReaderBean</userinput> implements SessionBean
144 {
145     private static final String FILE = "file";
146
147     private transient static BeanCacheStats cacheStats = Globals.queryStats;
148     private transient static FileStats       fileStats = Globals.fileStats;
149
150     private transient int                  totalSize;
151     private transient String               type;
152     private transient String               name;
153     private transient FileInputStream      fileInputStream;
154     private transient BufferedInputStream  inputStream;
155     private transient boolean              sawEnd;
156
157     public void <userinput moreinfo="none">getDataFile</userinput>(String filePath)
158         throws MiddlewareException
159     {
160         <userinput moreinfo="none">Globals.streamerLogger.debug("Begin download of file '"
161                                      + filePath + "'");</userinput>
162         this.type = FILE;
163         this.name = filePath;
164         this.sawEnd = false;
165
166         try {
167
168             // Create an input stream from the data file.
169             fileInputStream = new FileInputStream(new File(filePath));
170             inputStream     = new BufferedInputStream(fileInputStream);
171
172             <userinput moreinfo="none">fileStats.startDownload(this, FILE, name);</userinput>
173         }
174         catch(Exception ex) {
175             close( );
176             throw new MiddlewareException(ex);
177         }
178     }
179
</programlisting><para>The <literal moreinfo="none">readDataBlock( )</literal> method reads each data block from the source file. When it has read the entire source file, it logs the completion (lines 191–193):</para><programlisting id="I_programlisting20_tt425" format="linespecific">
180     public DataBlock <userinput moreinfo="none">readDataBlock( )</userinput>
181         throws MiddlewareException
182     {
183         byte buffer[] = new byte[<userinput moreinfo="none">Globals.<indexterm id="idx-CHP-20-1682" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamerBlockSize</userinput>];
184
185         try {
186             int size = inputStream.read(buffer);
187
188             if (size == -1) {
189                 close( );
190
191                 <userinput moreinfo="none">Globals.streamerLogger.debug("Completed download of " +
192                                              type + " '" + name + "': " +
193                                              totalSize + " bytes");
194
195                 cacheStats.incrementFileDownloadedCount( );
196                 cacheStats.incrementFileByteCount(totalSize);
197                 fileStats.endDownload(this, totalSize);</userinput>
198
199                 sawEnd = true;
200                 return null;
201             }
202             else {
203                 DataBlock block = new DataBlock(size, buffer);
204                 totalSize += size;
205                 return block;
206             }
207         }
208         catch(Exception ex) {
209             close( );
210             throw new MiddlewareException(ex);
211         }
212     }
213 }
</programlisting><para>Here are some sample <indexterm id="idx-CHP-20-1683" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamer service log entries:</para><programlisting id="I_programlisting20_tt426" format="linespecific">
    2004-12-21 19:17:43,320 INFO : jqpublic:
    Streamer.getDataFile(/surface/tactical/sol/120/jpeg/1P138831013ETH2809P2845L2M1.JPG)
    2004-12-21 19:17:43,324 DEBUG: Begin download of file '/surface/tactical/sol/120/
        jpeg/1P138831013ETH2809P2845L2M1JPG'
    2004-12-21 19:17:44,584 DEBUG: Completed download of file '/surface/tactical/sol/120/
        jpeg/1P138831013ETH2809P2845L2M1.JPG': 1876 bytes
</programlisting><para><xref linkend="a_graph_generated_from_mining_the_cip_streamer_service_logs"/> <indexterm id="idx-CHP-20-1684" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>shows a useful graph of information we can glean from log mining. The graph shows the trend in the amount of downloading (the number of files and the number of bytes downloaded) over a period of several months during the mission. Over shorter periods of time, the graph can show spikes whenever one of the rovers <indexterm id="idx-CHP-20-1685" significance="normal"><primary>Mak</primary></indexterm>makes an interesting discovery.</para><figure id="a_graph_generated_from_mining_the_cip_streamer_service_logs" label="20-6" float="0"><title>A graph generated from "mining" the CIP streamer service logs</title><mediaobject id="I_mediaobject20_tt427"><imageobject role="print"><imagedata fileref="figs/print/beauty_2006.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2006.png" format="PNG"/></imageobject></mediaobject></figure></sect2><sect2 id="monitoring" label="20.5.2"><title>Monitoring</title><para><indexterm id="idx-CHP-20-1686" significance="normal"><primary>streamer service (CIP)</primary><secondary>reliability</secondary><tertiary>logging</tertiary></indexterm>Logging enables us to analyze the performance of the services by examining what they have been doing over a period of time. Unlike log entries, which are most helpful in pinpointing problems and their causes, runtime monitoring helps us see how well the services are currently performing. It gives us a chance to make dynamic adjustments to improve performance or to head off any potential problems. As mentioned earlier, the ability to monitor operational behavior is often critical to the success of any large application.<indexterm id="idx-CHP-20-1687" significance="normal"><primary>logging</primary><secondary>CIP streamer service</secondary></indexterm></para><para>The code listings previously shown included statements that update the performance data kept by global static objects referenced by the fields <literal moreinfo="none">cacheStats</literal> and <literal moreinfo="none">fileStats</literal>. A middle-ware monitoring service probes this performance data upon request. The global objects to which these fields refer aren't shown, but you should be able to imagine what they contain. The key point is that it's not complicated to gather useful runtime performance data.</para><para>We wrote the <indexterm id="idx-CHP-20-1688" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP <indexterm id="idx-CHP-20-1689" significance="normal"><primary>Middleware Monitor Utility</primary></indexterm>Middleware Monitor Utility as a client application that periodically sends requests to the middleware monitoring service to obtain the current performance data. <xref linkend="screenshot_of_the_statistics_tab_of_the_middleware_monitor_util"/> shows a screenshot of the utility's Statistics tab that displays, among other runtime statistics, the number of files and bytes that have been downloaded and uploaded by the <indexterm id="idx-CHP-20-1690" significance="normal"><primary>streamer service (CIP)</primary></indexterm>streamer service, and the number of file errors (such as an invalid filename specified by a client application) that have occurred.</para><figure id="screenshot_of_the_statistics_tab_of_the_middleware_monitor_util" label="20-7" float="0"><title>Screenshot of the Statistics tab of the Middleware Monitor Utility</title><mediaobject id="I_mediaobject20_tt428"><imageobject role="print"><imagedata fileref="figs/print/beauty_2007.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2007.png" format="PNG"/></imageobject></mediaobject></figure><para>The <indexterm id="idx-CHP-20-1691" significance="normal"><primary>reliability of CIP</primary><secondary>streamer service</secondary></indexterm>streamer service provider bean's <literal moreinfo="none">doFileDownload( )</literal> and <literal moreinfo="none">readDataBlock( )</literal> methods both update the global file error count (lines 50 and 84 in the code shown earlier in the section "Logging"). The <literal moreinfo="none">getDataFile( )</literal> and <literal moreinfo="none">readDataBlock( )</literal> methods increment the global total service response time (lines 22 and 94). As seen in <xref linkend="screenshot_of_the_statistics_tab_of_the_middleware_monitor_util"/>, the middleware monitor utility displays average response times under the "Total Server Response" label.<indexterm id="idx-CHP-20-1692" significance="normal"><primary>Middleware Monitor Utility (CIP)</primary></indexterm></para><para>The file reader bean's <literal moreinfo="none">getDataFile( )</literal> method records the start of each file download (line 172). The <literal moreinfo="none">readDataBlock( )</literal> method increments the global total file and byte counts (lines 195 and 196) and records the completion of a download (line 197). <xref linkend="screenshot_of_the_files_tab_of_the_middleware_monitor_utility"/> shows a screenshot of the Files tab of the monitor utility, which displays current and recent file downloading and uploading activity.</para><figure id="screenshot_of_the_files_tab_of_the_middleware_monitor_utility" label="20-8" float="0"><title>Screenshot of the Files tab of the Middleware Monitor Utility</title><mediaobject id="I_mediaobject20_tt429"><imageobject role="print"><imagedata fileref="figs/print/beauty_2008.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2008.png" format="PNG"/></imageobject></mediaobject></figure></sect2></sect1><sect1 id="robustness" label="20.6"><title>Robustness</title><para>Change is inevitable, and beautiful code can handle change gracefully even after going into operation. We took a couple of measures to ensure that <indexterm id="idx-CHP-20-1693" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP is robust and can deal with changes in operational parameters:<indexterm id="idx-CHP-20-1694" significance="normal"><primary>robustness</primary></indexterm></para><itemizedlist><listitem><para>We avoided hardcoding parameters in the middleware <indexterm id="idx-CHP-20-1695" significance="normal"><primary>streamer service (CIP)</primary></indexterm>services.</para></listitem><listitem><para>We made it possible to <indexterm id="idx-CHP-20-1696" significance="normal"><primary>Mak</primary></indexterm>make changes to the middleware services that are already in operation with minimal interruption to the client applications.<indexterm id="I_indexterm20_tt430" class="endofrange" startref="idx-CHP-20-1656" significance="normal"><primary>streamer service (CIP)</primary></indexterm><indexterm id="I_indexterm20_tt431" class="endofrange" startref="idx-CHP-20-1672" significance="normal"><primary>streamer service (CIP)</primary><secondary>reliability</secondary></indexterm></para></listitem></itemizedlist><sect2 id="dynamic_reconfiguration" label="20.6.1"><title>Dynamic Reconfiguration</title><para>Most of the middleware services have certain key operational parameters. For example, as seen above, the streamer service downloads file contents in blocks, and so it has a block size. Instead of hardcoding the block size, we put the value in a parameter file that the service reads each time it first starts up. This happens whenever the streamer service provider bean is loaded (lines 3–5 in the code under the section "Logging").<indexterm id="idx-CHP-20-1697" significance="normal"><primary>robustness</primary><secondary>dynamic reconfiguration</secondary></indexterm></para><para>A <emphasis>middleware.properties</emphasis> file, which all the middleware services share and load, contains the line:<indexterm id="idx-CHP-20-1698" significance="normal"><primary>middleware.properties file</primary></indexterm></para><programlisting id="I_programlisting20_tt432" format="linespecific">
	middleware.streamer.blocksize = 65536
</programlisting><para>The file reader bean's <literal moreinfo="none">readDataBlock( )</literal> method can then refer to the value (line 183).</para><para>Each middleware service can load several parameter values at startup. One of the skills of a master software builder is knowing which key values of a service to expose as <indexterm id="idx-CHP-20-1699" significance="normal"><primary>loadable parameters for services</primary></indexterm>loadable parameters. They are certainly helpful during development; for instance, we were able to try different block sizes during development without having to recompile the streamer service each time.</para><para>But loadable parameters are even more critical for putting code into operation. In most production environments, it is difficult and expensive to <indexterm id="idx-CHP-20-1700" significance="normal"><primary>Mak</primary></indexterm>make changes to software that is already in operation. This was certainly true for the MER mission, which had a formal Change Control Board that scrutinized the justifications for making code changes once the mission was under way.</para><para>Avoiding <indexterm id="idx-CHP-20-1701" significance="normal"><primary>hardcoded parameter values</primary></indexterm>hardcoded parameter values is, of course, a basic Programming 101 dictum that applies to small and large applications alike. But it is especially important with large applications, which may have many more parameter values that are scattered throughout large bodies of code.</para></sect2><sect2 id="hot_swapping" label="20.6.2"><title>Hot Swapping</title><para><indexterm id="idx-CHP-20-1702" significance="normal"><primary>robustness</primary><secondary>hot swapping</secondary></indexterm>Hot swapping is an important feature of the commercial application server that we employed in the <indexterm id="idx-CHP-20-1703" significance="normal"><primary>CIP (Collaborative Information Portal)</primary></indexterm>CIP middleware. It is possible to deploy a middleware service that replaces one that is already running without first bringing down the middleware (and CIP altogether).<indexterm id="idx-CHP-20-1704" significance="normal"><primary>hot swapping</primary></indexterm></para><para>We use <indexterm id="idx-CHP-20-1705" significance="normal"><primary>robustness</primary><secondary>CIP (Collaborative Information Portal)</secondary><tertiary>hot swapping</tertiary></indexterm>hot swapping whenever we need to force a service to reload its parameter values after a change, which we accomplish simply by reloading a service on top of itself. Of course, a service such as the streamer service that uses stateful session beans (the file reader and writer beans) would lose all state information. So, we can hot swap such a service only during "quiet" periods when we know the service is not currently being used. For the streamer service, we can use the Middleware Monitor Utility's Files tab (see <xref linkend="screenshot_of_the_files_tab_of_the_middleware_monitor_utility"/>) to let us know when that's the case.</para><para>Hot swapping makes most sense in the context of a large enterprise application, where it's important to keep the rest of the application running while you are replacing part of it. With a small program, you'd probably just rerun the program to make a change.</para></sect2></sect1><sect1 id="conclusion-id009" label="20.7"><title>Conclusion</title><para>The Collaborative Information Portal proves that it is possible—yes, even at a huge government agency like NASA—to develop a large complex enterprise software system on time that successfully meets strict requirements for functionality, reliability, and robustness. The Mars rovers have far exceeded expectations, a testament of how well the hardware and the software, both on Mars and on Earth, were designed and built, and of the skills of the builders.</para><para>Unlike smaller programs, beauty for a large application is not necessarily found only in elegant algorithms. For CIP, beauty is in its implementation of a service-oriented architecture and in the numerous simple but well-chosen components—the nails that master software builders know just where to pound in.</para></sect1></chapter><chapter id="erp5_designing_for_maximum_adaptability" label="21" role=""><title>ERP5: Designing for Maximum Adaptability</title><para><emphasis>Rogerio Atem de Carvalho and Rafael Monnerat</emphasis><indexterm class="startofrange" id="idx-CHP-21-1706" significance="normal"><primary>ERP5</primary></indexterm><indexterm id="idx-CHP-21-1707" significance="normal"><primary>de Carvalho</primary></indexterm><indexterm id="idx-CHP-21-1708" significance="normal"><primary>Monnerat</primary></indexterm></para><para><emphasis>Enterprise resource planning systems are generally known</emphasis> as large, proprietary, and highly expensive products. In 2001, work on an open source ERP system known as <indexterm id="idx-CHP-21-1709" significance="normal"><primary>Python</primary><secondary>ERP5</secondary></indexterm>ERP5 (<ulink url="http://www.erp5.com"/>) began in two French companies, Nexedi (its main developer) and Coramy (its first user). ERP5 is named after the five main concepts that compose its core. It is based on the <indexterm id="idx-CHP-21-1710" significance="normal"><primary>Zope platform</primary></indexterm>Zope project and the Python scripting language, both of which are also open source.<indexterm id="idx-CHP-21-1711" significance="normal"><primary>enterprise resource planning systems</primary></indexterm></para><para>We have found that ERP5 is exceptionally easy to enhance, and easy for both developers and users to build on. One reason is that we adopted an innovative document-centric approach, instead of a process- or data-centric paradigm. The core idea of a <indexterm id="idx-CHP-21-1712" significance="normal"><primary>document-centric paradigm (ERP5)</primary></indexterm>document-centric paradigm is that every business process relies on a series of documents to make it happen. The document's fields correspond to the structure of the process—that is, the fields reflect the data and the relationships among this data. Thus, if you watch how the business experts who use the ERP5 system navigate through the documents, you will discover the process workflow.</para><para><indexterm id="idx-CHP-21-1713" significance="normal"><primary>ERP5</primary><secondary>Zope components used by</secondary></indexterm>Zope's Content Management Framework (<indexterm id="idx-CHP-21-1714" significance="normal"><primary>CMF (Content Management Framework)</primary></indexterm> <indexterm id="idx-CHP-21-1715" significance="normal"><primary>Zope platform</primary><secondary>CMF (Content Management Framework)</secondary></indexterm><indexterm id="idx-CHP-21-1716" significance="normal"><primary>de Carvalho</primary></indexterm>CMF) tools and concepts supply the technology behind this approach. Each instance of the CMF, called a <emphasis>portal</emphasis>, contains objects to which it offers services such as viewing, printing, workflow, and storage. A <indexterm id="idx-CHP-21-1717" significance="normal"><primary>Python</primary><secondary>ERP5</secondary><tertiary>document structure is implemented as portal class</tertiary></indexterm>document structure is implemented as a Python portal class, and its behavior is implemented as a portal workflow. Therefore, users interact with web documents that are in fact views of system objects controlled by proper workflows.<indexterm id="idx-CHP-21-1718" significance="normal"><primary>portal (CMF)</primary></indexterm></para><para>This chapter will show how this document-centric paradigm and a unified set of core concepts make <indexterm id="idx-CHP-21-1719" significance="normal"><primary>ERP (enterprise resource planning)</primary></indexterm>ERP5 a highly flexible ERP. We will illustrate these ideas by explaining how we used rapid development techniques to create <indexterm id="idx-CHP-21-1720" significance="normal"><primary>ERP5</primary></indexterm>ERP5's project management module, Project.</para><sect1 id="general_goals_of_erp" label="21.1"><title>General Goals of ERP</title><para>ERP is software that aims to integrate all the data and processes of an organization into a unique system. Since this is a real challenge, the ERP industry offers different versions of the same ERP software for different economic segments, such as oil and gas, mechanical, pharmaceutical, automobile, and government.<indexterm id="idx-CHP-21-1721" significance="normal"><primary>enterprise resource planning systems</primary><secondary>goals of</secondary></indexterm></para><para>ERP software generally consists of a series of modules that automate the operations of the organization. The most common modules include finance, inventory control, payroll, production planning and control, sales, and accounting. Those modules are designed for customization and adaptation at the user's site, because even though the organizations of a given economic segment share certain common practices, every organization wants to adapt the ERP system to its specific needs. ERP software also evolves quickly to accompany the evolution of the businesses it serves, and more and more modules are added to it over time.</para></sect1><sect1 id="erp5" label="21.2"><title>ERP5</title><para>ERP5 is developed and used by a growing business and academic community in France, Brazil, Germany, Luxembourg, Poland, Senegal, and India, among other countries. It offers an integrated business management solution based on the open source Zope plat-form (<ulink url="http://www.zope.org"/>), written in the Python language (<ulink url="http://www.python.org"/>). Among the <indexterm id="idx-CHP-21-1722" significance="normal"><primary>Zope platform</primary><secondary>key components used by ERP5</secondary></indexterm>key components of Zope used by ERP5 are:</para><variablelist><varlistentry><term><emphasis>ZODB</emphasis></term><listitem><para>An object database<indexterm id="idx-CHP-21-1723" significance="normal"><primary>ZODB</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>DCWorkflow</emphasis></term><listitem><para>A workflow engine<indexterm id="idx-CHP-21-1724" significance="normal"><primary>DCWorkflow</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Content Management Framework (CMF)</emphasis></term><listitem><para>An infrastructure for adding and moving content</para></listitem></varlistentry><varlistentry><term><emphasis>Zope Page Templates (ZPT)</emphasis></term><listitem><para>Rapid GUI scripting based on XML<indexterm id="idx-CHP-21-1725" significance="normal"><primary>ZPT (Zope Page Templates)</primary></indexterm></para></listitem></varlistentry></variablelist><para>In addition, <indexterm id="idx-CHP-21-1726" significance="normal"><primary>ERP5</primary></indexterm>ERP5 heavily relies on <indexterm id="idx-CHP-21-1727" significance="normal"><primary>XML technologies</primary></indexterm>XML technologies. Every object can be exported and imported in XML format, and two or more <indexterm id="idx-CHP-21-1728" significance="normal"><primary>databases</primary><secondary>ERP5 relational database</secondary></indexterm>ERP5 sites can share synchronized objects through the <indexterm id="idx-CHP-21-1729" significance="normal"><primary>SyncML protocol</primary></indexterm>SyncML protocol. <indexterm id="idx-CHP-21-1730" significance="normal"><primary>paths</primary><secondary>ERP5</secondary></indexterm>ERP5 also implements an <indexterm id="idx-CHP-21-1731" significance="normal"><primary>ERP5</primary><secondary>object-to-relational mapping scheme</secondary></indexterm>object-to-relational mapping scheme that stores the <indexterm id="idx-CHP-21-1732" significance="normal"><primary>de Carvalho</primary></indexterm>indexing attributes of each object in a relational database and allows much faster object search and retrieval than ZODB. In that way, objects are kept in ZODB, but searches are made using SQL, which is a standard query language.</para><para><indexterm id="idx-CHP-21-1733" significance="normal"><primary>relational databases</primary><secondary>ERP5</secondary></indexterm>ERP5 was conceived to be a very flexible framework for developing enterprise applications. Being flexible means being adaptable to various business models without incurring high costs for changes and maintenance. To accomplish this, it is necessary to define a core object-oriented model from which new components can be easily derived for specific purposes. This model must be abstract enough to embrace all basic business concepts.</para><para>As the name indicates, ERP5 therefore defines five abstract <indexterm id="idx-CHP-21-1734" significance="normal"><primary>ERP5</primary><secondary>concepts that lay the basis for representing business processes</secondary></indexterm>concepts that lay the basis for representing <indexterm id="idx-CHP-21-1735" significance="normal"><primary>business processes</primary></indexterm>business processes:</para><variablelist><varlistentry><term><emphasis>Resource</emphasis></term><listitem><para>Describes a resource necessary to realize a business process, such as individual skills, products, machines, and so on.</para></listitem></varlistentry><varlistentry><term><emphasis>Node</emphasis></term><listitem><para>A business entity that receives and sends <indexterm id="idx-CHP-21-1736" significance="normal"><primary>resources (ERP5)</primary></indexterm>resources. It can be related to a physical entity (such as industrial facilities) or an abstract one (such as a bank account). <indexterm id="idx-CHP-21-1737" significance="normal"><primary>nodes (ERP5)</primary></indexterm>Metanodes are nodes containing other nodes, such as companies.</para></listitem></varlistentry><varlistentry><term><emphasis>Path</emphasis></term><listitem><para>Describes how a node accesses resources it needs from another node. For instance, a path may be a trade procedure that defines how a client obtains a product from a supplier.</para></listitem></varlistentry><varlistentry><term><emphasis>Movement</emphasis></term><listitem><para>Describes a movement of resources among nodes at a given moment and for a given period of time. For example, one such movement can be the shipping of raw material from the warehouse to the factory. <indexterm id="idx-CHP-21-1738" significance="normal"><primary>movements (ERP5)</primary></indexterm>Movements are realizations of Paths.</para></listitem></varlistentry><varlistentry><term><emphasis>Item</emphasis></term><listitem><para>A unique instance of a resource. For instance, a CD driver is a resource for assembling a computer, while the CD driver Part Number 23E982 is an item.</para></listitem></varlistentry></variablelist><para>These, along with some other supporting concepts like Order and Delivery, form the ERP5 <indexterm id="idx-CHP-21-1739" significance="normal"><primary>Unified Business Model (UBM)</primary></indexterm>Unified Business Model (<indexterm id="idx-CHP-21-1740" significance="normal"><primary>UBM (Unified Business Model)</primary></indexterm>UBM). It is possible to implement a new business process by combining and extending the five concepts, as we will see in this chapter. The relationships among the five core concepts are shown in <xref linkend="erp5_core_classes"/>. A Path is related to a source node that sends a Resource to a destination node. A Movement is similar, representing a movement of an item that is described by a Resource from a source node to a destination node.</para><figure id="erp5_core_classes" label="21-1" float="0"><title>ERP5 core classes</title><mediaobject id="I_mediaobject21_tt433"><imageobject role="print"><imagedata fileref="figs/print/beauty_2101.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2101.png" format="PNG"/></imageobject></mediaobject></figure></sect1><sect1 id="the_underlying_zope_platform" label="21.3"><title>The Underlying Zope Platform</title><para>To understand why ERP5 is said to be document-driven, it is necessary first to understand how Zope and its Content Management Framework (CMF) work. Zope was originally developed as a web content management environment that provides a series of services to manage the life cycle of web documents. With time, people started to note that it can be also used to implement any kind of web-based application.<indexterm id="idx-CHP-21-1741" significance="normal"><primary>ERP5</primary></indexterm><indexterm id="idx-CHP-21-1742" significance="normal"><primary>Zope platform</primary></indexterm><indexterm id="idx-CHP-21-1743" significance="normal"><primary>de Carvalho</primary></indexterm></para><para>In keeping with Zope's web content focus, its CMF is a framework that aims to speed the development of applications based on content types. It provides a series of services associated to these types, such as workflow, searching, security, design, and testing. From Zope, CMF inherits access to the ZODB (Zope Object Database), which provides transactions and undo functionality.</para><para>CMF implements the structural part of applications through <indexterm id="idx-CHP-21-1744" significance="normal"><primary>CMF Types</primary></indexterm>CMF Types, maintained by the <literal moreinfo="none">portal_types</literal> service, which is in turn a kind of registry tool for the recognized types of a given portal. The visible part of a portal type is a document that represents it. To implement behavior, portal types have actions associated with them, composing a workflow, which in turn is the <indexterm id="idx-CHP-21-1745" significance="normal"><primary>CMF (Content Management Framework)</primary><secondary>implementation of structural part of applications with CMF Types</secondary></indexterm>implementation of a business process. An action on a document changes its state and is implemented by a Python script that realizes some business logic; for instance, calculating the total cost of an order. Given this framework, when developing an application in ERP5, we have to think in terms of documents that hold business process data and whose life cycles are kept by workflows, which implement the business process behavior.<indexterm id="idx-CHP-21-1746" significance="normal"><primary>portal_types service</primary></indexterm></para><para>To take advantage of the CMF structure, ERP5 code is divided into a four-level architecture that implements a chain of concept transformations, with configuration tasks at the highest level.</para><para>The first level comprises the five conceptual core classes. They have no code, only a skeleton, for the sake of simple documentation:</para><programlisting id="I_programlisting21_tt434" format="linespecific">
	class <indexterm id="idx-CHP-21-1747" significance="normal"><primary>Movement class (ERP5)</primary></indexterm>Movement:
	  """
	    Movement of a quantity of a resource in a given variation
	    from a source to a destination.
	  """
</programlisting><para>At the second level is the real core classes' implementation in Python. But here, they are still abstract classes. Still, there is already some <indexterm id="idx-CHP-21-1748" significance="normal"><primary>Zope platform</primary></indexterm>Zope stuff in the classes, and they inherit from <indexterm id="idx-CHP-21-1749" significance="normal"><primary>XMLObject class</primary></indexterm>XMLObject, which means that every object can be serialized into XML for synchronization or exporting.</para><para>Class attributes are organized into <emphasis>property sheets</emphasis>. Property sheets are configurable sets of attributes that facilitate the creation of different object <emphasis>views</emphasis>, potentially manipulated by different sets of class methods. Moreover, these views allow system administrators to set up security in a very flexible and sophisticated way.<indexterm id="idx-CHP-21-1750" significance="normal"><primary>property sheets</primary></indexterm></para><para>For instance, the <literal moreinfo="none">SimpleItem</literal> sheet bears <literal moreinfo="none">title, short_title</literal>, and <literal moreinfo="none">description</literal> attributes. The system administrator can set a security scheme where some users can only view these attributes, while others can write to them:<indexterm id="idx-CHP-21-1751" significance="normal"><primary>SimpleItem property sheet</primary></indexterm><indexterm id="idx-CHP-21-1752" significance="normal"><primary>de Carvalho</primary></indexterm></para><programlisting id="I_programlisting21_tt435" format="linespecific">
	class Movement(XMLObject):
	  """
	    Movement of a quantity of a resource in a given variation
	    from a source to a destination.
	  """
	  # defines the name of the type
	  meta_type = '<indexterm id="idx-CHP-21-1753" significance="normal"><primary>ERP5</primary></indexterm>ERP5 Movement'
	  # defines the CMF type name
	  portal_type = 'Movement'
	  # adds basic Zope security configuration
	  add_permission = Permissions.AddPortalContent
	  # the type is listed as a valid content type
	  isPortalContent = 1
	  # this type is enabled for ERP5 Rapid Application Development facilities
	  isRADContent = 1
	  # used for trade and inventory operations
	  isMovement = 1

	  # Declarative security
	         # stores basic class's security information
	  security = ClassSecurityInfo()
	         # as default, allows authenticated users to view the object
	  security.declareObjectProtected(Permissions.AccessContentsInformation)

	  # Declarative properties
	    property_sheets = ( PropertySheet.Base
	                    , PropertySheet.SimpleItem
	                    , PropertySheet.Amount
	                    , PropertySheet.Task
	                    , PropertySheet.Arrow
	                    , PropertySheet.Movement
	                    , PropertySheet.Price
	                    )
</programlisting><para>The third level holds the <indexterm id="idx-CHP-21-1754" significance="normal"><primary>Meta Classes (ERP5)</primary></indexterm>Meta classes, which are instantiable classes. At this tier, classes already represent specific business entities:</para><programlisting id="I_programlisting21_tt436" format="linespecific">
	<userinput moreinfo="none">class</userinput> <indexterm id="idx-CHP-21-1755" significance="normal"><primary>DeliveryLine class</primary></indexterm>DeliveryLine(Movement):
	    """

	      A DeliveryLine object allows lines to be implemented in
	      Deliveries (packing list, order, invoice etc).
	      It may include a price (for insurance, for customs, for invoices,
	      for <indexterm id="idx-CHP-21-1756" significance="normal"><primary>de Carvalho</primary></indexterm>orders etc).
	    """

	    meta_type = '<indexterm id="idx-CHP-21-1757" significance="normal"><primary>ERP5</primary></indexterm>ERP5 Delivery Line'
	    portal_type = 'Delivery Line'

	    # <replaceable>Declarative properties
	        # it is necessary the overload the property_sheets property
	        # inherited from Movement</replaceable>
	    property_sheets = ( PropertySheet.Base
	                      , PropertySheet.XMLObject
	                      , PropertySheet.CategoryCore
	                      , PropertySheet.Amount
	                      , PropertySheet.Task
	                      , PropertySheet.Arrow
	                      , PropertySheet.Movement
	                      , PropertySheet.Price
	                      , PropertySheet.VariationRange
	                      , PropertySheet.ItemAggregation
	                      , PropertySheet.SortIndex
	                      )
</programlisting><para>Finally, at the fourth level are the <indexterm id="idx-CHP-21-1758" significance="normal"><primary>Portal classes</primary></indexterm>Portal classes, which are CMF-based. This is the level at which configuration takes place. For instance, <xref linkend="properties_tab"/> shows the main part of the Properties tab. This screenshot shows, in particular, the properties of Task Report Line. This type is an implementation of the Delivery Line Meta type. It is interesting to note that new property sheets can be added at this tab, but they are not needed for our project tool.</para><figure id="properties_tab" label="21-2" float="0"><title>Properties tab</title><mediaobject id="I_mediaobject21_tt437"><imageobject role="print"><imagedata fileref="figs/print/beauty_2102.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2102.png" format="PNG"/></imageobject></mediaobject></figure><para><xref linkend="actions_tab"/> shows the Actions tab, listing actions associated with the Task Report Line type. Actions implement specific services for this type. In the figure, you can see the View and Print services.</para><figure id="actions_tab" label="21-3" float="0"><title>Actions tab</title><mediaobject id="I_mediaobject21_tt438"><imageobject role="print"><imagedata fileref="figs/print/beauty_2103.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2103.png" format="PNG"/></imageobject></mediaobject></figure><para>The <indexterm id="idx-CHP-21-1759" significance="normal"><primary>ERP5</primary><secondary>Zope platform</secondary><tertiary>four-level structure representing system classes</tertiary></indexterm>four-level structure <indexterm id="idx-CHP-21-1760" significance="normal"><primary>Movement class (ERP5)</primary><secondary>representing cash withdrawal and material transfer</secondary></indexterm>representing system classes makes it easy to add functionality and <indexterm id="idx-CHP-21-1761" significance="normal"><primary>Zope platform</primary></indexterm>platform features incrementally. It also allows a practice that is very common in <indexterm id="idx-CHP-21-1762" significance="normal"><primary>ERP5</primary></indexterm>ERP5: implementing new portal types without creating new classes in the system. All the programmer has to do is change the appearance of one, because ERP5's core concepts can represent entities of specific business domains.</para><para>For instance, a Movement can be used to represent both a cash withdrawal in the finances module and a transference of material from the warehouse to the factory in the inventory module. To do so, we create one portal type to represent a cash withdrawal and another to represent a material transfer, each using the appropriate business terms that appear in the GUI.</para><para><indexterm id="idx-CHP-21-1763" significance="normal"><primary>de Carvalho</primary></indexterm>Besides using basic CMF features, ERP5 also implements some extra <indexterm id="idx-CHP-21-1764" significance="normal"><primary>ERP5</primary><secondary>features to enhance programming productivity</secondary></indexterm>features to enhance programming productivity. Perhaps the most interesting is the concept of <indexterm id="idx-CHP-21-1765" significance="normal"><primary>relationship managers (ERP5)</primary></indexterm>relationship managers, which are objects responsible for keeping the relationships between pairs of objects. Coding relationship logic into each business class is often tedious and error-prone. Also, traditional relationship code spreads the implementation (back-pointers, deletion notifications, and so on) among many business classes, which is more difficult to track, maintain, and keep in sync than mediated approaches.</para><para>In ERP5, a portal service called <indexterm id="idx-CHP-21-1766" significance="normal"><primary>ERP5</primary><secondary>Portal Categories portal service</secondary></indexterm>Portal Categories records all the one-to-one, one-to-many, and many-to-many relationships between groups of related objects. Query methods, getters and setters, and relationship code are automatically generated.</para><para>This service holds <emphasis>base category</emphasis> objects, which connect classes that collaborate to carry out a given business process. For every base category, <indexterm id="idx-CHP-21-1767" significance="normal"><primary>ERP5</primary></indexterm>ERP5 automatically generates all necessary getters and setters. As an example, the base category <literal moreinfo="none">source</literal> is a reference for objects of the Node type. If, in a given ERP5 implementation, the class Order is configured to have this base category, the system will automatically include all the methods and references necessary to navigate from orders to nodes, and vice versa if desired.<indexterm id="idx-CHP-21-1768" significance="normal"><primary>de Carvalho</primary></indexterm><indexterm id="idx-CHP-21-1769" significance="normal"><primary>Order class (ERP5)</primary><secondary>source base category</secondary></indexterm><indexterm id="idx-CHP-21-1770" significance="normal"><primary>base category objects (Portal Categories)</primary></indexterm></para></sect1><sect1 id="erp5_project_concepts" label="21.4"><title>ERP5 Project Concepts</title><para>To exemplify how ERP5 modules are coded, we'll spend most of the rest of this chapter exploring ERP5 <indexterm class="startofrange" id="idx-CHP-21-1771" significance="normal"><primary>ERP5</primary><secondary>Project</secondary></indexterm>Project, a flexible <indexterm id="idx-CHP-21-1772" significance="normal"><primary>project management</primary></indexterm>project management tool that can be used in many ways.<indexterm id="idx-CHP-21-1773" significance="normal"><primary>project</primary></indexterm><indexterm class="startofrange" id="idx-CHP-21-1774" significance="normal"><primary>Project (ERP5)</primary></indexterm></para><para>Due to the fast and competitive global business environment, projects are the usual form through which businesses develop innovative products and services. Therefore, project management is gaining interest in every industry segment.</para><para>But what is a project? According to Wikipedia, a project is "a temporary endeavor under-taken to create a unique product or service" (<ulink url="http://en.wikipedia.org/wiki/Project"/>, last visited April 13, 2007).</para><para>The uniqueness of projects makes their management difficult, even for a small project sometimes. Hence the need for project management, which is "the discipline of organizing and managing resources in such a way that these resources deliver all the work required to complete a project <indexterm id="idx-CHP-21-1775" significance="normal"><primary>Project (ERP5)</primary><secondary>relations with Trade</secondary></indexterm>within defined scope, quality, time, and cost constraints" (<ulink url="http://en.wikipedia.org/wiki/Project_management"/>, last visited April 13, 2007).</para><para>Project management therefore must control a series of data related to resources such as money, time, and people to keep everything going as planned. Because of this, information tools are needed to ease the analysis of large amounts of data.</para><para>The first use for ERP5 Project was as an "internal" project management tool to support ERP5 instance creation projects. Afterwards, it was redesigned to support other types of projects in general. Even more broadly, this tool can manage order planning and execution wherever a project viewpoint can aid production planning and control. In other words, ERP5 Project should be adaptable to every situation where it is interesting to think in terms of a project composed of a series of tasks and limited by a series of constraints.</para><para>ERP5 allows the developer to reuse the current packages in delivering other packages as completely new modules. Following this concept, a new <indexterm id="idx-CHP-21-1776" significance="normal"><primary>business template (BT)</primary></indexterm>business template (<indexterm id="idx-CHP-21-1777" significance="normal"><primary>BT (business template)</primary></indexterm>BT) is created by basing it on an existing one.</para><para>By the time ERP5 Project started to be implemented, ERP5 already contained the <indexterm id="idx-CHP-21-1778" significance="normal"><primary>Trade BT</primary></indexterm>Trade BT. The development team thus decided to base Project on Trade, representing the planning part of a project by reusing the logic developed for trading operations. After finishing the first Project version, they could improve the Project BT and then use the improvements to refactor Trade BT, making it yet more flexible.</para><para>In building <indexterm id="idx-CHP-21-1779" significance="normal"><primary>Project (ERP5)</primary></indexterm>Project, the interesting parts of <indexterm id="idx-CHP-21-1780" significance="normal"><primary>de Carvalho</primary></indexterm>Trade are the <indexterm id="idx-CHP-21-1781" significance="normal"><primary>Order class (ERP5)</primary></indexterm>Order and <indexterm id="idx-CHP-21-1782" significance="normal"><primary>Delivery class</primary></indexterm>Delivery classes. These classes, also part of the UBM, are containers for Order Line and Delivery Line objects, which in turn are Movements that contain ordered and delivered items, as shown in <xref linkend="relations_between_trade_and_project"/><indexterm id="idx-CHP-21-1783" significance="normal"><primary>ERP5</primary><secondary>Project</secondary></indexterm>. In that figure, the subclasses at the lowest level are all portal types. Therefore, they have basically the same structure as their superclasses, but each portal type has a different GUI and modifications in its workflow to act according to project management logic.</para><figure id="relations_between_trade_and_project" label="21-4" float="0"><title>Relations between Trade and Project</title><mediaobject id="I_mediaobject21_tt439"><imageobject role="print"><imagedata fileref="figs/print/beauty_2104.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2104.png" format="PNG"/></imageobject></mediaobject></figure><para>The relation between Order and Delivery is maintained by <emphasis>causalities</emphasis>, which basically determine that for every confirmed order there will be a mirroring delivery sometime in the future. <indexterm id="idx-CHP-21-1784" significance="normal"><primary>tasks (ERP5)</primary></indexterm>Tasks and <indexterm id="idx-CHP-21-1785" significance="normal"><primary>task reports (ERP5)</primary></indexterm>task reports inherit the same behavior. Accordingly, order lines represent planned movements of resources between two nodes, which, after being confirmed, will be executed and generate delivery lines. Therefore, from a project management point of view, tasks implement project planning, and task reports implement project control.<indexterm id="idx-CHP-21-1786" significance="normal"><primary>causalities</primary></indexterm></para></sect1><sect1 id="coding_the_erp5_project" label="21.5"><title>Coding the ERP5 Project</title><para>The first thing we thought about in creating the Project BT was the main project class. Initially, instead of creating a new class, we decided to simply use Order itself, without change. But after some time, we realized that the business definitions for an order and a project are so different that we should simply create Project as a subclass of Order, without any new code in it, just for the sake of separating concerns. In this design, a project is an object that is described by a series of goals or milestones with one or more tasks <indexterm id="idx-CHP-21-1787" significance="normal"><primary>tasks (ERP5)</primary><secondary>associated with a project</secondary></indexterm>associated with each of them.<indexterm id="idx-CHP-21-1788" significance="normal"><primary>ERP5</primary><secondary>Project</secondary><tertiary>coding</tertiary></indexterm><indexterm class="startofrange" id="idx-CHP-21-1789" significance="normal"><primary>Project (ERP5)</primary><secondary>coding</secondary></indexterm><indexterm id="idx-CHP-21-1790" significance="normal"><primary>ERP5</primary></indexterm>
</para><para>Then, we had to decide how to implement task management since there are differences between a project and a trade operation. The first thing to consider is that tasks can occur outside projects—for instance, in production planning. Therefore, we consider a task as a composition of task lines, or smaller activities inside a task. In that way, we decouple tasks from projects, allowing them to be used in other situations, while keeping the relation with Project through <literal moreinfo="none">source_project</literal> and <literal moreinfo="none">destination_project</literal> base categories.<indexterm id="idx-CHP-21-1791" significance="normal"><primary>source_project base category</primary></indexterm><indexterm id="idx-CHP-21-1792" significance="normal"><primary>destination_project base category</primary></indexterm></para><para>Tasks are implemented through configuration, as we did for Task Report Line in <xref linkend="properties_tab"/>, with the difference of using <indexterm id="idx-CHP-21-1793" significance="normal"><primary>de Carvalho</primary></indexterm>Order as a metaclass. The creation of a task associated with a <indexterm id="idx-CHP-21-1794" significance="normal"><primary>Project (ERP5)</primary></indexterm>project is shown here:</para><programlisting id="I_programlisting21_tt440" format="linespecific">
	# Add a task in task_module. Context represents the current <indexterm id="idx-CHP-21-1795" significance="normal"><primary>ERP5</primary><secondary>Project</secondary></indexterm>project object.
	context_obj = context.getObject()
	# newContent is an <indexterm id="idx-CHP-21-1796" significance="normal"><primary>ERP5</primary></indexterm>ERP5 API method that creates a new content.
	task = context.task_module.newContent(portal_type = 'Task')
	# Set the <indexterm id="idx-CHP-21-1797" significance="normal"><primary>base categories (ERP5)</primary><secondary>source_project</secondary></indexterm>source_project reference to the task.
	task.setSourceProjectValue(context_obj)
	# Redirect the user to Task GUI, so that the user can edit its properties.
	return context.REQUEST.RESPONSE.redirect(task.absolute_url() + '?portal_status_
	message=Created+Task.')
</programlisting><para>Remember that for <indexterm id="idx-CHP-21-1798" significance="normal"><primary>source_project base category</primary><secondary>retrieving tasks of a project</secondary></indexterm>retrieving the tasks of a certain project, the programmer needs to use only the base category <literal moreinfo="none">source_project</literal>. With this category, ERP5 RAD automatically generates signatures and algorithms of accessors. It is interesting to note that the same accessors will be created for both Task and Project. The programmer decides which ones to use through configuration, using the Actions tab shown in <xref linkend="actions_tab"/>. In that tab, the programmer can define a new GUI for using the following methods:</para><programlisting id="I_programlisting21_tt441" format="linespecific">
	### These accessors are used to navigate from task to project

	# This method returns the related Project reference
	getSourceProject()

	# This method sets the related Project reference
	setSourceProject()

	# This method returns the related Project object
	getSourceProjectValue()

	# This method sets the related Project object
	setSourceProjectValue()

	### These accessors are used to navigate from project to task

	# This method returns references to related tasks
	getSourceProjectRelated()

	# This method is not generated in order to avoid an encapsulation break
	# setSourceProjectRelated()

	# This method returns the related tasks objects
	getSourceProjectRelatedValue()

	# This method is not generated in order to avoid an encapsulation break
	# setSourceProjectRelatedValue()
</programlisting><para>You must be asking where the <indexterm id="idx-CHP-21-1799" significance="normal"><primary>Project (ERP5)</primary><secondary>coding</secondary><tertiary>typical project domain attributes and behavior</tertiary></indexterm>typical project domain attributes and behavior are. The answer for the attributes, in most cases, is that they are attributes of Movement and some other UBM classes, masked in the GUI with other names. In other cases, the attribute is implemented through a base category, with all the accessors automatically generated as expected.</para><para>One example of this is the <indexterm id="idx-CHP-21-1800" significance="normal"><primary>tasks (ERP5)</primary><secondary>task predecessors</secondary></indexterm>task <indexterm id="idx-CHP-21-1801" significance="normal"><primary>de Carvalho</primary></indexterm>predecessors, a list of tasks that need to be executed before a given task—a very basic <indexterm id="idx-CHP-21-1802" significance="normal"><primary>Project (ERP5)</primary></indexterm>project management concept, not found on trade operations. This list is also implemented by a base category named <literal moreinfo="none">predecessor</literal>, which links a task to its <indexterm id="idx-CHP-21-1803" significance="normal"><primary>base categories (ERP5)</primary><secondary>predecessor</secondary></indexterm>predecessor in a configurable way because the category takes care of all the code needed.<indexterm id="idx-CHP-21-1804" significance="normal"><primary>predecessor base category</primary></indexterm></para><para>Workflows implement <indexterm id="idx-CHP-21-1805" significance="normal"><primary>workflows (ERP5)</primary><secondary>implementing task behavior</secondary></indexterm>task behavior. Again, basic Movement and more specialized Order behavior is reused. These workflows manipulate the objects in a way that makes sense for <indexterm id="idx-CHP-21-1806" significance="normal"><primary>ERP5</primary><secondary>Project</secondary></indexterm>project management, and include some scripts for doing so. Workflows make development easier because they are configurable, and the programmer needs to write scripts only for specific object manipulation.</para><para><xref linkend="task_workflow"/> shows the <indexterm id="idx-CHP-21-1807" significance="normal"><primary>tasks (ERP5)</primary><secondary>Task workflow</secondary></indexterm>Task workflow. In each box, words in parentheses represent the state ID. Transitions with the <literal moreinfo="none">_action</literal> suffix are trigged by GUI events; the others are internally trigged by workflow events. For each transition, it is possible to define pre-and post-scripts. These scripts are the ones that will manipulate the objects according to the business logic—in this case, the task execution logic. Task represents the planning view of the process, which essentially goes through <literal moreinfo="none">planned, ordered</literal>, and <literal moreinfo="none">confirmed</literal> states.</para><figure id="task_workflow" label="21-5" float="0"><title>Task workflow</title><mediaobject id="I_mediaobject21_tt442"><imageobject role="print"><imagedata fileref="figs/print/beauty_2105.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2105.png" format="PNG"/></imageobject></mediaobject></figure><para>This workflow is the same as Order, but some scripts were changed according to project domain logic. As an example, here is the script <literal moreinfo="none">order_validateData</literal>, which is called before every <literal moreinfo="none">_action</literal> as follows:<indexterm id="idx-CHP-21-1808" significance="normal"><primary>order_validateData script</primary></indexterm></para><programlisting id="I_programlisting21_tt443" format="linespecific">
	### This script check that necessary data exists on Task
	# gets the task object in use
	task = state_change.object
	error_message = ''
	message_list = []
	# checks if the task is attached to some <indexterm id="idx-CHP-21-1809" significance="normal"><primary>Project (ERP5)</primary></indexterm>project or not
	if task.getSource() is None:
	  message_list.append('No Source')
	# if the initial date is null, but there is a final date, makes
	# initialDate = finalDate
	if task.getStartDate() is None and task.getStopDate() is not None:
	  task.setStartDate(task.getStopDate())
	if task.getStartDate () is None:
	  message_list.append("No Date")
	if <indexterm id="idx-CHP-21-1810" significance="normal"><primary>de Carvalho</primary></indexterm>task.getDestination() is None:
	  message_list.append('No Destination')
	# for each contained object, filters the one that are movements.
	# A typical return would be something like
	#('Task Line', 'Sale Order Line', 'Purchase Order Line')
	for line in task.objectValues(portal_type=task.getPortalOrderMovementTypeList ()):
	  # checks if all movements have a associated resource
	  if line.getResourceValue() is None:
	    message_list.append("No Resource for line with id: %s" % line.getId())
	# if any error happened, raises a warning
	if len(message_list) &gt; 0:
	  raise ValidationFailed, "Warning: " + " --- ".join(message_list)
</programlisting><para><xref linkend="task_report_workflow"/> shows the <indexterm id="idx-CHP-21-1811" significance="normal"><primary>Task Report workflow</primary></indexterm>Task Report workflow. It follows the same logic as the Delivery workflow, with some added scripts, such as <literal moreinfo="none">taskReport_notifyAssignee</literal>, shown here.<indexterm id="idx-CHP-21-1812" significance="normal"><primary>taskReport_notifyAssignee script</primary></indexterm></para><figure id="task_report_workflow" label="21-6" float="0"><title>Task Report workflow</title><mediaobject id="I_mediaobject21_tt444"><imageobject role="print"><imagedata fileref="figs/print/beauty_2106.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2106.png" format="PNG"/></imageobject></mediaobject></figure><programlisting id="I_programlisting21_tt445" format="linespecific">
	task_report = state_change.object
	# searches for the assigner for the task
	source_person = task_report.getSourceValue(portal_type="Person")
	# searches for the assignee
	destination_person = task_report.getDestinationValue(portal_type="Person")
	# get the assigner email
	if source_person is not None:
	  from_email = destination_person.getDefaultEmailText()
	  email = source_person.getDefaultEmailValue()
	  if email is not None:
	    msg = """
	# preformmated string with message plus task data goes here
	"""
	    email.activate().send(from_url = from_email,
	                         subject="New Task Assigned to You",
	                         msg = msg)
</programlisting></sect1><sect1 id="conclusion-id010" label="21.6"><title>Conclusion</title><para>The ERP5 team was able to implement a highly flexible tool, used for both "traditional" project management and for order planning and execution control, by making substantial reuse of already existing core concepts and code. Actually, reuse is a daily operation in ERP5 development, to the point where entire new modules are created just by changing GUI elements and adjusting workflows.<indexterm id="idx-CHP-21-1813" significance="normal"><primary>workflows (ERP5)</primary><secondary>Task Report</secondary></indexterm></para><para>Because of this emphasis on reuse, queries on the object database can be done at the abstraction levels of portal types or meta classes. In the first case, the specific business domain concept is retrieved, such as a project task. In the second case, all objects related to the UBM generic concepts are retrieved, which is quite interesting for such requirements as statistics gathering.</para><para>In this chapter, we have edited some code snippets to make them more readable. All ERP5 code in its raw state is available at <ulink url="http://svn.erp5.org/erp5/trunk"/>.</para><sect2 id="acknowledgments-id002" label="21.6.1"><title>Acknowledgments</title><para>We would like to thank Jean-Paul Smets-Solanes, ERP5 creator and chief architect, and all the guys on the team, especially Romain Courteaud and Thierry Faucher. When the authors say <emphasis>we</emphasis> during the discussion of ERP5 design and implementation, they are refer-ring to all those nice folks at Nexedi.<indexterm id="I_indexterm21_tt446" class="endofrange" startref="idx-CHP-21-1706" significance="normal"><primary>ERP5</primary></indexterm><indexterm id="I_indexterm21_tt447" class="endofrange" startref="idx-CHP-21-1771" significance="normal"><primary>ERP5</primary><secondary>Project</secondary></indexterm><indexterm id="I_indexterm21_tt448" class="endofrange" startref="idx-CHP-21-1774" significance="normal"><primary>Project (ERP5)</primary></indexterm><indexterm id="I_indexterm21_tt449" class="endofrange" startref="idx-CHP-21-1789" significance="normal"><primary>Project (ERP5)</primary><secondary>coding</secondary></indexterm></para></sect2></sect1></chapter><chapter id="a_spoonful_of_sewage" label="22" role=""><title>A Spoonful of Sewage</title><para><emphasis>BryanCantrill</emphasis><indexterm id="idx-CHP-22-1814" significance="normal"><primary>software</primary><secondary>bugs as "spoonful of sewage in the barrel of wine"</secondary></indexterm> <indexterm id="idx-CHP-22-1815" significance="normal"><primary>Cantrill</primary></indexterm></para><para>If you put a spoonful of sewage in a barrel full of wine, you get sewage.</para><para><emphasis>Schopenhauer's Law of Entropy</emphasis></para><para><emphasis>Unlike most things that we engineer, software has a binary notion of correctness</emphasis>: either it is correct, or it is flawed. That is, unlike a bridge or an airplane or a microprocessor, software doesn't have physical parameters that limit the scope of its correctness; software doesn't have a rated load or a maximum speed or an environmental envelope. In this regard, software is much more like mathematical proof than physical machine: a proof's elegance or inelegance is subjective, but its correctness is not.<indexterm id="idx-CHP-22-1816" significance="normal"><primary>software</primary><secondary>correctness and purity of</secondary></indexterm></para><para>And indeed, this lends a purity to software that has traditionally only been enjoyed by mathematics: software, like mathematics, can be correct in an absolute and timeless sense. But if this purity of software is its Dr. Jekyll, software has a brittleness that is its Mr. Hyde: given that software can only be correct or flawed, a single flaw can become the difference between unqualified success and abject failure.</para><para>Of course, this is not to say that every bug is necessarily fatal—just that the possibility always exists that a single bug will reveal something much larger than its manifestations: a design flaw that calls into question the fundamental assumptions upon which the software was built. Such a flaw can shake software to its core and, in the worst case, invalidate it completely. That is, a single software bug can be the proverbial <indexterm id="idx-CHP-22-1817" significance="normal"><primary>spoonful of sewage in the barrel of wine</primary></indexterm>spoonful of sewage in the barrel of wine, turning what would otherwise be an enjoyable pleasure into a toxic stew.</para><para>For me personally, this fine line between wine and sewage was never so stark as in one incident in the <indexterm id="idx-CHP-22-1818" significance="normal"><primary>Solaris</primary><secondary>development of critical kernel subsystem</secondary></indexterm>development of a critical subsystem of the <indexterm class="startofrange" id="idx-CHP-22-1819" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm>Solaris kernel in 1999. This problem—and its solution—are worth discussing at some length, for they reveal how profound <indexterm id="idx-CHP-22-1820" significance="normal"><primary>design defects manifesting as bugs</primary></indexterm>design defects can manifest themselves as bugs, and how devilish the details can become when getting a complicated and important body of software to function perfectly.</para><para>A word of caution before we begin: this journey will take us deep into the core of the Solaris kernel, into some of the most fundamental and subtlest mechanism of the operating system. As such, the detail may seem crushing; like adventurous spelunkers, we will at times be wading through dark, cold water or squeezing through suffocatingly tight passages—but for those that make the trip, a hidden and beautiful underground cavern awaits. So if you're ready, don your headlamp, grab a water bottle, and let's descend into the Solaris kernel….</para><para>The subsystem that is the center of our story is the turnstile subsystem. A <emphasis>turnstile</emphasis> is the mechanism used to block and wake <indexterm id="idx-CHP-22-1821" significance="normal"><primary>waking up threads in Solaris</primary></indexterm>up threads in Solaris—it is the underpinning of synchronization primitives such as mutexes and reader/writer locks. Or, to let the code speak for itself:<footnote id="CHP-22-FNOTE-1"><para>This code is open source and is available at <ulink url="http://src.opensolaris.org/source/xref/onnv/onnv-gate/usr/src/uts/common/os/turnstile.c"/>.</para></footnote></para><programlisting id="I_programlisting22_tt450" format="linespecific">
	/*
	 * <indexterm id="idx-CHP-22-1822" significance="normal"><primary>turnstiles (Solaris)</primary></indexterm>Turnstiles provide blocking and wakeup support, including <indexterm id="idx-CHP-22-1823" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>priority
	 * inheritance, for synchronization primitives (e.g. mutexes and rwlocks).
	 * Typical usage is as follows:
	 *
	 * To block on lock 'lp' for read access in foo_enter( ):
	 *
	 *      ts = turnstile_lookup(lp);
	 *      [ If the lock is still held, set the waiters bit
	 *      <indexterm id="idx-CHP-22-1824" significance="normal"><primary>turnstile_block( ) function</primary></indexterm>turnstile_block(ts, TS_READER_Q, lp, &amp;foo_sobj_ops);
	 *
	 * To wake threads waiting for write access to lock 'lp' in foo_exit( ):
	 *
	 *      ts = turnstile_lookup(lp);
	 *      [ Either drop the lock (change owner to NULL) or perform a direct
	 *      [ handoff (change owner to one of the threads we're about to wake).
	 *      [ If we're going to wake the last waiter, clear the waiters bit.
	 *      turnstile_wakeup(ts, TS_WRITER_Q, nwaiters, new_owner or NULL);
	 *
	 * turnstile_lookup( ) returns holding the turnstile hash chain lock for lp.
	 * Both turnstile_block() and turnstile_wakeup( ) drop the turnstile lock.
	 * To abort a turnstile operation, the client must call turnstile_exit( ).
	 * 
	...
</programlisting><para>The turnstile abstraction thus allows synchronization primitives to focus on their own particular policy without worrying about the delicate mechanics of blocking and awakening. As the block comment mentions, <literal moreinfo="none">turnstile_block()</literal> is the function called to actually block the current thread on a synchronization primitive, and it is in this function that our subterranean journey begins in earnest with this cryptic comment of mine:</para><programlisting id="I_programlisting22_tt451" format="linespecific">
	/*
	 * Follow the blocking chain to its end, willing our <indexterm id="idx-CHP-22-1825" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>priority to
	 * everyone who's in our way.
	 */
	while (t-&gt;t_sobj_ops != NULL &amp;&amp;
	    (owner = SOBJ_OWNER(t-&gt;t_sobj_ops, t-&gt;t_wchan)) != NULL) {
	        if (owner == curthread) {
	                if (SOBJ_TYPE(sobj_ops) != SOBJ_USER_PI) {
	                        panic("Deadlock: cycle in blocking chain");
	                }
	                <userinput moreinfo="none">/*
	                 * If the cycle we've encountered ends in mp,
	                 * then we know it isn't a 'real' cycle because
	                 * we're going to drop mp before we go to sleep.
	                 * Moreover, since we've come full circle we know
	                 * that we must have willed priority to everyone
	                 * in our way. Therefore, we can break out now.
	                 */
	                if (t-&gt;t_wchan == (void *)mp)
	                           break;</userinput>
</programlisting><para>For me, this comment (and the two lines of code to which it refers, all highlighted in bold) will always be the canonical difference between sewage and wine: they were added in the final, frenzied moments of <indexterm id="idx-CHP-22-1826" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm>Solaris 8, in one of the more intense experiences of my engineering career—a week-long collaboration with fellow Sun engineer Jeff <indexterm id="idx-CHP-22-1827" significance="normal"><primary>Bonwick</primary></indexterm>Bonwick that required so much shared mental state that he and I both came to call it "the mind-meld."</para><para>We will come back to this code and the mind-meld behind it, but to get there, we first need to journey much deeper into the inner workings of turnstiles, exploring in particular how turnstiles address the classic problem of <emphasis>priority inversion</emphasis>.<indexterm id="idx-CHP-22-1828" significance="normal"><primary>priority inversion</primary></indexterm></para><para>If you are unfamiliar with the problem of <indexterm id="idx-CHP-22-1829" significance="normal"><primary>turnstiles (Solaris)</primary><secondary>priority inversion</secondary></indexterm>priority inversion, it can be described as follows: given three threads at three different priorities, if the highest priority thread blocks on a synchronization object held by the lowest priority thread, the middling priority thread could (in a pure priority preemptive system running on a uniprocessor) run in perpetuity, starving the highest priority thread. The result is illustrated in <xref linkend="priority_inversion"/>.</para><figure id="priority_inversion" label="22-1" float="0"><title>Priority inversion</title><mediaobject id="I_mediaobject22_tt452"><imageobject role="print"><imagedata fileref="figs/print/beauty_2201.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2201.png" format="PNG"/></imageobject></mediaobject></figure><para>One mechanism to solve priority inversion is a technique called <emphasis>priority inheritance</emphasis>. Under <indexterm id="idx-CHP-22-1830" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>priority inheritance, when one thread is going to block on a resource held by a lower priority thread, the higher priority thread <emphasis>wills</emphasis> its priority to the lower priority thread for the duration of the critical section. That is, the priority of the lower priority thread is <emphasis>boosted</emphasis> to that of the higher priority thread as long as the lower priority thread owns a resource that the higher priority thread needs. When the lower priority thread (running with a boosted priority) exits the critical section—when it releases the synchronization primitive upon which the higher priority thread is blocked—it awakens the blocked higher priority thread and returns itself to the lower priority. In this way, no middling priority thread ever has the opportunity to run—the inversion is averted.<indexterm class="startofrange" id="idx-CHP-22-1831" significance="normal"><primary>priority inheritance</primary></indexterm></para><para>Now, in <indexterm id="idx-CHP-22-1832" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm>Solaris we have long had <indexterm id="idx-CHP-22-1833" significance="normal"><primary>Solaris</primary><secondary>priority inheritance for kernel synchronization primitives</secondary></indexterm>priority inheritance for <indexterm id="idx-CHP-22-1834" significance="normal"><primary>kernel synchronization primitives</primary></indexterm>kernel synchronization primitives; indeed, this is one of the architectural differences between SunOS 4.x and Solaris 2.x, and it is one of the core services of the turnstile subsystem. And just getting priority inheritance right for kernel synchronization primitives is nasty: one must know who owns a lock, and one must know which lock the owner is blocked on (if any). That is, if a thread is blocking on a lock that is owned by a thread that is <emphasis>itself</emphasis> blocked, we need to be able to determine what lock the owning thread is blocked on, and which thread owns <emphasis>that</emphasis> lock. We call this <indexterm id="idx-CHP-22-1835" significance="normal"><primary>chain of blocked threads</primary></indexterm>chain of blocked threads the <emphasis>blocking chain</emphasis>, and because its nuances are central to the implementation of priority inheritance, it's worth fleshing out a plausible and concrete example of how one might develop.<indexterm id="idx-CHP-22-1836" significance="normal"><primary>blocking</primary><secondary>blocking chain</secondary></indexterm></para><para>For an example of a blocking chain, we can look to the <indexterm id="idx-CHP-22-1837" significance="normal"><primary>Solaris</primary><secondary>interaction between kernel memory allocator and Zettabyte Filesystem (ZFS)</secondary></indexterm>interaction between two well-known Solaris subsystems: the kernel memory allocator and the Zettabyte Filesystem (<indexterm id="idx-CHP-22-1838" significance="normal"><primary>ZFS (Zettabyte Filesystem)</primary></indexterm>ZFS). For purposes of our example, we don't need to understand these grand subsystems in any detail; we're just shining a flashlight into them, not exploring their many nooks and crannies. The salient bits about the kernel memory allocator are that it is an <emphasis>object-caching</emphasis> allocator—all allocations are served from caches that manage objects of a fixed size—and that it caches allocated buffers in per-CPU structures called <emphasis>magazines</emphasis>. When a magazine is exhausted, allocations are satisfied out of a structure called a <emphasis>depot</emphasis>. This tiered structure is highly scalable with respect to CPUs: by satisfying most allocations out of the per-CPU magazine structure (upon which contention is highly unlikely), the allocator exhibits near-linear CPU scalability. And while it is orthogonal to our purpose at the moment, I can't help but illuminate an elegant detail in the code that executes when a per-CPU magazine is empty and the depot lock (which is global per-cache) must be acquired:<indexterm id="idx-CHP-22-1839" significance="normal"><primary>object-caching allocator</primary></indexterm><indexterm id="idx-CHP-22-1840" significance="normal"><primary>magazines</primary></indexterm><indexterm id="idx-CHP-22-1841" significance="normal"><primary>depot</primary></indexterm></para><programlisting id="I_programlisting22_tt453" format="linespecific">
	/*
	 * If we can't get the depot lock without contention,
	 * update our contention count. We use the depot
	 * contention rate to determine whether we need to
	 * increase the magazine size for better scalability.
	 */
	if (!mutex_tryenter(&amp;cp-&gt;cache_depot_lock)) {
	        mutex_enter(&amp;cp-&gt;cache_depot_lock);
	        cp-&gt;cache_depot_contention++;
	}
</programlisting><para>This code doesn't simply acquire the lock, it <emphasis>attempts</emphasis> to acquire the lock, keeping track of the number of times that this attempt fails because the lock was held. The resulting count is a rough indicator of contention at the global layer, and if the count becomes too high in a given interval of time, the system increases the number of buffers stored at the per-CPU layer, reducing the contention at the global layer. This simple mechanism thus allows the subsystem to dynamically adjust its structures to reduce its own contention! Beautiful code, for certain.</para><para>Let's return to the construction of our example, and now to ZFS, where all we need to know is that files and directories have an in-memory structure called a <literal moreinfo="none">znode</literal>.</para><para>Given this background about the kernel memory allocator and ZFS, we can envision the following sequence of events:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>A thread T1, attempts an allocation from the <literal moreinfo="none">kmem_alloc_32</literal> cache on CPU 2, which requires taking the lock for CPU 2's <literal moreinfo="none">kmem_alloc_32</literal> magazine. <indexterm id="idx-CHP-22-1842" significance="normal"><primary>iterating over entire blocking chain coherently (in Solaris)</primary></indexterm>Discovering that the magazines for CPU 2 are all empty, T1 acquires the depot lock for the <literal moreinfo="none">kmem_alloc_32</literal> cache, and it is then preempted, with both the CPU 2 magazine lock and the depot lock held.</para></listitem><listitem><para>A second thread T2, running on CPU 3, attempts an unrelated allocation from the <literal moreinfo="none">kmem_alloc_32</literal> cache. As bad luck would have it, its magazines are also empty. T2 attempts to acquire the depot lock for the <literal moreinfo="none">kmem_alloc_32</literal> cache—but it sees that the lock is held by T1, and it blocks.</para></listitem><listitem><para>A third thread T3, runs on CPU 3 after T2 has blocked. This thread is attempting to create the ZFS file <emphasis>/foo/bar/mumble</emphasis>. As part of this operation, it must create a ZFS directory entry lock for the entry <emphasis>mumble</emphasis> in the directory <emphasis>/foo/bar</emphasis>. It acquires the lock on the <literal moreinfo="none">znode</literal> that corresponds to <emphasis>/foo/bar</emphasis> and then attempts to allocate a <literal moreinfo="none">zfs_dirlock_t</literal>. Because a <literal moreinfo="none">zfs_dirlock_t</literal> is 32 bytes in size, this allocation is to be satisfied from the <literal moreinfo="none">kmem_alloc_32</literal> cache, and T3 therefore attempts to acquire the magazine lock for the <literal moreinfo="none">kmem_alloc_32</literal> cache on CPU 3—but it sees that the lock is held by T2, and it blocks.</para></listitem><listitem><para>A fourth thread, T4, attempts to examine the contents of the directory <emphasis>/foo/bar</emphasis>. As a part of this operation, it attempts to acquire the lock on the <literal moreinfo="none">znode</literal> that corresponds to <emphasis>/foo/bar</emphasis>—but it sees that the lock is held by T3, and it blocks.</para></listitem></orderedlist><para>When T4 blocks, it is blocking on T3, which is in turn blocked on T2, which is in turn blocked on T1—and it is this chain of threads that constitutes the blocking chain. Having seen what a blocking chain might actually look like in the wild, it might be easier to appreciate the essential subtlety of <indexterm id="idx-CHP-22-1843" significance="normal"><primary>priority inheritance</primary><secondary>getting it correct</secondary></indexterm>getting <indexterm id="idx-CHP-22-1844" significance="normal"><primary>priority inheritance</primary></indexterm>priority inheritance correct: when a blocking thread wills its priority to its blocking chain, we must iterate over the entire blocking chain <emphasis>coherently</emphasis>. That is, when we iterate over the blocking chain, we must see a consistent snapshot of all of the threads that were on the blocking chain at that instant—no more and no less. In the context of this example, we wouldn't want to will our priority to T1 <emphasis>after</emphasis> it released the lock blocking T2 (and thus, transitively, T4)—this would potentially leave T1 at an artificially high priority.</para><para>So, how can we iterate over the blocking chain coherently? In <indexterm id="idx-CHP-22-1845" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm>Solaris, a thread's <indexterm id="idx-CHP-22-1846" significance="normal"><primary>dispatcher state of threads in Solaris</primary></indexterm>dispatcher state (e.g., whether it's running, enqueued to run, or sleeping) is protected by acquiring a special <indexterm id="idx-CHP-22-1847" significance="normal"><primary>spin lock (thread lock) in Solaris</primary></indexterm>spin lock known as its <emphasis>thread lock</emphasis>; it might be tempting to believe that in order to process the blocking chain coherently, we should simply acquire all of the thread locks at once. This won't work, however, in part because of the way that thread locks are implemented.<indexterm id="idx-CHP-22-1848" significance="normal"><primary>thread lock</primary></indexterm></para><para>A thread lock is a very special lock because it is not a spin lock in any traditional sense, but rather a <emphasis>pointer</emphasis> to a spin lock, with the lock that it points to being the lock that protects the structure currently managing the thread; as the management of a thread is changed from one structure to another, its thread lock is changed to point to the correct lock.</para><para>For example, if a thread is enqueued to run on a CPU, its thread lock points to a lock for the dispatch queue on that CPU for the thread's <indexterm id="idx-CHP-22-1849" significance="normal"><primary>priority inheritance</primary></indexterm>priority level, but when the thread is running on a CPU, the thread lock is changed to point to a lock within the CPU's <literal moreinfo="none">cpu_t</literal> structure. And if the thread should block on a synchronization primitive, its thread lock is changed to point to a lock in the (cue ominous, foreshadowing music) turnstile table.</para><para>This last structure will become much more important as we descend deeper, but for now, the critical point is this: we cannot simply acquire every thread lock because multiple threads can point to the <emphasis>same</emphasis> underlying dispatcher lock; if we simply tried to acquire them all, we might deadlock on ourselves as we spin, attempting to acquire a lock that we ourselves have already acquired!<footnote id="CHP-22-FNOTE-2"><para>There is a subtler problem here, too, of lock ordering; suffice it to say that acquiring all thread locks in a blocking chain is a nonstarter, for myriad reasons.</para></footnote></para><para>Fortunately, we don't actually have to hold every thread lock to assure a consistent snapshot of the blocking chain, thanks to an important (if self-evident) property of blocking chains: they can only become unwound from their <emphasis>unblocked</emphasis> ends. That is, the only way for a thread blocked on a synchronization primitive to become unblocked is to be explicitly awoken by the thread owning the synchronization primitive.</para><para>So in our example, the only way for (say) T3 to become runnable is to be awoken by T2. So if we proceed atomically from T3 to T2, and then atomically from T2 to T1, we're guaranteed that there is no window by which T3 can be awoken—even if we have dropped the thread lock for T3.</para><para>This means that we need not lock the <emphasis>entire</emphasis> chain—we need only lock <emphasis>two consecutive elements</emphasis> at a time: when T4 is to block, we can grab the lock for T3, then grab the lock for T2, then drop the lock for T3 and acquire the lock for T1, then drop the lock for T2, and so on. Because we're only looking to hold two thread locks at a time, it's easy to deal with the case where they point to the same underlying lock: if they point to the same underlying lock, we just retain that lock as we iterate over that element in the blocking chain.</para><para>This has <emphasis>almost</emphasis> resolved the issue of <indexterm id="idx-CHP-22-1850" significance="normal"><primary>blocking</primary><secondary>iterating over it coherently</secondary></indexterm>iterating over blocking chains, but a substantial hurdle remains—one that is the ramification of a different design decision. Recall that we mentioned that thread locks can point to dispatcher locks in the turnstile table. We now need to explain the turnstile table, as we will be encountering it several more times in our journey.</para><para>The turnstile table is a hash table keyed by the virtual address of the synchronization primitive; it is the table of queues upon which blocked threads are queued. Each queue is locked at its head, by a <emphasis>turnstile lock</emphasis>—and it is one of these locks that a thread's thread lock will point to if the thread is blocked on a synchronization primitive.</para><para>This is a critical, if subtle, design decision: when a thread is blocked on a synchronization primitive, it is <emphasis>not</emphasis> enqueued on a queue that is unique to the synchronization primitive, but rather one that may be shared by several synchronization primitives that happen to map to the same turnstile table entry.</para><para>Why was it done this way? As a highly parallel operating system, <indexterm id="idx-CHP-22-1851" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm>Solaris has fine-grained synchronization, meaning that there are many (many!) instances of synchronization primitives, and that they are manipulated very frequently—nearly always with zero contention. Thus, the structures that represent kernel synchronization primitives—<literal moreinfo="none">kmutex_t</literal> and <literal moreinfo="none">krwlock_t</literal>—must be as small as possible, and their manipulation must optimize for the common, uncontended case. Embedding the queue for the blocking chain in the synchronization primitive itself would lead to an unacceptable impact, either on space (by bloating the size of the primitive with a queue pointer and dispatcher lock) or on time (by slowing down the uncontended case to maintain a more complicated structure). Either way, it is unacceptable to situate the data structure for a blocking chain with the synchronization primitive itself—a turnstile table (or something like it) is required.</para><para>To restate the ramifications of the turnstile table: threads blocked on <emphasis>different</emphasis> synchronization primitives can have their thread locks point to the <emphasis>same</emphasis> turnstile lock. Given that we must hold two locks at a time while traversing the blocking chain, this creates a nasty lock ordering problem. When Jeff encountered this problem in his original implementation, he solved it in an elegant way; his comment in <literal moreinfo="none">turnstile_interlock()</literal> explains the problem and his solution:</para><programlisting id="I_programlisting22_tt454" format="linespecific">
	/*
	 * When we apply <indexterm id="idx-CHP-22-1852" significance="normal"><primary>priority inheritance</primary></indexterm>priority inheritance, we must grab the owner's thread lock
	 * while already holding the waiter's thread lock. If both thread locks are
	 * turnstile locks, this can lead to deadlock: while we hold L1 and try to
	 * grab L2, some unrelated thread may be applying <indexterm id="idx-CHP-22-1853" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>priority inheritance to
	 * some other blocking chain, holding L2 and trying to grab L1. The most
	 * obvious solution -- do a lock_try( ) for the owner lock -- isn't quite
	 * sufficient because it can cause livelock: each thread may hold one lock,
	 * try to grab the other, fail, bail out, and try again, looping forever.
	 * To prevent livelock we must define a winner, i.e. define an arbitrary
	 * lock ordering on the turnstile locks. For simplicity we declare that
	 * virtual address order defines lock order, i.e. if L1 &lt; L2, then the
	 * correct lock ordering is L1, L2. Thus the thread that holds L1 and
	 * wants L2 should spin until L2 is available, but the thread that holds
	 * L2 and can't get L1 on the first try must drop L2 and return failure.
	 * Moreover, the losing thread must not reacquire L2 until the winning
	 * thread has had a chance to grab it; to ensure this, the losing thread
	 * must grab L1 after dropping L2, thus spinning until the winner is done.
	 * Complicating matters further, note that the owner's thread lock pointer
	 * can change (i.e. be pointed at a different lock) while we're trying to
	 * grab it. If that happens, we must unwind our state and try again.
	 */
</programlisting><para>This lock ordering issue is part of what made it difficult to implement <indexterm id="idx-CHP-22-1854" significance="normal"><primary>priority inheritance</primary></indexterm>priority inheritance for kernel synchronization objects—and unfortunately, kernel-level priority inheritance solves only part of the priority inversion problem.</para><para>Providing priority inheritance exclusively for kernel synchronization objects has an obvious shortcoming: to build a multithreaded real-time system, one needs priority inheritance not just for kernel-level synchronization primitives, but also for <emphasis>user-level</emphasis> synchronization primitives. And it was this problem—<indexterm id="idx-CHP-22-1855" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>user-level priority inheritance—that we decided to address in <indexterm id="idx-CHP-22-1856" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm>Solaris 8. We assigned an engineer to solve it, and (with extensive guidance from those of us who best understand the guts of scheduling and synchronization), the new facility was integrated in October 1999.<indexterm id="idx-CHP-22-1857" significance="normal"><primary>priority inheritance</primary><secondary>user-level</secondary></indexterm></para><para>A few months later—in December of 1999—I was looking at an operating system failure that a colleague had encountered. It was immediately clear that this was some sort of defect in our implementation of <indexterm id="idx-CHP-22-1858" significance="normal"><primary>Solaris</primary><secondary>user-level priority inheritance</secondary></indexterm>user-level priority inheritance, but as I understood the bug, I came to realize that this was no surface problem: this was a design defect—and I could practically smell our wine turning to sewage.</para><para>Before explaining this bug—and the design defect that it revealed—it's worth discussing the methodology used to debug it. An important skill for any software engineer is the ability to analyze the failure of a complicated software system, and to present that analysis rigorously. And in any sufficiently complicated system, failure analysis will often be forensic: it will be based on a snapshot of system state at the time of failure. Indeed, such a snapshot of state is so fundamental to debugging that it carries with it a moniker from the dawn of computing: it is a "<indexterm id="idx-CHP-22-1859" significance="normal"><primary>core dump</primary></indexterm>core dump."</para><para>This variant of debugging—<emphasis>postmortem debugging</emphasis>—can be contrasted to the more traditional <emphasis>in situ</emphasis> debugging by which one is debugging a live and running (albeit stopped) system. Whereas with <emphasis>in situ</emphasis> debugging one can use breakpoints to iteratively test hypotheses about the system, with postmortem debugging one can use only the state of the system at the time of failure to test hypotheses. While this means that postmortem debugging is necessarily a less complete methodology than <emphasis>in situ</emphasis> debugging (as there are bugs for which there simply does not exist enough state at the time of failure to eliminate a significant number of hypotheses), there are many bugs that are not sufficiently reproducible to apply <emphasis>in situ</emphasis> debugging—there is no other way to debug them <emphasis>but</emphasis> postmortem.<indexterm id="idx-CHP-22-1860" significance="normal"><primary>postmortem debugging</primary></indexterm><indexterm id="idx-CHP-22-1861" significance="normal"><primary>in situ debugging</primary></indexterm></para><para>Moreover, because the more limited options afforded by postmortem debugging require more rigorous thinking around both hypothesis generation and validation, developing one's ability to debug postmortem makes one much more efficient at <emphasis>in situ</emphasis> debugging.</para><para>Finally, because the state of the system is static, one can present specific, rigorous analysis to peers, who can then perform their own analysis—in parallel—and draw their own conclusions. And even if not actively validated by others, this analysis is valuable, for drafting it forces one to address the holes in one's own logic. In short, postmortem debugging is an essential part of our craft—a skill that every serious software engineer should develop.</para><para>Given that background on (and plug for) postmortem debugging, and with the caveat that this analysis will not yet be completely (or perhaps not at all) comprehensible, here is my analysis of the bug at hand, as it appeared verbatim in my initial bug report:<footnote id="CHP-22-FNOTE-3"><para>"Beautiful Bug Reports," anyone?</para></footnote></para><programlisting id="I_programlisting22_tt455" format="linespecific">
	[ bmc, 12/13/99 ]

	The following sequence of events can explain the state in the <indexterm id="idx-CHP-22-1862" significance="normal"><primary>core dump</primary></indexterm>dump (the arrow
	denotes an ordering):

	        Thread A (300039c8580)                 Thread B (30003c492a0)
	        (executing on CPU 10)                   (executing on CPU 4)
	+-------------------------------------+ +-------------------------------------+
	|  Calls lwp_upimutex_lock() on       | |                                     |
	|  lock 0xff350000                    | |                                     |
	|                                     | |                                     |
	|  lwp_upimutex_lock() acquires       | |                                     |
	|  upibp-&gt;upib_lock                   | |                                     |
	|                                     | |                                     |
	|  lwp_upimutex_lock(), seeing the    | |                                     |
	|  lock held, calls turnstile_block() | |                                     |
	|                                     | |                                     |
	|  turnstile_block():                 | |                                     |
	|  - Acquires A's thread lock         | |                                     |
	|  - Transitions A into TS_SLEEP      | |                                     |
	|  - Drops A's thread lock            | |                                     |
	|  - Drops upibp-&gt;upib_lock           | |                                     |
	|  - Calls swtch()                    | |                                     |
	:                                     : :                                     :


	   +----------------------------------------------------------------------+
	   | Holder of 0xff350000 releases the lock, explicitly handing it off to |
	   | thread A (and thus setting upi_owner to 300039c8580)                 |
	   +----------------------------------------------------------------------+


	:                                    : :                                      :
	|                                    | |                                      |
	|  Returns from turnstile_block()    | |                                      |
	|                                    | |  Calls lwp_upimutex_lock() on        |
	|                                    | |  lock 0xff350000                     |
	|                                    | |                                      |
	|                                    | |  lwp_upimutex_lock() acquires        |
	|                                    | |  upibp-&gt;upib_lock          |
	|                                    | |  Seeing the lock held (by A), calls  |
	|                                    | |  turnstile_block()                   |
	|  Calls lwp_upimutex_owned() to     | |                                      |
	|  check for lock hand-off           | |  turnstile_block():                  |
	|                                    | |  - Acquires B's thread lock          |
	|  lwp_upimutex_owned() attempts     | |  - Transitions B into TS_SLEEP,      |
	|  to acquire upibp-&gt;upib_lock       | |    setting B's wchan to upimutex     |
	|                                    | |    corresponding to 0xff350000       |
	|  upibp-&gt;upib_lock is held by B;    | |  - Attempts to promote holder of     |
	|  calls into turnstile_block()      | |    0xff350000 (Thread A)             |
	|  through mutex_vector_enter()      | |  - Acquires A's thread lock          |
	|                                    | |  - Adjusts A's priority              |
	|  turnstile_block():                | |  - Drops A's thread lock             |
	|                          &lt;--------------+                                   |
	|  - Acquires A's thread lock        | |  - Drops B's thread lock             |
	|  - Attempts to promote holder of   | |                                      |
	|    upibp-&gt;upib_lock (Thread B)     | |                                      |
	|  - Acquires B's thread lock        | |  - Drops upibp-&gt;upib_lock            |
	|  - Adjusts B's priority            | |                                      |
	|  - Drops B's thread lock           | |                                      |
	|  - Seeing that B's wchan is not    | |                                      |
	|    NULL, attempts to continue      | |                                      |
	|    <indexterm id="idx-CHP-22-1863" significance="normal"><primary>priority inheritance</primary></indexterm>priority inheritance            | |                                      |
	|  - Calls SOBJ_OWNER() on B's wchan | |                                      |
	|  - Seeing that owner of B's wchan  | |                                      |
	|    is A, panics with "Deadlock:    | |                                      |
	|    cycle in blocking chain"        | |                                      |
	|                                    | |                                      |
	+------------------------------------+-+--------------------------------------+


	As the above sequence implies, the problem is in turnstile_block()

	        THREAD_SLEEP(t, &amp;tc-&gt;tc_lock);
	        t-&gt;t_wchan = sobj;
	        t-&gt;t_sobj_ops = sobj_ops;
	        ...
	        /*
	         * Follow the blocking chain to its end, or until we run out of
	         * inversions, willing our priority to everyone who's in our way.
	         */
	        while (inverted &amp;&amp; t-&gt;t_sobj_ops != NULL &amp;&amp;
	            (owner = SOBJ_OWNER(t-&gt;t_sobj_ops, t-&gt;t_wchan)) != NULL) {
	                ...
	        }
	(1) --&gt; thread_unlock_nopreempt(t);
	        /*
	         * At this point, "t" may not be curthread. So, use "curthread", from
	         * now on, instead of "t".
	         */
	        if (SOBJ_TYPE(sobj_ops) == SOBJ_USER_PI) {
	(2) --&gt;         mutex_exit(mp);
	                ...
	We're dropping the thread lock of the blocking thread (at (1)) before we drop
	the upibp-&gt;upib_lock at (2). From (1) until (2) we are violating one of
	the invariants of SOBJ_USER_PI locks: when sleeping on a SOBJ_USER_PI lock,
	_no_ kernel locks may be held; any held kernel locks can yield a deadlock
	panic.
</programlisting><para>Understanding the analysis requires some knowledge of implementation nomenclature:</para><variablelist><varlistentry><term><literal moreinfo="none">upibp</literal></term><listitem><para>A pointer to the in-kernel state associated with a held <indexterm id="idx-CHP-22-1864" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>user-level priority inheriting lock; the <literal moreinfo="none">upib_lock</literal> is the lock that protects this state.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">t_wchan</literal></term><listitem><para>The member of the thread structure that contains the pointer to the synchronization primitive upon which the thread (if any) is blocked.<footnote id="CHP-22-FNOTE-4"><para><literal moreinfo="none">wchan</literal> stands for <emphasis>wait channel</emphasis>, a term that dates back to the earliest days of UNIX at Bell Labs, and is itself almost certainly a bastardization of event <emphasis>channels</emphasis> from Multics.</para></footnote></para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">SOBJ_TYPE</literal></term><listitem><para>A macro that takes the ops vector for a synchronization primitive and returns a constant denoting the type; <literal moreinfo="none">SOBJ_USER_PI</literal> is the constant that denotes a <indexterm id="idx-CHP-22-1865" significance="normal"><primary>priority inheritance</primary><secondary>user-level</secondary></indexterm>user-level, priority-inheriting lock.</para></listitem></varlistentry></variablelist><para>The essence of the problem is this: <indexterm id="idx-CHP-22-1866" significance="normal"><primary>priority inheritance</primary><secondary>implementing for user-level locks</secondary></indexterm>for user-level locks, we normally keep track of the state associated with the lock (e.g., whether or not there's a waiter) at user-level—that information is considered purely advisory by the kernel. (There are several situations in which the waiters bit can't be trusted, and the kernel knows not to trust it in these situations.)</para><para>To implement <indexterm id="idx-CHP-22-1867" significance="normal"><primary>priority inheritance</primary></indexterm>priority inheritance for user-level locks, however, one must become much more precise about ownership; the ownership must be tracked the same way we track ownership for kernel-level synchronization primitives. That is, when we're doing the complicated thread lock dance in <literal moreinfo="none">turnstile_interlock()</literal>, we can't be doing loads from user-level memory to determine ownership. The nasty implication of this is that the kernel-level state tracking the <indexterm id="idx-CHP-22-1868" significance="normal"><primary>ownership of locks</primary></indexterm>ownership of the user-level lock must itself be protected by a lock, and that (in-kernel) lock must itself implement priority inheritance to avoid a potential inversion.</para><para>This leads us to a deadlock that we did not predict: the in-kernel lock must be acquired and dropped both to acquire the user-level lock <emphasis>and</emphasis> to drop it. That is, there are conditions in which a thread owns the in-kernel lock and wants the user-level lock, and there are conditions in which a thread owns the user-level lock and wants the in-kernel lock. As a result, there can exist blocking chains that appear circular—which will cause the kernel to induce an explicit panic. And indeed, that's exactly what happened in the failure analyzed above: thread A owned the user-level lock and wanted the in-kernel lock <literal moreinfo="none">(upib_lock)</literal>, and thread B owned the in-kernel lock and wanted the user-level lock—deadlock!</para><para>Once I understood the problem, it was disconcertingly easy to reproduce: in a few minutes I was able to pound out a test case that panicked the system in the same manner as seen in the <indexterm id="idx-CHP-22-1869" significance="normal"><primary>core dump</primary></indexterm>dump. (As an aside, this is one of the most gratifying feelings in software engineering: analyzing a failure postmortem, discovering that the bug should be easily reproduced, writing a test case testing the hypothesis, and then watching the system blow up just as you predicted. Nothing quite compares to this feeling; it's the software equivalent of the walk-off home run.)</para><para>While I had some ideas on how to fix this, the late date in the release and the seriousness of the problem prompted me to call Jeff at home to discuss. As Jeff and I discussed the problem, we couldn't seem to come up with a potential solution that didn't introduce a new problem. Indeed, the more we talked about the problem, the harder it seemed—and we realized that we had erred originally, both by underestimating the problem and by delegating its solution.</para><para>Worse, Jeff and I began to realize that there must be another manifestation lurking. We knew that if one were blocking on the in-kernel lock when the false deadlock was discovered, the kernel would explicitly panic. But what if one were blocking on the <indexterm id="idx-CHP-22-1870" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>user-level lock when the false deadlock was discovered? We quickly determined (and a test case con-firmed) that in this case, the attempt to acquire the <indexterm id="idx-CHP-22-1871" significance="normal"><primary>priority inheritance</primary><secondary>user-level</secondary></indexterm>user-level lock would (erroneously) return <literal moreinfo="none">EDEADLK</literal>. That is, the kernel would see that the "deadlock" was induced by a user-level synchronization primitive, and therefore assume that it was an application-induced deadlock—a bug in the application.</para><para>So in this failure mode, a correct program would have one of its calls to <literal moreinfo="none">pthread_mutex_lock</literal> erroneously fail—a failure mode even more serious than a panic, because any application that didn't check the return value of <literal moreinfo="none">pthread_mutex_lock</literal> (as one well might not) could easily corrupt its own data by assuming that it owned a lock that, in fact, it had failed to acquire.</para><para>This problem, if encountered in the wild, would be virtually undebuggable—it absolutely had to be fixed.</para><para>So, how to solve these problems? We found this to be a hard problem because we kept trying to find a way to avoid that in-kernel lock. I have presented the in-kernel lock as a natural constraint on the problem, but that was a conclusion that we came to only with tremendous reluctance. Whenever one of us came up with some scheme to avoid the lock, the other would find some window invalidating the scheme.</para><para>After exhausting ourselves on the alternatives, we were forced to the conclusion that an in-kernel lock was a constraint on the user-level <indexterm id="idx-CHP-22-1872" significance="normal"><primary>priority inheritance</primary></indexterm>priority inheritance problem—and our focus switched from avoiding the situation to detecting it.</para><para>There are two cases to detect: the panic case and the false deadlock case. The false dead-lock case is actually pretty easy to detect and handle, because we always find ourselves at the end of the blocking chain—and we always find that the lock that we own that induced the deadlock is the in-kernel lock passed as a parameter to <literal moreinfo="none">turnstile_block</literal>. Because we know that we have willed our priority to the entire blocking chain, we can just detect this and break out—and that is exactly what that cryptic comment that I added to <literal moreinfo="none">turnstile_ block</literal> described, and what those two lines effected (the in-kernel lock that is passed to <literal moreinfo="none">turnstile_block</literal> is stored in the local variable <literal moreinfo="none">mp</literal>).</para><para>The panic case is nastier to deal with. As a reminder, in this case the thread owns the user-level synchronization object and is blocking trying to acquire the in-kernel lock. We might wish to handle this case in a similar way, by reasoning as follows: if the deadlock ends in the current thread, and the last thread in the blocking chain is blocked on a user-level synchronization object, the deadlock is false. (That is, we might wish to handle this case by a more general handling of the above case.) This is simple, but it's also wrong: it ignores the possibility of an <emphasis>actual</emphasis> application-level deadlock (i.e., an application bug), in which <literal moreinfo="none">EDEADLK</literal> <emphasis>must</emphasis> be returned; a more precise approach is required.</para><para>To deal with this case, we observe that if a blocking chain runs from threads blocked on in-kernel synchronization objects to threads blocked on <indexterm id="idx-CHP-22-1873" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>user-level synchronization objects, we know that we're in this case and <emphasis>only</emphasis> this case.<footnote id="CHP-22-FNOTE-5"><para>Presumably like most other operating systems, <indexterm id="idx-CHP-22-1874" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm>Solaris never executes <indexterm id="idx-CHP-22-1875" significance="normal"><primary>priority inheritance</primary><secondary>user-level</secondary></indexterm>user-level code with kernel-level locks held—and never acquires user-level locks from in-kernel subsystems. This case is thus the only one in which we acquire a user-level lock with a kernel-level lock held.</para></footnote> Because we know that we've caught another thread in code in which it can't be preempted (because we know that the other thread must be in the midst of <literal moreinfo="none">turnstile_block</literal>, which explicitly disables preemption), we can fix this by busy-waiting until the lock changes, and then restarting the <indexterm id="idx-CHP-22-1876" significance="normal"><primary>priority inheritance</primary></indexterm>priority inheritance dance.</para><para>Here's the code to handle this case:<footnote id="CHP-22-FNOTE-6"><para>The code dealing with <literal moreinfo="none">turnstile_loser_lock</literal> didn't actually exist when we wrote this case; that was added to deal with (yet) another problem we discovered as a result of our four-day mind-meld. This problem deserves its own chapter, if only for the great name that Jeff gave it: "dueling losers." Shortly after Jeff postulated its existence, I actually saw a variant of this in the wild—a variant that I dubbed "cascading losers." But the losers—both dueling and cascading—will have to wait for another day.</para></footnote></para><programlisting id="I_programlisting22_tt456" format="linespecific">
	/*
	 * We now have the owner's thread lock. If we are traversing
	 * from non-SOBJ_USER_PI ops to SOBJ_USER_PI ops, then we know
	 * that we have caught the thread while in the TS_SLEEP state,
	 * but holding mp. We know that this situation is transient
	 * (mp will be dropped before the holder actually sleeps on
	 * the SOBJ_USER_PI sobj), so we will spin waiting for mp to
	 * be dropped. Then, as in the turnstile_interlock( ) failure
	 * case, we will restart the priority inheritance dance.
	 */
	if (SOBJ_TYPE(t-&gt;t_sobj_ops) != SOBJ_USER_PI &amp;&amp;
	    owner-&gt;t_sobj_ops != NULL &amp;&amp;
	    SOBJ_TYPE(owner-&gt;t_sobj_ops) == SOBJ_USER_PI) {
	        kmutex_t *upi_lock = (kmutex_t *)t-&gt;t_wchan;

	        ASSERT(IS_UPI(upi_lock));
	        ASSERT(SOBJ_TYPE(t-&gt;t_sobj_ops) == SOBJ_MUTEX);

	        if (t-&gt;t_lockp != owner-&gt;t_lockp)
	                thread_unlock_high(owner);
	        thread_unlock_high(t);
	        if (loser)
	                lock_clear(&amp;turnstile_loser_lock);

	        while (mutex_owner(upi_lock) == owner) {
	                SMT_PAUSE( );
	                continue;
	        }
	        if (loser)
	                lock_set(&amp;turnstile_loser_lock);
	        t = curthread;
	        thread_lock_high(t);
	        continue;
	}
</programlisting><para>Once these problems were fixed, we thought we were done. But further stress testing revealed that an even darker problem lurked—one that I honestly wasn't sure that we would be able to solve.</para><para>This time, the symptoms were different: instead of an explicit panic or an incorrect error value, the operating system simply hung—hard. Taking (and examining) a <indexterm id="idx-CHP-22-1877" significance="normal"><primary>core dump</primary></indexterm>dump of the system revealed that a thread had deadlocked attempting to acquire a thread lock from <literal moreinfo="none">turnstile_block( )</literal>, which had been called recursively from <literal moreinfo="none">turnstile_block( )</literal> via <literal moreinfo="none">mutex_vector_exit( )</literal>, the function that releases a mutex if it is found to have waiters. Given just this state, the problem was clear—and it felt like a punch in the gut.</para><para>Recall that the diabolical (but regrettably required) in-kernel lock needs to be acquired and dropped to either acquire or drop a <indexterm id="idx-CHP-22-1878" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>user-level <indexterm id="idx-CHP-22-1879" significance="normal"><primary>priority inheritance</primary></indexterm>priority-inheriting lock. When blocking on the <indexterm id="idx-CHP-22-1880" significance="normal"><primary>priority inheritance</primary><secondary>user-level locks waiving</secondary></indexterm>user-level lock, the kernel-level lock must be dropped after the thread has willed its priority, as essentially the last thing it does before it actually gives up the CPU via <literal moreinfo="none">swtch()</literal>. (This was the code quoted in part in my original analysis; the code marked <literal moreinfo="none">(2)</literal> in that analysis is the dropping of the kernel-level lock.)</para><para>But if another thread blocks on the kernel-level lock while we are dealing with the mechanics of blocking on the <indexterm id="idx-CHP-22-1881" significance="normal"><primary>priority inheritance</primary><secondary>user-level</secondary></indexterm>user-level lock, we will need to wake that waiter as part of dropping the kernel-level lock. Waking the waiter requires taking the thread lock in the turnstile table associated with the synchronization primitive, and then—in order to <emphasis>waive</emphasis> any inherited priority—acquiring the thread lock of the former holder of the lock (which is to say, the current thread).</para><para>Here's the problem: we are entering the function that waives inherited priority (the <literal moreinfo="none">turnstile_pi_waive()</literal> function) <emphasis>from</emphasis> <literal moreinfo="none">turnstile_block()</literal>, <emphasis>after</emphasis> we already appear to be blocked. In particular, the current thread's thread lock has already been changed to point not to the current CPU's lock, but to the lock for the entry <emphasis>in the turnstile table</emphasis> that corresponds to the user-level lock on which we are actually blocking. So, if the kernel-level lock and the user-level lock happen to hash to the same entry in the turnstile table (as they did in the failure in which we first saw this), the turnstile lock acquired in <literal moreinfo="none">turnstile_lookup()</literal> and the thread lock acquired in <literal moreinfo="none">turnstile_pi_waive()</literal> will be the <emphasis>same lock</emphasis>—and we will have <indexterm id="idx-CHP-22-1882" significance="normal"><primary>deadlock</primary><secondary>single-thread deadlock</secondary></indexterm>single-thread deadlock. Even if these locks happen not to hash to the same entry in the turnstile table, but happen not to be in the lock ordering dictated by <literal moreinfo="none">turnstile_ interlock()</literal>, we have the potential for a classic AB/BA deadlock. Sewage, either way.<indexterm id="idx-CHP-22-1883" significance="normal"><primary>turnstile_pi_waive( ) function</primary></indexterm></para><para>When we understood the problem, it seemed intractable. Given that the fundamental problem was that we were dropping the in-kernel lock after we appeared to be blocked, the tempting course would have been to find a way to eliminate the kernel-level lock. But we knew from our work on the earlier bugs that this line of thought was a dead end; we understood that the in-kernel lock was required, and we knew that it couldn't be dropped until priority had been willed down the entire blocking chain.</para><para>This left us challenging more fundamental assumptions: could we somehow flip the order in <literal moreinfo="none">turnstile_block()</literal> such that we willed priority <emphasis>before</emphasis> modifying the current thread's data structures to indicate that it's asleep? (No, it would introduce a window for priority inversion.) Could we somehow indicate that we are in this state such that the call to <literal moreinfo="none">turnstile_ pi_waive()</literal> from <literal moreinfo="none">turnstile_block()</literal> via <literal moreinfo="none">mutex_vector_enter()</literal> didn't induce the deadlock? (No, as this didn't address the multithreaded deadlock scenario.)</para><para>Whenever we came up with a hypothetical solution, we were quick to see its fatal flaws—and the more we thought about the problem, the more we saw flaws instead of solutions.</para><para>Hopelessness was beginning to set in; it was very frustrating that merely adding the new dimension of user-level <indexterm id="idx-CHP-22-1884" significance="normal"><primary>priority inheritance</primary></indexterm>priority inheritance could invalidate what had seemed to be a perfect mechanism. The spoon had become the barrel, and we felt adrift in sewage.</para><para>As we got up to seek solace in a nearby coffee shop, an idea occurred to us: if <indexterm id="idx-CHP-22-1885" significance="normal"><primary>user-level priority inheritance bug</primary></indexterm>user-level priority inheritance was the problem, perhaps we were being overly general in our thinking. Instead of solving this problem at its most abstract, why not deal specifically with <emphasis>this</emphasis> problem by, say, partitioning the turnstile table? We could hash the in-kernel locks protecting the user-level priority inheritance state to one half of the table, and hash every other lock to the other half.</para><para>This would guarantee us that the lock that we would be dropping immediately before calling <literal moreinfo="none">swtch()</literal> in <literal moreinfo="none">turnstile_block()</literal> would <emphasis>necessarily</emphasis> hash to a different entry in the turnstile table than the lock upon which we were blocking. Moreover, by <emphasis>guaranteeing</emphasis> that any kernel-level lock protecting the state of a user-level priority-inheriting lock hashed to a turn-stile table entry with a lower virtual address than any turnstile table entry for any other kind of lock, we would also be guaranteeing that the locking order dictated by <literal moreinfo="none">turnstile_ interlock()</literal> would always be observed; we would be solving both the single-threaded and multithreaded cases.</para><para>On the one hand, this solution seemed like some pretty gross special-casing; it would mean putting knowledge of one specific kind of lock (the lock protecting in-kernel, user-level priority inheritance state) into the generic turnstile system. On the other hand, we were certain that it would work, and it would be a reasonably straightforward and low-risk change—which was very important considering that we were in the final days of a two-year release cycle. It was also clarifying that we didn't have any other ideas; if and until we came up with something more elegant, this was going to have to be it.</para><para>So, Jeff and I discussed the details of our solution over coffee, and he returned to write the block comment explaining our deceptively simple code change. Frankly, given the arguable inelegance of our solution, I was expecting the comment to be something of a confessional, adorned with the usual adjectives used in such comments, like "gross," "disgusting," or "vile."<footnote id="CHP-22-FNOTE-7"><para>Which brings up a good tip: search for these words—along with classic standbys such as "XXX" and "FIXME"—in any source base for which you're curious where the bodies are buried.</para></footnote> But Jeff surprised me with what I believe is the best comment in all of <indexterm id="idx-CHP-22-1886" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm>Solaris—if not all of software:</para><programlisting id="I_programlisting22_tt457" format="linespecific">
	/*
	 * The turnstile hash table is partitioned into two halves: the lower half
	 * is used for upimutextab[] locks, the upper half for everything else.
	 * The reason for the distinction is that SOBJ_USER_PI locks present a
	 * unique problem: the upimutextab[] lock passed to turnstile_block( )
	 * cannot be dropped until the calling thread has blocked on its
	 * SOBJ_USER_PI lock and willed its <indexterm id="idx-CHP-22-1887" significance="normal"><primary>priority inheritance</primary></indexterm>priority down the blocking chain.
	 * At that point, the caller's t_lockp will be one of the turnstile locks.
	 * If mutex_exit( ) discovers that the upimutextab[] lock has waiters, it
	 * must wake them, which forces a lock ordering on us: the turnstile lock
	 * for the upimutextab[] lock will be acquired in mutex_vector_exit( ),
	 * which will eventually call into turnstile_pi_waive( ), which will then
	 * acquire the caller's thread lock, which in this case is the turnstile
	 * lock for the SOBJ_USER_PI lock. In general, when two turnstile locks
	 * must be held at the same time, the lock order must be the address order.
	 * Therefore, to prevent deadlock in turnstile_pi_waive( ), we must ensure
	 * that upimutextab[] locks *always* hash to lower addresses than any
	 * other locks.  <userinput moreinfo="none">You think this is cheesy?  Let's see you do better</userinput>.
	 */
	#define TURNSTILE_HASH_SIZE     128            /* must be power of 2 */
	#define TURNSTILE_HASH_MASK     (TURNSTILE_HASH_SIZE - 1)
	#define TURNSTILE_SOBJ_HASH(sobj)       \
	        ((((ulong_t)sobj &gt;&gt; 2) + ((ulong_t)sobj &gt;&gt; 9)) &amp; TURNSTILE_HASH_MASK)
	#define TURNSTILE_SOBJ_BUCKET(sobj)             \
	        ((IS_UPI(sobj) ? 0 : TURNSTILE_HASH_SIZE) + TURNSTILE_SOBJ_HASH(sobj))
	#define TURNSTILE_CHAIN(sobj)   turnstile_table[TURNSTILE_SOBJ_BUCKET(sobj)]

	typedef struct turnstile_chain {
	        turnstile_t     *tc_first;      /* first turnstile on hash chain */
	        disp_lock_t     tc_lock;        /* lock for this hash chain */
	} turnstile_chain_t;

	turnstile_chain_t       turnstile_table[2 * TURNSTILE_HASH_SIZE];
</programlisting><para>The tone of Jeff's comment much more accurately conveyed our sentiment than the confessional that I was envisioning: we implemented this solution not because we were defeated, but because it was the only way to conquer one of the most challenging problems that either of us had ever faced. And some may think it cheesy, but in the seven years since this code has integrated, no one has done better—and as of this writing, it seems unlikely that anyone ever will. To me at least, that's about as beautiful as code can get—cheesy or not.</para><para>So, the story had a happy ending: we integrated the fixes, and shipped the product on time. But the experience served to remind us of several principles of good <indexterm id="idx-CHP-22-1888" significance="normal"><primary>software engineering principles</primary></indexterm>software engineering:<indexterm id="I_indexterm22_tt458" class="endofrange" startref="idx-CHP-22-1831" significance="normal"><primary>priority inheritance</primary></indexterm><indexterm id="I_indexterm22_tt459" class="endofrange" startref="idx-CHP-22-1819" significance="normal"><primary>locking</primary><secondary>Solaris user-level priority inheritance bug</secondary></indexterm></para><variablelist><varlistentry><term><emphasis>Implement early</emphasis></term><listitem><para>None of the problems that we faced was foreseen by Jeff or me, despite the fact that we had both spent time thinking about the problem during its design and implementation. Indeed, even after we encountered the initial bugs and were thus revisiting the problem very closely, the deeper problem still didn't occur to us; we had to encounter it to understand it.</para></listitem></varlistentry><varlistentry><term><emphasis>Pound on it</emphasis></term><listitem><para>We would have encountered these issues much, much earlier if the original engineer had implemented stress tests instead of relying exclusively on functional tests. As software engineers, <emphasis>we are responsible for our own stress tests</emphasis>. Those that don't believe this—those have some patrician notion that writing such tests is too coarse for the delicate hands of a Gentleman Engineer—will deliver chronically broken software. This is not to say that one shouldn't have test engineers or organizations—just that the tests generated by those engineers and organizations should be thought of as supplementing the tests written by the original implementers, not replacing them.</para></listitem></varlistentry><varlistentry><term><emphasis>Focus on the edge conditions</emphasis></term><listitem><para>Part of the reason that young software engineers should cut their teeth debugging complicated systems is that it inculcates a lifelong skill: the ability to analyze a solution to a problem in terms of the ways that it <emphasis>won't</emphasis> work instead of the ways that it might—the ability to focus on the edge conditions. When conceiving of new software, we software engineers should not try to convince ourselves why our design will work; we should invalidate the reasons why it will not. This is not to advocate overanalysis in lieu of writing code, but rather to suggest that the first code written on any project should be the code in which bugs may invalidate larger design ideas.</para></listitem></varlistentry></variablelist><para>If these principles are applied, one will naturally gravitate to implementing the hardest problems at the earliest phase in any given project, and to putting in place the infrastructure to validate that that infrastructure works (and remains working). This won't eliminate the sewage, but it will assure that the most fetid spoonfuls are caught as early as possible, when design changes are still possible—and when the wine can still be saved.</para></chapter><chapter id="distributed_programming_with_mapReduce" label="23" role=""><title>Distributed Programming with MapReduce</title><para><emphasis>Jeffrey Dean and Sanjay Ghemawat</emphasis><indexterm class="startofrange" id="idx-CHP-23-1889" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm><indexterm id="idx-CHP-23-1890" significance="normal"><primary>Dean</primary></indexterm><indexterm id="idx-CHP-23-1891" significance="normal"><primary>Ghemawat</primary></indexterm></para><para><emphasis>This chapter describes the design and implementation of mapreduce</emphasis>, a programming system for large-scale data processing problems. <indexterm id="idx-CHP-23-1892" significance="normal"><primary>Google</primary><secondary>MapReduce</secondary></indexterm>MapReduce was developed as a way of simplifying the development of large-scale computations at Google. MapReduce programs are automatically parallelized and executed on a large cluster of commodity machines. The runtime system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required intermachine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system.<indexterm class="startofrange" id="idx-CHP-23-1893" significance="normal"><primary>MapReduce</primary></indexterm></para><sect1 id="a_motivating_example" label="23.1"><title>A Motivating Example</title><para>Suppose that you have 20 billion documents, and you want to generate a count of how often each unique <indexterm class="startofrange" id="idx-CHP-23-1894" significance="normal"><primary>word count program (example)</primary></indexterm>word occurs in the documents. With an average document size of 20 KB, just reading through the 400 terabytes of data on one machine will take roughly four months. Assuming we were willing to wait that long and that we had a machine with sufficient memory, the code would be relatively simple. <xref linkend="naiumlve_nonparallel_word_count_program"/> (all the examples in this chapter are pseudocode) shows a possible algorithm.</para><example id="naiumlve_nonparallel_word_count_program" label="23-1"><title>Naïve, nonparallel word count program</title><programlisting format="linespecific">
map&lt;string, int&gt; word_count;
for each document d {
  for each word w in d {
    word_count[w]++;
  }
 }
... save word_count to persistent storage ...
</programlisting></example><para>One way of speeding up this computation is to perform the same computation in parallel across each individual document, as shown in <xref linkend="parallelized_word_count_program"/>.<indexterm id="idx-CHP-23-1895" significance="normal"><primary>word count program (example)</primary><secondary>parallelized</secondary></indexterm></para><example id="parallelized_word_count_program" label="23-2"><title>Parallelized word count program</title><programlisting format="linespecific">
Mutex lock; // Protects word_count
map&lt;string, int&gt; word_count;
for each document d in parallel {
  for each word w in d {
    lock.Lock();
    word_count[w]++;
    lock.Unlock();
  }
}
... save word_count to persistent storage ...
</programlisting></example><para>The preceding code nicely parallelizes the input side of the problem. In reality, the code to start up threads would be a bit more complex, since we've hidden a bunch of details by using pseudocode. One problem <indexterm id="idx-CHP-23-1896" significance="normal"><primary>parallelized word count program (example)</primary><secondary>with partitioned storage</secondary></indexterm>with <xref linkend="parallelized_word_count_program"/> is that it uses a single global data structure for keeping track of the generated counts. As a result, there is likely to be significant lock contention with the <literal moreinfo="none">word_count</literal> data structure as the bottleneck. This problem can be fixed by partitioning the <literal moreinfo="none">word_count</literal> data structure into a number of buckets with a separate lock per bucket, as shown in <xref linkend="parallelized_word_count_program_with_partitioned_storage"/>.<indexterm id="idx-CHP-23-1897" significance="normal"><primary>parallelized word count program (example)</primary></indexterm></para><example id="parallelized_word_count_program_with_partitioned_storage" label="23-3"><title>Parallelized word count program with partitioned storage</title><programlisting format="linespecific">
struct CountTable {
  Mutex lock;
  map&lt;string, int&gt; word_count;
};
const int kNumBuckets = 256;
CountTable tables[kNumBuckets];
for each document d in parallel {
  for each word w in d {
    int bucket = hash(w) % kNumBuckets;
    tables[bucket].lock.Lock();
    tables[bucket].word_count[w]++;
    tables[bucket].lock.Unlock();
  }
}
for (int b = 0; b &lt; kNumBuckets; b++) {
  ... save tables[b].word_count to persistent storage ...
}
</programlisting></example><para>The program is still quite simple. However, it cannot scale beyond the number of processors in a single machine. Most affordable machines have eight or fewer processors, so even <indexterm id="idx-CHP-23-1898" significance="normal"><primary>parallelized word count program (example)</primary><secondary>with partitioned processors</secondary></indexterm>with perfect scaling, this approach will still require multiple weeks of processing to complete. Furthermore, we have been glossing over the problem of where the input data is stored and how fast it can be read by one machine.<indexterm id="idx-CHP-23-1899" significance="normal"><primary>partitioned storage for parallelized program</primary></indexterm></para><para>Further scaling requires that we distribute the data and the computation across multiple machines. For the moment, let's assume that the machines do not fail. One way to increase scaling is to start many processes on a cluster of networked machines. We will have many input processes, each one responsible for reading and processing a subset of the documents. We will also have many output processes, each responsible for managing one of the <literal moreinfo="none">word_count</literal> buckets. <xref linkend="parallelized_word_count_program_with_partitioned_processors"/> shows the algorithm.</para><example id="parallelized_word_count_program_with_partitioned_processors" label="23-4"><title>Parallelized word count program with partitioned processors</title><programlisting format="linespecific">
const int M = 1000;     // Number of input processes
const int R = 256;     // Number of output processes
main() {
  // Compute the number of documents to assign to each process
  const int D = number of documents / M;
  for (int i = 0; i &lt; M; i++) {
    fork InputProcess(i * D, (i + 1) * D);
  }
  for (int i = 0; i &lt; R; i++) {
    fork OutputProcess(i);
  }
  ... wait for all processes to finish ...
}

void InputProcess(int start_doc, int end_doc) {
  map&lt;string, int&gt; word_count[R];   // Separate table per output process
  for each doc d in range [start_doc .. end_doc-1] do {
    for each word w in d {
      int b = hash(w) % R;
      word_count[b][w]++;
    }
  }

  for (int b = 0; b &lt; R; b++) {
    string s = EncodeTable(word_count[b]);
    ... send s to output process b ...
  }
}

void OutputProcess(int bucket) {
  map&lt;string, int&gt; word_count;
  for each input process p {
    string s = ... read message from p ...
    map&lt;string, int&gt; partial = DecodeTable(s);
    for each &lt;word, count&gt; in partial do {
      word_count[word] += count;
    }
  }
  ... save word_count to persistent storage ...
}
</programlisting></example><para>This approach scales nicely on a network of workstations, but is significantly more complicated and hard to understand (even though we've hidden the details of marshaling and unmarshaling, as well as starting and synchronizing different processes). It also does not deal gracefully with machine failures. To deal with failures, we would extend <xref linkend="parallelized_word_count_program_with_partitioned_processors"/> to re-execute processes that failed before completion. To avoid double-counting data when we re-execute an input process, we would mark each piece of intermediate data with a generation number of the input process and modify the output processing so that it uses these generation numbers to discard duplicates. As you can imagine, adding this failure-handling support would further complicate things.<indexterm id="idx-CHP-23-1900" significance="normal"><primary>word count program (example)</primary></indexterm><indexterm id="idx-CHP-23-1901" significance="normal"><primary>partitioned processors for parallelized program</primary></indexterm></para></sect1><sect1 id="the_mapreduce_programming_model" label="23.2"><title>The MapReduce Programming Model</title><para>If you compare <xref linkend="naiumlve_nonparallel_word_count_program"/> with <xref linkend="parallelized_word_count_program_with_partitioned_processors"/>, you'll find that the simple task of counting words has been buried under lots of details about managing parallelism. If we can somehow separate the details of the original problem from the details of parallelization, we may be able to produce a general parallelization library or system that can be applied not just to this word-counting problem, but other large-scale processing problems. The parallelization pattern that we are using is:<indexterm id="idx-CHP-23-1902" significance="normal"><primary>distributed programming with MapReduce</primary><secondary>programming model</secondary></indexterm><indexterm id="idx-CHP-23-1903" significance="normal"><primary>MapReduce</primary></indexterm><indexterm id="idx-CHP-23-1904" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm></para><itemizedlist><listitem><para>For each input record, extract a set of key/value pairs that we care about from each record.</para></listitem><listitem><para>For each extracted key/value pair, combine it with other values that share the same key (perhaps filtering, aggregating, or transforming values in the process).</para></listitem></itemizedlist><para>Let's rewrite our program to implement the application-specific logic of counting word frequencies for each document and summing these counts across documents in two functions that we'll call Map and Reduce. The result is <xref linkend="division_of_word_counting_problem_into_map_and_reduce"/>.</para><example id="division_of_word_counting_problem_into_map_and_reduce" label="23-5"><title>Division of word counting problem into Map and Reduce</title><programlisting format="linespecific">
void Map(string document) {
  for each word w in document {
    EmitIntermediate(w, "1");
  }
}

void Reduce(string word, list&lt;string&gt; values) {
  int count = 0;
  for each v in values {
    count += StringToInt(v);
  }
  Emit(word, IntToString(count));
}
</programlisting></example><para>A simple <indexterm id="idx-CHP-23-1905" significance="normal"><primary>driver program for Map and Reduce functions (example)</primary></indexterm>driver program that uses these routines to accomplish the desired task on a single machine would look like <xref linkend="driver_for_map_and_reduce"/>.<indexterm id="idx-CHP-23-1906" significance="normal"><primary>word count program (example)</primary><secondary>division of problem into Map and Reduce functions</secondary></indexterm><indexterm id="idx-CHP-23-1907" significance="normal"><primary>word count program (example)</primary></indexterm><indexterm id="I_indexterm23_tt460" class="endofrange" startref="idx-CHP-23-1894" significance="normal"><primary>word count program (example)</primary></indexterm></para><example id="driver_for_map_and_reduce" label="23-6"><title>Driver for Map and Reduce</title><programlisting format="linespecific">
map&lt;string, list&lt;string&gt; &gt; intermediate_data;

void EmitIntermediate(string key, string value) {
  intermediate_data[key].append(value);
}

void Emit(string key, string value) {
  ... write key/value to final data file ...
}

void Driver(MapFunction mapper, ReduceFunction reducer) {
  for each input item do {
    mapper(item)
  }
  for each key k in intermediate_data {
    reducer(k, intermediate_data[k]);
  }
}

main() {
  Driver(Map, Reduce);
}
</programlisting></example><para>The Map function is called once for each input record. Any intermediate key/value pairs emitted by the Map function are collected together by the driver code. Then, the Reduce function is called for each unique intermediate key, together with a list of intermediate values associated with that key.</para><para>We're now back to an implementation that runs on a single machine. However, with things separated in this manner, we can now change the implementation of the driver program to make it deal with distribution, automatic parallelization, and fault tolerance without affecting the application-specific logic in the Map and Reduce functions. Furthermore, the driver is independent of the particular application logic implemented by the Map and Reduce functions, and therefore the same driver program can be reused with other Map and Reduce functions to solve different problems. Finally, notice that the Map and Reduce functions that implement the application-specific logic are nearly as understandable as the simple sequential code shown in <xref linkend="naiumlve_nonparallel_word_count_program"/>.</para></sect1><sect1 id="other_mapreduce_examples" label="23.3"><title>Other MapReduce Examples</title><para>We'll examine the implementation of a much more sophisticated driver program that automatically runs MapReduce programs on large-scale clusters of machines in a moment, but first, let's consider a few other problems and how they can be solved using Map-Reduce:<indexterm id="idx-CHP-23-1908" significance="normal"><primary>MapReduce</primary></indexterm></para><variablelist><varlistentry><term><emphasis>Distributed grep</emphasis></term><listitem><para>The Map function emits a line if it matches a supplied regular expression pattern. The Reduce function is an identity function that just copies the supplied intermediate data to the output.<indexterm id="idx-CHP-23-1909" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Reverse web-link graph</emphasis></term><listitem><para>A <indexterm id="idx-CHP-23-1910" significance="normal"><primary>forward web link graph</primary></indexterm>forward web-link graph is a graph that has an edge from node URL1 to node URL2 if the web page found at URL1 has a hyperlink to URL2. A <indexterm id="idx-CHP-23-1911" significance="normal"><primary>distributed programming with MapReduce</primary><secondary>reverse web-link graph</secondary></indexterm>reverse web-link graph is the same graph with the edges reversed. <indexterm id="idx-CHP-23-1912" significance="normal"><primary>MapReduce</primary></indexterm>MapReduce can easily be used to construct a reverse web-link graph. The Map function outputs <emphasis>&lt;target, source&gt;</emphasis> pairs for each link to a target URL found in a document named <emphasis>source</emphasis>. The Reduce function concatenates the list of all source URLs associated with a given target URL and emits the pair <emphasis>&lt;target, list of source URLs&gt;</emphasis>.<indexterm id="idx-CHP-23-1913" significance="normal"><primary>reverse web link graph</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Term vector per host</emphasis></term><listitem><para>A term vector summarizes the most important words that occur in a document or a set of documents as a list of <emphasis>&lt;word, frequency&gt;</emphasis> pairs. The Map function emits a <emphasis>&lt;hostname, term vector&gt;</emphasis> pair for each input document (where the hostname is extracted from the URL of the document). The Reduce function is passed all per-document term vectors for a given host. It adds these term vectors, throwing away infrequent terms, and then emits a final <emphasis>&lt;hostname, term vector&gt;</emphasis> pair.<indexterm id="idx-CHP-23-1914" significance="normal"><primary>term vector per host</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Inverted index</emphasis></term><listitem><para>An <indexterm id="idx-CHP-23-1915" significance="normal"><primary>distributed programming with MapReduce</primary><secondary>inverted index</secondary></indexterm>inverted index is a data structure that maps from each unique word to a list of documents that contain the word (where the documents are typically identified with a numeric identifier to keep the inverted index data relatively compact). The Map function parses each document and emits a sequence of <emphasis>&lt;word, docid&gt;</emphasis> pairs. The Reduce function accepts all docids for a given word, sorts the corresponding document IDs, and emits a <emphasis>&lt;word, list of docids&gt;</emphasis> pair. The set of all output pairs forms a simple inverted index. It is easy to augment this computation to keep track of word positions within each document.<indexterm id="idx-CHP-23-1916" significance="normal"><primary>inverted index</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Distributed sort</emphasis></term><listitem><para><indexterm id="idx-CHP-23-1917" significance="normal"><primary>MapReduce</primary></indexterm>MapReduce can also be used to sort data by a particular key. The Map function extracts the key from each record, and emits a <emphasis>&lt;key, record&gt;</emphasis> pair. The Reduce function emits all pairs unchanged (i.e., the identity Reduce function). This computation depends on the partitioning facilities and ordering properties described later in this chapter.<indexterm id="idx-CHP-23-1918" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm></para></listitem></varlistentry></variablelist><para>There are many more examples of computations that can easily be expressed as a Map-Reduce computation. For more complex computations, it is often easy to express them as a sequence of MapReduce steps or as an iterative application of a MapReduce computation, where the output of one MapReduce step is the input to the next MapReduce step.</para><para>One you start thinking of data processing problems in terms of MapReduce, they are often relatively easy to express. As some testament to this, over the last four years, the number of <indexterm id="idx-CHP-23-1919" significance="normal"><primary>Google</primary><secondary>MapReduce programs</secondary></indexterm>MapReduce programs at Google has gone from a small handful of candidate problems in March 2003 (when we started to design MapReduce) to more than 6,000 distinct MapReduce programs in December 2006. These programs were written by more than a thousand different software developers, many of whom had never written a parallel or <indexterm id="idx-CHP-23-1920" significance="normal"><primary>distributed programming with MapReduce</primary><secondary>distributed sort</secondary></indexterm>distributed program before using MapReduce.</para></sect1><sect1 id="a_distributed_mapreduce_implementation" label="23.4"><title>A Distributed MapReduce Implementation</title><para>Much of the benefit of the MapReduce programming model is that it nicely separates the expression of the desired computation from the underlying details of parallelization, failure handling, etc. Indeed, different implementations of the MapReduce programming model are possible for different kinds of computing platforms. The right choice depends on the environment. For example, one implementation may be suitable for a small shared-memory machine, another for a large NUMA multiprocessor, and yet another for an even larger collection of networked machines.<indexterm id="idx-CHP-23-1921" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm><indexterm id="idx-CHP-23-1922" significance="normal"><primary>MapReduce</primary></indexterm><indexterm id="idx-CHP-23-1923" significance="normal"><primary>sorting</primary><secondary>distributed</secondary></indexterm></para><para>A very simple single-machine implementation that supports the programming model was shown in the code fragment in <xref linkend="driver_for_map_and_reduce"/>. This section describes a more complex implementation that is targeted to running large-scale MapReduce jobs on the computing environment in wide use at Google: large clusters of commodity PCs connected together with switched Ethernet (see "Further Reading," at the end of this chapter). In this environment:</para><itemizedlist><listitem><para>Machines are typically dual-processor x86 processors running Linux, with 2–4 GB of memory per machine.</para></listitem><listitem><para>Machines are connected using commodity-networking hardware (typically 1 gigabit/ second switched Ethernet). Machines are organized into racks of 40 or 80 machines. These racks are connected to a central switch for the whole cluster. The bandwidth available when talking to other machines in the same rack is 1 gigabit/second per machine, while the per-machine bandwidth available at the central switch is much smaller (usually 50 to 100 megabits/second per machine).</para></listitem><listitem><para>Storage is provided by inexpensive IDE disks attached directly to individual machines. A distributed filesystem called <indexterm id="idx-CHP-23-1924" significance="normal"><primary>GFS (Google File System)</primary></indexterm>GFS (see the reference to "The Google File System" under "Further Reading," at the end of this chapter) is used to manage the data stored on these disks. GFS uses replication to provide availability and reliability on top of unreliable hardware by breaking files into chunks of 64 megabytes and storing (typically) 3 copies of each chunk on different machines.</para></listitem><listitem><para>Users submit jobs to a scheduling system. Each job consists of a set of tasks and is mapped by the scheduler to a set of available machines within a cluster.</para></listitem></itemizedlist><sect2 id="execution_overview" label="23.4.1"><title>Execution Overview</title><para>The Map function invocations are distributed across multiple machines by automatically partitioning the input data into a set of <emphasis>M</emphasis> splits. The input splits can be processed in parallel by different machines. Reduce invocations are distributed by partitioning the intermediate key space into <emphasis>R</emphasis> pieces using a partitioning function (e.g., <literal moreinfo="none">hash(key) %</literal> <emphasis>R</emphasis>).<indexterm id="idx-CHP-23-1925" significance="normal"><primary>distributed programming with MapReduce</primary><secondary>distributed implementation</secondary><tertiary>execution overview</tertiary></indexterm></para><para><xref linkend="relationships_between_processes_in_mapreduce"/> shows the actions that occur when the user program calls the MapReduce function (the numbered labels in <xref linkend="relationships_between_processes_in_mapreduce"/> correspond to the numbers in the following list).</para><figure id="relationships_between_processes_in_mapreduce" label="23-1" float="0"><title>Relationships between processes in MapReduce</title><mediaobject id="I_mediaobject23_tt461"><imageobject role="print"><imagedata fileref="figs/print/beauty_2301.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2301.png" format="PNG"/></imageobject></mediaobject></figure><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>The MapReduce library first splits the input files into <emphasis>M</emphasis> pieces (typically 16 megabytes to 64 megabytes per piece). It then starts up many copies of the program on a cluster of machines, by making a request to the cluster scheduling system.<indexterm id="idx-CHP-23-1926" significance="normal"><primary>MapReduce</primary></indexterm></para></listitem><listitem><para>One of the copies is special and is called the MapReduce <emphasis>master</emphasis>. The remaining tasks are assigned chunks of Map and Reduce work by the master. There are <emphasis>M</emphasis> map tasks and <emphasis>R</emphasis> reduce tasks. The master picks idle workers and assigns a map and/or a reduce task to each.</para></listitem><listitem><para>A worker that is assigned a map task reads the contents of the corresponding input split. It passes each input record to the user-defined Map function. The intermediate key/value pairs produced by the Map function are buffered in memory.</para></listitem><listitem><para>Periodically, the buffered pairs are written to local disk, partitioned into <emphasis>R</emphasis> separate buckets by the partitioning function. When the map task is completed, the worker notifies the master. The master forwards information about the location of the intermediate data generated by this map task to any workers that have been assigned reduce tasks. If there are remaining map tasks, the master assigns one of the remaining tasks to the newly idle worker.</para></listitem><listitem><para>When a reduce worker is told the locations of intermediate data for its reduce task, it issues remote procedure calls to read the buffered intermediate data from the local disk of the map workers. When a reduce worker has finished reading all intermediate data for its reduce task, it sorts it by the intermediate keys so that all occurrences of the same intermediate key are grouped together. If the intermediate data is too large to fit in memory on the reduce worker, an external sort is used.</para></listitem><listitem><para>The reduce worker iterates over the sorted intermediate key/value pairs. For each unique intermediate key encountered, it passes the key and the corresponding list <indexterm id="idx-CHP-23-1927" significance="normal"><primary>GFS (Google File System)</primary><secondary>management of input data</secondary></indexterm>of intermediate values to the user's Reduce function. Any key/value pairs generated by the user's Reduce function are appended to a final output file for this reduce partition. When the reduce task is done, the worker notifies the master. If there are remaining reduce tasks, the master assigns one of the remaining reduce tasks to the newly idle worker.</para></listitem></orderedlist><para>When all map tasks and reduce tasks have been completed, the <indexterm id="idx-CHP-23-1928" significance="normal"><primary>MapReduce</primary></indexterm>MapReduce function call in the user program returns, giving control back to the user code. At this point, the output of the MapReduce job is available in the <emphasis>R</emphasis> output files (one file per reduce task).</para><para>Several details of the implementation allow it to perform well in our environment.</para><variablelist><varlistentry><term><emphasis>Load balancing</emphasis></term><listitem><para>A MapReduce job typically has many more tasks than machines, which means that each worker will be assigned many different tasks by the master. The master assigns a new task to a machine when it finishes its previous task. This means that a faster machine will be assigned more tasks than a slower machine. Therefore, the assignment of tasks to machine is properly balanced even in a heterogeneous environment, and workers tend to be kept busy with useful work throughout the computation.<indexterm id="idx-CHP-23-1929" significance="normal"><primary>load balancing</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Fault tolerance</emphasis></term><listitem><para>Because this implementation of MapReduce is designed to run jobs <indexterm id="idx-CHP-23-1930" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm>distributed across hundreds or thousands of machines, the library must transparently handle machine failures.<indexterm id="idx-CHP-23-1931" significance="normal"><primary>fault tolerance</primary></indexterm></para><para>The master keeps state about which map and reduce tasks have been done by which workers. The master periodically sends a ping remote procedure call to each worker. If a worker does not respond to several consecutive pings, the master declares that worker as dead and assigns any work that was done by that worker to other machines for re-execution. Since a typical MapReduce execution might have 50 times as many map tasks as worker machines, recovery is very fast, because 50 separate machines can each pick up one map task for re-execution when a machine fails.</para><para>The master logs all updates of its scheduling state to a persistent logfile. If the master dies (a rare occurrence, since there is only one master), it is restarted by the cluster scheduling system. The new master instance reads the logfile to reconstruct its internal state.</para></listitem></varlistentry><varlistentry><term><emphasis>Locality</emphasis></term><listitem><para>Our MapReduce implementation conserves network bandwidth by taking advantage of the fact that the input data (managed by GFS) is stored on the same machines or racks on which the map computation is executed. For any given Map task, the MapReduce master finds the locations of the input data (there are typically multiple locations due to GFS's replication). The master then tries to schedule the map task on a machine that is close to one of the replicas of the tasks's input data. For large MapReduce jobs that use thousands of workers, most input data is read directly from local disk.<indexterm id="idx-CHP-23-1932" significance="normal"><primary>locality</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Backup tasks</emphasis></term><listitem><para>The running time of <indexterm id="idx-CHP-23-1933" significance="normal"><primary>MapReduce</primary></indexterm>MapReduce is often dominated by a few stragglers. (A straggler is any machine that takes a long time to execute one of the last few map or reduce tasks.) A task may take a long time to execute either because it is intrinsically expensive, or because it is running on a slow machine.<indexterm id="idx-CHP-23-1934" significance="normal"><primary>backup tasks</primary></indexterm></para><para>A machine might be slow for a wide variety of reasons. For example, the machine might be busy with other unrelated CPU-intensive processes, or the machine might have a faulty hard drive that causes frequent retries of read operations that slow disk reads by factors of 10 or 100.</para><para>We use backup tasks to solve the problem of stragglers. When there are only a few map tasks left, the master schedules (on idle workers) one backup execution for each of the remaining in-progress map tasks. Each remaining map task is marked as completed whenever one of the instances of the task finishes (the primary or the backup). A similar strategy is used for reduce tasks. We typically use just 1–2 percent additional computational resources for backup tasks, but have found that they significantly shorten the typical completion time of large <indexterm id="idx-CHP-23-1935" significance="normal"><primary>sorting</primary><secondary>MapReduce</secondary></indexterm>MapReduce operations.</para></listitem></varlistentry></variablelist></sect2></sect1><sect1 id="extensions_to_the_model" label="23.5"><title>Extensions to the Model</title><para>Although most uses of MapReduce require just writing Map and Reduce functions, we have extended the basic model with a few features that we have found useful in practice.<indexterm id="idx-CHP-23-1936" significance="normal"><primary>distributed programming with MapReduce</primary><secondary>extensions to the model</secondary></indexterm></para><variablelist><varlistentry><term><emphasis>Partitioning function</emphasis></term><listitem><para>MapReduce users specify the number of reduce tasks/output files that they desire (<emphasis>R</emphasis>). Intermediate data gets partitioned across these tasks using a partitioning function on the intermediate key. A default partitioning function is provided that uses hashing (<literal moreinfo="none">hash(key)%</literal> <replaceable>R</replaceable>) to evenly balance the data across the <emphasis>R</emphasis> partitions.<indexterm id="idx-CHP-23-1937" significance="normal"><primary>partitioning function (MapReduce)</primary></indexterm></para><para>In some cases, however, it is useful to partition data by some other function of the key. For example, sometimes the output keys are URLs, and we want all entries for a single host to end up in the same output file. To support situations like this, the users of the MapReduce library can provide their own custom partitioning function. For example, using <literal moreinfo="none">hash(Hostname(urlkey))%</literal> <replaceable>R</replaceable> as the partitioning function causes all URLs from the same host to end up in the same output file.</para></listitem></varlistentry><varlistentry><term><emphasis>Ordering guarantees</emphasis></term><listitem><para>Our MapReduce implementation sorts the intermediate data to group together all intermediate values that share the same intermediate key. Since many users find it convenient to have their Reduce function called on keys in sorted order, and we have already done all of the necessary work, we expose this to users by guaranteeing this ordering property in the interface to the MapReduce library.<indexterm id="idx-CHP-23-1938" significance="normal"><primary>ordering guarantees (MapReduce)</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Skipping bad records</emphasis></term><listitem><para>Sometimes there are bugs in user code that cause the Map or Reduce functions to crash deterministically on certain records. Such bugs may cause a large MapReduce execution to fail after doing large amounts of computation. The preferred course of action is to fix the bug, but sometimes this is not feasible; <indexterm id="idx-CHP-23-1939" significance="normal"><primary>MapReduce</primary><secondary>resources for further reading</secondary></indexterm>for instance, the bug may be in a third-party library for which source code is not available. Also, it is sometimes acceptable to ignore a few records, such as when doing statistical analysis on a large data set. Thus, we provide an optional mode of execution where the <indexterm id="idx-CHP-23-1940" significance="normal"><primary>MapReduce</primary></indexterm>MapReduce library detects records that cause deterministic crashes and skips these records in subsequent re-executions, in order to make forward progress.<indexterm id="idx-CHP-23-1941" significance="normal"><primary>skipping bad records (MapReduce)</primary></indexterm><indexterm id="idx-CHP-23-1942" significance="normal"><primary>records (faulty)</primary></indexterm></para><para>Each worker process installs a signal handler that catches segmentation violations and bus errors. Before invoking a user Map or Reduce operation, the MapReduce library stores the sequence number of the record in a global variable. If the user code generates a signal, the signal handler sends a "last gasp" UDP packet that contains the sequence number to the MapReduce master. When the master has seen more than one failure on a particular record, it indicates that the record should be skipped when it issues the next re-execution of the corresponding Map or Reduce task.</para><para>A number of other extensions are discussed in a lengthier <indexterm id="idx-CHP-23-1943" significance="normal"><primary>GFS (Google File System)</primary><secondary>paper about design and implementation</secondary></indexterm>paper about MapReduce (see "Further Reading," below).</para></listitem></varlistentry></variablelist></sect1><sect1 id="conclusion-id011" label="23.6"><title>Conclusion</title><para>MapReduce has proven to be a valuable tool at Google. As of early 2007, we have more than 6,000 distinct programs written using the MapReduce <indexterm id="idx-CHP-23-1944" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm>programming model, and run more than 35,000 MapReduce jobs per day, processing about 8 petabytes of input data per day (a sustained rate of about 100 gigabytes per second). Although we originally developed the MapReduce programming model as part of our efforts to rewrite the indexing system for our web search product, it has shown itself to be useful across a very broad range of problems, including machine learning, statistical machine translation, log analysis, information retrieval experimentation, and general large-scale data processing and computation tasks.</para></sect1><sect1 id="further_reading-id001" label="23.7"><title>Further Reading</title><variablelist><varlistentry><term>A more detailed description of MapReduce appeared in the OSDI ‘04 conference:</term><listitem><para>"MapReduce: Simplified Data Processing on Large Clusters." Jeffrey <indexterm id="idx-CHP-23-1945" significance="normal"><primary>Dean</primary></indexterm>Dean and Sanjay <indexterm id="idx-CHP-23-1946" significance="normal"><primary>Ghemawat</primary></indexterm>Ghemawat. Appeared in <emphasis>OSDI '04: Sixth Symposium on Operating System Design and Implementation</emphasis>, San Francisco, CA, December, 2004. Available from <ulink url="http://labs.google.com/papers/mapreduce.html"/>.</para></listitem></varlistentry><varlistentry><term>A paper about the design and implementation of the Google File System appeared in the SOSP ‘03 conference:</term><listitem><para>"The Google File System." Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. <emphasis>19th ACM Symposium on Operating Systems Principles</emphasis>, Lake George, NY, October, 2003. Available from <ulink url="http://labs.google.com/papers/gfs.html"/>.</para></listitem></varlistentry><varlistentry><term>A paper describing the general hardware infrastructure at Google appeared in IEEE Micro:</term><listitem><para>"Web Search for a Planet: The Google Cluster Architecture." Luiz Barroso, Jeffrey <indexterm id="idx-CHP-23-1947" significance="normal"><primary>Dean</primary></indexterm>Dean, and Urs Hoelzle. IEEE Micro, Volume 23, Issue 2 (March 2003), pp. 22–28. Available from <ulink url="http://labs.google.com/papers/googlecluster.html"/>.</para></listitem></varlistentry><varlistentry><term>A language called Sawzall developed at Google for logs analysis runs on top of Map-Reduce:</term><listitem><para>"Interpreting the Data: Parallel Analysis with Sawzall." Rob Pike, Sean Dorward, Robert Griesemer, Sean Quinlan. <emphasis>Scientific Programming Journal</emphasis> Special Issue on Grids and Worldwide Computing Programming Models and Infrastructure 13:4, pp. 227– 298. Available from <ulink url="http://labs.google.com/papers/sawzall.html"/>.<indexterm id="idx-CHP-23-1948" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm><indexterm id="idx-CHP-23-1949" significance="normal"><primary>Sawzall language for logs analysis</primary></indexterm></para></listitem></varlistentry></variablelist></sect1><sect1 id="acknowledgments-id003" label="23.8"><title>Acknowledgments</title><para>A number of people have made substantial contributions to the continued development and improvement of <indexterm id="idx-CHP-23-1950" significance="normal"><primary>MapReduce</primary></indexterm>MapReduce, including Tom Annau, Matt Austern, Chris Colohan, Frank Dabek, Walt Drummond, Xianping Ge, Victoria Gilbert, Shan Lei, Josh Levenberg, Nahush Mahajan, Greg Malewicz, Russell Power, Will Robinson, Ioannis Tsoukalidis, and Jerry Zhao. MapReduce builds on a number of pieces of infrastructure developed at Google, including the Google File System and our cluster scheduling system. We would like to especially thank the developers of those systems. Finally, we thank all the users of Map-Reduce within Google's engineering organization for providing helpful feedback, suggestions, and bug reports.</para></sect1><sect1 id="appendix_word_count_solution" label="23.9"><title>Appendix: Word Count Solution</title><para>This section contains the full C++ <indexterm id="idx-CHP-23-1951" significance="normal"><primary>C++</primary><secondary>implementation of MapReduce word frequency counting example</secondary></indexterm>implementation of the word frequency counting example that was used in the early part of this chapter. The code can also be found on the O'Reilly <indexterm id="idx-CHP-23-1952" significance="normal"><primary>web site for this book</primary></indexterm>web site for this book (<ulink url="http://www.oreilly.com/catalog/9780596510046"/>):<indexterm id="idx-CHP-23-1953" significance="normal"><primary>MapReduce</primary><secondary>word count program (example) C++ implementation</secondary></indexterm><indexterm id="I_indexterm23_tt462" class="endofrange" startref="idx-CHP-23-1889" significance="normal"><primary>distributed programming with MapReduce</primary></indexterm><indexterm id="I_indexterm23_tt463" class="endofrange" startref="idx-CHP-23-1893" significance="normal"><primary>MapReduce</primary></indexterm></para><programlisting id="I_programlisting23_tt464" format="linespecific">
    #include "mapreduce/mapreduce.h"

    // User's map function
    class WordCounter : public Mapper {
     public:
      virtual void Map(const MapInput&amp; input) {
        const string&amp; text = input.value();
        const int n = text.size();
        for (int i = 0; i &lt; n; ) {
          // Skip past leading whitespace
          while ((i &lt; n) &amp;&amp; isspace(text[i]))
            i++;

          // Find word end
          int start = i;
          while ((i &lt; n) &amp;&amp; !isspace(text[i]))
            i++;
          if (start &lt; i)
            EmitIntermediate(text.substr(start,i-start),"1");
        }
      }
    };
    REGISTER_MAPPER(WordCounter);

    // User's reduce function
    class Adder : public Reducer {
      virtual void Reduce(ReduceInput* input) {
        // Iterate over all entries with the
        // same key and add the values
        int64 value = 0;
        while (!input-&gt;done()) {
          value += StringToInt(input-&gt;value());
          input-&gt;NextValue();
        }

        // Emit sum for input-&gt;key()
        Emit(IntToString(value));
      }
    };
    REGISTER_REDUCER(Adder);

    int main(int argc, char** argv) {
      ParseCommandLineFlags(argc, argv);

      <indexterm id="idx-CHP-23-1954" significance="normal"><primary>MapReduce</primary></indexterm>MapReduceSpecification spec;

      // Store list of input files into "spec"
      for (int i = 1; i &lt; argc; i++) {
        MapReduceInput* input = spec.add_input();
        input-&gt;set_format("text");
        input-&gt;set_filepattern(argv[i]);
        input-&gt;set_mapper_class("WordCounter");
      }

      // Specify the output files:
      //    /gfs/test/freq-00000-of-00100
      //    /gfs/test/freq-00001-of-00100
      //    ...
      MapReduceOutput* out = spec.output();
      out-&gt;set_filebase("/gfs/test/freq");
      out-&gt;set_num_tasks(100);
      out-&gt;set_format("text");
      out-&gt;set_reducer_class("Adder");

      // Optional: do partial sums within map
      // tasks to save network bandwidth
      out-&gt;set_combiner_class("Adder");

      // Tuning parameters: use at most 2,000
      // machines and 100 MB of memory per task
      spec.set_machines(2000);
      spec.set_map_megabytes(100);
      spec.set_reduce_megabytes(100);
      // Now run it
      MapReduceResult result;
      if (!MapReduce(spec, &amp;result)) abort( );

      // Done: 'result' structure contains info
      // about counters, time taken, number of
      // machines used, etc.

      return 0;
    }
</programlisting></sect1></chapter><chapter id="beautiful_concurrency" label="24" role=""><title>Beautiful Concurrency</title><para><emphasis>Simon Peyton Jones</emphasis><indexterm class="startofrange" id="idx-CHP-24-1955" significance="normal"><primary>concurrency</primary></indexterm><indexterm id="idx-CHP-24-1956" significance="normal"><primary>Jones</primary></indexterm></para><para><emphasis>The free lunch is over.<footnote id="CHP-24-FNOTE-1"><para>Herb Sutter, "The free lunch is over: a fundamental turn toward concurrency in software," <emphasis>Dr. Dobb's Journal</emphasis>, March 2005.</para></footnote> We have grown used to the idea</emphasis> that our programs will go faster when we buy a next-generation processor, but that time has passed. While that next-generation chip will have more CPUs, each individual CPU will be no faster than the previous year's model. If we want our programs to run faster, we must learn to write <indexterm id="idx-CHP-24-1957" significance="normal"><primary>parallel programs</primary></indexterm>parallel programs.<footnote id="CHP-24-FNOTE-2"><para>Herb Sutter and James Larus, "Software and the concurrency revolution," <emphasis>ACM Queue</emphasis>, Vol. 3, No. 7, September 2005.</para></footnote></para><para><indexterm id="idx-CHP-24-1958" significance="normal"><primary>beautiful code</primary><secondary>parallel programs</secondary></indexterm>Parallel programs execute in a nondeterministic way, so they are hard to test, and bugs can be almost impossible to reproduce. For me, a beautiful program is one that is so simple and elegant that it obviously has no mistakes, rather than merely having no obvious mistakes.<footnote id="CHP-24-FNOTE-3"><para>This turn of phrase is due to Tony Hoare.</para></footnote> If we want to write <indexterm id="idx-CHP-24-1959" significance="normal"><primary>modular programming</primary><secondary>parallel programs less modular</secondary></indexterm>parallel programs that work reliably, we must pay particular attention to beauty. Sadly, parallel programs are often <emphasis>less</emphasis> beautiful than their sequential cousins; in particular they are, as we shall see, less <emphasis>modular</emphasis>.</para><para>In this chapter, I'll describe <emphasis>Software Transactional Memory</emphasis> (<indexterm id="idx-CHP-24-1960" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM), a promising new approach to programming shared-memory parallel processors that seems to support modular programs in a way that current technology does not. By the time we are done, I hope you will be as enthusiastic as I am about STM. It is not a solution to every problem, but it is a beautiful and inspiring attack on the daunting ramparts of <indexterm id="idx-CHP-24-1961" significance="normal"><primary>concurrency</primary></indexterm>concurrency.<indexterm id="idx-CHP-24-1962" significance="normal"><primary>transactional memory</primary></indexterm></para><sect1 id="a_simple_example_bank_accounts" label="24.1"><title>A Simple Example: Bank Accounts</title><para>Here is a simple programming task.<indexterm class="startofrange" id="idx-CHP-24-1963" significance="normal"><primary>bank accounts (concurrent programming example)</primary></indexterm></para><blockquote><para>Write a procedure to transfer money from one bank account to another. To keep things simple, both accounts are held in memory: no interaction with databases is required. The procedure must operate correctly in a concurrent program, in which many threads may call <literal moreinfo="none">transfer</literal> simultaneously. No thread should be able to observe a state in which the money has left one account, but not arrived in the other (or vice versa).</para></blockquote><para>This example is somewhat unrealistic, but its simplicity allows us to focus in this chapter on what is new about the solution: the language <indexterm id="idx-CHP-24-1964" significance="normal"><primary>Haskell</primary></indexterm>Haskell and transactional memory. But first let us briefly look at the conventional approach.</para><sect2 id="bank_accounts_using_locks" label="24.1.1"><title>Bank Accounts Using Locks</title><para>The dominant technologies used for <indexterm id="idx-CHP-24-1965" significance="normal"><primary>condition variables</primary><secondary>coordinating concurrent programs</secondary></indexterm>coordinating concurrent programs today are <emphasis>locks</emphasis> and <emphasis>condition variables</emphasis>. In an object-oriented language, every object has an implicit lock, and the locking is done by <emphasis>synchronized methods</emphasis>, but the idea is the same. So, one might define a class for <indexterm id="idx-CHP-24-1966" significance="normal"><primary>locking</primary><secondary>bank accounts using locks</secondary></indexterm>bank accounts something like this:<indexterm class="startofrange" id="idx-CHP-24-1967" significance="normal"><primary>concurrency</primary><secondary>bank accounts (example)</secondary></indexterm><indexterm id="idx-CHP-24-1968" significance="normal"><primary>bank accounts (concurrent programming example)</primary><secondary>using locks</secondary></indexterm><indexterm id="idx-CHP-24-1969" significance="normal"><primary>synchronized methods</primary></indexterm></para><programlisting id="I_programlisting24_tt465" format="linespecific">
	class Account {
	  Int balance;
	  synchronized void withdraw( Int n ) {
	    balance = balance - n; }
	  void deposit( Int n ) {
	    withdraw( -n ); }
	}
</programlisting><para>We must be careful to use a <literal moreinfo="none">synchronized</literal> method for <literal moreinfo="none">withdraw</literal>, so that we do not get any missed decrements if two threads call <literal moreinfo="none">withdraw</literal> at the same time. The effect of <literal moreinfo="none">synchronized</literal> is to take a lock on the account, run <literal moreinfo="none">withdraw</literal>, and then release the lock.</para><para>Now, here is how we might write the code for <literal moreinfo="none">transfer</literal>:</para><programlisting id="I_programlisting24_tt466" format="linespecific">
	void transfer( Account from, Account to, Int amount ) {
	  from.withdraw( amount );
	  to.deposit( amount ); }
</programlisting><para>This code is fine for a sequential program, but in a concurrent program, another thread could observe an intermediate state in which the money has left account <literal moreinfo="none">from</literal> but has not arrived in <literal moreinfo="none">to</literal>. The fact that both methods are <literal moreinfo="none">synchronized</literal> does not help us at all. Account <literal moreinfo="none">from</literal> is first locked and then unlocked by the call to method <literal moreinfo="none">withdraw</literal>, and then <literal moreinfo="none">to</literal> is locked and unlocked by <literal moreinfo="none">deposit</literal>. In between the two calls, the money is (visibly) absent from both accounts.</para><para><indexterm id="idx-CHP-24-1970" significance="normal"><primary>condition variables</primary><secondary>blocking in bank account transactions</secondary></indexterm>In a finance program, that might be unacceptable. How do we fix it? The usual solution would be to add <indexterm id="idx-CHP-24-1971" significance="normal"><primary>deadlock</primary><secondary>explicit locking code in bank account program</secondary></indexterm>explicit locking code like so:</para><programlisting id="I_programlisting24_tt467" format="linespecific">
	void transfer( Account from, Account to, Int amount ) {
	  from.lock(); to.lock();
	    from.<indexterm id="idx-CHP-24-1972" significance="normal"><primary>locking</primary><secondary>problems with locks</secondary></indexterm>withdraw( amount );
	    to.deposit( amount );
	  from.unlock(); to.unlock() }
</programlisting><para>But this program is fatally prone to deadlock. In particular, consider the (unlikely) situation in which another thread is transferring money in the opposite direction between the same two <indexterm id="idx-CHP-24-1973" significance="normal"><primary>bank accounts (concurrent programming example)</primary></indexterm>accounts. Then each thread might get one lock and then block indefinitely waiting for the other.</para><para>Once recognized—and the problem is not always so obvious—the standard fix is to put an arbitrary global order on the <indexterm id="idx-CHP-24-1974" significance="normal"><primary>concurrency</primary><secondary>locks</secondary></indexterm>locks, and to acquire them in increasing order. The locking code would then become:</para><programlisting id="I_programlisting24_tt468" format="linespecific">
	if from &lt; to
	  then { from.lock(); to.lock(); }
	  else { to.lock(); from.lock(); }
</programlisting><para>That works fine when the full set of required locks can be predicted in advance, but that is not always the case. For example, suppose <literal moreinfo="none">from.withdraw</literal> is implemented by transferring money out of the <literal moreinfo="none">from2</literal> account if <literal moreinfo="none">from</literal> does not have enough funds. We don't know whether to acquire <literal moreinfo="none">from2's</literal> lock until we have read <literal moreinfo="none">from</literal>, and by then it is too late to acquire the locks in the "right" order. Furthermore, the very existence of <literal moreinfo="none">from2</literal> may be a private matter that should be known by <literal moreinfo="none">from</literal>, but not by <literal moreinfo="none">transfer</literal>. And even if <literal moreinfo="none">transfer</literal> did know about <literal moreinfo="none">from2</literal>, the locking code must now take three locks, presumably by sorting them into the right order.</para><para>Matters become even more complicated when we want to <emphasis>block</emphasis>. For example, suppose that <literal moreinfo="none">transfer</literal> should block if <literal moreinfo="none">from</literal> has insufficient funds. This is usually done by waiting on a <emphasis>condition variable</emphasis>, while simultaneously releasing <literal moreinfo="none">from</literal>'s lock. It gets much trickier if we want to block until there are sufficient funds in <literal moreinfo="none">from</literal> and <literal moreinfo="none">from2</literal> considered together.</para></sect2><sect2 id="locks_are_bad" label="24.1.2"><title>Locks Are Bad</title><para>To make a long story short, today's dominant technology for concurrent programming—locks and condition variables—is fundamentally flawed. Here are some standard difficulties, some of which we have just seen:</para><variablelist><varlistentry><term><emphasis>Taking too few locks</emphasis></term><listitem><para>It is easy to forget to take a lock and thereby end up with two threads that modify the same variable simultaneously.<indexterm id="idx-CHP-24-1975" significance="normal"><primary>locking</primary><secondary>problems with locks</secondary><tertiary>taking too few</tertiary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Taking too many locks</emphasis></term><listitem><para>It is easy to take too many locks and thereby inhibit <indexterm id="idx-CHP-24-1976" significance="normal"><primary>concurrency</primary></indexterm>concurrency (at best) or cause deadlock (at worst).<indexterm id="idx-CHP-24-1977" significance="normal"><primary>locking</primary><secondary>problems with locks</secondary><tertiary>taking too many</tertiary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Taking the wrong locks</emphasis></term><listitem><para>In lock-based programming, the connection between a lock and the data it protects <indexterm id="idx-CHP-24-1978" significance="normal"><primary>blocking</primary><secondary>lack of modularity</secondary></indexterm>often exists only in the mind of the programmer and is <indexterm id="idx-CHP-24-1979" significance="normal"><primary>condition variables</primary><secondary>no support for modular programming</secondary></indexterm>not explicit in the program. As a result, it is all too easy to take or hold the wrong locks.<indexterm id="idx-CHP-24-1980" significance="normal"><primary>locking</primary><secondary>problems with locks</secondary><tertiary>taking in wrong order</tertiary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Taking locks in the wrong order</emphasis></term><listitem><para>In lock-based programming, one must be careful to take locks in the "right" order. Avoiding the deadlock that can otherwise occur is always tiresome and error-prone, and sometimes extremely difficult.<indexterm id="idx-CHP-24-1981" significance="normal"><primary>locking</primary><secondary>problems with locks</secondary><tertiary>taking the wrong locks</tertiary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Error recovery</emphasis></term><listitem><para><indexterm id="idx-CHP-24-1982" significance="normal"><primary>locking</primary><secondary>problems with locks</secondary><tertiary>error recovery</tertiary></indexterm>Error recovery can be very hard because the programmer must guarantee that no error can leave the system in a state that is inconsistent, or in which locks are held indefinitely.<indexterm id="idx-CHP-24-1983" significance="normal"><primary>errors</primary><secondary>recovery problems with locks</secondary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Lost wakeups and erroneous retries</emphasis></term><listitem><para>It is easy to forget to signal a condition variable on which a thread is waiting, or to retest a condition after a wakeup.<indexterm id="idx-CHP-24-1984" significance="normal"><primary>locking</primary><secondary>problems with locks</secondary><tertiary>lost wakeups and erroneous retries</tertiary></indexterm></para></listitem></varlistentry></variablelist><para>But the fundamental shortcoming of lock-based programming is that <emphasis>locks and condition variables do not support modular programming</emphasis>. By "modular programming," I mean the process of building large programs by gluing together smaller programs. Locks make this impossible. For example, we could not use our (correct) implementations of <literal moreinfo="none">withdraw</literal> and <literal moreinfo="none">deposit</literal> unchanged to implement <literal moreinfo="none">transfer</literal>; instead, we had to expose the locking protocol. Blocking and choice are even less modular. For example, suppose we had a version of <literal moreinfo="none">withdraw</literal> that blocked if the source account had insufficient funds. Then we would not be able to use <literal moreinfo="none">withdraw</literal> directly to withdraw money from A or B (depending on which had sufficient funds), without exposing the blocking condition—and even then it wouldn't be easy. This critique is elaborated elsewhere.<footnote id="CHP-24-FNOTE-4"><para>Edward A. Lee, "The problem with threads,"<emphasis>IEEE Computer</emphasis>, Vol. 39, No. 5, pp. 33–42, May 2006; J. K. Ousterhout, "Why threads are a bad idea (for most purposes)," Invited Talk, <emphasis>USENIX Technical Conference</emphasis>, January 1996; Tim Harris, Simon Marlow, Simon Peyton <indexterm id="idx-CHP-24-1985" significance="normal"><primary>Jones</primary></indexterm>Jones, and Maurice Herlihy, "Composable memory transactions," <emphasis>ACM Symposium on Principles and Practice of Parallel Programming (PPoPP '05)</emphasis>, June 2005.</para></footnote><indexterm id="idx-CHP-24-1986" significance="normal"><primary>modular programming</primary><secondary>not supported by locks and condition variables</secondary></indexterm></para></sect2></sect1><sect1 id="software_transactional_memory" label="24.2"><title>Software Transactional Memory</title><para>Software Transactional Memory is a promising new approach to the challenge of <indexterm id="idx-CHP-24-1987" significance="normal"><primary>concurrency</primary></indexterm>concurrency, as I will explain in this section. I shall explain <indexterm id="idx-CHP-24-1988" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM using <indexterm class="startofrange" id="idx-CHP-24-1989" significance="normal"><primary>Haskell</primary></indexterm>Haskell, the most beautiful programming language I know, because STM fits into Haskell particularly elegantly. If you don't know any Haskell, don't worry; we'll learn it as we go.</para><sect2 id="side_effects_and_inputoutput_in_haskell" label="24.2.1"><title>Side Effects and Input/Output in Haskell</title><para>Here is the beginning of the code for <literal moreinfo="none">transfer</literal> in Haskell:<indexterm class="startofrange" id="idx-CHP-24-1990" significance="normal"><primary>Haskell</primary><secondary>side effects and input/output</secondary></indexterm><indexterm id="I_indexterm24_tt469" class="endofrange" startref="idx-CHP-24-1963" significance="normal"><primary>bank accounts (concurrent programming example)</primary></indexterm><indexterm id="I_indexterm24_tt470" class="endofrange" startref="idx-CHP-24-1967" significance="normal"><primary>concurrency</primary><secondary>bank accounts (example)</secondary></indexterm></para><programlisting id="I_programlisting24_tt471" format="linespecific">
	transfer :: Account -&gt; Account -&gt; Int -&gt; IO ( )
	-- Transfer 'amount' from account 'from' to account 'to'
	transfer from to amount = ...
</programlisting><para>The second line of this definition, starting with --, is a comment. The first line gives the <emphasis>type signature</emphasis> for <literal moreinfo="none">transfer</literal>.<footnote id="CHP-24-FNOTE-5"><para>You may think it odd that there are three function arrows in this <indexterm id="idx-CHP-24-1991" significance="normal"><primary>( ) (parentheses)</primary><secondary>type in Haskell</secondary></indexterm>type signature, rather than one. That's because <indexterm id="idx-CHP-24-1992" significance="normal"><primary>Haskell</primary></indexterm>Haskell supports <emphasis>currying</emphasis>, which you can find described in any book about <indexterm id="idx-CHP-24-1993" significance="normal"><primary>comments</primary><secondary>Haskell</secondary></indexterm>Haskell (<emphasis>Haskell: The Craft of Functional Programming</emphasis>, by S.J. Thompson [Addison-Wesley]), or on Wikipedia. For the purposes of this chapter, simply treat all the types except the final one as arguments.</para></footnote> This signature says that <literal moreinfo="none">transfer</literal> takes as its arguments two values of type <literal moreinfo="none">Account</literal> (the source and destination accounts) and an <literal moreinfo="none">Int</literal> (the amount to transfer), and returns a value of type <literal moreinfo="none">IO ( )</literal>. This result type says, "<literal moreinfo="none">transfer</literal> returns an action that, when performed, may have some <indexterm id="idx-CHP-24-1994" significance="normal"><primary>Haskell</primary><secondary>side effects and input/output</secondary></indexterm>side effects, and then returns a value of type <literal moreinfo="none">( )</literal>." The type <literal moreinfo="none">( )</literal>, pronounced "unit," has just one value, which is also written <literal moreinfo="none">( )</literal>; it is akin to <literal moreinfo="none">void</literal> in C. So, <literal moreinfo="none">transfer's</literal> result type <literal moreinfo="none">IO ( )</literal> announces that its side effects constitute the only reason for calling it. Before we go further, we must explain how side effects are handled <indexterm class="startofrange" id="idx-CHP-24-1995" significance="normal"><primary>I/O in Haskell</primary></indexterm>in Haskell.<indexterm id="idx-CHP-24-1996" significance="normal"><primary>type signature (Haskell)</primary></indexterm></para><para>A <emphasis>side effect</emphasis> is anything that reads or writes mutable state. Input/output is a prominent example of a side effect. For example, here are the signatures of two Haskell functions with input/output effects:</para><programlisting id="I_programlisting24_tt472" format="linespecific">
	hPutStr  :: Handle -&gt; String -&gt; IO ()
	hGetLine :: Handle -&gt; IO String
</programlisting><para>We call any value of type <literal moreinfo="none">IO t</literal> an <emphasis>action</emphasis>. So, (<literal moreinfo="none">hPutStrh "hello"</literal>) is an action<footnote id="CHP-24-FNOTE-6"><para><indexterm class="startofrange" id="idx-CHP-24-1997" significance="normal"><primary>side effects</primary><secondary>in Haskell</secondary></indexterm>In Haskell, we write function application using simple juxtaposition. In most languages you would write <literal moreinfo="none">hPutStr(h, "hello")</literal>, but in Haskell you write simply (<literal moreinfo="none">hPutStrh "hello"</literal>).</para></footnote> that, when performed, will print <literal moreinfo="none">hello</literal> on handle<footnote id="CHP-24-FNOTE-7"><para>A <literal moreinfo="none">Handle</literal> in Haskell plays the role of a file descriptor in C: it says which file or pipe to read or write. As in Unix, there are three predefined handles: <literal moreinfo="none">stdin, stdout</literal>, and <literal moreinfo="none">stderr</literal>.</para></footnote> <literal moreinfo="none">h</literal> and return the unit value. Similarly, (<literal moreinfo="none">hGetLine h</literal>) is an action that, when performed, will read a line of input from handle <literal moreinfo="none">h</literal> and return it as a <literal moreinfo="none">String</literal>. We can glue together little side-effecting programs to make bigger side-effecting programs using Haskell's <literal moreinfo="none">do</literal> notation. For example, <literal moreinfo="none">EchoLine</literal> reads a string from the input and prints it:<indexterm id="idx-CHP-24-1998" significance="normal"><primary>do notation (Haskell)</primary></indexterm></para><programlisting id="I_programlisting24_tt473" format="linespecific">
	hEchoLine :: Handle -&gt; IO String
	hEchoLine h = do { s &lt;- hGetLine h
	                 ; hPutStr h ("I just read: " ++ s ++ "\n")
	                 ; return s }
</programlisting><para>The notation <literal moreinfo="none">do</literal> {<replaceable>a</replaceable><emphasis role="strong"><subscript>1</subscript></emphasis>; …; <replaceable>a</replaceable><emphasis role="strong"><subscript>n</subscript></emphasis>} constructs an action by gluing together the smaller <indexterm id="idx-CHP-24-1999" significance="normal"><primary>actions (Haskell)</primary></indexterm>actions <replaceable>a</replaceable><subscript>1</subscript>…<replaceable>a</replaceable><emphasis><subscript>n</subscript></emphasis> in sequence. So <literal moreinfo="none">hEchoLine h</literal> is an action that, when performed, will first perform <literal moreinfo="none">hGetLine h</literal> to read a line from <literal moreinfo="none">h</literal>, naming the result <literal moreinfo="none">s</literal>. Then it will perform <literal moreinfo="none">hPutStr</literal> to print <literal moreinfo="none">s</literal>, preceded <footnote id="CHP-24-FNOTE-8"><para>The ++ operator concatenates two strings.</para></footnote>by "<literal moreinfo="none">I just read</literal>: ". Finally, it will return the string <literal moreinfo="none">s</literal>. This last line is interesting because <literal moreinfo="none">return</literal> is not a built-in language construct: rather, it is a perfectly ordinary function with type:</para><programlisting id="I_programlisting24_tt474" format="linespecific">
	return :: a -&gt; IO a
</programlisting><para>The action <literal moreinfo="none">return v</literal>, when performed, returns v without <indexterm id="idx-CHP-24-2000" significance="normal"><primary>I/O in Haskell</primary></indexterm>having caused any <indexterm id="idx-CHP-24-2001" significance="normal"><primary>Haskell</primary><secondary>side effects and input/output</secondary></indexterm>side effects. <footnote id="CHP-24-FNOTE-9"><para>The <literal moreinfo="none">IO</literal> type indicates the <emphasis>possibility</emphasis> of side effects, not the <emphasis>certainty</emphasis></para></footnote>. This function works on values of any type, and we indicate this by using a type variable a in its type.</para><para>Input/output is one important sort of side effect. Another is the act of reading or writing a <indexterm id="idx-CHP-24-2002" significance="normal"><primary>mutable variables</primary></indexterm>mutable variable. For example, here is a function that increments the value of <indexterm id="idx-CHP-24-2003" significance="normal"><primary>variables</primary><secondary>reading/writing a mutable variable</secondary></indexterm>a mutable variable:</para><programlisting id="I_programlisting24_tt475" format="linespecific">
	incRef :: IORef Int -&gt; IO ( )
	incRef var = do { val &lt;- readIORef var
	                ; writeIORef var (val+1) }
</programlisting><para>Here, <literal moreinfo="none">incRef var</literal> is an action that first performs <literal moreinfo="none">readIORef var</literal> to read the value of the variable, naming its value <literal moreinfo="none">val</literal>, and then performs <literal moreinfo="none">writeIORef</literal> to write the value (<literal moreinfo="none">val+1</literal>) into the variable. The types of <literal moreinfo="none">readIORef</literal> and <literal moreinfo="none">writeIORef</literal> are as follows:</para><programlisting id="I_programlisting24_tt476" format="linespecific">
	readIORef  :: IORef a -&gt; IO a
	writeIORef :: IORef a -&gt; a -&gt; IO ( )
</programlisting><para>A value of type <literal moreinfo="none">IORef t</literal> should be thought of as a pointer, or reference, to a mutable location containing a value of type <literal moreinfo="none">t</literal>, a bit like the type (<literal moreinfo="none">t*</literal>) in C. In the case of <literal moreinfo="none">incRef</literal>, the argument has type <literal moreinfo="none">IORef Int</literal> because <literal moreinfo="none">incRef</literal> applies only to locations that contain an <literal moreinfo="none">Int</literal>.</para><para>So far, I have explained how to build big actions by combining smaller ones together—but how does an action ever actually get performed? In <indexterm id="idx-CHP-24-2004" significance="normal"><primary>Haskell</primary></indexterm>Haskell, the whole program defines a single <literal moreinfo="none">IO</literal> action, called <literal moreinfo="none">main</literal>. To run the program is to perform the action <literal moreinfo="none">main</literal>. For example, here is a complete program:<indexterm id="idx-CHP-24-2005" significance="normal"><primary>main (I/O action in Haskell)</primary></indexterm><indexterm id="idx-CHP-24-2006" significance="normal"><primary>actions (Haskell)</primary><secondary>main</secondary></indexterm></para><programlisting id="I_programlisting24_tt477" format="linespecific">
	main :: IO ( )
	main = do { hPutStr stdout "Hello"
	          ; hPutStr stdout " world\n" }
</programlisting><para>This program is a sequential program because the <literal moreinfo="none">do</literal> notation combines IO actions in sequence. To construct a concurrent program we need one more primitive, <literal moreinfo="none">forkIO</literal>:<indexterm id="idx-CHP-24-2007" significance="normal"><primary>forkIO function (Haskell)</primary></indexterm></para><programlisting id="I_programlisting24_tt478" format="linespecific">
	forkIO :: IO a -&gt; IO ThreadId
</programlisting><para>The function <literal moreinfo="none">forkIO</literal>, which is built into Haskell, takes an <literal moreinfo="none">IO</literal> action as its argument, and spawns it as a concurrent Haskell thread. Once created, it is run concurrently with all the other Haskell threads by the Haskell runtime system. For example, suppose we modified our main program thus:<footnote id="CHP-24-FNOTE-10"><para>In the first line of <literal moreinfo="none">main</literal>, we <literal moreinfo="none">could</literal> instead have written <literal moreinfo="none">tid &lt;-forkIO (hPutStr…</literal>), to bind the <literal moreinfo="none">ThreadId</literal> returned by <literal moreinfo="none">forkIO</literal> to <literal moreinfo="none">tid</literal>. However, because we do not use the returned <literal moreinfo="none">ThreadId</literal>, we are free to discard it by omitting the <literal moreinfo="none">tid&lt;-</literal>part.</para></footnote></para><programlisting id="I_programlisting24_tt479" format="linespecific">
	main :: IO ( )
	main = do { forkIO (hPutStr stdout "Hello")
	          ; hPutStr stdout " world\n" }
</programlisting><para>Now, the two <literal moreinfo="none">hPutStr</literal> actions would run concurrently. Which of them would "win" (by printing its string first) is unspecified. <indexterm id="idx-CHP-24-2008" significance="normal"><primary>Haskell</primary></indexterm>Haskell threads spawned by <literal moreinfo="none">forkIO</literal> are extremely lightweight: they occupy a few hundred bytes of memory, and it is perfectly reasonable for a single program to spawn thousands of them.</para><para>Gentle reader, you may by now be feeling that Haskell is a very clumsy and verbose language. After all, our three-line definition of <literal moreinfo="none">incRef</literal> accomplishes no more than <literal moreinfo="none">x++</literal> does in C! Indeed, <indexterm id="idx-CHP-24-2009" significance="normal"><primary>I/O in Haskell</primary></indexterm>in Haskell <indexterm id="idx-CHP-24-2010" significance="normal"><primary>Haskell</primary><secondary>side effects and input/output</secondary></indexterm>side effects are extremely explicit and somewhat verbose. However, remember first that Haskell is primarily a <emphasis>functional</emphasis> language. Most programs are written in the functional core of Haskell, which is rich, expressive, and concise. Haskell thereby gently encourages you to write programs that make sparing use of side effects.<indexterm id="idx-CHP-24-2011" significance="normal"><primary>Haskell</primary><secondary>side effects and I/O</secondary><tertiary>functional nature of Haskell</tertiary></indexterm></para><para>Second, notice that <indexterm id="idx-CHP-24-2012" significance="normal"><primary>side effects</primary><secondary>in Haskell</secondary><tertiary>being explicit about</tertiary></indexterm>being explicit about side effects reveals a good deal of useful information. Consider two functions:</para><programlisting id="I_programlisting24_tt480" format="linespecific">
	f :: Int -&gt; Int
	g :: Int -&gt; IO Int
</programlisting><para>From looking only at their types, we can see that <literal moreinfo="none">f</literal> is a pure function: it has no side effects. Given a particular <literal moreinfo="none">Int</literal>, say <literal moreinfo="none">42</literal>, the call (<literal moreinfo="none">f 42</literal>) will return the same value every time it is called. In contrast, <literal moreinfo="none">g</literal> has side effects, and this is apparent in its type. Each time <literal moreinfo="none">g</literal> is performed, it may give a different result—for example, it may read from <literal moreinfo="none">stdin</literal> or modify a mutable variable—even if its argument is the same every time. This ability to make side effects explicit will prove very useful in what follows.</para><para>Lastly, actions are first-class values: they may be passed as arguments, as well as returned as results. For example, here is the definition of a (simplified) <literal moreinfo="none">for</literal> loop function, written entirely <indexterm id="idx-CHP-24-2013" significance="normal"><primary>side effects</primary><secondary>in Haskell</secondary></indexterm>in Haskell rather than being built-in:</para><programlisting id="I_programlisting24_tt481" format="linespecific">
	nTimes :: Int -&gt; IO ( ) -&gt; IO ( )
	nTimes 0 do_this = return ( )
	nTimes n do_this = do { do_this; nTimes (n-1) do_this }
</programlisting><para>This recursive function takes an <literal moreinfo="none">Int</literal> saying how many times to loop, and an action <literal moreinfo="none">do_this</literal>; it returns an action that, when performed, performs the <literal moreinfo="none">do_this</literal> action <literal moreinfo="none">n</literal> times. Here is an example that uses <literal moreinfo="none">nTimes</literal> to print <literal moreinfo="none">Hello</literal> 10 times:</para><programlisting id="I_programlisting24_tt482" format="linespecific">
	main = nTimes 10 (hPutStr stdout "Hello\n")
</programlisting><para>In effect, by treating actions <indexterm id="idx-CHP-24-2014" significance="normal"><primary>actions (Haskell)</primary><secondary>treated as first-class values</secondary></indexterm>as first-class values, Haskell supports <emphasis>user-defined control structures</emphasis>.<indexterm id="idx-CHP-24-2015" significance="normal"><primary>user-defined control structures (in Haskell)</primary></indexterm></para><para>This chapter is not the place for a full introduction to Haskell, or even to side effects in Haskell. A good starting point for further reading is my tutorial "Tackling the awkward squad."<footnote id="CHP-24-FNOTE-11"><para>Simon Peyton <indexterm id="idx-CHP-24-2016" significance="normal"><primary>Jones</primary></indexterm>Jones, "Tackling the awkward squad: monadic input/output, <indexterm id="idx-CHP-24-2017" significance="normal"><primary>concurrency</primary></indexterm>concurrency, exceptions, and foreign-language calls in Haskell," C. A. R. Hoare, M. Broy, and R. Steinbrueggen, editors, <emphasis>Engineering theories of software construction</emphasis>, Marktoberdorf Summer School 2000, NATO ASI Series, pp. 47–96, IOS Press, 2001.</para></footnote><indexterm id="I_indexterm24_tt483" class="endofrange" startref="idx-CHP-24-1995" significance="normal"><primary>I/O in Haskell</primary></indexterm><indexterm id="I_indexterm24_tt484" class="endofrange" startref="idx-CHP-24-1990" significance="normal"><primary>Haskell</primary><secondary>side effects and input/output</secondary></indexterm><indexterm id="I_indexterm24_tt485" class="endofrange" startref="idx-CHP-24-1997" significance="normal"><primary>side effects</primary><secondary>in Haskell</secondary></indexterm></para></sect2><sect2 id="transactions_in_haskell" label="24.2.2"><title>Transactions in Haskell</title><para>Now, we can return to our <literal moreinfo="none">transfer</literal> function. Here is its code:<indexterm id="idx-CHP-24-2018" significance="normal"><primary>transactions (in Haskell)</primary></indexterm><indexterm id="idx-CHP-24-2019" significance="normal"><primary>Haskell</primary></indexterm></para><programlisting id="I_programlisting24_tt486" format="linespecific">
	transfer :: Account -&gt; Account -&gt; Int -&gt; IO ( )
	-- Transfer 'amount' from account 'from' to account 'to'
	transfer from to amount
	 = <indexterm id="idx-CHP-24-2020" significance="normal"><primary>atomically function (Haskell)</primary></indexterm>atomically (do { deposit to amount
	                  ; withdraw from amount })
</programlisting><para>The inner <literal moreinfo="none">do</literal> block should by now be fairly self-explanatory: we call <literal moreinfo="none">deposit</literal> to deposit <literal moreinfo="none">amount</literal> in <literal moreinfo="none">to</literal>, and <literal moreinfo="none">withdraw</literal> to withdraw <literal moreinfo="none">amount</literal> from account <literal moreinfo="none">from</literal>. We will write these auxiliary functions in a moment, but first let's look at the call to <literal moreinfo="none">atomically</literal>. It takes an action as its argument and performs it atomically. More precisely, it makes two guarantees:</para><variablelist><varlistentry><term><emphasis>Atomicity</emphasis></term><listitem><para>The effects of <literal moreinfo="none">atomically act</literal> become visible to another thread all at once. This ensures that no other thread can see a state in which money has been deposited in <literal moreinfo="none">to</literal> but not yet withdrawn from <literal moreinfo="none">from</literal>.<indexterm id="idx-CHP-24-2021" significance="normal"><primary>atomicity (Haskell transactions)</primary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Isolation</emphasis></term><listitem><para>During a call <literal moreinfo="none">atomically act</literal>, the action <literal moreinfo="none">act</literal> is completely unaffected by other threads. It is as if <literal moreinfo="none">act</literal> takes a snapshot of the state of the world when it begins running, and then executes against that snapshot.<indexterm id="idx-CHP-24-2022" significance="normal"><primary>isolation (Haskell transactions)</primary></indexterm></para></listitem></varlistentry></variablelist><para>Here is a simple execution model for <literal moreinfo="none">atomically</literal>. Suppose there is a single, global lock. Then <literal moreinfo="none">atomically act</literal> grabs the lock, performs the action <literal moreinfo="none">act</literal>, and releases the lock. This implementation brutally ensures that no two atomic blocks can be executed simultaneously, and thereby ensures atomicity.</para><para>There are two problems with this model. First, it does not ensure isolation at all: while one thread is accessing an <literal moreinfo="none">IORef</literal> inside an atomic block (holding the Global Lock), there is nothing to stop <emphasis>another</emphasis> thread from writing the same <literal moreinfo="none">IORef</literal> directly (i.e., outside <literal moreinfo="none">atomically</literal>, without holding the Global Lock), thereby destroying the isolation guarantee. Second, performance is dreadful because every atomic block is serialized even if no actual interference is possible.</para><para>I will discuss the second problem shortly, in the section "Implementing Transactional Memory." Meanwhile, the first objection is easily addressed with the type system. We give <literal moreinfo="none">atomically</literal> the following type:</para><programlisting id="I_programlisting24_tt487" format="linespecific">
	atomically :: <indexterm id="idx-CHP-24-2023" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM a -&gt; IO a
</programlisting><para>The argument of <literal moreinfo="none">atomically</literal> is an action of type <literal moreinfo="none">STM a</literal>. An <literal moreinfo="none">STM</literal> action is like an <literal moreinfo="none">IO</literal> action, in that it can have side effects, but the range of side effects for <literal moreinfo="none">STM</literal> actions is much smaller. The main thing you can do in an STM action is to read or write a transactional variable, of type (<literal moreinfo="none">TVar a</literal>), much as we could read or write <literal moreinfo="none">IORefs</literal> in an <literal moreinfo="none">IO</literal> action:<footnote id="CHP-24-FNOTE-12"><para>The nomenclature is inconsistent here: it would be more consistent to use either <literal moreinfo="none">TVar</literal> and <literal moreinfo="none">IOVar</literal>,or <literal moreinfo="none">TRef</literal> and <literal moreinfo="none">IORef</literal>. But it would be disruptive to change at this stage; for better or worse, we have <literal moreinfo="none">TVar</literal> and <literal moreinfo="none">IORef</literal>.</para></footnote><indexterm id="idx-CHP-24-2024" significance="normal"><primary>STM actions</primary></indexterm></para><programlisting id="I_programlisting24_tt488" format="linespecific">
	readTVar  :: TVar a -&gt; STM a
	writeTVar :: TVar a -&gt; a -&gt; <indexterm id="idx-CHP-24-2025" significance="normal"><primary>STM (Software Transactional Memory)</primary><secondary>transactions in Haskell</secondary></indexterm><indexterm id="idx-CHP-24-2026" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM ( )
</programlisting><para><literal moreinfo="none">STM</literal> actions can be composed together with the same <literal moreinfo="none">do</literal> notation as <literal moreinfo="none">IO</literal> actions—the do notation is overloaded to work on both types, as is <literal moreinfo="none">return</literal>.<footnote id="CHP-24-FNOTE-13"><para>This overloading of <literal moreinfo="none">do</literal> notation and <literal moreinfo="none">return</literal> is not an ad hoc trick to support <literal moreinfo="none">IO</literal> and <literal moreinfo="none">STM</literal>. Rather, IO and STM are both examples of a common pattern, called a <emphasis>monad</emphasis> (described in P. L. Wadler, "The essence of functional programming," <emphasis>20th ACM Symposium on Principles of Programming Languages [POPL '92</emphasis>], Albuquerque, pp. 1–14, ACM, January 1992), and the overloading is achieved by expressing that common pattern using <indexterm id="idx-CHP-24-2027" significance="normal"><primary>Haskell</primary></indexterm>Haskell's very general <emphasis>type-class</emphasis> mechanism (described in P. L. Wadler and S. Blott, "How to make ad-hoc polymorphism less ad hoc," <emphasis>Proc 16th ACM Symposium on Principles of Programming Languages</emphasis>, Austin, Texas, ACM, January 1989; and Simon Peyton <indexterm id="idx-CHP-24-2028" significance="normal"><primary>Jones</primary></indexterm>Jones, Mark Jones, and Erik Meijer, "Type classes: an exploration of the design space," J. Launch-bury, editor, <emphasis>Haskell workshop</emphasis>, Amsterdam, 1997).</para></footnote> Here, for example, is the code for <literal moreinfo="none">withdraw</literal>:<indexterm id="idx-CHP-24-2029" significance="normal"><primary>do notation (Haskell)</primary><secondary>composing STM actions</secondary></indexterm></para><programlisting id="I_programlisting24_tt489" format="linespecific">
	type Account = TVar Int

	withdraw :: Account -&gt; Int -&gt; STM ( )
	withdraw acc amount
	  = do { bal &lt;- readTVar acc
	       ; writeTVar acc (bal - amount) }
</programlisting><para>We represent an <literal moreinfo="none">Account</literal> by a transactional variable containing an <literal moreinfo="none">Int</literal> for the account balance. Then <literal moreinfo="none">withdraw</literal> is an <literal moreinfo="none">STM</literal> action that decrements the balance in the account by <literal moreinfo="none">amount</literal>.</para><para>To complete the definition of <literal moreinfo="none">transfer</literal>, we can define <literal moreinfo="none">deposit</literal> in terms of <literal moreinfo="none">withdraw</literal>:</para><programlisting id="I_programlisting24_tt490" format="linespecific">
	deposit :: Account -&gt; Int -&gt; STM ( )
	deposit acc amount = withdraw acc (- amount)
</programlisting><para>Notice that <literal moreinfo="none">transfer</literal> ultimately performs four primitive read/write actions: a read and then write on account <literal moreinfo="none">to</literal>, followed by a read and then write on account <literal moreinfo="none">from</literal>. These four actions execute atomically, and that meets the specification given at the start of the section "A Simple Example: Bank Accounts."</para><para>The type system neatly prevents us from reading or writing a <literal moreinfo="none">TVar</literal> outside of a transaction. For example, suppose we tried this:</para><programlisting id="I_programlisting24_tt491" format="linespecific">
	bad :: Account -&gt; IO ( )
	bad acc = do { hPutStr stdout "Withdrawing..."
	             ; withdraw acc 10 }
</programlisting><para>This program is rejected because the <literal moreinfo="none">hPutStr</literal> is an <literal moreinfo="none">IO</literal> action, while the <literal moreinfo="none">withdraw</literal> is an <literal moreinfo="none">STM</literal> action, and the two cannot be combined in a single <literal moreinfo="none">do</literal> block. If we wrap a call to <literal moreinfo="none">atomically</literal> around the <literal moreinfo="none">withdraw</literal>, all is well:</para><programlisting id="I_programlisting24_tt492" format="linespecific">
	good :: Account -&gt; IO ( )
	good acc = do { hPutStr stdout "Withdrawing..."
	              ; atomically (withdraw acc 10) }
</programlisting></sect2><sect2 id="implementing_transactional_memory" label="24.2.3"><title>Implementing Transactional Memory</title><para>The guarantees of atomicity and isolation that I described earlier should be all that a programmer needs in order to use <indexterm id="idx-CHP-24-2030" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM. Even so, I often find it helpful to have a reasonable implementation model to guide my intuitions, and I will sketch one such implementation in this section. But remember that this is just <emphasis>one</emphasis> possible implementation. One of the beauties of the STM abstraction is that it presents a small, clean interface that can be implemented in a variety of ways, some simple and some sophisticated.<indexterm id="idx-CHP-24-2031" significance="normal"><primary>STM (Software Transactional Memory)</primary><secondary>implementing transactional memory</secondary></indexterm></para><para>One particularly attractive implementation is well established in the database world, namely <emphasis>optimistic execution</emphasis>. When <literal moreinfo="none">atomically act</literal> is performed, a thread-local <emphasis>transaction log</emphasis> is allocated, initially empty. Then the action <literal moreinfo="none">act</literal> is performed, without taking any locks at all. While performing <literal moreinfo="none">act</literal>, each call to <literal moreinfo="none">writeTVar</literal> writes the address of the <literal moreinfo="none">TVar</literal> and its new value into the log; it does not write to the <literal moreinfo="none">TVar</literal> itself. Each call to <literal moreinfo="none">readTVar</literal> first searches the log (in case the <literal moreinfo="none">TVar</literal> was written by an earlier call to <literal moreinfo="none">writeTVar</literal>); if no such record is found, the value is read from the <literal moreinfo="none">TVar</literal> itself, and the <literal moreinfo="none">TVar</literal> and value read are recorded in the log. In the meantime, other threads might be running their own atomic blocks, reading and writing <literal moreinfo="none">TVars</literal> like crazy.<indexterm id="idx-CHP-24-2032" significance="normal"><primary>optimistic execution</primary></indexterm><indexterm id="idx-CHP-24-2033" significance="normal"><primary>transaction log</primary></indexterm></para><para>When the action <literal moreinfo="none">act</literal> is finished, the implementation first <emphasis>validates</emphasis> the log and, if validation is successful, <emphasis>commits</emphasis> the log. The validation step examines each <literal moreinfo="none">readTVar</literal> recorded in the log and checks that the value in the log matches the value currently in the real <literal moreinfo="none">TVar</literal>. If so, validation succeeds, and the commit step takes all the writes recorded in the log and writes them into the real <literal moreinfo="none">TVars</literal>.<indexterm id="idx-CHP-24-2034" significance="normal"><primary>commits</primary></indexterm></para><para>These steps are performed truly indivisibly: the implementation disables interrupts, or uses locks or compare-and-swap instructions—whatever is necessary to ensure that validation and commit are perceived by other threads as completely indivisible. All of this is handled by the implementation, however, and the programmer does not need to know or care how it is done.</para><para>What if validation fails? Then the transaction has had an inconsistent view of memory. So, we abort the transaction, reinitialize the log, and run <literal moreinfo="none">act</literal> all over again. This process is called <emphasis>re-execution</emphasis>. Because none of <literal moreinfo="none">act</literal>'s writes have been committed to memory, it is perfectly safe to run it again. However, notice that it is crucial that <literal moreinfo="none">act</literal> contains no effects <emphasis>other than</emphasis> reads and writes on <literal moreinfo="none">TVars</literal>. For example, consider:<indexterm id="idx-CHP-24-2035" significance="normal"><primary>re-execution (transactions in STM)</primary></indexterm></para><programlisting id="I_programlisting24_tt493" format="linespecific">
	atomically (do { x &lt;- readTVar xv
	               ; y &lt;- readTVar yv
	               ; if x&gt;y then launchMissiles
	                           else return () })
</programlisting><para>where <literal moreinfo="none">launchMissiles::IO ( )</literal> causes serious international side effects. Because the atomic block is executed without taking locks, it might have an inconsistent view of memory if other threads are concurrently modifying <literal moreinfo="none">xv</literal> and <literal moreinfo="none">yv</literal>. If that happens, it would be a mistake to launch the missiles, and only <emphasis>then</emphasis> discover that validation fails so the transaction should be rerun. Fortunately, the <indexterm id="idx-CHP-24-2036" significance="normal"><primary>actions (Haskell)</primary><secondary>type system preventing IO actions running inside STM actions</secondary></indexterm>type system prevents us from running <literal moreinfo="none">IO</literal> actions inside <literal moreinfo="none">STM</literal> actions, so the above fragment would be rejected by the type checker. This is another big advantage of distinguishing the types of <literal moreinfo="none">IO</literal> and <literal moreinfo="none">STM</literal> actions.<indexterm id="idx-CHP-24-2037" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm></para></sect2><sect2 id="blocking_and_choice" label="24.2.4"><title>Blocking and Choice</title><para>Atomic blocks as we have introduced them so far are utterly inadequate to coordinate concurrent programs. They lack two key facilities: <emphasis>blocking</emphasis> and <emphasis>choice</emphasis>. In this section, I'll describe how the basic STM interface is elaborated to include them in a fully modular way.</para><para>Suppose that a thread should <emphasis>block</emphasis> if it attempts to overdraw an account (i.e., withdraw more than the current balance). Situations like this are common in concurrent programs: for example, a thread should block if it reads from an empty buffer, or when it waits for an event. We achieve this in STM by adding the single function <literal moreinfo="none">retry</literal>, whose type is:</para><programlisting id="I_programlisting24_tt494" format="linespecific">
	retry :: STM a
</programlisting><para>Here is a modified version of <literal moreinfo="none">withdraw</literal> that blocks if the balance would go negative:</para><programlisting id="I_programlisting24_tt495" format="linespecific">
	limitedWithdraw :: Account -&gt; Int -&gt; STM ( )
	limitedWithdraw acc amount
	  = do { bal &lt;- readTVar acc
	       ; if amount &gt; 0 &amp;&amp; amount &gt; bal
	         then retry
	         else writeTVar acc (bal - amount) }
</programlisting><para>The semantics of <literal moreinfo="none">retry</literal> are simple: if a <literal moreinfo="none">retry</literal> action is performed, the current transaction is abandoned and retried at some later time. It would be correct to retry the transaction immediately, but it would also be inefficient: the state of the account will probably be unchanged, so the transaction will again hit the <literal moreinfo="none">retry</literal>. An efficient implementation would instead block the thread until some other thread writes to <literal moreinfo="none">acc</literal>. How does the implementation know to wait on <literal moreinfo="none">acc?</literal> Because the transaction reads <literal moreinfo="none">acc</literal> on the way to the <literal moreinfo="none">retry</literal>, and that fact is conveniently recorded in the transaction log.</para><para>The conditional in <literal moreinfo="none">limitedWithdraw</literal> has a very common pattern: check that a Boolean condition is satisfied and, if not, <literal moreinfo="none">retry</literal>. This pattern is easy to abstract as a function, <literal moreinfo="none">check</literal>:</para><programlisting id="I_programlisting24_tt496" format="linespecific">
	check :: Bool -&gt; STM ( )
	check True = return ( )
	check False = retry
</programlisting><para>Now, we can use <literal moreinfo="none">check</literal> to re-express <literal moreinfo="none">limitedWithdraw</literal> a little more neatly:</para><programlisting id="I_programlisting24_tt497" format="linespecific">
	limitedWithdraw :: Account -&gt; Int -&gt; STM ( )
	limitedWithdraw acc amount
	  = do { bal &lt;- readTVar acc
	       ; check (amount &lt;= 0 || amount &lt;= bal)
	       ; writeTVar acc (bal - amount) }
</programlisting><para>We now turn our attention to <emphasis>choice</emphasis>. Suppose you want to withdraw money from account A if it has enough money, but if not then withdraw it from account B? For that, we need the ability to choose an alternative action if the first one retries. To support choice, STM <indexterm id="idx-CHP-24-2038" significance="normal"><primary>Haskell</primary></indexterm>Haskell has one further primitive action, called <literal moreinfo="none">orElse</literal>, whose type is:</para><programlisting id="I_programlisting24_tt498" format="linespecific">
	orElse :: STM a -&gt; STM a -&gt; STM a
</programlisting><para>Like <literal moreinfo="none">atomically</literal>, <literal moreinfo="none">orElse</literal> takes actions as its arguments, and glues them together to make a bigger action. Its semantics are as follows. The action (<literal moreinfo="none">orElse a1 a2</literal>) first performs <literal moreinfo="none">a1</literal>. If <literal moreinfo="none">a1</literal> retries (i.e., calls <literal moreinfo="none">retry</literal>), it tries <literal moreinfo="none">a2</literal> instead. If a2 also retries, the whole action retries. It may be easier to see how <literal moreinfo="none">orElse</literal> is used:</para><programlisting id="I_programlisting24_tt499" format="linespecific">
	limitedWithdraw2 :: Account -&gt; Account -&gt; Int -&gt; <indexterm id="idx-CHP-24-2039" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM ( )
	-- (limitedWithdraw2 acc1 acc2 amt) withdraws amt from acc1,
	-- if acc1 has enough money, otherwise from acc2.
	-- If neither has enough, it retries.
	limitedWithdraw2 acc1 acc2 amt
	  = orElse (limitedWithdraw acc1 amt) (limitedWithdraw acc2 amt)
</programlisting><para>Because the result of <literal moreinfo="none">orElse</literal> is itself an <literal moreinfo="none">STM</literal> action, you can feed it to another call to <literal moreinfo="none">orElse</literal> and so choose among an arbitrary number of alternatives.</para></sect2><sect2 id="summary_of_basic_stm_operations" label="24.2.5"><title>Summary of Basic STM Operations</title><para>In this section, I have introduced all the key transactional memory operations supported by STM <indexterm id="idx-CHP-24-2040" significance="normal"><primary>Haskell</primary></indexterm>Haskell. They are summarized in <xref linkend="the_key_operations_of_stm_haskell"/>. This table includes one operation that has not so far arisen: <literal moreinfo="none">newTVar</literal> is the way in which you can create new <literal moreinfo="none">TVar</literal> cells, and we will use it in the following section.<indexterm id="idx-CHP-24-2041" significance="normal"><primary>Haskell</primary><secondary>summary of basic STM Haskell operations</secondary></indexterm></para><table id="the_key_operations_of_stm_haskell" label="24-1"><title>The key operations of STM Haskell</title><tgroup cols="2"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><thead><row><entry><para>Operation</para></entry><entry><para>Type signature</para></entry></row></thead><tbody><row><entry><para><literal moreinfo="none">atomically</literal></para></entry><entry><para><literal moreinfo="none">STM a -&gt; IO a</literal></para></entry></row><row><entry><para><literal moreinfo="none">retry</literal></para></entry><entry><para><literal moreinfo="none">STM a</literal></para></entry></row><row><entry><para><literal moreinfo="none">orElse</literal></para></entry><entry><para><literal moreinfo="none">STM a -&gt; STM a -&gt; STM a</literal></para></entry></row><row><entry><para><literal moreinfo="none">newTVar</literal></para></entry><entry><para><literal moreinfo="none">a -&gt; STM (TVar a)</literal></para></entry></row><row><entry><para><literal moreinfo="none">readTVar</literal></para></entry><entry><para><literal moreinfo="none">TVar a -&gt; STM a</literal></para></entry></row><row><entry><para><literal moreinfo="none">writeTVar</literal></para></entry><entry><para><literal moreinfo="none">TVar a -&gt; a -&gt; STM ( )</literal></para></entry></row></tbody></tgroup></table></sect2></sect1><sect1 id="the_santa_claus_problem" label="24.3"><title>The Santa Claus Problem</title><para>I want to show you a complete, runnable concurrent program using STM. A well-known example is the so-called <indexterm class="startofrange" id="idx-CHP-24-2042" significance="normal"><primary>STM (Software Transactional Memory)</primary><secondary>Santa Claus problem (example program)</secondary></indexterm>Santa Claus problem,<footnote id="CHP-24-FNOTE-14"><para>My choice was influenced by the fact that I am writing these words on December 22.</para></footnote> originally attributed to Trono:<footnote id="CHP-24-FNOTE-15"><para>J. A. Trono, "A new exercise in <indexterm id="idx-CHP-24-2043" significance="normal"><primary>concurrency</primary></indexterm>concurrency," <emphasis>SIGCSE Bulletin</emphasis>, Vol. 26, pp. 8–10, 1994.</para></footnote><indexterm class="startofrange" id="idx-CHP-24-2044" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm></para><blockquote><para>Santa repeatedly sleeps until wakened by either all of his nine reindeer, back from their holidays, or by a group of three of his ten elves. If awakened by the reindeer, he harnesses each of them to his sleigh, delivers toys with them and finally unharnesses them (allowing them to go off on holiday). If awakened by a group of elves, he shows each of the group into his study, consults with them on toy R&amp;D and finally shows them each out (allowing them to go back to work). Santa should give priority to the reindeer in the case that there is both a group of elves and a group of reindeer waiting.</para></blockquote><para>Using a well-known example allows you to directly compare my solution with well-described solutions in other languages. In particular, Trono's paper gives a semaphore-based solution that is partially correct. Ben-Ari gives a solution in Ada95 and in Ada.<footnote id="CHP-24-FNOTE-16"><para>Nick Benton, "Jingle bells: Solving the <indexterm id="idx-CHP-24-2045" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm>Santa Claus problem in Polyphonic C#," Technical report, Microsoft Research, 2003.</para></footnote> Benton gives a solution in Polyphonic C#.<footnote id="CHP-24-FNOTE-17"><para>Mordechai Ben-Ari, "How to solve the <indexterm id="idx-CHP-24-2046" significance="normal"><primary>STM (Software Transactional Memory)</primary><secondary>Santa Claus problem (example program)</secondary></indexterm>Santa Claus problem," <emphasis>Concurrency: Practice and Experience</emphasis>, Vol. 10, No. 6, pp. 485–496, 1998.</para></footnote><indexterm id="idx-CHP-24-2047" significance="normal"><primary>concurrency</primary></indexterm></para><sect2 id="reindeer_and_elves" label="24.3.1"><title>Reindeer and Elves</title><para>The basic idea of the <indexterm id="idx-CHP-24-2048" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM <indexterm id="idx-CHP-24-2049" significance="normal"><primary>Haskell</primary></indexterm>Haskell implementation is this. Santa makes one "<literal moreinfo="none">Group</literal>" for the elves and one for the reindeer. Each elf (or reindeer) tries to join its Group. If it succeeds, it gets two "<literal moreinfo="none">Gates</literal>" in return. The first <literal moreinfo="none">Gate</literal> allows Santa to control when the elf can enter the study and also lets Santa know when they are all inside. Similarly, the second <literal moreinfo="none">Gate</literal> controls the elves leaving the study. Santa, for his part, waits for either of his two <literal moreinfo="none">Groups</literal> to be ready, and then uses that <literal moreinfo="none">Group's Gates</literal> to marshal his helpers (elves or reindeer) through their task. Thus the helpers spend their lives in an infinite loop: try to join a group, move through the gates under Santa's control, and then delay for a random interval before trying to join a group again.</para><para>Rendering this informal description in Haskell gives the following code for an elf:<footnote id="CHP-24-FNOTE-18"><para>I have given this function a suffix 1 because it deals with only one iteration of the elf, whereas in reality the elves rejoin the fun when they are done with their task. We will define <literal moreinfo="none">elf</literal> in the section "The Main Program."</para></footnote></para><programlisting id="I_programlisting24_tt500" format="linespecific">
	elf1 :: Group -&gt; Int -&gt; IO ( )
	elf1 group elf_id = do { (in_gate, out_gate) &lt;- joinGroup group
	                       ; passGate in_gate
	                       ; meetInStudy elf_id
	                       ; passGate out_gate }
</programlisting><para>The <literal moreinfo="none">elf</literal> is passed its <literal moreinfo="none">Group</literal> and an <literal moreinfo="none">Int</literal> that specifies its elfin identity. This identity is used only in the call to <literal moreinfo="none">meetInStudy</literal>, which simply prints out a message to say what is happening:<footnote id="CHP-24-FNOTE-19"><para>The function <literal moreinfo="none">putStr</literal> is a library function that calls <literal moreinfo="none">hPutStr stdout</literal>.</para></footnote></para><programlisting id="I_programlisting24_tt501" format="linespecific">
	meetInStudy :: Int -&gt; IO ( )
	meetInStudy id = putStr ("Elf " ++ show id ++ " meeting in the study\n")
</programlisting><para>The elf calls <literal moreinfo="none">joinGroup</literal> to join its group and <literal moreinfo="none">passGate</literal> to pass through each of the gates:</para><programlisting id="I_programlisting24_tt502" format="linespecific">
	joinGroup :: Group -&gt; IO (Gate, Gate)
	passGate   :: Gate -&gt; IO ( )
</programlisting><para>The code for reindeer is identical, except that reindeer deliver toys rather than meet in the study:</para><programlisting id="I_programlisting24_tt503" format="linespecific">
	deliverToys :: Int -&gt; IO ( )
	deliverToys id = putStr ("Reindeer " ++ show id ++ " delivering toys\n")
</programlisting><para>Because <literal moreinfo="none">IO</literal> actions are first-class, we can abstract over the common pattern, like this:<indexterm id="idx-CHP-24-2050" significance="normal"><primary>IO actions (Haskell)</primary></indexterm></para><programlisting id="I_programlisting24_tt504" format="linespecific">
	helper1 :: Group -&gt; IO () -&gt; IO ( )
	helper1 group do_task = do { (in_gate, out_gate) &lt;- joinGroup group
	                           ; passGate in_gate
	                           ; do_task
	                           ; passGate out_gate }
</programlisting><para>The second argument of <literal moreinfo="none">helper1</literal> is an <literal moreinfo="none">IO</literal> action that is the helper's task, which the helper performs between the two <literal moreinfo="none">passGate</literal> calls. Now we can specialize <literal moreinfo="none">helper1</literal> to be either an elf or a reindeer:</para><programlisting id="I_programlisting24_tt505" format="linespecific">
	elf1, reindeer1 :: Group -&gt; Int -&gt; IO ( )
	elf1      gp id = helper1 gp (meetInStudy id)
	reindeer1 gp id = helper1 gp (deliverToys id)
</programlisting></sect2><sect2 id="gates_and_groups" label="24.3.2"><title>Gates and Groups</title><para>The first abstraction is a <literal moreinfo="none">Gate</literal>, which supports the following interface:</para><programlisting id="I_programlisting24_tt506" format="linespecific">
	newGate     :: Int -&gt; <indexterm id="idx-CHP-24-2051" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM Gate
	passGate    :: Gate -&gt; IO ( )
	operateGate :: Gate -&gt; IO ( )
</programlisting><para>A <literal moreinfo="none">Gate</literal> has a fixed <emphasis>capacity</emphasis>, <literal moreinfo="none">n</literal>, which we specify when we make a new <literal moreinfo="none">Gate</literal>, and a mutable <emphasis>remaining capacity</emphasis>. This remaining capacity is decremented whenever a helper calls <literal moreinfo="none">passGate</literal> to go through the gate; if the remaining capacity is zero, <literal moreinfo="none">passGate</literal> blocks. A <literal moreinfo="none">Gate</literal> is created with zero remaining capacity, so that no helpers can pass through it. <indexterm id="idx-CHP-24-2052" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm>Santa opens the gate with <literal moreinfo="none">operateGate</literal>, which sets its remaining capacity back to <literal moreinfo="none">n</literal>.</para><para>Here, then, is a possible implementation of a <literal moreinfo="none">Gate</literal>:</para><programlisting id="I_programlisting24_tt507" format="linespecific">
	data Gate = MkGate Int (TVar Int)

	newGate :: Int -&gt; STM Gate
	newGate n = do { tv &lt;- newTVar 0; return (MkGate n tv) }

	passGate :: Gate -&gt; IO ( )
	passGate (MkGate n tv)
	  = atomically (do { n_left &lt;- readTVar tv
	                   ; check (n_left &gt; 0)
	                   ; writeTVar tv (n_left-1) })

	operateGate :: Gate -&gt; IO ( )
	operateGate (MkGate n tv)
	  = do { atomically (writeTVar tv n)
	       ; atomically (do { n_left &lt;- readTVar tv
	                    ; check (n_left == 0) }) }
</programlisting><para>The first line declares <literal moreinfo="none">Gate</literal> to be a new <emphasis>data type</emphasis>, with a single <emphasis>data constructor</emphasis> <literal moreinfo="none">MkGate</literal>.<footnote id="CHP-24-FNOTE-20"><para>A data type declaration is not unlike a C <literal moreinfo="none">struct</literal> declaration, with <literal moreinfo="none">MkGate</literal> being the structure tag.</para></footnote> The constructor has two <emphasis>fields</emphasis>: an <literal moreinfo="none">Int</literal> giving the gate capacity, and a <literal moreinfo="none">TVar</literal> whose contents says how many helpers can go through the gate before it closes. If the <literal moreinfo="none">TVar</literal> contains zero, the gate is closed.</para><para>The function <literal moreinfo="none">newGate</literal> makes a new <literal moreinfo="none">Gate</literal> by allocating a <literal moreinfo="none">TVar</literal> and building a <literal moreinfo="none">Gate</literal> value by calling the <literal moreinfo="none">MkGate</literal> constructor. Dually, <literal moreinfo="none">passGate</literal> uses pattern-matching to take apart the <literal moreinfo="none">MkGate</literal> constructor; then, it decrements the contents of the <literal moreinfo="none">TVar</literal>, using <literal moreinfo="none">check</literal> to ensure there is still capacity in the gate, as we did with <literal moreinfo="none">withdraw</literal> in the section "Blocking and Choice." Finally, <literal moreinfo="none">operateGate</literal> first opens the <literal moreinfo="none">Gate</literal> by writing its full capacity into the <literal moreinfo="none">TVar</literal>, and then waits for the <literal moreinfo="none">TVar</literal> to be decremented to zero.</para><para>A Group has the following interface:</para><programlisting id="I_programlisting24_tt508" format="linespecific">
	newGroup   :: Int -&gt; IO Group
	joinGroup  :: Group -&gt; IO (Gate,Gate)
	awaitGroup :: Group -&gt; <indexterm id="idx-CHP-24-2053" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM (Gate,Gate)
</programlisting><para>Again, a <literal moreinfo="none">Group</literal> is created empty, with a specified capacity. An elf may join a group by calling <literal moreinfo="none">joinGroup</literal>, a call that blocks if the group is full. <indexterm id="idx-CHP-24-2054" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm>Santa calls <literal moreinfo="none">awaitGroup</literal> to wait for the group to be full; when it is full, he gets the <literal moreinfo="none">Group</literal>'s gates, <emphasis>and</emphasis> the <literal moreinfo="none">Group</literal> is immediately reinitialized with fresh <literal moreinfo="none">Gates</literal>, so that another group of eager elves can start assembling.</para><para>Here is a possible implementation:</para><programlisting id="I_programlisting24_tt509" format="linespecific">
	data Group = MkGroup Int (TVar (Int, Gate, Gate))

	newGroup n = atomically (do { g1 &lt;- newGate n; g2 &lt;- newGate n
	                            ; tv &lt;- newTVar (n, g1, g2)
	                            ; return (MkGroup n tv) })
</programlisting><para>Again, <literal moreinfo="none">Group</literal> is declared as a fresh data type, with constructor <literal moreinfo="none">MkGroup</literal> and two fields: the <literal moreinfo="none">Group's</literal> full capacity, and a <literal moreinfo="none">TVar</literal> containing its number of empty slots and its two <literal moreinfo="none">Gates</literal>. Creating a new <literal moreinfo="none">Group</literal> is a matter of creating new <literal moreinfo="none">Gates</literal>, initializing a new <literal moreinfo="none">TVar</literal>, and returning a structure built with <literal moreinfo="none">MkGroup</literal>.</para><para>The implementations of <literal moreinfo="none">joinGroup</literal> and <literal moreinfo="none">awaitGroup</literal> are now more or less determined by these data structures:</para><programlisting id="I_programlisting24_tt510" format="linespecific">
	joinGroup (MkGroup n tv)
	  = atomically (do { (n_left, g1, g2) &lt;- readTVar tv
	                   ; check (n_left &gt; 0)
	                   ; writeTVar tv (n_left-1, g1, g2)
	                   ; return (g1,g2) })

	awaitGroup (MkGroup n tv)
	  = do { (n_left, g1, g2) &lt;- readTVar tv
	       ; check (n_left == 0)
	       ; new_g1 &lt;- newGate n; new_g2 &lt;- newGate n
	       ; writeTVar tv (n,new_g1,new_g2)
	       ; return (g1,g2) }
</programlisting><para>Notice that <literal moreinfo="none">awaitGroup</literal> makes new gates when it reinitializes the <literal moreinfo="none">Group</literal>. This ensures that a new group can assemble while the old one is still talking to Santa in the study, with no danger of an elf from the new group overtaking a sleepy elf from the old one.</para><para>Reviewing this section, you may notice that I have given some of the <literal moreinfo="none">Group</literal> and <literal moreinfo="none">Gate</literal> operations <literal moreinfo="none">IO</literal> types (e.g., <literal moreinfo="none">newGroup</literal>, <literal moreinfo="none">joinGroup</literal>), and some <literal moreinfo="none">STM</literal> types (e.g., <literal moreinfo="none">newGate</literal>, <literal moreinfo="none">awaitGroup</literal>). How did I make these choices? For example, <literal moreinfo="none">newGroup</literal> has an <literal moreinfo="none">IO</literal> type, which means that I can never call it from within an <literal moreinfo="none">STM</literal> action. But this is merely a matter of convenience: I could instead have given <literal moreinfo="none">newGroup</literal> an <literal moreinfo="none">STM</literal> type, by omitting the <literal moreinfo="none">atomically</literal> in its definition. In exchange, I would have had to write <literal moreinfo="none">atomically(newGroupn)</literal> at each call site, rather than merely <literal moreinfo="none">newGroup n</literal>. The merit of <indexterm id="idx-CHP-24-2055" significance="normal"><primary>STM actions</primary><secondary>giving functions STM types wherever possible</secondary></indexterm>giving <literal moreinfo="none">newGate</literal> an <literal moreinfo="none">STM</literal> type is that it is more compos-able, a generality that <literal moreinfo="none">newGroup</literal> did not need in this program. In contrast, I wanted to call <literal moreinfo="none">newGate</literal> inside <literal moreinfo="none">newGroup</literal>, and so I gave <literal moreinfo="none">newGate</literal> an <literal moreinfo="none">STM</literal> type.<indexterm id="idx-CHP-24-2056" significance="normal"><primary>IO actions (Haskell)</primary><secondary>STM actions vs. as function types</secondary></indexterm></para><para>In general, when designing a library, you should give the functions <literal moreinfo="none">STM</literal> types <indexterm id="idx-CHP-24-2057" significance="normal"><primary>IO actions (Haskell)</primary><secondary>situations where use is essential</secondary></indexterm>wherever possible. You can think of <literal moreinfo="none">STM</literal> actions as Lego bricks that can be glued together—using do {…}, <literal moreinfo="none">retry</literal>, and <literal moreinfo="none">orElse</literal>—to make bigger <literal moreinfo="none">STM</literal> actions. However, as soon as you wrap a block in <literal moreinfo="none">atomically</literal>, making it an <literal moreinfo="none">IO</literal> type, it can no longer be combined atomically with other actions. There is a good reason for that: a value of IO type can perform arbitrary, irrevocable input/output (such as <literal moreinfo="none">launchMissiles</literal>).</para><para>It is therefore good library design to export <literal moreinfo="none">STM</literal> actions (rather than <literal moreinfo="none">IO</literal> actions) whenever possible, because they are composable; their type advertises that they have no irrevocable effects. The library client can readily get from <literal moreinfo="none">STM</literal> to <literal moreinfo="none">IO</literal> (using <literal moreinfo="none">atomically</literal>), but not vice versa.</para><para>Sometimes, however, it is <emphasis>essential</emphasis> to use an <literal moreinfo="none">IO</literal> action. Look at <literal moreinfo="none">operateGate</literal>. The two calls to <literal moreinfo="none">atomically</literal> cannot be combined into one, because the first has an externally visible side effect (opening the gate), while the second blocks until all the elves have woken up and gone through it. So, <literal moreinfo="none">operateGate</literal> <emphasis>must</emphasis> have an <literal moreinfo="none">IO</literal> type.</para></sect2><sect2 id="the_main_program" label="24.3.3"><title>The Main Program</title><para>We will first implement the outer structure of the program, although we have not yet implemented <indexterm id="idx-CHP-24-2058" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm>Santa himself. Here it is:</para><programlisting id="I_programlisting24_tt511" format="linespecific">
	main = do { elf_group &lt;- newGroup 3
	          ; sequence_ [ elf elf_group n | n &lt;- [1..10] ]

	          ; rein_group &lt;- newGroup 9	
	          ; sequence_ [ reindeer rein_group n | n &lt;- [1..9] ]

	          ; forever (santa elf_group rein_group) }
</programlisting><para>The first line creates a <literal moreinfo="none">Group</literal> for the elves with capacity <literal moreinfo="none">3</literal>. The second line is more mysterious: it uses a so-called <emphasis>list comprehension</emphasis> to create a list of <literal moreinfo="none">IO</literal> actions and calls sequence_ to execute them in sequence. The <indexterm id="idx-CHP-24-2059" significance="normal"><primary>IO actions (Haskell)</primary><secondary>list comprehension</secondary></indexterm>list comprehension [<literal moreinfo="none">e|</literal><replaceable>x</replaceable><literal moreinfo="none">&lt;-</literal><replaceable>xs</replaceable><literal moreinfo="none">]</literal> is read, "the list of all <literal moreinfo="none">e</literal> where <replaceable>x</replaceable> is drawn from the list <replaceable>xs</replaceable>." So, the argument to <literal moreinfo="none">sequence_</literal> is the list:<indexterm id="idx-CHP-24-2060" significance="normal"><primary>list comprehension (Haskell)</primary></indexterm></para><programlisting id="I_programlisting24_tt512" format="linespecific">
	[elf elf_group 1, elf elf_group 2, ..., elf elf_group 10]
</programlisting><para>Each of these calls yields an <literal moreinfo="none">IO</literal> action that spawns an elf thread. The function <literal moreinfo="none">sequence_</literal> takes a list of <literal moreinfo="none">IO</literal> actions and returns an action that, when performed, runs each of the actions in the list in order:<footnote id="CHP-24-FNOTE-21"><para>The type [<literal moreinfo="none">IO a</literal>] means "a list of values of type <literal moreinfo="none">IO a</literal>." You may also wonder about the underscore in the name <literal moreinfo="none">sequence_</literal>: it's because there is a related function sequence, whose type is <literal moreinfo="none">[IO a] -&gt; IO [a]</literal>, that gathers the results of the argument actions into a list. Both <literal moreinfo="none">sequence</literal> and <literal moreinfo="none">sequence_</literal> are defined in the <literal moreinfo="none">Prelude</literal> library, which is imported by default.</para></footnote></para><programlisting id="I_programlisting24_tt513" format="linespecific">
	sequence_ :: [IO a] -&gt; IO ( )
</programlisting><para>An <literal moreinfo="none">elf</literal> is built from <literal moreinfo="none">elf1</literal>, but with two differences. First, we want the elf to loop indefinitely, and second, we want it to run in a separate thread:</para><programlisting id="I_programlisting24_tt514" format="linespecific">
	elf :: Group -&gt; Int -&gt; IO ThreadId
	elf gp id = <indexterm id="idx-CHP-24-2061" significance="normal"><primary>forkIO function (Haskell)</primary></indexterm>forkIO (forever (do { elf1 gp id; randomDelay }))
</programlisting><para>The <literal moreinfo="none">forkIO</literal> part spawns its argument as a separate <indexterm id="idx-CHP-24-2062" significance="normal"><primary>Haskell</primary></indexterm>Haskell thread (see the earlier section "Side Effects and Input/Output in Haskell"). In turn, <literal moreinfo="none">forkIO's</literal> argument is a call to <literal moreinfo="none">forever</literal>, which runs <emphasis>its</emphasis> argument repeatedly (compare to the definition of <literal moreinfo="none">nTimes</literal> in "Side Effects and Input/Output in Haskell"):</para><programlisting id="I_programlisting24_tt515" format="linespecific">
	forever :: IO () -&gt; IO ( )
	-- Repeatedly perform the action
	forever act = do { act; forever act }
</programlisting><para>Finally, the expression (<literal moreinfo="none">elf1 gp id</literal>) is an <literal moreinfo="none">IO</literal> action, and we want to repeat that action indefinitely, followed each time by a random delay:</para><programlisting id="I_programlisting24_tt516" format="linespecific">
	randomDelay :: IO ( )
	-- Delay for a random time between 1 and 1,000,000 microseconds
	randomDelay = do { waitTime &lt;- getStdRandom (randomR (1, 1000000))
	                 ; threadDelay waitTime }
</programlisting><para>The rest of the <indexterm id="idx-CHP-24-2063" significance="normal"><primary>main action (Haskell)</primary></indexterm>main program should be self-explanatory. We make 9 reindeer in the same way that we made 10 elves, except that we call <literal moreinfo="none">reindeer</literal> instead of <literal moreinfo="none">elf</literal>:</para><programlisting id="I_programlisting24_tt517" format="linespecific">
	reindeer :: Group -&gt; Int -&gt; IO ThreadId
	reindeer gp id = forkIO (forever (do { reindeer1 gp id; randomDelay }))
</programlisting><para>The code for <literal moreinfo="none">main</literal> finishes by reusing <literal moreinfo="none">forever</literal> to run <literal moreinfo="none">santa</literal> repeatedly. All that remains is to implement Santa himself.<indexterm id="idx-CHP-24-2064" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm></para></sect2><sect2 id="implementing_santa" label="24.3.4"><title>Implementing Santa</title><para>Santa is the most interesting participant of this little drama because he makes choices. He must wait until there is <emphasis>either</emphasis> a group of reindeer waiting <emphasis>or</emphasis> a group of elves. Once he has made his choice of which group to attend to, he must take them through their task. Here is his code:</para><programlisting id="I_programlisting24_tt518" format="linespecific">
	santa :: Group -&gt; Group -&gt; IO ( )
	santa elf_gp rein_gp
	  = do { putStr "----------\n"
	     ; (task, (in_gate, out_gate))
	            &lt;- atomically (orElse
	                   (<indexterm id="idx-CHP-24-2065" significance="normal"><primary>choose function (Haskell)</primary></indexterm>chooseGroup rein_gp "deliver toys")
	                   (chooseGroup elf_gp "meet in my study"))

	     ; putStr ("Ho! Ho! Ho! let's " ++ task ++ "\n")
	     ; operateGate in_gate
	      -- Now the helpers do their task
	     ; operateGate out_gate }

	where
	  chooseGroup :: Group -&gt; String -&gt; <indexterm id="idx-CHP-24-2066" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM (String, (Gate,Gate))
	  chooseGroup gp task = do { gates &lt;- awaitGroup gp
	                       ; return (task, gates) }
</programlisting><para>The choice is made by the <literal moreinfo="none">orElse</literal>, which first attempts to choose the reindeer (thereby giving them priority), and otherwise chooses the elves. The <literal moreinfo="none">chooseGroup</literal> function does an <literal moreinfo="none">awaitGroup</literal> call on the appropriate group, and returns a pair consisting of a string that indicates the task (delivering toys or meeting in the study) and the two gates that <indexterm id="idx-CHP-24-2067" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm>Santa must operate to take the group through the task. Once the choice is made, Santa prints out a message and operates the two gates in sequence.</para><para>This implementation works fine, but we will also explore an alternative, more general version, because <literal moreinfo="none">santa</literal> demonstrates a very common programming pattern. The pattern is this: a thread (Santa in this case) makes a choice in one atomic transaction, followed by one or more further consequential transactions. Another typical example might be: take a message from one of several message queues, act on the message, and repeat. In the Santa scenario, the consequential action was very similar for both elves and reindeer—in both cases, Santa had to print a message and operate two gates. But that would not work if Santa had to do very different things for elves and reindeer. One approach would be to return a Boolean indicating which was chosen, and dispatch on that Boolean after the choice, but that becomes inconvenient as more alternatives are added. Here is another approach that works better:</para><programlisting id="I_programlisting24_tt519" format="linespecific">
	santa :: Group -&gt; Group -&gt; IO ()
	santa elf_gp rein_gp
	  = do { putStr "----------\n"
	       ; choose [(awaitGroup rein_gp, run "deliver toys"),
	                 (awaitGroup elf_gp, run "meet in my study")] }
	  where
	    run :: String -&gt; (Gate,Gate) -&gt; IO ()
	    run task (in_gate,out_gate)
	      = do { putStr ("Ho! Ho! Ho! let's " ++ task ++ "\n")
	           ; operateGate in_gate
	           ; operateGate out_gate }
</programlisting><para>The function <literal moreinfo="none">choose</literal> is like a guarded command: it takes a list of pairs, waits until the first component of a pair is ready to "fire," and then executes the second component. So <literal moreinfo="none">choose</literal> has this type:<footnote id="CHP-24-FNOTE-22"><para>In <indexterm id="idx-CHP-24-2068" significance="normal"><primary>Haskell</primary></indexterm>Haskell, the type [<replaceable>ty</replaceable>] means a list whose elements have type <replaceable>ty</replaceable>. In this case, choose's argument is a list of pairs, written (<replaceable>ty</replaceable>1, <replaceable>ty</replaceable>2); the first component of the pair has type <literal moreinfo="none">STM a</literal>, while the second is a function with type <literal moreinfo="none">a-&gt;IO ( )</literal>.</para></footnote></para><programlisting id="I_programlisting24_tt520" format="linespecific">
	choose :: [(STM a, a -&gt; IO ())] -&gt; IO ( )
</programlisting><para>The guard is an <literal moreinfo="none">STM</literal> action delivering a value of type <literal moreinfo="none">a</literal>; when the <literal moreinfo="none">STM</literal> action is ready (that is, does not retry), <literal moreinfo="none">choose</literal> can pass the value to the second component, which must therefore be a function expecting a value of type <literal moreinfo="none">a</literal>. With this in mind, <indexterm id="idx-CHP-24-2069" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm>santa should be easy reading. He uses <literal moreinfo="none">awaitGroup</literal> to wait for a ready <literal moreinfo="none">Group</literal>; the <literal moreinfo="none">choose</literal> function gets the pair of <literal moreinfo="none">Gates</literal> returned by <literal moreinfo="none">awaitGroup</literal> and passes it to the <literal moreinfo="none">run</literal> function. The latter operates the two gates in succession—recall that <literal moreinfo="none">operateGate</literal> blocks until all the elves (or reindeer) have gone through the gate.</para><para>The code for <literal moreinfo="none">choose</literal> is brief, but a little mind-bending:</para><programlisting id="I_programlisting24_tt521" format="linespecific">
	choose :: [(STM a, a -&gt; IO ( ))] -&gt; IO ( )
	choose choices = do { act &lt;- atomically (foldr1 orElse actions)
	                    ; act }
	  where
	    actions :: [<indexterm id="idx-CHP-24-2070" significance="normal"><primary>IO actions (Haskell)</primary><secondary>STM (IO ( )) action type</secondary></indexterm>STM (IO ( ))]
	    actions = [ do { val &lt;- guard; return (rhs val) }
	              | (guard, rhs) &lt;- choices ]
</programlisting><para>First, it forms <indexterm id="idx-CHP-24-2071" significance="normal"><primary>STM actions</primary><secondary>forming a list and combining with orElse</secondary></indexterm>a list, <literal moreinfo="none">actions</literal>, of <literal moreinfo="none">STM</literal> actions, which it then combines with <literal moreinfo="none">orElse</literal>. (The call <literal moreinfo="none">foldr1</literal> ⊕[<literal moreinfo="none">x</literal><subscript>1</subscript>,…,<literal moreinfo="none">x</literal><emphasis>n</emphasis>] returns <literal moreinfo="none">x</literal><subscript>1</subscript> ⊕ <literal moreinfo="none">x</literal><subscript>2</subscript> ⊕ … ⊕ <literal moreinfo="none">x</literal><subscript><emphasis>n</emphasis></subscript>.) Each of these <literal moreinfo="none">STM</literal> actions itself returns an IO action, namely <emphasis>the thing to be done when the choice is made</emphasis>. That is why each action in the list has the cool type <literal moreinfo="none">STM(IO( ))</literal>. The code first makes an atomic choice among the list of alternatives, getting the action <literal moreinfo="none">act</literal>, with type <literal moreinfo="none">IO( )</literal> in return—and then performs the action act. The list of choices, <literal moreinfo="none">actions</literal>, is constructed by taking each pair (<literal moreinfo="none">guard, rhs</literal>) from the list of choices, running the guard (an <literal moreinfo="none">STM</literal> action), and returning the <literal moreinfo="none">IO</literal> action gotten by applying the rhs to the <literal moreinfo="none">guard's</literal> return value.</para></sect2><sect2 id="compiling_and_running_the_program" label="24.3.5"><title>Compiling and Running the Program</title><para>I have presented <emphasis>all</emphasis> the code for this example. If you simply add the appropriate import statements at the top, listed here, you should be good to go:<footnote id="CHP-24-FNOTE-23"><para>You can get the code online at <ulink url="http://research.microsoft.com/~simonpj/papers/stm/Santa.hs.gz"/>.</para></footnote></para><programlisting id="I_programlisting24_tt522" format="linespecific">
	module Main where
	  import Control.Concurrent.STM
	  import Control.Concurrent
	  import System.Random
</programlisting><para>To compile the code, use the <indexterm id="idx-CHP-24-2072" significance="normal"><primary>Glasgow Haskell Compiler (GHC)</primary></indexterm>Glasgow Haskell Compiler, <indexterm id="idx-CHP-24-2073" significance="normal"><primary>GHC (Glasgow Haskell Compiler)</primary></indexterm>GHC:<footnote id="CHP-24-FNOTE-24"><para>GHC is available for free at <ulink url="http://haskell.org/ghc"/>.<indexterm id="idx-CHP-24-2074" significance="normal"><primary>Haskell</primary></indexterm></para></footnote></para><programlisting id="I_programlisting24_tt523" format="linespecific">
	$ <userinput moreinfo="none">ghc Santa.hs -package stm -o santa</userinput>
</programlisting><para>Finally, you can run the program:<indexterm id="I_indexterm24_tt524" class="endofrange" startref="idx-CHP-24-2044" significance="normal"><primary>Santa Claus problem (concurrent program using STM)</primary></indexterm><indexterm id="I_indexterm24_tt525" class="endofrange" startref="idx-CHP-24-2042" significance="normal"><primary>STM (Software Transactional Memory)</primary><secondary>Santa Claus problem (example program)</secondary></indexterm></para><programlisting id="I_programlisting24_tt526" format="linespecific">
	$ <userinput moreinfo="none">./santa</userinput>
	----------
	Ho! Ho! Ho! let's deliver toys
	Reindeer 8 delivering toys
	Reindeer 7 delivering toys
	Reindeer 6 delivering toys
	Reindeer 5 delivering toys
	Reindeer 4 delivering toys
	Reindeer 3 delivering toys
	Reindeer 2 delivering toys
	Reindeer 1 delivering toys
	Reindeer 9 delivering toys
	----------
	Ho! Ho! Ho! let's meet in my study
	Elf 3 meeting in the study
	Elf 2 meeting in the study
	Elf 1 meeting in the study
	...and so on...
</programlisting></sect2></sect1><sect1 id="reflections_on_haskell" label="24.4"><title>Reflections on Haskell</title><para>Haskell is, first and foremost, a <emphasis>functional</emphasis> language. Nevertheless, I think that it is also the world's most beautiful <emphasis>imperative</emphasis> language. Considered as an imperative language, Haskell's unusual features are that:<indexterm id="idx-CHP-24-2075" significance="normal"><primary>Haskell</primary></indexterm></para><itemizedlist><listitem><para><indexterm id="idx-CHP-24-2076" significance="normal"><primary>data types</primary><secondary>Haskell</secondary><tertiary>distinguishing actions from pure values</tertiary></indexterm>Actions (which have effects) are rigorously distinguished from pure values by the type system.</para></listitem><listitem><para>Actions are <indexterm id="idx-CHP-24-2077" significance="normal"><primary>first-class values</primary></indexterm>first-class values. They can be passed to functions, returned as results, formed into lists, and so on, all without causing any side effects.</para></listitem></itemizedlist><para>Using actions as first-class values, the programmer can define <emphasis>application-specific control structures</emphasis>, rather than make do with the ones provided by the language designer. For example, <literal moreinfo="none">nTimes</literal> is a simple <literal moreinfo="none">for</literal> loop, and <literal moreinfo="none">choose</literal> implements a sort of guarded command. We also saw other applications of actions as values. In the main program, we used Haskell's rich expression language (in this case, list comprehensions) to generate a list of actions, which we then performed in order, using <literal moreinfo="none">sequence_</literal>. Earlier, when defining <literal moreinfo="none">helper1</literal>, we improved modularity by abstracting out an action from a chunk of code. To illustrate these points, I have perhaps overused Haskell's abstraction power in the Santa code, which is a very small program. For large programs, though, it is hard to overstate the importance of actions as values.<indexterm id="idx-CHP-24-2078" significance="normal"><primary>application-specific control structures</primary></indexterm></para><para>On the other hand, I have underplayed other aspects of Haskell—higher-order functions, lazy evaluation, data types, polymorphism, type classes, and so on—because of the focus on <indexterm id="idx-CHP-24-2079" significance="normal"><primary>concurrency</primary></indexterm>concurrency. Not many Haskell programs are as imperative as this one! You can find a great deal of information about Haskell at <ulink url="http://haskell.org"/>, including books, tutorials, Haskell compilers and interpreters, Haskell libraries, mailing lists, and much more besides.</para></sect1><sect1 id="conclusion-id012" label="24.5"><title>Conclusion</title><para>My main goal is to persuade you that you can write programs in a fundamentally more modular way using <indexterm id="idx-CHP-24-2080" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm>STM than you can with locks and condition variables. First, though, note that transactional memory allows us to completely avoid many of the standard problems that plague lock-based <indexterm id="idx-CHP-24-2081" significance="normal"><primary>modular programming</primary><secondary>concurrent programming using STM</secondary></indexterm>concurrent programs (as explained earlier in the section "Locks Are Bad"). <emphasis>None of these problems arises in STM Haskell</emphasis>. The type system prevents you from reading or writing a <literal moreinfo="none">TVar</literal> outside an atomic block, and because there <emphasis>are</emphasis> no programmer-visible locks, the questions of which locks to take, and in which order, simply do not arise. Other benefits of STM, which I lack the space to describe here, include freedom from lost wakeups and the treatment of exceptions and error recovery.<indexterm id="idx-CHP-24-2082" significance="normal"><primary>STM (Software Transactional Memory)</primary></indexterm><indexterm id="idx-CHP-24-2083" significance="normal"><primary>Haskell</primary></indexterm></para><para>However, as we also discussed in the section "Locks Are Bad," the worst problem with lock-based programming is that <emphasis>locks do not compose</emphasis>. In contrast, any function with an <literal moreinfo="none">STM</literal> type in Haskell can be composed, using sequencing or choice, with any other function with an <literal moreinfo="none">STM</literal> type to make a new function of <literal moreinfo="none">STM</literal> type. Furthermore, the compound function will guarantee all the same atomicity properties that the individual functions did. In particular, blocking (<literal moreinfo="none">retry</literal>) and choice (<literal moreinfo="none">orElse</literal>), which are fundamentally non-modular when expressed using locks, are fully modular in STM. For example, consider this transaction, which uses functions we defined in the section "Blocking and Choice":</para><programlisting id="I_programlisting24_tt527" format="linespecific">
	atomically (do { limitedWithdraw a1 10
	               ; limitedWithdraw2 a2 a3 20 })
</programlisting><para>This transaction blocks until <literal moreinfo="none">a1</literal> contains at least 10 units, and either <literal moreinfo="none">a2</literal> or <literal moreinfo="none">a3</literal> has 20 units. However, that complicated blocking condition is not written explicitly by the programmer, and indeed if the <literal moreinfo="none">limitedWithdraw</literal> functions are implemented in a sophisticated library, the programmer might have no idea what their blocking conditions are. STM is modular: small programs can be glued together to make larger programs <emphasis>without exposing their implementations</emphasis>.</para><para>There are many aspects of <indexterm id="idx-CHP-24-2084" significance="normal"><primary>transactional memory</primary></indexterm>transactional memory that I have not covered in this brief overview, including important topics such as nested transactions, exceptions, progress, starvation, and invariants. You can find many of them discussed in papers about STM Haskell.<footnote id="CHP-24-FNOTE-25"><para>Tim Harris, Simon Marlow, Simon Peyton <indexterm id="idx-CHP-24-2085" significance="normal"><primary>Jones</primary></indexterm>Jones, and Maurice Herlihy, "Composable memory transactions," <emphasis>ACM Symposium on Principles and Practice of Parallel Programming (PPoPP '05</emphasis>), June 2005; Tim Harris and Simon Peyton Jones, "Transactional memory with data invariants," <emphasis>First ACM SIGPLAN Workshop on Languages, Compilers, and Hardware Support for Transactional Computing (TRANSACT '06</emphasis>), Ottawa, June 2006, ACM; Anthony Discolo, Tim Harris, Simon Marlow, Simon Peyton Jones, and Satnam Singh, "Lock-free data structures using STMs in Haskell," <emphasis>Eighth International Symposium on Functional and Logic Programming (FLOPS '06</emphasis>), April 2006.</para></footnote></para><para>Transactional memory is a particularly good "fit" for Haskell. In STM, the implementation potentially must track every memory load and store, but a Haskell STM need only track <literal moreinfo="none">TVar</literal> operations, and these form only a tiny fraction of all the memory loads and stores executed by a Haskell program. Furthermore, the treatment of actions as first-class values, and the rich type system, allow us to offer strong static guarantees without extending the language in any way. However, there is nothing to stop the adoption of transactional memory in mainstream imperative languages, although it may be less elegant and require more language support. Indeed doing so is a hot research topic; Larus and Rajwar give a comprehensive summary.<footnote id="CHP-24-FNOTE-26"><para>James Larus and Ravi Rajwar, <emphasis>Transactional Memory</emphasis>, Morgan &amp; Claypool, 2006.</para></footnote><indexterm id="I_indexterm24_tt528" class="endofrange" startref="idx-CHP-24-1955" significance="normal"><primary>concurrency</primary></indexterm><indexterm id="I_indexterm24_tt529" class="endofrange" startref="idx-CHP-24-1989" significance="normal"><primary>Haskell</primary></indexterm></para><para>Using STM is like using a high-level language instead of assembly code—you can still write buggy programs, but many tricky bugs simply cannot occur, and it is much easier to focus attention on the higher-level aspects of the program. There is, alas, no silver bullet that will make concurrent programs easy to write. But STM looks like a promising step forward, and one that will help you to write beautiful code.</para></sect1><sect1 id="acknowledgments-id004" label="24.6"><title>Acknowledgments</title><para>I would like to thank those who helped me to improve the chapter with their feedback: Bo Adler, Justin Bailey, Matthew Brecknell, Paul Brown, Conal Elliot, Tony Finch, Kathleen Fisher, Greg Fitzgerald, Benjamin Franksen, Jeremy Gibbons, Tim Harris, Robert Helgesson, Dean Herington, David House, Brian Hulley, Dale Jordan, Marnix Klooster, Chris Kuklewicz, Evan Martin, Greg Meredith, Neil Mitchell, Jun Mukai, Michal Palka, Sebastian Sylvan, Johan Tibell, Aruthur van Leeuwen, Wim Vanderbauwhede, David Wakeling, Dan Wang, Peter Wasilko, Eric Willigers, Gaal Yahas, and Brian Zimmer. My special thanks go to Kirsten Chevalier, Andy Oram, and Greg Wilson for their particularly detailed reviews.</para></sect1></chapter><chapter id="syntactic_abstraction_the_syntax-case_expander" label="25" role=""><title>Syntactic Abstraction: The syntax-case Expander</title><para><emphasis>R. Kent Dybvig</emphasis><indexterm class="startofrange" id="idx-CHP-25-2086" significance="normal"><primary>syntactic abstraction</primary></indexterm><indexterm id="idx-CHP-25-2087" significance="normal"><primary>Dybvig</primary></indexterm></para><para><emphasis>When writing computer programs, certain patterns arise over and over again</emphasis>. For example, programs must often loop through the elements of arrays, increment or decrement the values of variables, and perform multiway conditionals based on numeric or character values. <indexterm id="idx-CHP-25-2088" significance="normal"><primary>programming languages</primary></indexterm>Programming language designers typically acknowledge this by including <indexterm id="idx-CHP-25-2089" significance="normal"><primary>C language</primary><secondary>special-purpose syntactic constructs</secondary></indexterm>special-purpose syntactic constructs that handle the most common patterns. C, for instance, provides multiple looping constructs, multiple conditional constructs, and multiple constructs for incrementing or otherwise updating the value of a variable.<footnote id="CHP-25-FNOTE-1"><para><emphasis>The C Programming Language</emphasis>, Second Edition, Brian W. Kernighan and Dennis M. Ritchie, Prentice Hall, 1988.</para></footnote></para><para>Some patterns are less common but may occur <indexterm id="idx-CHP-25-2090" significance="normal"><primary>patterns</primary><secondary>frequently encountered in computer programming</secondary></indexterm>frequently in a certain class of programs, or perhaps just within a single program. These patterns may not even be anticipated by a language's designers, who in any case would typically choose not to incorporate syntactic constructs to handle such patterns in the language core.</para><para>Yet, recognizing that such patterns do arise and that special-purpose syntactic constructs can make programs both simpler and easier to read, language designers sometimes include a mechanism <indexterm id="idx-CHP-25-2091" significance="normal"><primary>identifiers</primary><secondary>unintended variable captures</secondary><tertiary>scoping in output instead of input</tertiary></indexterm><indexterm id="idx-CHP-25-2092" significance="normal"><primary>macros</primary><secondary>for syntactic abstraction</secondary></indexterm>for <emphasis>syntactic abstraction</emphasis>, such as C's <indexterm id="idx-CHP-25-2093" significance="normal"><primary>preprocessor macros (C)</primary></indexterm>preprocessor macros or <indexterm id="idx-CHP-25-2094" significance="normal"><primary>Common LISP macros</primary></indexterm>Common Lisp<footnote id="CHP-25-FNOTE-2"><para><emphasis>Common Lisp: The Language</emphasis>, Second Edition, Guy L. Steele Jr., Digital Press, 1990.</para></footnote> <indexterm id="idx-CHP-25-2095" significance="normal"><primary>LISP</primary><secondary>macros</secondary></indexterm>macros. When such facilities are absent or are inadequate for a specific purpose, an external tool, such as the <emphasis>m4</emphasis> macro expander,<footnote id="CHP-25-FNOTE-3"><para><emphasis>The M4 Macro Processor</emphasis>, Brian W. Kernighan and Dennis M. Ritchie, 1979.</para></footnote> may be brought to bear.<indexterm id="idx-CHP-25-2096" significance="normal"><primary>syntactic abstraction</primary></indexterm><indexterm id="idx-CHP-25-2097" significance="normal"><primary>m4 macro expander</primary></indexterm></para><para><indexterm id="idx-CHP-25-2098" significance="normal"><primary>C language</primary><secondary>syntactic abstraction mechanism</secondary></indexterm>Syntactic abstraction facilities differ in several significant ways. C's preprocessor macros are essentially <indexterm id="idx-CHP-25-2099" significance="normal"><primary>tokens</primary><secondary>token-based C preprocessor macros</secondary></indexterm>token-based, allowing the replacement of a macro call with a sequence of tokens; text passed to the macro call is substituted for the macro's formal parameters, if any. Lisp macros are <indexterm id="idx-CHP-25-2100" significance="normal"><primary>expression-based LISP macros</primary></indexterm>expression-based, allowing the replacement of a single expression with another expression, computed in Lisp itself and based on the subforms of the macro call, if any.</para><para>In both cases, identifiers appearing within a macro-call subform are scoped where they appear in the output, rather than where they appear in the input, possibly leading to unintended <emphasis>capture</emphasis> of a <indexterm class="startofrange" id="idx-CHP-25-2101" significance="normal"><primary>variable capture problems</primary></indexterm>variable reference by a <indexterm id="idx-CHP-25-2102" significance="normal"><primary>bindings</primary><secondary>variable</secondary></indexterm>variable binding.<indexterm class="startofrange" id="idx-CHP-25-2103" significance="normal"><primary>capture of a variable reference by a variable binding</primary></indexterm></para><para>For example, consider the simple <indexterm id="idx-CHP-25-2104" significance="normal"><primary>Scheme language</primary><secondary>transformation of or form into let and if</secondary></indexterm>transformation of Scheme's or form<footnote id="CHP-25-FNOTE-4"><para>"Revised report on the algorithmic language Scheme," Richard Kelsey, William Clinger, and Jonathan Rees, editors, <emphasis>Higher-Order and Symbolic Computation</emphasis>, Vol. 11, No. 1, pp. 7–105, 1998. Also appeared in <emphasis>ACM SIGPLAN Notices</emphasis>, Vol. 33, No. 9, September 1998.</para></footnote> into <literal moreinfo="none">let</literal> and <literal moreinfo="none">if</literal> in the following example:</para><programlisting id="I_programlisting25_tt530" format="linespecific">
	(or e<replaceable><subscript>1</subscript></replaceable> e<replaceable><subscript>2</subscript></replaceable>) → (let ([t e<replaceable><subscript>1</subscript></replaceable>]) (if t t e<replaceable><subscript>2</subscript></replaceable>))
</programlisting><note id="note-3" role="missingmanual"><para>Readers unfamiliar with Scheme might want to read the first few chapters of <emphasis>The Scheme Programming Language</emphasis>, Third Edition (R. Kent <indexterm id="idx-CHP-25-2105" significance="normal"><primary>Dybvig</primary></indexterm>Dybvig, MIT Press), which is available online at <ulink url="http://www.scheme.com/tspl3"/>.</para></note><para>An <literal moreinfo="none">or</literal> form must return the value of its first subform, if it evaluates to a true (any non-false) value. The <literal moreinfo="none">let</literal> expression is used to name this value so that it is not computed twice.</para><para>The previous transformation works fine in most cases, but it breaks down if the identifier <literal moreinfo="none">t</literal> appears free in <literal moreinfo="none">e</literal><replaceable><subscript>2</subscript></replaceable> (i.e., outside of any binding for <literal moreinfo="none">t</literal> in <literal moreinfo="none">e</literal><replaceable><subscript>2</subscript></replaceable>), as in the following expression:</para><programlisting id="I_programlisting25_tt531" format="linespecific">
	(let ([t #t]) (or #f t))
</programlisting><para>This should evaluate to the true value <literal moreinfo="none">#t</literal>. With the simple transformation of <literal moreinfo="none">or</literal> specified previously, however, the expression expands to:</para><programlisting id="I_programlisting25_tt532" format="linespecific">
	(let ([t #t])
	  (let ([t #f])
	    (if t t t)))
</programlisting><para>which evaluates to the false value <literal moreinfo="none">#f</literal>.</para><para>Once seen, this problem is easily addressed by using a generated identifier for the <indexterm id="idx-CHP-25-2106" significance="normal"><primary>identifiers</primary><secondary>unintended variable captures</secondary><tertiary>introduced bindings and references</tertiary></indexterm>introduced binding:</para><programlisting id="I_programlisting25_tt533" format="linespecific">
	(or e<replaceable><subscript>1</subscript></replaceable> e<replaceable><subscript>2</subscript></replaceable>) → (let ([<replaceable>g</replaceable> e<replaceable><subscript>1</subscript></replaceable>]) (if <replaceable>g g</replaceable> e<replaceable><subscript>2</subscript></replaceable>))
</programlisting><para>where <replaceable>g</replaceable> is a generated (fresh) identifier.</para><para>As Kohlbecker, Friedman, Felleisen, and Duba observe in their seminal paper on hygienic macro expansion<footnote id="CHP-25-FNOTE-5"><para>"Hygienic macro expansion," Eugene Kohlbecker, Daniel P. Friedman, Matthias Felleisen, and Bruce Duba, <emphasis>Proceedings of the 1986 ACM Conference on Lisp and Functional Programming</emphasis>, pp. 151–161, 1986.</para></footnote> <indexterm id="idx-CHP-25-2107" significance="normal"><primary>variable capture problems</primary></indexterm>variable <indexterm id="idx-CHP-25-2108" significance="normal"><primary>capture of a variable reference by a variable binding</primary></indexterm>capture problems like this are insidious, because a transformation may work correctly for a large body of code only to fail sometime later in a way that may be difficult to debug.</para><para>While unintended captures caused by introduced identifier <emphasis>bindings</emphasis> can always be solved by using generated identifiers, no such simple solution is available for introduced identifier <emphasis>references</emphasis>, which may be captured by bindings in the context of the macro call. In the following expression, <literal moreinfo="none">if</literal> is lexically bound in the context of an <literal moreinfo="none">or</literal> expression:<indexterm id="idx-CHP-25-2109" significance="normal"><primary>references (variable)</primary></indexterm></para><programlisting id="I_programlisting25_tt534" format="linespecific">
	(let ([if (lambda (x y z) "oops")]) (or #f #f))
</programlisting><para><indexterm id="idx-CHP-25-2110" significance="normal"><primary>variable capture problems</primary><secondary>solving with hygienic macro expansion</secondary></indexterm>With the second transformation for <literal moreinfo="none">or</literal>, this expression expands into:</para><programlisting id="I_programlisting25_tt535" format="linespecific">
	(let ([if (lambda (x y z) "oops")])
	  (let ([<replaceable>g</replaceable> #f])
	    (if <replaceable>g g</replaceable> #f)))
</programlisting><para>where <replaceable>g</replaceable> is a fresh identifier. The value of the expression should be <literal moreinfo="none">#f</literal>, but will actually be "<literal moreinfo="none">oops</literal>" because the locally bound procedure <literal moreinfo="none">if</literal> is used in place of the original <literal moreinfo="none">if</literal> conditional syntax.</para><para>Limiting the language by <indexterm id="idx-CHP-25-2111" significance="normal"><primary>keywords</primary><secondary>reserving the names of</secondary></indexterm>reserving the names of keywords such as <literal moreinfo="none">let</literal> and <literal moreinfo="none">if</literal> would solve this problem for keywords, but it would not solve the problem generally. For instance, the same situation can arise with the introduced reference to the user-defined <indexterm id="idx-CHP-25-2112" significance="normal"><primary>bindings</primary><secondary>variable</secondary></indexterm>variable <literal moreinfo="none">add1</literal> in the following transformation of <literal moreinfo="none">increment</literal>:</para><programlisting id="I_programlisting25_tt536" format="linespecific">
	(increment <replaceable>x</replaceable>) → (set! <replaceable>x</replaceable> (add1 <replaceable>x</replaceable>))
</programlisting><para>Kohlbecker et al. invented the concept of <emphasis>hygienic</emphasis> macro expansion to solve both kinds of capturing problems, borrowing the term "hygiene" from Barendregt.<footnote id="CHP-25-FNOTE-6"><para>"Introduction to the lambda calculus," H. P. Barendregt, <emphasis>Nieuw Archief voor Wisenkunde</emphasis>, Vol. 4, No. 2, pp. 337–372, 1984.</para></footnote> Barendregt's hygiene condition for the λ-calculus holds that the free variables of one expression substituted into another are assumed not to be captured by bindings in the other, unless such capture is explicitly required. Kohlbecker et al. adapted this into the following <emphasis>hygiene condition for macro expansion</emphasis>:<indexterm id="idx-CHP-25-2113" significance="normal"><primary>hygiene condition for macro expansion</primary></indexterm></para><blockquote><para>Generated identifiers that become binding instances in the completely expanded program must only bind variables that are generated at the same transcription step.</para></blockquote><para>In practice, this requirement forces the expander to rename identifiers as necessary to avoid unintended <indexterm id="idx-CHP-25-2114" significance="normal"><primary>capture of a variable reference by a variable binding</primary></indexterm>captures. For example, with the original <literal moreinfo="none">or</literal> transformation:</para><programlisting id="I_programlisting25_tt537" format="linespecific">
	(or e<replaceable><subscript>1</subscript></replaceable> e<replaceable><subscript>2</subscript></replaceable>) → (let ([t e<replaceable><subscript>1</subscript></replaceable>]) (if t t e<replaceable><subscript>2</subscript></replaceable>))
</programlisting><para>the expression:</para><programlisting id="I_programlisting25_tt538" format="linespecific">
	(let ([t #t]) (or #f t))
</programlisting><para>expands into the equivalent of:</para><programlisting id="I_programlisting25_tt539" format="linespecific">
	(let ([t0 #t])
	  (let ([t1 #f])
	    (if t1 t1 t0)))
</programlisting><para>which properly evaluates to #t. Similarly, the expression:</para><programlisting id="I_programlisting25_tt540" format="linespecific">
	(let ([if (lambda (x y z) "oops")]) (or #f #f))
</programlisting><para>expands into the equivalent of:</para><programlisting id="I_programlisting25_tt541" format="linespecific">
	(let ([if0 (lambda (x y z) "oops")])
	  (let ([t #f])
	    (if t t #f)))
</programlisting><para>which properly evaluates to <literal moreinfo="none">#f</literal>.</para><para>In essence, hygienic macro expansion implements <indexterm id="idx-CHP-25-2115" significance="normal"><primary>lexical scoping</primary></indexterm>lexical scoping with respect to the source code, whereas <indexterm id="idx-CHP-25-2116" significance="normal"><primary>unhygienic macro expansion</primary></indexterm>unhygienic expansion implements <indexterm id="idx-CHP-25-2117" significance="normal"><primary>hygienic macro expansion</primary><secondary>lexical scoping implemented for source code</secondary></indexterm>lexical scoping with respect to the code after expansion.</para><para>Hygienic expansion can preserve lexical scope only to the extent that the scope is preserved by the transformations it is told to perform. A transformation can still produce code that apparently violates lexical scoping. This can be illustrated with the following (incorrect) transformation of <literal moreinfo="none">let</literal>:</para><programlisting id="I_programlisting25_tt542" format="linespecific">
	(let ((<replaceable>x e</replaceable>)) <replaceable>body</replaceable>) → (letrec ((<replaceable>x e</replaceable>)) <replaceable>body</replaceable>)
</programlisting><para>The expression <replaceable>e</replaceable> should appear outside the scope of the binding of the <indexterm id="idx-CHP-25-2118" significance="normal"><primary>variable capture problems</primary></indexterm>variable <replaceable>x</replaceable>, but in the output it appears inside, due to the semantics of <literal moreinfo="none">letrec</literal>.</para><para>The <indexterm id="idx-CHP-25-2119" significance="normal"><primary>expansion algorithms</primary><secondary>hygienic macro expansion algorithm (KFFD)</secondary></indexterm>hygienic macro expansion algorithm (<indexterm id="idx-CHP-25-2120" significance="normal"><primary>KFFD (hygienic macro expansion algorithm)</primary></indexterm>KFFD) described by Kohlbecker et al. is both clever and elegant. It works by adding a timestamp to each <indexterm id="idx-CHP-25-2121" significance="normal"><primary>bindings</primary><secondary>variable</secondary></indexterm>variable introduced by a macro, and then uses the timestamps to distinguish like-named variables as it renames lexically bound variables. <indexterm id="idx-CHP-25-2122" significance="normal"><primary>hygienic macro expansion</primary><secondary>KFFD algorithm</secondary></indexterm>KFFD has some shortcomings that prevent its direct use in practice, however. The most serious are a lack of support for local macro bindings and quadratic overhead resulting from the complete rewrite of each expression as timestamping and renaming are performed.</para><para>These shortcomings are addressed by the <literal moreinfo="none">syntax-rules</literal> system, developed by Clinger, <indexterm id="idx-CHP-25-2123" significance="normal"><primary>Dybvig</primary></indexterm>Dybvig, Hieb, and Rees for the Revised Report on Scheme.<footnote id="CHP-25-FNOTE-7"><para>"Revised report on the algorithmic language Scheme," William Clinger and Jonathan Rees, editors, <emphasis>LISP Pointers</emphasis>, Vol. 4, No. 3, pp. 1–55, July–September 1991.</para></footnote> The simple pattern-based nature of the <literal moreinfo="none">syntax-rules</literal> system permits it to be implemented easily and efficiently.<footnote id="CHP-25-FNOTE-8"><para>"Macros that work," William <indexterm id="idx-CHP-25-2124" significance="normal"><primary>lambda expressions</primary><secondary>in define-syntax form</secondary></indexterm>Clinger and Jonathan Rees, <emphasis>Conference Record of the Eighteenth Annual ACM Symposium on Principles of Programming Languages</emphasis>, pp. 155–162, January 1991.</para></footnote> Unfortunately, it also limits the utility of the mechanism, so that many useful <indexterm id="idx-CHP-25-2125" significance="normal"><primary>syntactic abstraction</primary></indexterm>syntactic abstractions are either difficult or impossible to write.<indexterm id="idx-CHP-25-2126" significance="normal"><primary>syntax-rules system</primary></indexterm></para><para>The <literal moreinfo="none">syntax-case</literal> system<footnote id="CHP-25-FNOTE-9"><para>"Syntactic abstraction in Scheme," R. Kent <indexterm id="idx-CHP-25-2127" significance="normal"><primary>Dybvig</primary></indexterm>Dybvig, Robert Hieb, and Carl Bruggeman, <emphasis>Lisp and Symbolic Computation</emphasis>, Vol. 5, No. 4, pp. 295–326, 1993.</para></footnote> was developed to address the shortcomings of the original algorithm without the limitations of <literal moreinfo="none">syntax-rules</literal>. The system supports local macro bindings and operates with constant overhead, yet allows macros to use the full expressive power of the Scheme language. It is upwardly compatible with <literal moreinfo="none">syntax-rules</literal>, which can be expressed as a simple macro in terms of <literal moreinfo="none">syntax-case</literal>, and it permits the same pattern language to be used even for "low-level" macros for which <literal moreinfo="none">syntax-rules</literal> cannot be used. It also provides a mechanism for allowing <emphasis>intended</emphasis> <indexterm id="idx-CHP-25-2128" significance="normal"><primary>capture of a variable reference by a variable binding</primary></indexterm>captures—i.e., allowing hygiene to be "bent" or "broken" in a selective and straightforward manner. In addition, it handles several practical aspects of expansion that must be addressed in a real implementation, such as internal definitions and tracking of source information through macro expansion.<indexterm id="idx-CHP-25-2129" significance="normal"><primary>intended variable captures</primary></indexterm><indexterm id="idx-CHP-25-2130" significance="normal"><primary>syntax-case form</primary></indexterm><indexterm id="idx-CHP-25-2131" significance="normal"><primary>syntax-case system</primary></indexterm></para><para>This all comes at a price in terms of the complexity of the expansion algorithm and the size of the code required to implement it. A study of a complete implementation in all its glory is therefore beyond the scope of this chapter. Instead, we'll investigate a simplified version of the expander that illustrates the underlying algorithm and the most important aspects of its implementation.</para><sect1 id="brief_introduction_to_syntax-case" label="25.1"><title>Brief Introduction to syntax-case</title><para>We'll start with a few brief <literal moreinfo="none">syntax-case</literal> examples, adapted from the <emphasis>Chez Scheme Version 7 User's Guide</emphasis> (R. Kent Dybvig, Cadence Research Systems, 2005). Additional examples and a more detailed description of <literal moreinfo="none">syntax-case</literal> are given in that document and in <emphasis>The Scheme Programming Language</emphasis>, Third Edition.<indexterm class="startofrange" id="idx-CHP-25-2132" significance="normal"><primary>syntax-case</primary><secondary>introduction to</secondary></indexterm><indexterm id="idx-CHP-25-2133" significance="normal"><primary>Scheme language</primary><secondary>syntax-case</secondary></indexterm><indexterm id="idx-CHP-25-2134" significance="normal"><primary>macros</primary><secondary>syntax-case macro definition</secondary></indexterm></para><para>The following definition of or illustrates the form of a <literal moreinfo="none">syntax-case</literal> <indexterm id="idx-CHP-25-2135" significance="normal"><primary>syntax-case</primary><secondary>introduction to</secondary><tertiary>macro definition</tertiary></indexterm>macro definition:<indexterm id="I_indexterm25_tt543" class="endofrange" startref="idx-CHP-25-2103" significance="normal"><primary>capture of a variable reference by a variable binding</primary></indexterm><indexterm id="I_indexterm25_tt544" class="endofrange" startref="idx-CHP-25-2101" significance="normal"><primary>variable capture problems</primary></indexterm></para><programlisting id="I_programlisting25_tt545" format="linespecific">
	(<indexterm id="idx-CHP-25-2136" significance="normal"><primary>define-syntax form</primary></indexterm>define-syntax or
	  (lambda (x)
	    (syntax-case x ()
	      [(_ e1 e2)
	       (syntax (let ([t e1]) (if t t e2)))])))
</programlisting><para>The <literal moreinfo="none">define-syntax</literal> form creates a <indexterm id="idx-CHP-25-2137" significance="normal"><primary>keywords</primary><secondary>keyword binding</secondary></indexterm>keyword binding, associating the keyword <literal moreinfo="none">or</literal> in this case with a transformation procedure, or <emphasis>transformer</emphasis>. The transformer is obtained by evaluating, at expansion time, the <literal moreinfo="none">lambda</literal> expression on the righthand side of the <literal moreinfo="none">define-syntax</literal> form. The <literal moreinfo="none">syntax-case</literal> form is used to parse the input, and the <literal moreinfo="none">syntax</literal> form is used to construct the output, via straightforward pattern matching. The <emphasis>pattern</emphasis> (_ <literal moreinfo="none">e1 e2</literal>) specifies the shape of the input, with the underscore (_) marking where the keyword or appears, and the pattern variables <literal moreinfo="none">e1</literal> and <literal moreinfo="none">e2</literal> bound <indexterm id="idx-CHP-25-2138" significance="normal"><primary>syntax-case</primary><secondary>introduction to</secondary></indexterm>to the first and second subforms. The <emphasis>template</emphasis> <literal moreinfo="none">(let([te1]) (iftte2))</literal> specifies the output, with <literal moreinfo="none">e1</literal> and <literal moreinfo="none">e2</literal> inserted from the input.<indexterm id="idx-CHP-25-2139" significance="normal"><primary>template specifying output in define-syntax form</primary></indexterm></para><para>The form (<literal moreinfo="none">syntax</literal> <replaceable>template</replaceable>) may be abbreviated to <literal moreinfo="none">#</literal>'<replaceable>template</replaceable>, so the previous definition may be rewritten as follows:</para><programlisting id="I_programlisting25_tt546" format="linespecific">
	(define-syntax or
	   (lambda (x)
	      (syntax-case x ()
	        [(_ e1 e2)
	         (syntax (let ([t e1]) (if t t e2))])))
</programlisting><para>Macros may also be bound within a single expression via <literal moreinfo="none">letrec-syntax</literal>.<indexterm id="idx-CHP-25-2140" significance="normal"><primary>letrec-syntax</primary></indexterm></para><programlisting id="I_programlisting25_tt547" format="linespecific">
	(letrec-syntax ([or (lambda (x)
	                      (syntax-case x ()
	                        [(_ e1 e2)
	                         #'(let ([t e1]) (if t t e2))]))])
	 (or a b))
</programlisting><para>Macros can be recursive (i.e., expand into occurrences of themselves), as illustrated by the following version of or that handles an arbitrary number of subforms. Multiple <literal moreinfo="none">syntax-case</literal> clauses are required to handle the two base cases and the recursion case:</para><programlisting id="I_programlisting25_tt548" format="linespecific">
	(define-syntax or
	  (lambda (x)
	    (syntax-case x ()
	      [(_) #'#f]
	      [(_ e) #'e]
	      [(_ e1 e2 e3 ...)
	       #'(let ([t e1]) (if t t (or e2 e3 ...)))])))
</programlisting><para>An <indexterm id="idx-CHP-25-2141" significance="normal"><primary>syntax-case</primary><secondary>introduction to</secondary><tertiary>input or output form followed by ellipsis</tertiary></indexterm>input or output form followed by an ellipsis in the <literal moreinfo="none">syntax-case</literal> pattern language matches or produces zero or more forms.</para><para><indexterm id="idx-CHP-25-2142" significance="normal"><primary>syntax-case</primary><secondary>introduction to</secondary><tertiary>hygiene</tertiary></indexterm>Hygiene is ensured for the definitions of <literal moreinfo="none">or</literal> in this example, so that the introduced binding for t and the introduced references to <literal moreinfo="none">let, if</literal>, and even or are scoped properly. If we want to bend or break hygiene, we do so with the <indexterm id="idx-CHP-25-2143" significance="normal"><primary>datum-&gt;syntax procedure (syntax-case)</primary></indexterm>procedure <literal moreinfo="none">datum-&gt;syntax</literal>, which produces a syntax object from an arbitrary <indexterm id="idx-CHP-25-2144" significance="normal"><primary>s-expression</primary></indexterm>s-expression. The identifiers within the s-expression are treated as if they appeared in the original source where the first argument, the <emphasis>template identifier</emphasis>, appeared.<indexterm id="idx-CHP-25-2145" significance="normal"><primary>template identifier</primary></indexterm></para><para>We can use this fact to create a simple <literal moreinfo="none">method</literal> syntax that implicitly binds the name <literal moreinfo="none">this</literal> to the first (object) argument:</para><programlisting id="I_programlisting25_tt549" format="linespecific">
	(define-syntax method
	  (lambda (x)
	    (syntax-case x ()
	      [(k (x ...) e1 e2 ...)
	       (with-syntax ([this (datum-&gt;syntax #'k 'this)])
	         #'(lambda (this x ...) e1 e2 ...))])))
</programlisting><para>By using the keyword <literal moreinfo="none">k</literal>, extracted from the input, as the template variable, the variable <literal moreinfo="none">this</literal> is treated as if it were present in the <literal moreinfo="none">method</literal> form, so that:<indexterm id="idx-CHP-25-2146" significance="normal"><primary>method form (syntax-case)</primary></indexterm></para><programlisting id="I_programlisting25_tt550" format="linespecific">
	(method (a) (f this a))
</programlisting><para>is treated as the equivalent of:</para><programlisting id="I_programlisting25_tt551" format="linespecific">
	(lambda (this a) (f this a))
</programlisting><para>with no renaming <indexterm id="idx-CHP-25-2147" significance="normal"><primary>syntax-case</primary><secondary>introduction to</secondary></indexterm>to prevent the introduced binding from capturing the source-code reference.</para><para>The <literal moreinfo="none">with-syntax</literal> form used in the definition of <literal moreinfo="none">method</literal> creates local pattern-variable bindings. It is a simple macro written in terms of <literal moreinfo="none">syntax-case</literal>:<indexterm id="idx-CHP-25-2148" significance="normal"><primary>with-syntax form</primary></indexterm><indexterm class="startofrange" id="idx-CHP-25-2149" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary></indexterm></para><programlisting id="I_programlisting25_tt552" format="linespecific">
	(define-syntax with-syntax
	  (lambda (x)
	    (syntax-case x ()
	      [(_ ((p e0) ...) e1 e2 ...)
	       #'(syntax-case (list e0 ...) ()
	           [(p ...) (begin e1 e2 ...)])])))
</programlisting><para>The <literal moreinfo="none">datum-&gt;syntax</literal> <indexterm id="idx-CHP-25-2150" significance="normal"><primary>datum-&gt;syntax procedure (syntax-case)</primary></indexterm>procedure can be used for arbitrary expressions, as illustrated by the following definition of <literal moreinfo="none">include</literal>:<indexterm id="idx-CHP-25-2151" significance="normal"><primary>include form</primary></indexterm></para><programlisting id="I_programlisting25_tt553" format="linespecific">
	(define-syntax include
	  (lambda (x)
	    (define read-file
	      (lambda (fn k)
	        (let ([p (open-input-file fn)])
	          (let f ([x (read p)])
	            (if (eof-object? x)
	                (begin (close-input-port p) '())
	                (cons (datum-&gt;syntax k x) (f (read p))))))))
	    (syntax-case x ()
	      [(k filename)
	       (let ([fn (syntax-&gt;datum #'filename)])
	         (with-syntax ([(e ...) (read-file fn #'k)])
	           #'(begin e ...)))])))
</programlisting><para>The form (<literal moreinfo="none">include "filename"</literal>) has the effect of treating the forms within the named file as if they were present in the source code in place of the <literal moreinfo="none">include</literal> form. In addition to using <literal moreinfo="none">datum-&gt;syntax</literal>, include also uses its inverse operator, <literal moreinfo="none">syntax-&gt;datum</literal>, to convert the filename subform into a string it can pass to <literal moreinfo="none">open-input-file</literal>.</para></sect1><sect1 id="expansion_algorithm" label="25.2"><title>Expansion Algorithm</title><para>The <literal moreinfo="none">syntax-case</literal> expansion algorithm is essentially a lazy variant of the KFFD algorithm that operates on an abstract representation of the input expression rather than on the traditional s-expression representation. The abstract representation encapsulates both a representation of an input form and a <emphasis>wrap</emphasis> that enables the algorithm to determine the scope of all identifiers within the form. The wrap consists of <emphasis>marks</emphasis> and <emphasis>substitutions</emphasis>.<indexterm class="startofrange" id="idx-CHP-25-2152" significance="normal"><primary>syntax-case</primary><secondary>expansion algorithm</secondary></indexterm><indexterm id="idx-CHP-25-2153" significance="normal"><primary>marks</primary></indexterm><indexterm id="idx-CHP-25-2154" significance="normal"><primary>substitutions</primary></indexterm><indexterm id="I_indexterm25_tt554" class="endofrange" startref="idx-CHP-25-2132" significance="normal"><primary>syntax-case</primary><secondary>introduction to</secondary></indexterm></para><para>Marks are like KFFD timestamps and are added to the portions of a macro's output that are introduced by the macro.</para><para>Substitutions map identifiers <indexterm id="idx-CHP-25-2155" significance="normal"><primary>identifiers</primary><secondary>mapping to bindings with substitutions</secondary></indexterm>to bindings with the help of a compile-time environment. Substitutions are created whenever a binding form, such as <literal moreinfo="none">lambda</literal>, is encountered, and they are added to the wraps of the <indexterm id="idx-CHP-25-2156" significance="normal"><primary>syntax objects</primary></indexterm>syntax objects representing the forms within the scope of the binding form's bindings. A substitution applies to an identifier only if the identifier has the same name and marks as the substituted identifier.</para><para>Expansion operates in a recursive, top-down fashion. As the expander encounters a macro call, it invokes the associated transformer on the form, marking it first with a fresh mark and then marking it again with the same mark. Like marks cancel, so only the introduced portions of the macro's output—i.e., those portions not simply copied from the input to the output—remain marked.</para><para>When a core form is encountered, a core form in the output language of the expander (in our case, the traditional s-expression representation) is produced, with any subforms recursively expanded as necessary. Variable references are replaced by generated names via the substitution mechanism.</para><sect2 id="representations" label="25.2.1"><title>Representations</title><para>The most important aspect of the <literal moreinfo="none">syntax-case</literal> mechanism is its abstract representation of program source code as <emphasis>syntax objects</emphasis>. As described above, a syntax object encapsulates not only a representation of the program source code but also a wrap that provides sufficient information about the identifiers contained within the code to implement hygiene:<indexterm id="idx-CHP-25-2157" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>representations</tertiary></indexterm><indexterm id="idx-CHP-25-2158" significance="normal"><primary>representations (syntax-case expansion algorithm)</primary></indexterm></para><programlisting id="I_programlisting25_tt555" format="linespecific">
	(define-record syntax-object (expr wrap))
</programlisting><para>The <literal moreinfo="none">define-record</literal> form creates a new type of value with the specified name (in this case, <literal moreinfo="none">syntax-object</literal>) and fields (in this case, <literal moreinfo="none">expr</literal> and <literal moreinfo="none">wrap</literal>), along with a set of procedures to manipulate it. The procedures in this case are:</para><variablelist><varlistentry><term><literal moreinfo="none">make-syntax-object</literal></term><listitem><para>Returns a new syntax object with the <literal moreinfo="none">expr</literal> and <literal moreinfo="none">wrap</literal> fields initialized to the values of its arguments</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">syntax-object?</literal></term><listitem><para>Returns true if and only if its argument is a syntax object</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">syntax-object-expr</literal></term><listitem><para>Returns the value of the <literal moreinfo="none">expr</literal> field of a <literal moreinfo="none">syntax-object</literal></para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">syntax-object-wrap</literal></term><listitem><para>Returns the value of the <literal moreinfo="none">wrap</literal> field of a syntax object</para></listitem></varlistentry></variablelist><para>A complete implementation of <literal moreinfo="none">syntax-case</literal> might also include, within each syntax object, source information to be tracked through the expansion process.</para><para>Each wrap, as explained previously, consists of a list of marks and substitutions. Marks are distinguished by their object identity and do not require any fields:</para><programlisting id="I_programlisting25_tt556" format="linespecific">
	(define-record mark ())
</programlisting><para>A substitution maps <indexterm id="idx-CHP-25-2159" significance="normal"><primary>substitutions</primary><secondary>mapping a symbolic name and list of marks to a label</secondary></indexterm>a symbolic name and list of marks to a label:</para><programlisting id="I_programlisting25_tt557" format="linespecific">
	(define-record subst (sym mark* label))
</programlisting><para><indexterm id="idx-CHP-25-2160" significance="normal"><primary>labels</primary></indexterm>Labels, like marks, are distinguished by their identity and require no fields:</para><programlisting id="I_programlisting25_tt558" format="linespecific">
	(define-record label ())
</programlisting><para>The expand-time environment maintained by the expander maps labels to <emphasis>bindings</emphasis>. The environment is structured as a traditional <emphasis>association list</emphasis>—i.e., a list of pairs, each car of which contains a label and each cdr of which contains a binding. Bindings consist of a <indexterm id="idx-CHP-25-2161" significance="normal"><primary>type (bindings)</primary></indexterm>type (represented as a symbol) and a <indexterm id="idx-CHP-25-2162" significance="normal"><primary>value (bindings)</primary></indexterm>value:<indexterm id="idx-CHP-25-2163" significance="normal"><primary>bindings</primary></indexterm><indexterm id="idx-CHP-25-2164" significance="normal"><primary>association lists</primary></indexterm></para><programlisting id="I_programlisting25_tt559" format="linespecific">
	(define-record binding (type value))
</programlisting><para>The type identifies the nature of the binding: <literal moreinfo="none">macro</literal> for <indexterm id="idx-CHP-25-2165" significance="normal"><primary>keyword bindings</primary></indexterm>keyword bindings and <literal moreinfo="none">lexical</literal> for <literal moreinfo="none">lexical</literal> variable bindings. The value is any additional information required to specify the binding, such as the transformation procedure when the binding is a keyword binding.<indexterm id="idx-CHP-25-2166" significance="normal"><primary>lexical variable bindings</primary></indexterm></para></sect2><sect2 id="producing_expander_output" label="25.2.2"><title>Producing Expander Output</title><para>The expander's output is a simple s-expression in the core language and is thus constructed for the most part using Scheme's <literal moreinfo="none">quasiquote</literal> <indexterm id="idx-CHP-25-2167" significance="normal"><primary>Scheme language</primary><secondary>quasiquote syntax for creating list structure</secondary></indexterm>syntax for creating list structure. For example, a <literal moreinfo="none">lambda</literal> expression may be created with formal parameter <replaceable>var</replaceable> and body <replaceable>body</replaceable> as follows:<indexterm id="idx-CHP-25-2168" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>producing expander output</tertiary></indexterm><indexterm id="idx-CHP-25-2169" significance="normal"><primary>quote form (syntax-case)</primary></indexterm></para><programlisting id="I_programlisting25_tt560" format="linespecific">
	`(lambda (<replaceable>,var) ,body</replaceable>)
</programlisting><para>The expander does need to create fresh names, however, and does so via the <literal moreinfo="none">gen-var</literal> helper, which makes use of the Scheme <indexterm id="idx-CHP-25-2170" significance="normal"><primary>Scheme language</primary><secondary>primitives for converting strings to and from symbols</secondary></indexterm>primitives for converting strings to symbols and vice versa, along with a local sequence counter:<indexterm id="idx-CHP-25-2171" significance="normal"><primary>gen-var helper</primary></indexterm></para><programlisting id="I_programlisting25_tt561" format="linespecific">
	(define gen-var
	  (let ([n 0])
	    (lambda (id)
	      (set! n (+ n 1))
	      (let ([name (syntax-object-expr id)])
	        (string-&gt;symbol (format "~s.~s" name n))))))
</programlisting></sect2><sect2 id="stripping_syntax_objects" label="25.2.3"><title>Stripping Syntax Objects</title><para>Whenever a <literal moreinfo="none">quote</literal> form is encountered in the input, the expander must return a representation of the constant contents appearing within the <literal moreinfo="none">quote</literal> form. To do this, it must strip off any embedded syntax objects and wraps using the <literal moreinfo="none">strip</literal> procedure, which traverses the syntax object and list structure of its input and recreates an s-expression representation of its input:<indexterm id="idx-CHP-25-2172" significance="normal"><primary>syntax objects</primary><secondary>stripping</secondary></indexterm><indexterm id="idx-CHP-25-2173" significance="normal"><primary>strip procedure</primary></indexterm></para><programlisting id="I_programlisting25_tt562" format="linespecific">
	(define strip
	  (lambda (x)
	    (cond
	      [(syntax-object? x)
	       (if (top-marked? (syntax-object-wrap x))
	           (syntax-object-expr x)
	           (strip (syntax-object-expr x)))]
	      [(pair? x)
	       (let ([a (strip (car x))] [d (strip (cdr x))])
	         (if (and (eq? a (car x)) (eq? d (cdr x)))
	             x
	             (cons a d)))]
	      [else x])))
</programlisting><para>Traversal terminates along any branch of the input expression when something other than a syntax object or pair is found—i.e., when a symbol or immediate value is found. It also terminates when a syntax object is found to be "<indexterm id="idx-CHP-25-2174" significance="normal"><primary>top mark</primary></indexterm>top marked"—i.e., when its wrap contains a unique <emphasis>top mark</emphasis>:</para><programlisting id="I_programlisting25_tt563" format="linespecific">
	(define top-mark (make-mark))

	(define top-marked?
	  (lambda (wrap)
	    (and (not (null? wrap))
	    (or (eq? (car wrap) top-mark)
	        (top-marked? (cdr wrap))))))
</programlisting><para>When the expander creates a syntax object representing the original input, it uses a wrap that contains the top mark at its base, specifically to allow the stripping code detect when it has reached the syntax-object base and need not traverse the object further. This feature prevents the expander from traversing constants unnecessarily so that it can easily preserve shared and cyclic structure, and not be confused by the presence of quoted syntax objects in the input.</para></sect2><sect2 id="syntax_errors" label="25.2.4"><title>Syntax Errors</title><para>The expander reports <indexterm id="idx-CHP-25-2175" significance="normal"><primary>syntax-case</primary><secondary>expansion algorithm</secondary><tertiary>syntax errors</tertiary></indexterm>syntax errors via <literal moreinfo="none">syntax-error</literal>, which is defined as follows:<indexterm id="idx-CHP-25-2176" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>syntax errors</tertiary></indexterm><indexterm id="idx-CHP-25-2177" significance="normal"><primary>syntax-error</primary></indexterm></para><programlisting id="I_programlisting25_tt564" format="linespecific">
	(define syntax-error
	  (lambda (object message)
	    (error #f "~a ~s" message (strip object))))
</programlisting><para>If the implementation attaches source information to syntax objects, this source information can be used to construct an error message that incorporates the source line and character position.</para></sect2><sect2 id="structural_predicates" label="25.2.5"><title>Structural Predicates</title><para>The <indexterm id="idx-CHP-25-2178" significance="normal"><primary>syntax objects</primary><secondary>nonatomic structure</secondary></indexterm>nonatomic structure of a syntax object is always determined with the patterns of a <literal moreinfo="none">syntax-case</literal> form. The <literal moreinfo="none">identifier?</literal> predicate determines whether a syntax object represents an identifier:<indexterm id="idx-CHP-25-2179" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>structural predicates</tertiary></indexterm><indexterm id="idx-CHP-25-2180" significance="normal"><primary>identifier? predicate</primary></indexterm></para><programlisting id="I_programlisting25_tt565" format="linespecific">
	(define identifier?
	  (lambda (x)
	    (and (syntax-object? x)
	         (symbol? (syntax-object-expr x)))))
</programlisting><para>Similarly, the <literal moreinfo="none">self-evaluating?</literal> predicate is used, after stripping a syntax object, to deter-mine whether it represents a constant:<indexterm id="idx-CHP-25-2181" significance="normal"><primary>self-evaluating? predicate</primary></indexterm></para><programlisting id="I_programlisting25_tt566" format="linespecific">
	(define self-evaluating?
	  (lambda (x)
	    (or (boolean? x) (number? x) (string? x) (char? x))))
</programlisting></sect2><sect2 id="creating_wraps" label="25.2.6"><title>Creating Wraps</title><para>A mark or substitution is added to a syntax object by extending the wrap:<indexterm id="idx-CHP-25-2182" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>creating wraps</tertiary></indexterm><indexterm id="idx-CHP-25-2183" significance="normal"><primary>wraps</primary><secondary>creating</secondary></indexterm></para><programlisting id="I_programlisting25_tt567" format="linespecific">
	(define add-mark
	  (lambda (mark x)
	    (extend-wrap (list mark) x)))

	(define add-subst
	  (lambda (id label x)
	    (extend-wrap
	      (list (make-subst
	              (syntax-object-expr id)
	              (wrap-marks (syntax-object-wrap id))
	              label))
	x)))
</programlisting><para>If the syntax object is only partially wrapped, the wrap is extended simply by creating a syntax object encapsulating the partially wrapped structure. Otherwise, the syntax object is rebuilt with the new wrap joined to the old wrap:</para><programlisting id="I_programlisting25_tt568" format="linespecific">
	(define extend-wrap
	  (lambda (wrap x)
	    (if (syntax-object? x)
	        (make-syntax-object
	          (syntax-object-expr x)
	          (join-wraps wrap (syntax-object-wrap x)))
	        (make-syntax-object x wrap))))
</programlisting><para>Joining two wraps is almost as simple as appending the lists of marks. The only complication is that the <indexterm id="idx-CHP-25-2184" significance="normal"><primary>syntax-case</primary><secondary>expansion algorithm</secondary></indexterm>expansion algorithm requires that two like marks cancel when they meet.</para><programlisting id="I_programlisting25_tt569" format="linespecific">
	(define join-wraps
	  (lambda (wrap1 wrap2)
	    (cond
	      [(null? wrap1) wrap2]
	      [(null? wrap2) wrap1]
	      [else
	       (let f ([w (car wrap1)] [w* (cdr wrap1)])
	         (if (null? w*)
	             (if (and (mark? w) (eq? (car wrap2) w))
	                 (cdr wrap2)
	                 (cons w wrap2))
	             (cons w (f (car w*) (cdr w*)))))])))
</programlisting></sect2><sect2 id="manipulating_environments" label="25.2.7"><title>Manipulating Environments</title><para>Environments map labels to bindings and are represented as association lists. Extending an environment therefore involves adding a single pair <indexterm id="idx-CHP-25-2185" significance="normal"><primary>bindings</primary><secondary>mapping to labels with environments</secondary></indexterm>mapping a label to a binding:<indexterm id="idx-CHP-25-2186" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>manipulating environments</tertiary></indexterm><indexterm id="idx-CHP-25-2187" significance="normal"><primary>environments (syntax-case expansion algorithm)</primary></indexterm></para><programlisting id="I_programlisting25_tt570" format="linespecific">
	(define extend-env
	  (lambda (label binding env)
	    (cons (cons label binding) env)))
</programlisting></sect2><sect2 id="identifier_resolution" label="25.2.8"><title>Identifier Resolution</title><para><indexterm id="idx-CHP-25-2188" significance="normal"><primary>bindings</primary><secondary>determining binding associated with an identifier</secondary></indexterm>Determining the binding associated with an identifier is a two-step process. The first step is to determine the label associated with the identifier in the identifier's wrap, and the second is to look the label up in the current environment:<indexterm id="idx-CHP-25-2189" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>identifier resolution</tertiary></indexterm></para><programlisting id="I_programlisting25_tt571" format="linespecific">
	define id-binding
	 (lambda (id r)
	   (label-binding id (<indexterm id="idx-CHP-25-2190" significance="normal"><primary>id-label procedure</primary></indexterm>id-label id) r)))
</programlisting><para>The marks and substitutions that appear <indexterm id="idx-CHP-25-2191" significance="normal"><primary>marks</primary><secondary>appearing in an identifier's wrap</secondary></indexterm>in an identifier's wrap determine the associated label, if any. Substitutions map names and lists of marks to labels. Any substitution whose name is not the name of the identifier is ignored, as is any whose marks do not match. The names are symbols and are thus compared using the pointer equivalence operator, <literal moreinfo="none">eq?</literal>.</para><para>The set of marks considered relevant are those that were layered onto the wrap before the substitution. Thus, the set of marks to which a substitution's marks are compared changes as the search through the wrap proceeds. The starting set of marks is the entire set that appears in the wrap. Each time a mark is encountered during the search for a matching substitution in the wrap, the first mark in the list is removed:</para><programlisting id="I_programlisting25_tt572" format="linespecific">
	(define id-label
	  (lambda (id)
	    (let ([sym (syntax-object-expr id)]
	          [wrap (syntax-object-wrap id)])
	      (let search ([wrap wrap] [mark* (wrap-marks wrap)])
	        (if (null? wrap)
	            (syntax-error id "undefined identifier")
	            (let ([w0 (car wrap)])
	              (if (mark? w0)
	                  (search (cdr wrap) (cdr mark*))
	                  (if (and (eq? (subst-sym w0) sym)
	                           (<indexterm id="idx-CHP-25-2192" significance="normal"><primary>same-marks? predicate</primary></indexterm>same-marks? (subst-mark* w0) mark*))
	                      (subst-label w0)
	                      (search (cdr wrap) mark*)))))))))
</programlisting><para>If no matching substitution exists in the wrap, the identifier is undefined, and a syntax error is signaled. It would be possible instead to treat all such identifier references as global variable references.</para><para>The <literal moreinfo="none">id-label</literal> procedure obtains the starting list of marks via <literal moreinfo="none">wrap-marks</literal> and uses the <literal moreinfo="none">same-marks?</literal> predicate to compare lists of marks:</para><programlisting id="I_programlisting25_tt573" format="linespecific">
	(define wrap-marks
	  (lambda (wrap)
	    (if (null? wrap)
	        '()
	        (let ([w0 (car wrap)])
	          (if (mark? w0)
	              (cons w0 (wrap-marks (cdr wrap)))
	              (wrap-marks (cdr wrap)))))))

	(define same-marks?
	  (lambda (m1* m2*)
	    (if (null? m1*)
	        (null? m2*)
	        (and (not (null? m2*))
	             (eq? (car m1*) (car m2*))
	             (same-marks? (cdr m1*) (cdr m2*))))))
</programlisting><para>Once a label has been found, <literal moreinfo="none">id-binding</literal> is used to find the associated binding, if any, using the <literal moreinfo="none">assq</literal> procedure for performing association-list lookups. If an association is found, the binding in the cdr of the association is returned:<indexterm id="idx-CHP-25-2193" significance="normal"><primary>association lists</primary><secondary>assq procedure for lookups</secondary></indexterm></para><programlisting id="I_programlisting25_tt574" format="linespecific">
	(define label-binding
	  (lambda (id label r)
	    (let ([a (assq label r)])
	      (if a
	          (cdr a)
	          (syntax-error id "displaced lexical")))))
</programlisting><para>If no binding is found, the identifier is a "displaced lexical." This occurs when a macro improperly inserts into its output a reference to an identifier that is not visible in the context of the macro output.</para></sect2><sect2 id="the_expander" label="25.2.9"><title>The Expander</title><para>With the mechanisms for handling wraps and environments in place, the <indexterm id="idx-CHP-25-2194" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>expander</tertiary></indexterm>expander is straightforward. The expression expander, <literal moreinfo="none">exp</literal>, handles macro calls, lexical variable references, applications, core forms, and constants. Macro calls come in two forms: singleton macro-keyword references and structured forms with a macro keyword in the first position.<indexterm id="idx-CHP-25-2195" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>expander</tertiary></indexterm><indexterm id="idx-CHP-25-2196" significance="normal"><primary>exp procedure</primary></indexterm></para><para>The <literal moreinfo="none">exp</literal> procedure takes three arguments: a syntax object <replaceable>x</replaceable>, a <indexterm id="idx-CHP-25-2197" significance="normal"><primary>runtime environment (exp procedure)</primary></indexterm>runtime environment <replaceable>r</replaceable>, and a <indexterm id="idx-CHP-25-2198" significance="normal"><primary>meta environment (exp procedure)</primary></indexterm>meta environment <replaceable>mr</replaceable>. The runtime environment is used to process ordinary expressions whose code will appear in the expander's output, while the <indexterm id="idx-CHP-25-2199" significance="normal"><primary>environments (syntax-case expansion algorithm)</primary><secondary>meta environment and runtime environment</secondary></indexterm>meta environment is used to process transformer expressions (e.g., on the righthand sides of <literal moreinfo="none">letrec-syntax</literal> bindings), which are evaluated and used at expansion time. The difference between the runtime and meta environments is that the meta environment does not contain lexical variable bindings, because these bindings are not available when the transformer is evaluated and used:</para><programlisting id="I_programlisting25_tt575" format="linespecific">
	(define exp
	  (lambda (x r mr)
	    (<indexterm id="idx-CHP-25-2200" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary></indexterm>syntax-case x ()
	   [id
	    (identifier? #'id)
	    (let ([b (id-binding #'id r)])
	     (case (binding-type b)
	       [(macro) (exp (<indexterm id="idx-CHP-25-2201" significance="normal"><primary>exp-macro procedure</primary></indexterm>exp-macro (binding-value b) x) r mr)]
	       [(lexical) (binding-value b)]
	       [else (syntax-error x "invalid syntax")]))]
	  [(e0 e1 ...)
	   (identifier? #'e0)
	   (let ([b (id-binding #'e0 r)])
	     (case (binding-type b)
	       [(macro) (exp (exp-macro (binding-value b) x) r mr)]
	       [(lexical)
	        `(,(binding-value b) ,@(exp-exprs #'(e1 ...) r mr))]
	       [(core) (exp-core (binding-value b) x r mr)]
	       [else (syntax-error x "invalid syntax")]))]
	  [(e0 e1 ...)
	   `(,(exp #'e0 r mr) ,@(exp-exprs #'(e1 ...) r mr))]
	  [_
	   (let ([d (strip x)])
	     (if (self-evaluating? d)
	         d
	         (syntax-error x "invalid syntax")))])))
</programlisting><para>Macro calls are handled by <literal moreinfo="none">exp-macro</literal> (described shortly) and then re-expanded. Lexical variables are rewritten into the binding value, which is always a generated variable name. Applications are rewritten into lists as in the traditional s-expression syntax for Lisp and Scheme, with the subforms expanded recursively. Core forms are handled by <literal moreinfo="none">exp-core</literal> (described shortly); any recursion back to the expression <indexterm id="idx-CHP-25-2202" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>expander</tertiary></indexterm>expander is performed explicitly by the core transformer. A constant is rewritten into the constant value, stripped of its syntax wrapper.</para><para>The <indexterm id="idx-CHP-25-2203" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>expander</tertiary></indexterm>expander <indexterm id="idx-CHP-25-2204" significance="normal"><primary>syntax form</primary><secondary>use by expander</secondary></indexterm>uses <literal moreinfo="none">syntax-case</literal> and <literal moreinfo="none">syntax</literal> (in its abbreviated form—i.e., #'<replaceable>template</replaceable>) to parse and refer to the input or portions thereof. Because the expander is also charged with implementing <literal moreinfo="none">syntax-case</literal>, this may seem like a paradox. In actuality, it is handled by bootstrapping one version of the expander using a previous version. The expander would be much more tedious to write if <literal moreinfo="none">syntax-case</literal> and <literal moreinfo="none">syntax</literal> were not used.</para><para>The <literal moreinfo="none">exp-macro</literal> procedure applies the transformation procedure (the value part of the macro binding) to the entire macro form, which may either be a single macro keyword or a structured expression with the macro keyword at its head. The <literal moreinfo="none">exp-macro</literal> procedure first adds a fresh mark to the wrap of the input form, then applies the same mark to the wrap of the output form. The first mark serves as an "anti-mark" that cancels out the second mark, so the net effect is that the mark adheres only to the portions of the output that were introduced by the transformer, thus uniquely identifying the portions of the code introduced at this transcription step:</para><programlisting id="I_programlisting25_tt576" format="linespecific">
	(define exp-macro
	  (lambda (p x)
	    (let ([m (make-mark)])
	      (add-mark m (p (add-mark m x))))))
</programlisting><para>The <literal moreinfo="none">exp-core</literal> procedure simply applies the given <indexterm class="startofrange" id="idx-CHP-25-2205" significance="normal"><primary>transformers</primary><secondary>core</secondary></indexterm>core transformer (the value part of the core binding) to the input form:<indexterm id="idx-CHP-25-2206" significance="normal"><primary>exp-core procedure</primary></indexterm></para><programlisting id="I_programlisting25_tt577" format="linespecific">
	(define exp-core
	  (lambda (p x r mr)
	    (p x r mr)))
</programlisting><para>The <literal moreinfo="none">exp-exprs</literal> procedure used to process application subforms simply maps the <indexterm id="idx-CHP-25-2207" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>expander</tertiary></indexterm>expander over the forms:<indexterm id="idx-CHP-25-2208" significance="normal"><primary>exp-exprs procedure</primary></indexterm></para><programlisting id="I_programlisting25_tt578" format="linespecific">
	(define exp-exprs
	  (lambda (x* r mr)
	    (map (lambda (x) (exp x r mr)) x*)))
</programlisting></sect2><sect2 id="core_transformers" label="25.2.10"><title>Core Transformers</title><para>Transformers for several representative core forms (<literal moreinfo="none">quote, if, lambda, let</literal>, and <literal moreinfo="none">letrec-syntax</literal>) are described here. Adding transformers for other core forms, such as <literal moreinfo="none">letrec</literal> or <literal moreinfo="none">let-syntax</literal>, is straightforward.<indexterm id="idx-CHP-25-2209" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>core transformers</tertiary></indexterm><indexterm id="idx-CHP-25-2210" significance="normal"><primary>if form</primary></indexterm></para><para>The <literal moreinfo="none">exp-quote</literal> procedure produces an s-expression <indexterm id="idx-CHP-25-2211" significance="normal"><primary>s-expression</primary><secondary>representing a quote form</secondary></indexterm>representing a <literal moreinfo="none">quote</literal> form, with the data value stripped of its syntax wrap:<indexterm id="idx-CHP-25-2212" significance="normal"><primary>exp-quote procedure (syntax-case)</primary></indexterm></para><programlisting id="I_programlisting25_tt579" format="linespecific">
	(define exp-quote
	  (lambda (x r mr)
	    (<indexterm id="idx-CHP-25-2213" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary></indexterm>syntax-case x ()
	      [(_ d) `(quote ,(strip #'d))])))
</programlisting><para>The <literal moreinfo="none">exp-if</literal> procedure produces an s-expression representation of an <literal moreinfo="none">if</literal> form, with the sub-forms recursively expanded:<indexterm id="idx-CHP-25-2214" significance="normal"><primary>exp-if procedure</primary></indexterm></para><programlisting id="I_programlisting25_tt580" format="linespecific">
	(define exp-if
	  (lambda (x r mr)
	    (syntax-case x ()
	      [(_ e1 e2 e3)
	        `(if ,(exp #'e1 r mr)
	             ,(exp #'e2 r mr)
	             ,(exp #'e3 r mr))])))
</programlisting><para>The <literal moreinfo="none">exp-lambda</literal> procedure handles <literal moreinfo="none">lambda</literal> expressions that have only a single formal parameter and only a single body expression. Extending it to handle multiple parameters is straightforward. It is less straightforward to handle arbitrary <literal moreinfo="none">lambda</literal> bodies, including internal definitions, but support for internal definitions is beyond the scope of this chapter.<indexterm id="idx-CHP-25-2215" significance="normal"><primary>exp-lambda procedure</primary></indexterm></para><para>When the s-expression representation of a <literal moreinfo="none">lambda</literal> expression is produced, a generated variable name is created for the formal parameter. A substitution mapping the identifier to a fresh label is added to the wrap on the body, and the environment is extended with an association from the label to a <literal moreinfo="none">lexical</literal> binding whose value is the generated variable,during the recursive processing of the body:</para><programlisting id="I_programlisting25_tt581" format="linespecific">
	(define exp-lambda
	  (lambda (x r mr)
	    (syntax-case x ()
	  [(_ (var) body)
	   (<indexterm id="idx-CHP-25-2216" significance="normal"><primary>let form</primary></indexterm>let ([label (make-label)] [new-var (gen-var #'var)])
	     `(lambda (,new-var)
	        ,(exp (add-subst #'var label #'body)
	              (extend-env label
	                (make-binding 'lexical new-var)
	                r)
	              mr)))])))
</programlisting><para>The meta environment is not extended because the meta environment should not include lexical variable bindings.</para><para>The <literal moreinfo="none">exp-let</literal> procedure that transforms <indexterm id="idx-CHP-25-2217" significance="normal"><primary>single-binding let forms</primary></indexterm>single-binding <literal moreinfo="none">let</literal> forms is similar to the transformer for <literal moreinfo="none">lambda</literal>, but a bit more involved:<indexterm id="idx-CHP-25-2218" significance="normal"><primary>exp-let procedure</primary></indexterm></para><programlisting id="I_programlisting25_tt582" format="linespecific">
	(define exp-let
	  (lambda (x r mr)
	    (<indexterm id="idx-CHP-25-2219" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary></indexterm>syntax-case x ()
	      [(_ ([var expr]) body)
	       (let ([label (make-label)] [new-var (gen-var #'var)])
	         `(let ([,new-var ,(exp #'expr r mr)])
	            ,(exp (add-subst #'var label #'body)
	                  (extend-env label
	               (make-binding 'lexical new-var)
	               r)
	             mr)))])))
</programlisting><para>The body is in the scope of the binding created by <literal moreinfo="none">let</literal>, so it is expanded with the extended wrap and environment. The righthand-side expression, <literal moreinfo="none">expr</literal>, is not within the scope, so it is expanded with the original wrap and environment.</para><para>The <literal moreinfo="none">exp-letrec-syntax</literal> procedure handles <indexterm id="idx-CHP-25-2220" significance="normal"><primary>single-binding letrec-syntax forms</primary></indexterm>single-binding <literal moreinfo="none">letrec-syntax</literal> forms. As with <literal moreinfo="none">lambda</literal> and <literal moreinfo="none">let</literal>, a substitution mapping the bound identifier—in this case, a keyword rather than a variable—to a fresh label is added to the wrap on the body, and an association from the label to a binding is added to the environment while the body is recursively processed. The binding is a macro binding rather than a <literal moreinfo="none">lexical</literal> binding, and the binding value is the result of recursively expanding and evaluating the righthand-side expression of the <literal moreinfo="none">letrec-syntax</literal> form.<indexterm id="idx-CHP-25-2221" significance="normal"><primary>exp-letrec-syntax procedure</primary></indexterm></para><para>In contrast with <literal moreinfo="none">let</literal>, the righthand-side expression is also wrapped with a substitution from the keyword to the label and expanded with the extended environment; this allows the macro to be recursive. This would not be done if the form were a <literal moreinfo="none">let-syntax</literal> form instead of a <literal moreinfo="none">letrec-syntax</literal> form. The output produced by expanding a <literal moreinfo="none">letrec-syntax</literal> form consists only of the output of the recursive call to the expander on the body of the form:<indexterm id="idx-CHP-25-2222" significance="normal"><primary>let-syntax form</primary></indexterm></para><programlisting id="I_programlisting25_tt583" format="linespecific">
	(define <indexterm id="idx-CHP-25-2223" significance="normal"><primary>letrec-syntax forms</primary><secondary>exp-letrec-syntax transformer</secondary></indexterm>exp-letrec-syntax
	  (lambda (x r mr)
	    (syntax-case x ()
	      [(_ ((kwd expr)) body)
	       (let ([label (make-label)])
	         (let ([b (make-binding 'macro
	                    (eval (exp (add-subst #'kwd label #'expr)
	                               mr mr)))])
	    (exp (add-subst #'kwd label #'body)
	         (extend-env label b r)
	         (extend-env label b mr))))])))
</programlisting><para>Both the runtime and meta environments are extended in this case, since <indexterm id="idx-CHP-25-2224" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>core transformers</tertiary></indexterm>transformers are available both in runtime and transformer code.</para></sect2><sect2 id="parsing_and_constructing_syntax_objects" label="25.2.11"><title>Parsing and Constructing Syntax Objects</title><para>Macros are written in a pattern-matching style using <literal moreinfo="none">syntax-case</literal> to match and take apart the input, and <literal moreinfo="none">syntax</literal> to reconstruct the output. The implementation of the pattern matching and reconstruction is outside the scope of this chapter, but the following low-level operators can be used as the basis for the implementation. The <literal moreinfo="none">syntax-case</literal> form can be built from the following set of three operators that treat syntax objects as abstract s-expressions:<indexterm id="idx-CHP-25-2225" significance="normal"><primary>syntax objects</primary><secondary>parsing and constructing</secondary></indexterm></para><programlisting id="I_programlisting25_tt584" format="linespecific">
	(define <indexterm id="idx-CHP-25-2226" significance="normal"><primary>syntax-pair? operator</primary></indexterm>syntax-pair?
	  (lambda (x)
	    (pair? (syntax-object-expr x))))

	(define <indexterm id="idx-CHP-25-2227" significance="normal"><primary>syntax-car operator</primary></indexterm>syntax-car
	  (lambda (x)
	    (<indexterm id="idx-CHP-25-2228" significance="normal"><primary>extend-wrap helper</primary></indexterm>extend-wrap
	      (syntax-object-wrap x)
	      (car (syntax-object-expr x)))))

	(define <indexterm id="idx-CHP-25-2229" significance="normal"><primary>syntax-cdr operator</primary></indexterm>syntax-cdr
	  (lambda (x)
	    (extend-wrap
	      (syntax-object-wrap x)
	      (cdr (syntax-object-expr x)))))
</programlisting><para>The definitions of <literal moreinfo="none">syntax-car</literal> and <literal moreinfo="none">syntax-cdr</literal> employ the <literal moreinfo="none">extend-wrap</literal> helper defined in the earlier section "Creating Wraps" to push the wrap on the pair onto the car and cdr.</para><para>Similarly, <literal moreinfo="none">syntax</literal> can be built from the following more basic version of <literal moreinfo="none">syntax</literal> that handles constant input, but not pattern variables and ellipses:</para><programlisting id="I_programlisting25_tt585" format="linespecific">
	(define exp-syntax
	  (lambda (x r mr)
	    (syntax-case x ()
	      [(_ t) `(quote ,#'t)])))
</programlisting><para>In essence, the simplified version of syntax is just like <literal moreinfo="none">quote</literal> except that <literal moreinfo="none">syntax</literal> does not strip the encapsulated value but rather leaves the syntax wrappers intact.</para></sect2><sect2 id="comparing_identifiers" label="25.2.12"><title>Comparing Identifiers</title><para>Identifiers are compared based on their intended use. They may be compared as symbols by using the pointer equivalence operator <literal moreinfo="none">eq?</literal> on the symbolic names of the identifiers. They may also be compared according to their intended use as free or bound identifiers in the output of a macro.<indexterm id="idx-CHP-25-2230" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>comparing identifiers</tertiary></indexterm><indexterm id="idx-CHP-25-2231" significance="normal"><primary>identifiers</primary><secondary>comparing</secondary></indexterm><indexterm id="I_indexterm25_tt586" class="endofrange" startref="idx-CHP-25-2205" significance="normal"><primary>transformers</primary><secondary>core</secondary></indexterm></para><para>Two identifiers are considered equivalent by <literal moreinfo="none">free-identifier=?</literal> if they would resolve to the same binding if introduced into the output of a macro outside of any binding introduced by the macro. Equivalency is tested by comparing the labels to which the identifiers resolve, as described previously in the section "Identifier Resolution":<indexterm id="idx-CHP-25-2232" significance="normal"><primary>free-identifier=? predicate</primary></indexterm></para><programlisting id="I_programlisting25_tt587" format="linespecific">
	(define free-identifier=?
	  (lambda (x y)
	    (eq? (id-label x) (id-label y))))
</programlisting><para>The <literal moreinfo="none">free-identifier=?</literal> predicate is often used to check for auxiliary keywords, such as <literal moreinfo="none">else</literal> in <literal moreinfo="none">cond</literal> or <literal moreinfo="none">case</literal>.</para><para>Two identifiers are considered equivalent by <literal moreinfo="none">bound-identifier=?</literal> if a reference to one would be captured by an enclosing binding for another. This is accomplished by comparing the names and marks of the two identifiers:<indexterm id="idx-CHP-25-2233" significance="normal"><primary>bound-identifier=? predicate</primary></indexterm></para><programlisting id="I_programlisting25_tt588" format="linespecific">
	(define bound-identifier=?
	  (lambda (x y)
	    (and (eq? (syntax-object-expr x) (syntax-object-expr y))
	         (same-marks?
	           (wrap-marks (syntax-object-wrap x))
	           (wrap-marks (syntax-object-wrap y))))))
</programlisting><para>The <literal moreinfo="none">bound-identifier=?</literal> predicate is often used to check for duplicate identifier errors in a binding form, such as <literal moreinfo="none">lambda</literal> or <literal moreinfo="none">let</literal>.</para></sect2><sect2 id="conversions" label="25.2.13"><title>Conversions</title><para>The <indexterm id="idx-CHP-25-2234" significance="normal"><primary>syntax objects</primary><secondary>conversion of s-expressions to/from</secondary></indexterm>conversion from <indexterm id="idx-CHP-25-2235" significance="normal"><primary>datum-&gt;syntax procedure (syntax-case)</primary><secondary>converting s-expression to syntax object</secondary></indexterm>s-expression to syntax object performed by <literal moreinfo="none">datum-&gt;syntax</literal> requires only that the wrap be transferred from the template identifier to the s-expression:<indexterm id="idx-CHP-25-2236" significance="normal"><primary>s-expression</primary><secondary>conversion to/from syntax object using datum-&gt;syntax</secondary></indexterm><indexterm id="idx-CHP-25-2237" significance="normal"><primary>conversions between s-expressions and syntax objects</primary></indexterm></para><programlisting id="I_programlisting25_tt589" format="linespecific">
	(define datum-&gt;syntax
	   (lambda (template-id x)
	      (make-syntax-object x (syntax-object-wrap template-id))))
</programlisting><para>The opposite conversion involves stripping the wrap away from a syntax object, so <literal moreinfo="none">syntax-&gt;datum</literal> is just <literal moreinfo="none">strip</literal>:</para><programlisting id="I_programlisting25_tt590" format="linespecific">
	(define syntax-&gt;datum strip)
</programlisting></sect2><sect2 id="starting_expansion" label="25.2.14"><title>Starting Expansion</title><para>All of the pieces are now in place to expand Scheme <indexterm id="idx-CHP-25-2238" significance="normal"><primary>Scheme language</primary><secondary>expanding expressions containing macros into expressions in the core language</secondary></indexterm>expressions containing macros into expressions in the core language. The main expander merely supplies an initial wrap and environment that include names and bindings for the core forms and primitives:<indexterm id="idx-CHP-25-2239" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary><tertiary>starting expansion</tertiary></indexterm><indexterm id="idx-CHP-25-2240" significance="normal"><primary>syntax-case</primary><secondary>expansion algorithm</secondary></indexterm></para><programlisting id="I_programlisting25_tt591" format="linespecific">
	(define expand
	  (lambda (x)
	    (let-values ([(wrap env) (initial-wrap-and-env)])
	      (exp (make-syntax-object x wrap) env env))))
</programlisting><para>The initial wrap consists of a set of substitutions mapping each predefined identifier to a fresh label, and the initial environment associates each of these labels with the corresponding binding:</para><programlisting id="I_programlisting25_tt592" format="linespecific">
	(define initial-wrap-and-env
	  (lambda ()
	    (define id-binding*
	      `((quote . ,(make-binding 'core exp-quote))
	        (if . ,(make-binding 'core exp-if))
	        (lambda . ,(make-binding 'core exp-lambda))
	        (let . ,(make-binding 'core exp-let))
	        (letrec-syntax . ,(make-binding 'core exp-letrec-syntax))
	        (identifier? . ,(make-binding 'lexical 'identifier?))
	        (free-identifier=? . ,(make-binding 'lexical 'free-identifier=?))
	        (bound-identifier=? . ,(make-binding 'lexical 'bound-identifier=?))
	        (datum-&gt;syntax . ,(make-binding 'lexical 'datum-&gt;syntax))
	        (syntax-&gt;datum . ,(make-binding 'lexical 'syntax-&gt;datum))
	        (syntax-error . ,(make-binding 'lexical 'syntax-error))
	        (syntax-pair? . ,(make-binding 'lexical 'syntax-pair?))
	        (syntax-car . ,(make-binding 'lexical 'syntax-car))
	        (syntax-cdr . ,(make-binding 'lexical 'syntax-cdr))
	        (syntax . ,(make-binding 'core exp-syntax))
	        (list . ,(make-binding 'core 'list))))
	    (let ([label* (map (lambda (x) (make-label)) id-binding*)])
	      (values
	        `(,@(map (lambda (sym label)
	                   (make-subst sym (list top-mark) label))
	                 (map car id-binding*)
	                 label*)
	          ,top-mark)
	        (map cons label* (map cdr id-binding*))))))
</programlisting><para>In addition to the entries listed, the initial environment should also include bindings for the built-in <indexterm id="idx-CHP-25-2241" significance="normal"><primary>syntactic abstraction</primary></indexterm>syntactic forms we have not implemented (e.g., <literal moreinfo="none">letrec</literal> and <literal moreinfo="none">let-syntax</literal>), as well as for all built-in Scheme procedures. It should also include a full version of <literal moreinfo="none">syntax</literal> and, in place of <literal moreinfo="none">syntax-pair?, syntax-car</literal>, and <literal moreinfo="none">syntax-cdr</literal>, it should include <literal moreinfo="none">syntax-case</literal>.</para></sect2></sect1><sect1 id="example" label="25.3"><title>Example</title><para>We now trace through the following example from the beginning of this chapter:<indexterm class="startofrange" id="idx-CHP-25-2242" significance="normal"><primary>syntax-case</primary><secondary>expander example</secondary></indexterm></para><programlisting id="I_programlisting25_tt593" format="linespecific">
	(let ([t #t]) (or #f t))
</programlisting><para>We assume that <literal moreinfo="none">or</literal> has been defined to do the transformation given at the beginning of the chapter, using the equivalent of the following definition of <literal moreinfo="none">or</literal> from the section "Brief Introduction to <literal moreinfo="none">syntax-case</literal>":<indexterm id="I_indexterm25_tt594" class="endofrange" startref="idx-CHP-25-2149" significance="normal"><primary>expansion algorithms</primary><secondary>syntax-case</secondary></indexterm><indexterm id="I_indexterm25_tt595" class="endofrange" startref="idx-CHP-25-2152" significance="normal"><primary>syntax-case</primary><secondary>expansion algorithm</secondary></indexterm></para><programlisting id="I_programlisting25_tt596" format="linespecific">
	(define-syntax or
	  (lambda (x)
	    (syntax-case x ()
	      [(_ e1 e2) #'(let ([t e1]) (if t t e2))])))
</programlisting><para>At the outset, the <indexterm id="idx-CHP-25-2243" significance="normal"><primary>syntax-case</primary><secondary>expander example</secondary></indexterm>expander is presented with a syntax object whose expression is(<literal moreinfo="none">let ([t #t]) (or #f t)</literal>), and the wrap is empty, except for the contents of the initial wrap, which we suppress for brevity. (We identify syntax objects by enclosing the expression and wrap entries, if any, in angle brackets.)</para><programlisting id="I_programlisting25_tt597" format="linespecific">
	&lt;(let ((t #t)) (or #f t))&gt;
</programlisting><para>The expander is also presented with the initial environment, which we assume contains a binding for the macro <literal moreinfo="none">or</literal> as well as for the core forms and built-in procedures. Again, these environment entries are omitted for brevity, along with the meta environment, which plays no role here since we are not expanding any transformer expressions.</para><para>The <literal moreinfo="none">let</literal> expression is recognized as a core form because <literal moreinfo="none">let</literal> is present in the initial wrap and environment. The transformer for <literal moreinfo="none">let</literal> recursively expands the righthand-side expression <literal moreinfo="none">#t</literal> in the input environment, yielding <literal moreinfo="none">#t</literal>. It also recursively expands the body with an extended wrap that maps <literal moreinfo="none">x</literal> to a fresh label <literal moreinfo="none">l1</literal>:</para><programlisting id="I_programlisting25_tt598" format="linespecific">
	&lt;(or #f t) [t x () → l1]&gt;
</programlisting><para>Substitutions are shown with enclosing brackets, the name and list of marks separated by the symbol x, and the label following a right arrow.</para><para>The environment is also extended to map the label to a binding of type <literal moreinfo="none">lexical</literal> with the fresh name <literal moreinfo="none">t.1</literal>:</para><programlisting id="I_programlisting25_tt599" format="linespecific">
	l1 → lexical(t.1)
</programlisting><para>The <literal moreinfo="none">or</literal> form is recognized as a macro call, so the transformer for <literal moreinfo="none">or</literal> is invoked, producing a new expression to be evaluated in the same environment. The input of the <literal moreinfo="none">or</literal> transformer is marked with a fresh mark <literal moreinfo="none">m2</literal>, and the same mark is added to the output, yielding:</para><programlisting id="I_programlisting25_tt600" format="linespecific">
	&lt;(&lt;let&gt; ((&lt;t&gt; #f))
	    (&lt;if&gt; &lt;t&gt; &lt;t&gt; &lt;t m2 [t x () → l1]&gt;))
	   m2&gt;
</programlisting><para>The differences between the syntax objects representing the introduced identifier <literal moreinfo="none">t</literal> and the identifier <literal moreinfo="none">t</literal> extracted from the input are crucial in determining how each is renamed when the expander reaches it, which will be described shortly.</para><para>The <literal moreinfo="none">#f</literal> appearing on the righthand side of the <literal moreinfo="none">let</literal> is technically a syntax object with the same wraps as the occurrence of <literal moreinfo="none">t</literal> extracted from the input, but the wrap is unimportant for constants, so we treat it, for the sake of simplicity, as if it were not wrapped.</para><para>We have another core <literal moreinfo="none">let</literal> expression. In the process of recognizing and parsing the <literal moreinfo="none">let</literal> expression, the mark <literal moreinfo="none">m2</literal> is pushed onto the subforms:</para><programlisting id="I_programlisting25_tt601" format="linespecific">
	(&lt;let m2&gt; ((&lt;t m2&gt; #f))
	   &lt;(&lt;if&gt; &lt;t&gt; &lt;t&gt; &lt;t m2 [t x () → l1]&gt;)
	   m2&gt;)
</programlisting><para>The transformer for <literal moreinfo="none">let</literal> recursively expands the righthand-side expression <literal moreinfo="none">#f</literal>, yielding <literal moreinfo="none">#f</literal>, then recursively expands the body with an extended wrap mapping the introduced <literal moreinfo="none">t</literal> with mark <literal moreinfo="none">m2</literal> to a fresh label <literal moreinfo="none">l2</literal>:</para><programlisting id="I_programlisting25_tt602" format="linespecific">
	&lt;(&lt;if&gt; &lt;t&gt; &lt;t&gt; &lt;t m2 [t x () → l1]&gt;)
	   [t x (m2) → l2]
	   m2&gt;
</programlisting><para>The environment is also extended to map the label to a binding of type <literal moreinfo="none">lexical</literal> with the fresh name <literal moreinfo="none">t.2</literal>:</para><programlisting id="I_programlisting25_tt603" format="linespecific">
	l2 → lexical(t.2), l1 → lexical(t.1)
</programlisting><para>The resulting expression is recognized as an <literal moreinfo="none">if</literal> core form. In the process of recognizing and parsing it, the <indexterm id="idx-CHP-25-2244" significance="normal"><primary>syntax-case</primary><secondary>expander example</secondary></indexterm>expander pushes the outer substitution and marks onto the component parts. The mark <literal moreinfo="none">m2</literal> that already appears in the wrap for the last occurrence of <literal moreinfo="none">t</literal> cancels the mark <literal moreinfo="none">m2</literal> on the outer wrap, leaving that occurrence of <literal moreinfo="none">t</literal> unmarked:</para><programlisting id="I_programlisting25_tt604" format="linespecific">
	(&lt;if [t x (m2) → l2] m2&gt;
	   &lt;t [t x (m2) → l2] m2&gt;
	   &lt;t [t x (m2) → l2] m2&gt;
	   &lt;t [t x (m2) → l2] [t x () → l1]&gt;)
</programlisting><para>The transformer for <literal moreinfo="none">if</literal> recursively processes its subforms in the input environment. The first:</para><programlisting id="I_programlisting25_tt605" format="linespecific">
	&lt;t [t x (m2) → l2] m2&gt;
</programlisting><para>is recognized as an identifier reference because the expression is a symbol <literal moreinfo="none">(t)</literal>. The substitution appearing in the wrap applies in this case, since the name <literal moreinfo="none">(t)</literal> and marks <literal moreinfo="none">(m2)</literal> are the same. So the expander looks for <literal moreinfo="none">l2</literal> in the environment and finds that it maps to the lexical variable <literal moreinfo="none">t.2.</literal> The second subform is the same and so also maps to <literal moreinfo="none">t.2.</literal> The third, however, is different:</para><programlisting id="I_programlisting25_tt606" format="linespecific">
	&lt;t [t x (m2) → l2] [t x () → l1]&gt;)
</programlisting><para>This identifier lacks the <literal moreinfo="none">m2</literal> mark, so the first substitution does not apply, even though the name is the same. The second does apply because it has the same name and the same set of marks (none beyond the top mark from the suppressed initial wrap). The expander thus looks for <literal moreinfo="none">l1</literal> in the environment and finds that it maps to <literal moreinfo="none">t.1</literal>.</para><para>On the way out, the <literal moreinfo="none">if</literal> expression is reconstructed as:</para><programlisting id="I_programlisting25_tt607" format="linespecific">
	(if t.2 t.2 t.1)
</programlisting><para>The inner <literal moreinfo="none">let</literal> expression is reconstructed as:</para><programlisting id="I_programlisting25_tt608" format="linespecific">
	(let ([t.2 #f]) (if t.2 t.2 t.1))
</programlisting><para>And the outer <literal moreinfo="none">let</literal> expression is reconstructed as:</para><programlisting id="I_programlisting25_tt609" format="linespecific">
	(let ([t.1 #t]) (let ([t.2 #f]) (if t.2 t.2 t.1)))
</programlisting><para>which is exactly what we want, although the particular choice of fresh names is not important as long as they are distinct.<indexterm id="I_indexterm25_tt610" class="endofrange" startref="idx-CHP-25-2242" significance="normal"><primary>syntax-case</primary><secondary>expander example</secondary></indexterm></para></sect1><sect1 id="conclusion-id013" label="25.4"><title>Conclusion</title><para>The simplified expander described here illustrates the basic algorithm that underlies a complete implementation of <literal moreinfo="none">syntax-case</literal>, without the complexities of the pattern-matching mechanism, handling of internal definitions, and additional core forms that are usually handled by an expander. The representation of environments is tailored to the single-binding <literal moreinfo="none">lambda, let</literal>, and <literal moreinfo="none">letrec-syntax</literal> forms implemented by the expander; a more efficient representation that handles groups of bindings would typically be used in practice. While these additional features are not trivial to add, they are conceptually independent of the expansion algorithm.</para><para>The <literal moreinfo="none">syntax-case</literal> expander extends the KFFD hygienic macro-expansion algorithm with support for local syntax bindings and controlled capture, among other things, and also eliminates the quadratic expansion overhead of the KFFD algorithm.</para><para>The KFFD algorithm is simple and elegant, and an expander based on it could certainly be a beautiful piece of code. The <literal moreinfo="none">syntax-case</literal> expander, on the other hand, is of necessity considerably more complex. It is not, however, any less beautiful, for there can still be beauty in complex software as long as it is well structured and does what it is designed to do.<indexterm id="I_indexterm25_tt611" class="endofrange" startref="idx-CHP-25-2086" significance="normal"><primary>syntactic abstraction</primary></indexterm></para></sect1></chapter><chapter id="labor-saving_architecture_an_object-oriented_framework_for_netw" label="26" role=""><title>Labor-Saving Architecture: An Object-Oriented Framework for Networked Software</title><para><emphasis>William R. Otte and Douglas C. Schmidt</emphasis><indexterm class="startofrange" id="idx-CHP-26-2245" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm><indexterm id="idx-CHP-26-2246" significance="normal"><primary>networked software</primary></indexterm><indexterm id="idx-CHP-26-2247" significance="normal"><primary>Otte</primary></indexterm><indexterm id="idx-CHP-26-2248" significance="normal"><primary>Schmidt</primary></indexterm></para><para><emphasis>Developing software for networked applications is hard</emphasis>, and developing reusable software for networked applications is even harder. First, there are the complexities inherent to distributed systems, such as optimally mapping application services onto hardware nodes, synchronizing service initialization, and ensuring availability while masking partial failures. These complexities can stymie even experienced software developers because they arise from fundamental challenges in the domain of network programming.</para><para>Unfortunately, developers must also master <emphasis>accidental complexities</emphasis>, such as low-level and nonportable programming interfaces and the use of function-oriented design techniques that require tedious and error-prone revisions as requirements and/or platforms evolve. These complexities arise largely from limitations with the software tools and techniques applied historically by developers of networked software.<indexterm id="idx-CHP-26-2249" significance="normal"><primary>accidental complexities encountered by developers</primary></indexterm></para><para>Despite the use of object-oriented technologies in many domains, such as graphical user interfaces and productivity tools, much networked software still uses C-level <indexterm id="idx-CHP-26-2250" significance="normal"><primary>C language</primary><secondary>operating system (OS) APIs</secondary></indexterm>operating system (OS) application programmatic interfaces (APIs), such as the Unix <indexterm id="idx-CHP-26-2251" significance="normal"><primary>Unix operating system</primary><secondary>socket API</secondary></indexterm>socket API or the Windows <indexterm id="idx-CHP-26-2252" significance="normal"><primary>Windows operating systems</primary><secondary>threading API</secondary></indexterm>threading API. Many accidental complexities of networked programming stem from the use of these C-level OS APIs, which are not type-safe, often not reentrant, and not portable across OS platforms. The C APIs were also designed before the wide-spread adoption of modern design methods and technologies, so they encourage developers to decompose their problems functionally in terms of processing steps in a top-down design, instead of using OO design and programming techniques. Experience over the past several decades has shown that <indexterm id="idx-CHP-26-2253" significance="normal"><primary>functional decomposition of nontrivial software</primary></indexterm>functional decomposition of nontrivial software complicates maintenance and evolution because functional requirements are rarely stable design centers. <footnote id="CHP-26-FNOTE-1"><para><emphasis>Object-Oriented Software Construction</emphasis>, Second Edition, Bertrand Meyer, Prentice Hall, 1997.</para></footnote><indexterm id="idx-CHP-26-2254" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm></para><para>Fortunately, two decades of advances in design/implementation techniques and programming languages have made it much easier to write and reuse <indexterm id="idx-CHP-26-2255" significance="normal"><primary>networked software</primary></indexterm>networked software. In particular, object-oriented (OO) programming languages (such as C++, Java, and C#) combined with <emphasis>patterns</emphasis> (such as Wrapper Facades, <footnote id="CHP-26-FNOTE-2"><para><emphasis>Pattern-Oriented Software Architecture, Vol. 2: Patterns for Concurrent and Networked Objects</emphasis>, Douglas <indexterm id="idx-CHP-26-2256" significance="normal"><primary>Schmidt</primary></indexterm>Schmidt, Michael Stal, Hans Rohnert, and Frank Buschmann, John Wiley and Sons, 2000.</para></footnote>Adapters, and the Template Method <footnote id="CHP-26-FNOTE-3"><para><emphasis>Design Patterns: Elements of Reusable Object-Oriented Software</emphasis>, Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, Addison-Wesley, 1995.</para></footnote>), and frameworks (such as <indexterm id="idx-CHP-26-2257" significance="normal"><primary>host infrastructure middleware</primary></indexterm>host infrastructure middleware like ACE<footnote id="CHP-26-FNOTE-4"><para>C++ Network Programming, Vol. 2: Systematic Reuse with ACE and Frameworks, Douglas C. Schmidt and Stephen D. Huston, Addison-Wesley Longman, 2003.</para></footnote> and the Java <indexterm id="idx-CHP-26-2258" significance="normal"><primary>Java</primary><secondary>class libraries for network programming</secondary></indexterm>class libraries for network programming, <footnote id="CHP-26-FNOTE-5"><para><emphasis>Java Network Programming</emphasis>, Third Edition, <indexterm id="idx-CHP-26-2259" significance="normal"><primary>Otte</primary></indexterm>Elliotte Rusty Harold, O'Reilly, 2004.</para></footnote>and similar <indexterm id="idx-CHP-26-2260" significance="normal"><primary>middleware</primary><secondary>host infrastructure</secondary></indexterm>host infrastructure middleware) help to encapsulate low-level functional OS APIs and mask syntactic and semantic differences between platforms. As a result, developers can focus on application-specific behavior and properties in their software, rather than repeatedly wrestling with the accidental complexities of programming the low-level networking and OS infrastructure.</para><para>A key benefit of applying patterns and frameworks <indexterm id="idx-CHP-26-2261" significance="normal"><primary>frameworks</primary><secondary>applied to networked software</secondary></indexterm>to networked software is that they can help developers craft reusable architectures that (1) capture the common structure and behavior in a particular domain, and (2) make it easy to change or replace various algorithms, policies, and mechanisms selectively without affecting other existing parts of the architecture. While most developers of networked software can apply well-designed OO frameworks to their applications, the knowledge of how to create such a framework remains a black art that has historically been learned only by extensive (and expensive) trial and error.</para><para>In addition to the conventional challenges of devising a flexible OO design that can expand and contract to meet new requirements, networked software must often run efficiently and scalably in a range of operating environments. The goal of this chapter is to help demystify the black art of OO <indexterm id="idx-CHP-26-2262" significance="normal"><primary>object-oriented (OO) programming languages</primary><secondary>frameworks for networked software</secondary></indexterm>frameworks for networked software by using a case study to systematically dissect the design and implementation of a representative networked software application.</para><para>In general, the beauty of our solution stems from its use of patterns and OO techniques to balance key domain forces, such as reusability, extensibility, and performance. In particular, our approach enables developers to identify common design/programming artifacts, thereby enhancing reuse. It also provide a means to encapsulate variabilities in a common and parameterizable way, thereby enhancing extensibility and portability.</para><sect1 id="sample_application_logging_service" label="26.1"><title>Sample Application: Logging Service</title><para>The OO software that we use as the basis of our case study is a <indexterm id="idx-CHP-26-2263" significance="normal"><primary>logging</primary><secondary>networked logging service (example application)</secondary></indexterm>networked logging service. As shown in <xref linkend="architecture_of_a_networked_logging_service"/>, this service consists of client applications that generate log records and send them to a central logging server that receives and stores the log records for later inspection and processing.<indexterm id="idx-CHP-26-2264" significance="normal"><primary>networked software</primary><secondary>logging service application</secondary></indexterm></para><figure id="architecture_of_a_networked_logging_service" label="26-1" float="0"><title>Architecture of a networked logging service</title><mediaobject id="I_mediaobject26_tt612"><imageobject role="print"><imagedata fileref="figs/print/beauty_2601.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2601.png" format="PNG"/></imageobject></mediaobject></figure><para>The logging server portion (at the center of <xref linkend="architecture_of_a_networked_logging_service"/>) of our networked logging service provides an ideal context for demonstrating the beauty of OO <indexterm id="idx-CHP-26-2265" significance="normal"><primary>networked software</primary></indexterm>networked software because it exhibits the following dimensions of design-time variability that developers can choose from when implementing such a server:</para><itemizedlist><listitem><para>Different interprocess communication (<indexterm id="idx-CHP-26-2266" significance="normal"><primary>IPC (interprocess communication) mechanisms</primary></indexterm>IPC) mechanisms (such as sockets, SSL, shared memory, TLI, named pipes, etc.) that developers can use to send and receive log records.</para></listitem><listitem><para><indexterm id="idx-CHP-26-2267" significance="normal"><primary>concurrency</primary><secondary>different models</secondary></indexterm>Different concurrency models (such as iterative, reactive, thread-per-connection, process-per-connection, various types of thread pools, etc.) that developers can use to process log records.</para></listitem><listitem><para>Different locking <indexterm id="idx-CHP-26-2268" significance="normal"><primary>locking</primary><secondary>strategies for</secondary></indexterm>strategies (such as thread-level or process-level recursive mutex, nonrecursive mutex, readers/writer lock, null mutex, etc.) that developers can use to serialize access to resources, such as a count of the number of requests, shared by multiple threads.</para></listitem><listitem><para>Different <indexterm id="idx-CHP-26-2269" significance="normal"><primary>logging</primary><secondary>log record formats</secondary></indexterm>log record formats that can be transmitted from client to server. Once received by the server, the log records can be handled in different ways—e.g., printed to console, stored to a single file, or even one file per client to maximize parallel writes to disk.</para></listitem></itemizedlist><para>It is relatively straightforward to implement any one of these combinations, such as running one thread per connection-logging server using socket-based IPC and a thread-level nonrecursive mutex. A one-size-fits-all solution, however, is inadequate to meet the needs of all logging services because different customer requirements and different operating environments can have significantly different impacts on time/space trade-offs, cost, and schedule. A key challenge is therefore to design a configurable logging server that is <emphasis>easily extensible</emphasis> to meet new needs with a <emphasis>minimum of effort</emphasis>.</para><para>At the heart of the solution to this challenge is a thorough understanding of the patterns and associated design techniques needed to develop OO frameworks that efficiently:</para><itemizedlist><listitem><para>Capture common structure and behavior in base classes and generic classes</para></listitem><listitem><para>Enable selective customization of behavior via subclasses and by providing concrete parameters to generic classes</para></listitem></itemizedlist><para><xref linkend="object-oriented_design_for_the_logging_server_framework"/> illustrates the design of an OO <indexterm id="idx-CHP-26-2270" significance="normal"><primary>logging server framework</primary></indexterm>logging server framework that realizes these goals. The core of this design is the <literal moreinfo="none">Logging_Server</literal> class, which defines the common structure and functionality for the logging server via the use of:<indexterm id="idx-CHP-26-2271" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm><indexterm id="idx-CHP-26-2272" significance="normal"><primary>Logging_Server abstract base class</primary></indexterm></para><itemizedlist><listitem><para><indexterm id="idx-CHP-26-2273" significance="normal"><primary>data types</primary><secondary>C++ parameterized types</secondary></indexterm>C++ <indexterm id="idx-CHP-26-2274" significance="normal"><primary>C++</primary><secondary>parameterized types</secondary></indexterm>parameterized types, which allow developers to defer the selection of data types <indexterm id="idx-CHP-26-2275" significance="normal"><primary>patterns</primary><secondary>used in OO logging server framework</secondary></indexterm>used in generic classes or functions until their point of instantiation</para></listitem><listitem><para>The <indexterm id="idx-CHP-26-2276" significance="normal"><primary>Template Method pattern</primary></indexterm>Template Method pattern, which defines the skeleton of an algorithm, delegating individual steps to methods that may be overridden by subclasses</para></listitem><listitem><para>The <indexterm id="idx-CHP-26-2277" significance="normal"><primary>Wrapper Facade pattern</primary></indexterm>Wrapper Facade pattern, which encapsulates non-object-oriented APIs and data within type-safe object-oriented classes</para></listitem></itemizedlist><para>Subclasses and concrete instantiations of <literal moreinfo="none">Logging_Server</literal> refine this common reusable architecture to customize variable steps in the logging server behavior by selecting desired IPC mechanisms, concurrency models, and locking strategies. The <literal moreinfo="none">Logging_Server</literal> is thus a <emphasis>product-line architecture</emphasis> <footnote id="CHP-26-FNOTE-6"><para><indexterm id="idx-CHP-26-2278" significance="normal"><primary>networked software</primary></indexterm>Software Product Lines: Practices and Patterns, Paul Clements and Linda Northrop, Addison-Wesley, 2001.</para></footnote>that defines an integrated set of classes that collaborate to define a reusable design for a family of related logging servers.</para><figure id="object-oriented_design_for_the_logging_server_framework" label="26-2" float="0"><title>Object-oriented design for the logging server framework</title><mediaobject id="I_mediaobject26_tt613"><imageobject role="print"><imagedata fileref="figs/print/beauty_2602.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2602.png" format="PNG"/></imageobject></mediaobject></figure><para>The remainder of this chapter is organized as follows. The next section describes the OO <indexterm class="startofrange" id="idx-CHP-26-2279" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary></indexterm>design of the logging server framework, exploring its architecture and the forces that influence the design of the OO framework to illustrate why we selected certain patterns and language features, as well as summarizing alternative approaches that we rejected for various reasons. Two further sections present several C++ sequential programming instantiations of the logging server framework and of concurrent programming instantiations of this framework. We conclude by summarizing the beauty of the OO software concepts and techniques in this chapter.<indexterm id="idx-CHP-26-2280" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm><indexterm id="idx-CHP-26-2281" significance="normal"><primary>logging server framework</primary></indexterm></para></sect1><sect1 id="object-oriented_design_of_the_logging_server_framework" label="26.2"><title>Object-Oriented Design of the Logging Server Framework</title><para>Before we discuss the OO design of our logging server, it is important to understand several <indexterm id="idx-CHP-26-2282" significance="normal"><primary>logging server framework</primary><secondary>sequential logging servers</secondary><tertiary>key concepts about OO frameworks</tertiary></indexterm>key concepts about OO frameworks. Most programmers are familiar with the concept of a class library, which is a set of reusable classes that provides functionality that may be used when developing OO programs. OO frameworks extend the benefits of OO <indexterm id="idx-CHP-26-2283" significance="normal"><primary>class libraries</primary></indexterm>class libraries in the following ways: <footnote id="CHP-26-FNOTE-7"><para>"Frameworks = Patterns + Components," Ralph Johnson, <emphasis>Communications of the ACM</emphasis>, Vol. 40, No. 10, October 1997.</para></footnote><indexterm id="idx-CHP-26-2284" significance="normal"><primary>frameworks</primary><secondary>object-oriented</secondary></indexterm></para><variablelist><varlistentry><term><emphasis>They define "semi-complete" applications that embody domain-specific object structures and functionality</emphasis></term><listitem><para>Classes in a framework work together to provide a generic architectural skeleton for applications in a particular domain, such as graphical user interfaces, avionics mission computing, or <indexterm id="idx-CHP-26-2285" significance="normal"><primary>networked software</primary></indexterm>networked logging services. Complete applications can be composed by inheriting from and/or instantiating framework components. In contrast, class libraries are less domain-specific and provide a smaller scope of reuse. For instance, class library components such as classes for strings, complex numbers, arrays, and bitsets are relatively low-level and ubiquitous across many application domains.</para></listitem></varlistentry><varlistentry><term><emphasis>Frameworks are active and exhibit "inversion of control" at runtime</emphasis></term><listitem><para>Class libraries are typically passive—i.e., they perform isolated bits of processing when invoked by threads of control from self-directed application objects. In contrast, frameworks are active—i.e., they direct the flow of control within an application via <indexterm id="idx-CHP-26-2286" significance="normal"><primary>patterns</primary><secondary>event-dispatching</secondary></indexterm>event-dispatching patterns, such as <indexterm id="idx-CHP-26-2287" significance="normal"><primary>Reactor pattern</primary></indexterm>Reactor <footnote id="CHP-26-FNOTE-8"><para><indexterm id="idx-CHP-26-2288" significance="normal"><primary>Schmidt</primary></indexterm>Schmidt et al., <emphasis>op. cit</emphasis>.</para></footnote> and <indexterm id="idx-CHP-26-2289" significance="normal"><primary>Observer pattern</primary></indexterm>Observer. <footnote id="CHP-26-FNOTE-9"><para>Gamma et al., <emphasis>op. cit</emphasis>.</para></footnote> The "inversion of control" in the runtime architecture of a framework is often referred to as "The Hollywood Principle," which states "Don't call us, we'll call you." <footnote id="CHP-26-FNOTE-10"><para>"Pattern Hatching - Protection, Part I: The Hollywood Principle," John Vlissides, <emphasis>C++ Report</emphasis>, February 1996.</para></footnote><indexterm id="idx-CHP-26-2290" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm><indexterm id="idx-CHP-26-2291" significance="normal"><primary>inversion of control in runtime architecture of OO framework</primary></indexterm></para></listitem></varlistentry></variablelist><para>Frameworks are typically <indexterm id="idx-CHP-26-2292" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary></indexterm>designed by analyzing various potential problems that the framework might address and identifying which parts of each solution are the same and which areas of each solution are unique. This design method is called <emphasis>commonality/variability analysis</emphasis>, <footnote id="CHP-26-FNOTE-11"><para>"Commonality and Variability in <indexterm id="idx-CHP-26-2293" significance="normal"><primary>networked software</primary></indexterm>Software Engineering." J. Coplien, D. Hoffman, and D. Weiss, <emphasis>IEEE Software</emphasis>, Vol. 15, No. 6, November/December 1998.</para></footnote>which covers the following topics:<indexterm id="idx-CHP-26-2294" significance="normal"><primary>commonality/variability analysis</primary></indexterm></para><variablelist><varlistentry><term><emphasis>Scope</emphasis></term><listitem><para>Defines the domains (i.e., the problem areas a framework addresses) and the context of the framework.</para></listitem></varlistentry><varlistentry><term><emphasis>Commonalities</emphasis></term><listitem><para>Describe the attributes that recur across all members of the family of products based on the framework.<indexterm id="idx-CHP-26-2295" significance="normal"><primary>logging server framework</primary><secondary>sequential logging servers</secondary><tertiary>commonalities</tertiary></indexterm></para></listitem></varlistentry><varlistentry><term><emphasis>Variabilities</emphasis></term><listitem><para>Describe the attributes unique to the different members of the family of products.<indexterm id="idx-CHP-26-2296" significance="normal"><primary>variabilities in OO framework analysis</primary></indexterm></para></listitem></varlistentry></variablelist><sect2 id="understanding_the_commonalities" label="26.2.1"><title>Understanding the Commonalities</title><para>The first step in designing our <indexterm id="idx-CHP-26-2297" significance="normal"><primary>logging server framework</primary></indexterm>logging server framework is therefore to understand the parts of the system that should be implemented by the framework (commonalities) and the parts of the system left to be specialized in subclasses or parameters (variabilities). This analysis is straightforward because the steps involved in processing a log record sent over a network can be decomposed into the steps shown in <xref linkend="logging_server_main_loop"/>, which are common to all logging server implementations.<indexterm id="idx-CHP-26-2298" significance="normal"><primary>object-oriented framework for networked software</primary><secondary>design of logging server framework</secondary><tertiary>commonalities</tertiary></indexterm><indexterm id="idx-CHP-26-2299" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary><tertiary>commonalities</tertiary></indexterm></para><para>During this stage of the design process, we define each step as abstractly as possible. For example, at this stage we've made minimal assumptions about the type of IPC mechanisms, other than they are connection-oriented to ensure reliable delivery of log records. Likewise, we've avoided specifying the type of concurrency strategy (e.g., whether the server can handle multiple requests, and if so, how they are dispatched) or the synchronization mechanism used by each step. The actual choice of specific behavior for a step is thus deferred to the subsequent concrete implementations that provide a particular variant for each step.</para><figure id="logging_server_main_loop" label="26-3" float="0"><title>Logging server main loop</title><mediaobject id="I_mediaobject26_tt614"><imageobject role="print"><imagedata fileref="figs/print/beauty_2603.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2603.png" format="PNG"/></imageobject></mediaobject></figure><para>The Template Method pattern is a useful way to define abstract steps and defer implementation of their specific behaviors to later steps in the design process. This pattern defines a base class that implements the common—but abstract—steps in the <emphasis>template method</emphasis> in terms of <emphasis>hook methods</emphasis> that can be overridden selectively by concrete implementations. Programming language features, such as pure virtual functions in C++ or abstract methods in Java, can be used to ensure that all concrete implementations define the hook methods. <xref linkend="template_method_pattern_and_its_application_to_the_logging_serv"/> shows the <indexterm id="idx-CHP-26-2300" significance="normal"><primary>Template Method pattern</primary><secondary>structure and application to logging server</secondary></indexterm>structure of the Template Method pattern and demonstrates how this pattern is applied to the <indexterm id="idx-CHP-26-2301" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary></indexterm>design of our OO <indexterm id="idx-CHP-26-2302" significance="normal"><primary>logging server framework</primary></indexterm>logging server framework.<indexterm id="idx-CHP-26-2303" significance="normal"><primary>hook methods</primary></indexterm></para><figure id="template_method_pattern_and_its_application_to_the_logging_serv" label="26-4" float="0"><title>Template Method pattern and its application to the logging server</title><mediaobject id="I_mediaobject26_tt615"><imageobject role="print"><imagedata fileref="figs/print/beauty_2604.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2604.png" format="PNG"/></imageobject></mediaobject></figure></sect2><sect2 id="accommodating_variation" label="26.2.2"><title>Accommodating Variation</title><para>Although the Template Method pattern addresses the overall design of the steps in our logging server <indexterm id="idx-CHP-26-2304" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm>framework, we're left with the question of how to accommodate all three dimensions of variability defined earlier (IPC, concurrency, and synchronization mechanisms) needed to support our design. One approach would simply use the Template Method pattern and implement one IPC/concurrency/synchronization combination per concrete subclass. Unfortunately, this approach would yield exponential growth in the number of concrete subclasses, as each addition to any dimension could generate another implementation for each possible combination of the other dimensions. A pure Template Method design, therefore, would not be substantially better than handcrafting one-off implementations of a logging server for each variant.<indexterm id="idx-CHP-26-2305" significance="normal"><primary>logging server framework</primary><secondary>sequential logging servers</secondary><tertiary>variation</tertiary></indexterm></para><para>A more effective and scalable <indexterm id="idx-CHP-26-2306" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary></indexterm>design could leverage the fact that our variability dimensions are largely independent. The choice of a different IPC mechanism, for instance, is unlikely to require changes in the concurrency or synchronization mechanisms used. Moreover, there is a high-level commonality in how different types of IPC and synchronization mechanisms function—e.g., IPC mechanisms can initiate/accept connections and send/receive data on connections, whereas synchronization mechanisms have operations to acquire and release locks. The design challenge is to encapsulate the accidental complexities in these APIs so that they can be used interchangeably.</para><para>A solution to this challenge is to use the <indexterm id="idx-CHP-26-2307" significance="normal"><primary>Wrapper Facade pattern</primary></indexterm>Wrapper Facade pattern, which presents a single unified OO interface for the underlying non-OO IPC and synchronization mechanisms provided by system functions in an OS. Wrapper facades are particularly useful for enhancing portability by hiding accidental complexities between mechanisms, as well as making it less tedious and error-prone to work with these APIs. For instance, a wrapper facade can define a higher-level type system that ensures that only correct operations are called on the underlying non-OO (and less type-safe) OS IPC and synchronization data structures. The role of a wrapper facade is shown in <xref linkend="wrapper_facade_design_pattern"/>.</para><figure id="wrapper_facade_design_pattern" label="26-5" float="0"><title>Wrapper facade design pattern</title><mediaobject id="I_mediaobject26_tt616"><imageobject role="print"><imagedata fileref="figs/print/beauty_2605.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2605.png" format="PNG"/></imageobject></mediaobject></figure><para>ACE is a widely used example of host infrastructure middleware that defines unified OO interfaces using wrapper facades for both IPC and synchronization mechanisms. We base the wrapper facades in this chapter on simplified versions of those provided by ACE. <xref linkend="some_ace_wrapper_facades_for_passive_connection_establishment_a"/> shows some of the <indexterm id="idx-CHP-26-2308" significance="normal"><primary>ACE wrapper facades</primary></indexterm>ACE wrapper facades.</para><figure id="some_ace_wrapper_facades_for_passive_connection_establishment_a" label="26-6" float="0"><title>Some ACE wrapper facades for passive connection establishment and synchronization</title><mediaobject id="I_mediaobject26_tt617"><imageobject role="print"><imagedata fileref="figs/print/beauty_2606.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2606.png" format="PNG"/></imageobject></mediaobject></figure><para>The <literal moreinfo="none">Acceptor</literal> wrapper facade provides the means to create passive-mode connections and provides "traits" to represent aspects of a mechanism that work essentially the same way across different implementations, just with different APIs. For instance, <literal moreinfo="none">PEER_STREAM</literal> and <literal moreinfo="none">PEER_ADDR</literal> <indexterm id="idx-CHP-26-2309" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary></indexterm>designate dependent wrapper facades appropriate for sending/receiving data and for addressing by the IPC mechanism, respectively. <literal moreinfo="none">SOCK_Acceptor</literal> is a subclass of <literal moreinfo="none">Acceptor</literal> used in this chapter to implement a factory for passively establishing connections implemented using the socket API.<indexterm id="idx-CHP-26-2310" significance="normal"><primary>IPC (interprocess communication) mechanisms</primary><secondary>ACE wrapper facades</secondary></indexterm><indexterm id="idx-CHP-26-2311" significance="normal"><primary>Acceptor wrapper facade</primary></indexterm></para><para>The <literal moreinfo="none">Mutex</literal> wrapper facade provides an interface whose methods acquire and release locks, including a <literal moreinfo="none">Recursive_Mutex</literal> implemented using a mutex that will not deadlock when acquired multiple times by the same thread, a <literal moreinfo="none">RW_Lock</literal> that implements readers/writer semantics, and a <literal moreinfo="none">Null_Mutex</literal> whose <literal moreinfo="none">acquire( )/release( )</literal> methods are inline no-ops. The last class mentioned is an example of the <indexterm id="idx-CHP-26-2312" significance="normal"><primary>Null Object pattern</primary></indexterm>Null Object pattern <footnote id="CHP-26-FNOTE-12"><para>"The Null Object Pattern," Bobby Woolf, in <emphasis>Pattern Languages of Program Design, Volume 3</emphasis>, Robert C. Martin, Dirk Riehle, and Frank Buschmann, Addison-Wesley, 1997.</para></footnote>and is useful for eliminating synchronization without changing application code. <xref linkend="some_ace_wrapper_facades_for_passive_connection_establishment_a"/> makes it appear as if each family of classes is related by inheritance, but they are actually implemented by classes unrelated by inheritance that have a common interface and can be used as type parameters to C++ templates. We made this design choice to avoid virtual method call overhead.<indexterm id="idx-CHP-26-2313" significance="normal"><primary>Mutex wrapper facade</primary></indexterm></para></sect2><sect2 id="tying_it_all_together" label="26.2.3"><title>Tying It All Together</title><para>Another design challenge is how to associate a <indexterm id="idx-CHP-26-2314" significance="normal"><primary>IPC (interprocess communication) mechanisms</primary><secondary>associating concurrency strategy with</secondary></indexterm>concurrency strategy with an IPC and synchronization mechanism. One approach would be to use the <indexterm id="idx-CHP-26-2315" significance="normal"><primary>Strategy pattern</primary></indexterm>Strategy pattern, <footnote id="CHP-26-FNOTE-13"><para>Gamma et al., <emphasis>op. cit</emphasis>.</para></footnote>which encapsulates algorithms as objects so they can be swapped at runtime. This approach would provide the <literal moreinfo="none">Logging_Server</literal> with a pointer to abstract base classes of <literal moreinfo="none">Acceptor</literal> and <literal moreinfo="none">Mutex</literal>, and then rely on dynamic binding and polymorphism to dispatch the virtual methods to the appropriate subclass instances.<indexterm id="idx-CHP-26-2316" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary><tertiary>tying it all together</tertiary></indexterm><indexterm id="idx-CHP-26-2317" significance="normal"><primary>Logging_Server abstract base class</primary></indexterm></para><para>While a Strategy-based approach is feasible, it is not ideal. Each incoming log record may generate several calls to methods in the <literal moreinfo="none">Acceptor</literal> and <literal moreinfo="none">Mutex</literal> wrapper facades. Performance could therefore degrade, because virtual methods incur more overhead than nonvirtual method calls. Given that dynamically swapping IPC or synchronization mechanisms are not a requirement for our <indexterm id="idx-CHP-26-2318" significance="normal"><primary>logging server framework</primary></indexterm>logging servers, a more efficient solution is to use C++ parameterized types to instantiate our logging server classes with the wrapper facades for IPC and synchronization.</para><para>We therefore define the following generic abstract base class called <literal moreinfo="none">Logging_Server</literal> from which all logging servers in this chapter will inherit:</para><programlisting id="I_programlisting26_tt618" format="linespecific">
	template &lt;typename ACCEPTOR, typename MUTEX&gt;
	class Logging_Server {
	 public:
	   typedef Log_Handler&lt;typename ACCEPTOR::PEER_STREAM&gt; HANDLER;

	   Logging_Server (int argc, const char *argv);

	   // Template method that runs each step in the main event loop.
	   virtual void run (void);

	protected:
	   // Hook methods that enable each step to be varied.
	   virtual void open (void);
	   virtual void wait_for_multiple_events (void) = 0;
	   virtual void handle_connections (void) = 0;
	   virtual void handle_data
	                   (typename ACCEPTOR::PEER_STREAM *stream = 0) = 0;

	   // Increment the request count, protected by the mutex.
	   virtual void count_request (size_t number = 1);

	   // Instance of template parameter that accepts connections.
	   ACCEPTOR acceptor_;

	   // Keeps a count of the number of log records received.
	   size_t request_count_;

	   // Instance of template parameter that serializes access to
	   // the request_count_.
	   MUTEX mutex_;

	   // Address that the server will listen on for connections.
	   std:string server_address_;
	};
</programlisting><para>Most methods in <literal moreinfo="none">Logging_Server</literal> are pure virtual, which ensures that subclasses implement them. The <literal moreinfo="none">open( )</literal> and <literal moreinfo="none">count_request( )</literal> methods that follow, however, are reused by all <indexterm id="idx-CHP-26-2319" significance="normal"><primary>logging server framework</primary></indexterm>logging servers in this chapter:<indexterm id="idx-CHP-26-2320" significance="normal"><primary>Logging_Server abstract base class</primary><secondary>open( ) and request( ) methods</secondary></indexterm></para><programlisting id="I_programlisting26_tt619" format="linespecific">
	template &lt;typename ACCEPTOR, typename MUTEX&gt;
	Logging_Server&lt;ACCEPTOR, MUTEX&gt;::Logging_Server
	(int argc, char *argv[]): request_count_ (0) {
	  // Parse the argv arguments and store the server address_...
	}

	template &lt;typename ACCEPTOR, typename MUTEX&gt; void
	Logging_Server&lt;ACCEPTOR, MUTEX&gt;::open (void) {
	  return acceptor_.open (server_address_);
	}


	template &lt;typename ACCEPTOR, typename MUTEX&gt; void
	Logging_Server&lt;ACCEPTOR, MUTEX&gt;::count_request (size_t number) {
	  mutex_.acquire (); request_count_ += number; mutex_.release ();
	}
</programlisting><para>The <literal moreinfo="none">Log_Handler</literal> class is responsible for demarshaling a log record from a connected data stream whose IPC mechanism is <indexterm id="idx-CHP-26-2321" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary></indexterm>designated by the <literal moreinfo="none">ACCEPTOR</literal> type parameter. The implementation of this class is outside the scope of this chapter, and could itself be another dimension of variability—that is, logging servers might want to support different log message formats. If we were to support <indexterm id="idx-CHP-26-2322" significance="normal"><primary>hook methods</primary><secondary>in Logging_Server run( ) template method</secondary></indexterm>varying the format of method of storing incoming log messages, this class could be yet another template parameter in our logging <indexterm id="idx-CHP-26-2323" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm>framework. For our purposes, it is sufficient to know that it is parameterized by the IPC mechanism and provides two methods: <literal moreinfo="none">peer( )</literal>, which returns a reference to the data stream, and <literal moreinfo="none">log_record( )</literal>, which reads a single log record from the stream.<indexterm id="idx-CHP-26-2324" significance="normal"><primary>Log_Handler class</primary></indexterm></para><para>The primary entry point into <literal moreinfo="none">Logging_Server</literal> is the template method called <literal moreinfo="none">run( )</literal>, which implements the steps outlined in <xref linkend="logging_server_main_loop"/>, delegating the specific steps to the hook methods declared in the protected section of <literal moreinfo="none">Logging_Server</literal>, as shown in the following code fragment:<indexterm id="idx-CHP-26-2325" significance="normal"><primary>Logging_Server abstract base class</primary><secondary>run( ) method</secondary></indexterm></para><programlisting id="I_programlisting26_tt620" format="linespecific">
	template &lt;typename ACCEPTOR, typename MUTEX&gt; void
	Logging_Server&lt;ACCEPTOR, MUTEX&gt;::run (void) {
	  try {
	    // Step 1: initialize an IPC factory endpoint to listen for
	    // new connections on the server address.
	    open ();

	    // Step 2: Go into an event loop
	    for (;;) {
	      // Step 2a: wait for new connections or log records
	      // to arrive.
	wait_for_multiple_events ();

	// Step 2b: accept a new connection (if available)
	      handle_connections ();

	      // Step 2c: process received log record (if available)
	      handle_data ();
	    }
	  } catch (...) { /* ... Handle the exception ... */ }
	}
</programlisting><para>The beauty of this code is that:</para><itemizedlist><listitem><para>Its pattern-based <indexterm id="idx-CHP-26-2326" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary></indexterm>design makes it easy to handle variation in concurrency models, such as by varying the behavior of the <literal moreinfo="none">run( )</literal> template method by providing specific implementations of the hook methods in the implementation of subclasses.</para></listitem><listitem><para>Its template-based design makes it easy to handle variation in IPC and synchronization mechanisms, such as by plugging different types into the <literal moreinfo="none">ACCEPTOR</literal> and <literal moreinfo="none">MUTEX</literal> template parameters.</para></listitem></itemizedlist></sect2></sect1><sect1 id="implementing_sequential_logging_servers" label="26.3"><title>Implementing Sequential Logging Servers</title><para>This section demonstrates the implementation of logging servers that feature <indexterm id="idx-CHP-26-2327" significance="normal"><primary>sequential concurrency models</primary></indexterm>sequential concurrency models—i.e., all processing is performed in a single thread. We cover both iterative and reactive implementations of <indexterm id="idx-CHP-26-2328" significance="normal"><primary>logging</primary><secondary>sequential logging servers</secondary></indexterm>sequential logging servers.<indexterm class="startofrange" id="idx-CHP-26-2329" significance="normal"><primary>networked software</primary><secondary>implementing sequential logging servers</secondary></indexterm><indexterm id="idx-CHP-26-2330" significance="normal"><primary>logging server framework</primary></indexterm><indexterm id="I_indexterm26_tt621" class="endofrange" startref="idx-CHP-26-2279" significance="normal"><primary>networked software</primary><secondary>design of logging server framework</secondary></indexterm></para><sect2 id="an_iterative_logging_server" label="26.3.1"><title>An Iterative Logging Server</title><para>Iterative servers process all log records from each client before handling any log records from the next client. Since there is no need to spawn or synchronize threads, we use the <literal moreinfo="none">Null_Mutex</literal> facade to parameterize the <literal moreinfo="none">Iterative_Logging_Server</literal> subclass template, as follows:<indexterm id="idx-CHP-26-2331" significance="normal"><primary>logging</primary><secondary>sequential logging servers</secondary></indexterm><indexterm id="idx-CHP-26-2332" significance="normal"><primary>Null_Mutex facade</primary></indexterm><indexterm id="idx-CHP-26-2333" significance="normal"><primary>Iterative_Logging_Server</primary></indexterm></para><programlisting id="I_programlisting26_tt622" format="linespecific">
	template &lt;typename ACCEPTOR&gt;
	   class Iterative_Logging_Server :
	  virtual Logging_Server&lt;ACCEPTOR, Null_Mutex&gt; {
	public:
	  typedef Logging_Server&lt;ACCEPTOR, Null_Mutex&gt;::HANDLER HANDLER;
	  Iterative_Logging_Server (int argc, char *argv[]);

	protected:
	  virtual void open (void);
	  virtual void wait_for_multiple_events (void) {};
	  virtual void handle_connections (void);
	  virtual void handle_data
	    (typename ACCEPTOR::PEER_STREAM *stream = 0);
	  HANDLER log_handler_;

	  // One log file shared by all clients.
	  std::ofstream logfile_;
	};
</programlisting><para><indexterm id="idx-CHP-26-2334" significance="normal"><primary>networked software</primary><secondary>implementing sequential logging servers</secondary></indexterm>Implementing this version of our server is straightforward. The <literal moreinfo="none">open( )</literal> method decorates the behavior of the method from the <literal moreinfo="none">Logging_Server</literal> base class by opening an output file before delegating to the parent's <literal moreinfo="none">open( )</literal>, as follows:</para><programlisting id="I_programlisting26_tt623" format="linespecific">
	template &lt;typename ACCEPTOR&gt; void
	Interative_Logging_Server&lt;ACCEPTOR&gt;::open (void) {
	  logfile_.open (filename_.c_str ());
	  if (!logfile_.good ()) throw std::runtime_error;
	  // Delegate to the parent's open() method.
	  Logging_Server&lt;ACCEPTOR, Null_Mutex&gt;::open ();
	}
</programlisting><para>The <literal moreinfo="none">wait_for_multiple_events( )</literal> method is a no-op. It is not needed because we just handle a single connection at any one time. The <literal moreinfo="none">handle_connections( )</literal> method therefore simply blocks until a new connection is established, as follows:</para><programlisting id="I_programlisting26_tt624" format="linespecific">
	template &lt;typename ACCEPTOR&gt; void
	Iterative_Logging_Server&lt;ACCEPTOR&gt;::handle_connections (void)
	{ acceptor_.accept (log_handler_.peer ()); }
</programlisting><para>Finally, <literal moreinfo="none">handle_data( )</literal> simply reads log records from the client and writes them to the log-file until the client closes the connection or an error occurs:</para><programlisting id="I_programlisting26_tt625" format="linespecific">
	template &lt;typename ACCEPTOR&gt; void
	Iterative_Logging_Server&lt;ACCEPTOR&gt;::handle_data (void) {
	    while (log_handler_.log_record (logfile _))
	      count_request ();
	   }
</programlisting><para>While the iterative server is straightforward to implement, it suffers from the drawback of being able to service only one client at a time. A second client that attempts to connect may time out while waiting for the first to finish its request.</para></sect2><sect2 id="a_reactive_logging_server" label="26.3.2"><title>A Reactive Logging Server</title><para>The reactive logging server alleviates one of the primary drawbacks with the iterative logging server in the previous section by processing multiple client connections and log record requests via operating system <indexterm id="idx-CHP-26-2335" significance="normal"><primary>synchronous event demultiplexing APIs (operating systems)</primary></indexterm>synchronous event demultiplexing APIs provided by the OS, such as <literal moreinfo="none">select( )</literal> and <literal moreinfo="none">WaitForMultipleObjects( )</literal>. These APIs can monitor multiple clients by waiting in a single thread of control for I/O-related events to occur on a group of I/O handles, and then interleave the processing of log records. Since a reactive logging server is still fundamentally <indexterm id="idx-CHP-26-2336" significance="normal"><primary>sequential concurrency models</primary></indexterm>sequential, however, it inherits from the iterative logging server implemented earlier, as shown in <xref linkend="reactive_logging_server_interface"/>.<indexterm id="idx-CHP-26-2337" significance="normal"><primary>Reactive_Logging_Server class</primary></indexterm></para><figure id="reactive_logging_server_interface" label="26-7" float="0"><title>Reactive logging server interface</title><mediaobject id="I_mediaobject26_tt626"><imageobject role="print"><imagedata fileref="figs/print/beauty_2607.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2607.png" format="PNG"/></imageobject></mediaobject></figure><para>The <literal moreinfo="none">Reactive_Logging_Server</literal> class overrides all four hook methods that it inherits from base class <literal moreinfo="none">Iterative_Logging_Server</literal>. Its <literal moreinfo="none">open( )</literal> hook method decorates the behavior of the base class method to initialize the <literal moreinfo="none">ACE_Handle_Set</literal> member variables, which are part of the wrapper facades that simplify the use of <literal moreinfo="none">select( )</literal>, as shown here:<indexterm id="idx-CHP-26-2338" significance="normal"><primary>ACE_Handle_Set member variables</primary></indexterm></para><programlisting id="I_programlisting26_tt627" format="linespecific">
	template &lt;typename ACCEPTOR&gt; void
	Reactive_Logging_Server&lt;ACCEPTOR&gt;::open () {
	  // Delegate to base class.
	  Iterative_Logging_Server&lt;ACCEPTOR&gt;::open ();

	  // Mark the handle associated with the acceptor as active.
	  master_set_.set_bit (acceptor_.get_handle ());

	  // Set the acceptor's handle into non-blocking mode.
	  acceptor_.enable (NONBLOCK);
	}
</programlisting><para>The <literal moreinfo="none">wait_for_multiple_events( )</literal> method is needed in this implementation, unlike its counterpart in <literal moreinfo="none">Iterative_Server</literal>. As shown in <xref linkend="using_an_asynchronous_event_demultiplexer_in_the_reactive_loggi"/>, this method <indexterm id="idx-CHP-26-2339" significance="normal"><primary>hook methods</primary><secondary>use in reactive logging server implementation</secondary></indexterm>uses a synchronous event demultiplexer (in this case, the <literal moreinfo="none">select( )</literal> call) to detect which I/O handles have connection or data activity pending.<indexterm id="idx-CHP-26-2340" significance="normal"><primary>connection/data event handling</primary></indexterm></para><figure id="using_an_asynchronous_event_demultiplexer_in_the_reactive_loggi" label="26-8" float="0"><title>Using an asynchronous event demultiplexer in the Reactive_Logging_Server program</title><mediaobject id="I_mediaobject26_tt628"><imageobject role="print"><imagedata fileref="figs/print/beauty_2608.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2608.png" format="PNG"/></imageobject></mediaobject></figure><para>After <literal moreinfo="none">wait_for_multiple_events( )</literal> has executed, the <literal moreinfo="none">Reactive_Logging_Server</literal> has a cached set of handles with pending activity (i.e., either new connection requests or new incoming data events), which will then be handled by its other two hook methods: <literal moreinfo="none">handle_data( )</literal> and <literal moreinfo="none">handle_connections( )</literal>. The <literal moreinfo="none">handle_connections( )</literal> method checks whether the acceptors handle is active and, if so, accepts as many connections as possible and caches them in the <literal moreinfo="none">master_handle_set_</literal>. Similarly, the <literal moreinfo="none">handle_data( )</literal> method iterates over the remaining active handles marked by <literal moreinfo="none">select( )</literal> earlier. This activity is simplified by the ACE <indexterm id="idx-CHP-26-2341" significance="normal"><primary>ACE wrapper facades</primary><secondary>socket wrapper facade</secondary></indexterm>socket wrapper facade that implements an instance of the <indexterm id="idx-CHP-26-2342" significance="normal"><primary>Iterator pattern</primary></indexterm>Iterator pattern <footnote id="CHP-26-FNOTE-14"><para>Gamma et al., <emphasis>op. cit</emphasis>.</para></footnote>for socket handle sets, as shown in <xref linkend="reactive_server_connectiondata_event_handling"/>.<indexterm id="idx-CHP-26-2343" significance="normal"><primary>asynchronous event demultiplexer in reactive logging server</primary></indexterm><indexterm id="idx-CHP-26-2344" significance="normal"><primary>logging</primary><secondary>sequential logging servers</secondary></indexterm></para><para>The following code implements a <literal moreinfo="none">Reactive_Logging_Server</literal> <indexterm id="idx-CHP-26-2345" significance="normal"><primary>Reactive_Logging_Server</primary><secondary>main program that uses the socket API</secondary></indexterm>main program that uses the socket API:</para><programlisting id="I_programlisting26_tt629" format="linespecific">
	int main (int argc, char *argv[]) {
	  Reactive_Logging_Server&lt;SOCK_Acceptor&gt; server (argc, argv);
	  server.run ();
	  return 0;
	}
</programlisting><figure id="reactive_server_connectiondata_event_handling" label="26-9" float="0"><title>Reactive server connection/data event handling</title><mediaobject id="I_mediaobject26_tt630"><imageobject role="print"><imagedata fileref="figs/print/beauty_2609.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2609.png" format="PNG"/></imageobject></mediaobject></figure><para>The first line of our main function parameterizes the <literal moreinfo="none">Reactive_Logging_Server</literal> with the <literal moreinfo="none">SOCK_Acceptor</literal> type, which will cause the C++ compiler to generate code for a reactive logging server that is able to communicate over sockets. This will, in turn, parameterize its <literal moreinfo="none">Logging_Server</literal> base class with both the <literal moreinfo="none">SOCK_Acceptor</literal> and <literal moreinfo="none">Null Mutex</literal>, by virtue of the hard-coded template argument provided when we inherited from it. The second line calls the <literal moreinfo="none">run( )</literal> template method, which is delegated to the <literal moreinfo="none">Logging_Server</literal> base class, which itself delegates to the various hook methods we implemented in this class.<indexterm id="idx-CHP-26-2346" significance="normal"><primary>hook methods</primary><secondary>in Logging_Server run( ) template method</secondary></indexterm><indexterm id="idx-CHP-26-2347" significance="normal"><primary>SOCK_Acceptor type</primary></indexterm><indexterm id="idx-CHP-26-2348" significance="normal"><primary>Null Mutex</primary></indexterm></para></sect2><sect2 id="evaluating_the_sequential_logging_server_solutions" label="26.3.3"><title>Evaluating the Sequential Logging Server Solutions</title><para>The <literal moreinfo="none">Reactive_Logging_Server</literal> improves upon the <literal moreinfo="none">Iterative_Logging_Server</literal> by interleaving its servicing of multiple clients, rather than just handling one client in its entirety at a time. It does not take advantage of OS concurrency mechanisms, however, so it cannot leverage multiprocessors effectively. Nor can it overlap computation and communication by processing log records while reading new records. These limitations impede its scalability as the number of clients increases, even if the underlying hardware supports multiple simultaneous threads of execution.<indexterm id="idx-CHP-26-2349" significance="normal"><primary>Reactive_Logging_Server</primary><secondary>evaluating</secondary></indexterm><indexterm id="idx-CHP-26-2350" significance="normal"><primary>logging</primary><secondary>sequential logging servers</secondary></indexterm><indexterm id="idx-CHP-26-2351" significance="normal"><primary>Iterative_Logging_Server</primary><secondary>evaluating</secondary></indexterm><indexterm id="idx-CHP-26-2352" significance="normal"><primary>sequential concurrency models</primary></indexterm></para><para>Although <literal moreinfo="none">Iterative_Logging_Server</literal> and <literal moreinfo="none">Reactive_Logging_Server</literal> run only in a single thread of control—and are thus not scalable for most production systems—their simplicity high-lights several more beautiful aspects of our OO <indexterm id="idx-CHP-26-2353" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm>framework-based design:</para><itemizedlist><listitem><para>Our use of hook methods in the <literal moreinfo="none">Logging_Server::run( )</literal> template method shields application developers from low-level details—e.g., how a logging server performs IPC and event demulxiplexing operations—thereby enabling the developers to focus on domain-specific application logic by leveraging the expertise of framework designers.</para></listitem><listitem><para>Our use of <indexterm id="idx-CHP-26-2354" significance="normal"><primary>wrapper facades</primary></indexterm>wrapper facades allows us to lock/unlock mutexes, listen on a particular IPC mechanism to accept new connections, and wait for multiple I/O events concisely, efficiently, and portably. Without these useful abstractions, we would have had to write many lines of tedious and error-prone code that would be hard to understand, debug, and evolve.</para></listitem></itemizedlist><para>The benefits from these abstractions become more apparent with more complex <indexterm id="idx-CHP-26-2355" significance="normal"><primary>logging</primary><secondary>concurrent logging servers</secondary></indexterm>concurrent logging servers shown next, as well as with more complex <indexterm id="idx-CHP-26-2356" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm>framework use cases, such as graphical user interfaces <footnote id="CHP-26-FNOTE-15"><para>Gamma et al., <emphasis>op. cit</emphasis>.</para></footnote>or communication middleware. <footnote id="CHP-26-FNOTE-16"><para><indexterm id="idx-CHP-26-2357" significance="normal"><primary>Schmidt</primary></indexterm>Schmidt et al., <emphasis>op. cit</emphasis>.</para></footnote></para></sect2></sect1><sect1 id="implementing_concurrent_logging_servers" label="26.4"><title>Implementing Concurrent Logging Servers</title><para>To overcome the scalability limitations of the iterative and reactive servers shown in the previous sections, the logging servers in this section use OS <indexterm id="idx-CHP-26-2358" significance="normal"><primary>sequential concurrency models</primary></indexterm>concurrency mechanisms: processes and threads. Using the APIs provided by operating systems to spawn threads or processes, however, can be a daunting task due to accidental complexities in their design. These complexities stem from semantic and syntactic differences that exist not only between different operating systems, but also different versions of the same operating system. Our solution to these complexities is again to apply wrapper facades that provide a consistent interface across platforms and integrate these wrapper facades into our OO <literal moreinfo="none">Logging_Server</literal> framework.<indexterm class="startofrange" id="idx-CHP-26-2359" significance="normal"><primary>networked software</primary><secondary>implementing concurrent logging servers</secondary></indexterm><indexterm id="idx-CHP-26-2360" significance="normal"><primary>networked software</primary><secondary>implementing sequential logging servers</secondary></indexterm></para><sect2 id="a_thread-per-connection_logging_server" label="26.4.1"><title>A Thread-per-Connection Logging Server</title><para>Our thread-per-connection logging server (<literal moreinfo="none">TPC_Logging_Server</literal>) runs a main thread that waits for and accepts new connections from clients. After accepting a new connection, a new worker thread is spawned to handle incoming log records from that connection. <xref linkend="steps_in_the_thread-per-connection_logging_server"/> shows the steps in this process.</para><figure id="steps_in_the_thread-per-connection_logging_server" label="26-10" float="0"><title>Steps in the thread-per-connection logging server</title><mediaobject id="I_mediaobject26_tt631"><imageobject role="print"><imagedata fileref="figs/print/beauty_2610.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2610.png" format="PNG"/></imageobject></mediaobject></figure><para>The main loop for this particular logging server differs from the steps depicted in <xref linkend="logging_server_main_loop"/> because the call to <literal moreinfo="none">handle_data( )</literal> is not necessary, as the worker threads are responsible for that call. There are two ways to handle this situation:<indexterm id="I_indexterm26_tt632" class="endofrange" startref="idx-CHP-26-2329" significance="normal"><primary>networked software</primary><secondary>implementing sequential logging servers</secondary></indexterm></para><itemizedlist><listitem><para>We could note that the base <literal moreinfo="none">run( )</literal> method calls <literal moreinfo="none">handle_data( )</literal> with the default argument of a <literal moreinfo="none">NULL</literal> pointer, and simply have our implementation exit immediately for that input.</para></listitem><listitem><para>We could simply override the <literal moreinfo="none">run( )</literal> method with our own implementation that omits this call.</para></listitem></itemizedlist><para>The second solution may at first appear advantageous because it avoids a virtual method call to <literal moreinfo="none">handle_data( )</literal>. The first solution is better in this case, however, because the performance hit of that virtual call is not a limiting factor, and overriding the <literal moreinfo="none">run( )</literal> template method would prevent this class from benefiting from changes to the base class implementation, potentially causing it to fail in subtle and pernicious ways.</para><para>The main challenge here is <indexterm id="idx-CHP-26-2361" significance="normal"><primary>networked software</primary><secondary>implementing concurrent logging servers</secondary></indexterm>implementing the concurrency strategy itself. As with the <literal moreinfo="none">Iterative_Server</literal> in the earlier section "An Iterative <indexterm id="idx-CHP-26-2362" significance="normal"><primary>logging</primary><secondary>concurrent logging servers</secondary></indexterm>Logging Server," the <literal moreinfo="none">wait_for_ multiple_events( )</literal> method is superfluous because our main loop simply waits for new connections, so it is sufficient for <literal moreinfo="none">handle_connections( )</literal> to block on <literal moreinfo="none">accept( )</literal> and subsequently spawn worker threads to handle connected clients. Our <literal moreinfo="none">TPC_Logging_Server</literal> class must therefore provide a method to serve as an entry point for the thread. In C and C++, a class method may serve as an entry point to a thread only if the class is defined as static, so we define the <literal moreinfo="none">TPC_Logging_Server::svc( )</literal> static class method.</para><para>At this point, we have an important design decision to make: what exactly does the thread entry point do? It is tempting to simply have the <literal moreinfo="none">svc( )</literal> method itself perform all of the work necessary to receive log records from its associated connection. This design is less than ideal, however, because static methods cannot be virtual, as that would cause problems if we later derive a new logging server from this implementation to change the way it handles data events. Application developers would then be forced to provide an implementation of <literal moreinfo="none">handle_connections( )</literal> that is textually identical to this class to call the proper static method.</para><para>Moreover, to leverage our existing design and code, it is preferable to have the log record processing logic inside the <literal moreinfo="none">handle_data( )</literal> method and to define a <literal moreinfo="none">Thread_Args</literal> helper object that holds the peer returned from <literal moreinfo="none">accept( )</literal> and a pointer to the <literal moreinfo="none">Logging_Server</literal> object itself. Our class interface will therefore look like the diagram in <xref linkend="thread-per-connection_server_interface"/>.</para><figure id="thread-per-connection_server_interface" label="26-11" float="0"><title>Thread-per-connection server interface</title><mediaobject id="I_mediaobject26_tt633"><imageobject role="print"><imagedata fileref="figs/print/beauty_2611.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2611.png" format="PNG"/></imageobject></mediaobject></figure><para>The remainder of <literal moreinfo="none">TPC_Logging_Server</literal> is straightforward to implement, requiring only that our thread entry point delegate processing to the virtual method <literal moreinfo="none">handle_data( )</literal> using the <literal moreinfo="none">server_pointer</literal> contained within the <literal moreinfo="none">Thread_Args</literal> helper object passed to the <literal moreinfo="none">svc( )</literal> method, as shown in <xref linkend="thread-per-connection_thread_behavior"/>.<indexterm id="idx-CHP-26-2363" significance="normal"><primary>logging</primary><secondary>concurrent logging servers</secondary></indexterm></para><figure id="thread-per-connection_thread_behavior" label="26-12" float="0"><title>Thread-per-connection thread behavior</title><mediaobject id="I_mediaobject26_tt634"><imageobject role="print"><imagedata fileref="figs/print/beauty_2612.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2612.png" format="PNG"/></imageobject></mediaobject></figure><para>The following code implements a <literal moreinfo="none">TPC_Logging_Server</literal> main program that uses the secure socket API and the readers/writer lock:</para><programlisting id="I_programlisting26_tt635" format="linespecific">
	int main (int argc, char *argv[]) {
	  TPC_Logging_Server&lt;SSL_Acceptor, RW_Lock&gt; server (argc, argv);
	  server.run ();
	  return 0;
	}
</programlisting><para>This <literal moreinfo="none">main( )</literal> function instantiates a <literal moreinfo="none">TPC_Logging_Server</literal> that communicates using SSL connections, and uses an <literal moreinfo="none">RW_Lock</literal> to synchronize the <literal moreinfo="none">count_connections( )</literal> function in the <literal moreinfo="none">Logging_Server</literal> base class. Except for the name of the class we are instantiating, <literal moreinfo="none">this main( )</literal> function is identical to the one that was written earlier in this chapter for the <literal moreinfo="none">Reactive_Logging_Server</literal>. This commonality is another beautiful aspect of our design: regardless of the particular combination of concurrency, IPC, and synchronization mechanisms we choose to use, the instantiation and invocation of our server remains the same.</para><para>The thread-per-connection logging service addresses the scalability limitations with the sequential implementations described earlier in the section "Evaluating the Sequential Logging Server Solutions." The design of our OO <indexterm id="idx-CHP-26-2364" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm>framework makes it straightforward to integrate this concurrency model with minimal changes to the existing code. In particular, <literal moreinfo="none">TPC_Logging_Server</literal> inherits implementations of <literal moreinfo="none">open( )</literal>, <literal moreinfo="none">count_request( )</literal>, and most importantly <literal moreinfo="none">run( )</literal>, allowing this class to leverage bug fixes and improvements to our main event loop transparently. Moreover, adding the necessary synchronization around the <literal moreinfo="none">request_count_ is</literal> simply a matter of parameterizing the <literal moreinfo="none">TPC_Logging_Server</literal> with the <literal moreinfo="none">RW_LOCK</literal> class.</para></sect2><sect2 id="a_process-per-connection_logging_server" label="26.4.2"><title>A Process-per-Connection Logging Server</title><para>The process-per-connection logging server described next is similar to the thread-per-connection design shown in <xref linkend="steps_in_the_thread-per-connection_logging_server"/>, except that instead of spawning a thread, we spawn a new process to handle incoming log records from each client. The choice of processes over threads for concurrency forces us to make design choices to accommodate the variations in process-creation semantics between platforms. There are two key semantic differences between the process APIs on Linux and Windows that our server design must encapsulate:<indexterm id="idx-CHP-26-2365" significance="normal"><primary>logging</primary><secondary>concurrent logging servers</secondary></indexterm></para><itemizedlist><listitem><para>In Linux (and other POSIX systems) the primary vehicle for creating new processes is the <literal moreinfo="none">fork( )</literal> system function, which generates an exact duplicate of the calling program image, including open I/O handles. The processes differ only in their return value from <literal moreinfo="none">fork( )</literal>. At this point, child processes can choose to proceed from that point, or load a different program image using the <literal moreinfo="none">exec*( )</literal> family of system calls.</para></listitem><listitem><para>Windows, however, uses the <literal moreinfo="none">CreateProcess( )</literal> API call, which is functionally equivalent to a POSIX <literal moreinfo="none">fork( )</literal>, followed immediately by a call to one of the <literal moreinfo="none">exec*( )</literal> system functions. The impact of this difference is that in Windows you have an <emphasis>entirely new process</emphasis> that by default <emphasis>does not</emphasis> have access to I/O handles open in the parent. To use a connection accepted by the parent process, therefore, the handle must be explicitly duplicated and passed to the child on the command line.</para></listitem></itemizedlist><para>We therefore define a set of wrapper facades that not only hide the syntactic differences between platforms, but also provide a way to hide the semantic differences as well. These wrappers consist of the three cooperating classes shown in <xref linkend="portable_process_wrapper_facades"/>. The <literal moreinfo="none">Process</literal> class represents a single process and is used to create and synchronize processes. The <literal moreinfo="none">Process_Options</literal> class provides a way to set both platform-independent process options (such as command-line options and environment variables) and platform-specific process options (such as avoiding zombie processes). Finally, the <literal moreinfo="none">Process_Manager</literal> class portably manages the life cycle of groups of processes. We won't cover all the uses of these wrapper facades in this chapter, though they are based on the wrapper facades in ACE. <footnote id="CHP-26-FNOTE-17"><para><emphasis>C</emphasis>++ <emphasis>Network Programming, Vol. 1: Mastering Complexity with ACE and Patterns</emphasis>, Douglas C. <indexterm id="idx-CHP-26-2366" significance="normal"><primary>Schmidt</primary></indexterm>Schmidt and Stephen D. Huston, Addison-Wesley, 2001.</para></footnote>It is sufficient to know that not only can processes be created portably on Linux and Windows, but also that I/O handles can be duplicated and passed portably and automatically to the new process.</para><para>The design challenge is therefore to accommodate the fact that processes spawned after new connections are accepted will start at the beginning of our program. We certainly don't want child processes to attempt to open a new acceptor and listen for connections of their own; instead, they should listen for data events only on their assigned handle. A naïve solution to this problem would rely on applications to detect this condition and call a special entry point defined in the interface to our process-based <literal moreinfo="none">Logging_Server</literal> class.</para><figure id="portable_process_wrapper_facades" label="26-13" float="0"><title>Portable process wrapper facades</title><mediaobject id="I_mediaobject26_tt636"><imageobject role="print"><imagedata fileref="figs/print/beauty_2613.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2613.png" format="PNG"/></imageobject></mediaobject></figure><para>This simple solution, however, is less than ideal. It would require us not only to change the public interface of our process-based <literal moreinfo="none">Logging_Server</literal>, but to expose intimate implementation details to applications, violating encapsulation. A better solution is to override the <literal moreinfo="none">run( )</literal> template method inherited from the <literal moreinfo="none">Logging_Server</literal> base class, which is passed a copy of the command-line argument by users, to determine whether it has been passed any I/O handles. If not, the process assumes it is a parent and delegates to the base class <literal moreinfo="none">run( )</literal> method. Otherwise, the process assumes it's a child, so it decodes the handle and <literal moreinfo="none">calls handle_data( )</literal>, as shown in <xref linkend="process-per-connection_run_template_method"/>.<indexterm id="idx-CHP-26-2367" significance="normal"><primary>logging</primary><secondary>concurrent logging servers</secondary></indexterm></para><figure id="process-per-connection_run_template_method" label="26-14" float="0"><title>Process-per-connection run( ) template method</title><mediaobject id="I_mediaobject26_tt637"><imageobject role="print"><imagedata fileref="figs/print/beauty_2614.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2614.png" format="PNG"/></imageobject></mediaobject></figure><para>The remainder of this server implementation is straightforward. As shown in <xref linkend="connection_handling_for_the_process-per-connection_server"/>, the process wrapper facade makes the procedure for spawning our worker processes fairly simple. The implementation for <literal moreinfo="none">handle_data( )</literal> should be textually identical to that shown in <xref linkend="thread-per-connection_thread_behavior"/>.</para><figure id="connection_handling_for_the_process-per-connection_server" label="26-15" float="0"><title>Connection handling for the process-per-connection server</title><mediaobject id="I_mediaobject26_tt638"><imageobject role="print"><imagedata fileref="figs/print/beauty_2615.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2615.png" format="PNG"/></imageobject></mediaobject></figure><para>Our reimplementation of the <literal moreinfo="none">run( )</literal> method from the <literal moreinfo="none">Logging_Server</literal> base class allows us to maintain the beautifully simple, straightforward, and uniform invocation used by our other logging servers:</para><programlisting id="I_programlisting26_tt639" format="linespecific">
	int main (int argc, char *argv[]) {
	  PPC_Logging_Server&lt;SSL_Acceptor, Null_Mutex&gt; server (argc, argv);
	  server.run ( );
	  return 0;
	}
</programlisting><para>This <literal moreinfo="none">main( )</literal> program differs from the thread-per-connection server only in the name of the class that is instantiated and the choice of a <literal moreinfo="none">Null_Mutex</literal> for synchronization. The dispatch of either a parent or a child process is handled transparently by the <literal moreinfo="none">run( )</literal> method, driven by the command-line arguments passed to the <literal moreinfo="none">PPC_Logging_Server</literal> constructor.</para></sect2><sect2 id="evaluating_the_concurrent_logging_server_solutions" label="26.4.3"><title>Evaluating the Concurrent Logging Server Solutions</title><para>Both <indexterm id="idx-CHP-26-2368" significance="normal"><primary>logging</primary><secondary>concurrent logging servers</secondary></indexterm>concurrent logging servers described in this section significantly enhance the <literal moreinfo="none">Reactive_Logging_Server</literal> and <literal moreinfo="none">Iterative_Logging_Server</literal> in their ability to scale as the number of clients increases by taking leveraging hardware and OS support for multiple threads of execution. It is hard, however, to develop thread-per-connection and process-per-connection concurrency strategies in a platform-agnostic manner. We accomplished this task by using wrapper facades to hide platform differences. Our <indexterm id="idx-CHP-26-2369" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm>framework-based server design also provided a common external interface to the <literal moreinfo="none">Logging_Server</literal> class, shielding the bulk of the logging server from the configured concurrency strategy. Moreover, our design leveraged the <literal moreinfo="none">run( )</literal> template method inherited from the <literal moreinfo="none">Logging_Server</literal> base class, allowing our implementations to integrate bug fixes or other enhancements to the main server event loop.</para></sect2></sect1><sect1 id="conclusion-id014" label="26.5"><title>Conclusion</title><para>The logging server application presented in this chapter provides a digestible but realistic vehicle for showing how to apply OO design/programming techniques, patterns, and frameworks to implementation software for networked applications. In particular, our OO framework demonstrates a number of beautiful design elements, ranging from abstract design to concrete elements in the implementations of the different concurrency models. Our design also uses C++ features, such as templates and virtual functions, in conjunction with design patterns, such as Wrapper Facade and the Template Method, to create a family of logging servers that is portable, reusable, flexible, and extensible.</para><para>The Template Method pattern in the <literal moreinfo="none">Logging_Server</literal> base class's <literal moreinfo="none">run( )</literal> method allowed us to define common steps in a logging server, deferring specialization of individual steps of its operation to hook methods in derived classes. While this pattern helped factor out common steps into the base class, it did not adequately address all our required points of variability, such as synchronization and IPC mechanisms, For these remaining dimensions, therefore, we used the Wrapper Facade pattern to hide semantic and syntactic differences, ultimately making use of these dimensions entirely orthogonal to the implementation of individual concurrency models. This design allowed us to use parameterized classes to address these dimensions of variability, which increased the flexibility of our framework without affecting its performance adversely.</para><para>Finally, our individual implementations of concurrency models, such as thread-per-connection and process-per-connection, used wrapper facades to make their implementations more elegant and portable. The end result was a labor-saving software architecture that enabled developers to reuse common design and programming artifacts, as well as provide a means to encapsulate variabilities in a common, parameterizable way.</para><para>A concrete implementation of this logging server framework may be found at <ulink url="http://www.dre.vanderbilt.edu/~schmidt/DOC_ROOT/ACE/examples/Beautiful_Code"/>, and in the ACE distribution in the file <emphasis>ACE_wrappers/examples/Beautiful_Code</emphasis>.<indexterm id="I_indexterm26_tt640" class="endofrange" startref="idx-CHP-26-2245" significance="normal"><primary>object-oriented framework for networked software</primary></indexterm><indexterm id="I_indexterm26_tt641" class="endofrange" startref="idx-CHP-26-2359" significance="normal"><primary>networked software</primary><secondary>implementing concurrent logging servers</secondary></indexterm></para></sect1></chapter><chapter id="integrating_business_partners_the_restful_way" label="27" role=""><title>Integrating Business Partners the RESTful Way</title><para><emphasis>Andrew Patzer</emphasis><indexterm id="idx-CHP-27-2370" significance="normal"><primary>business partners</primary></indexterm><indexterm id="idx-CHP-27-2371" significance="normal"><primary>Patzer</primary></indexterm></para><para><emphasis>A few years back, when i was a consultant</emphasis>, I went through a period of a year or two when it seemed that every client I spoke with was absolutely certain he needed a Web Services solution for his business. Of course, not many of my clients actually understood what that meant or the reasons why they might need that kind of architecture, but since they kept hearing about Web Services on the Internet, in magazines, and at trade shows, they figured they'd better get on the bus before it was too late.</para><para>Don't get me wrong. I'm not against Web Services. I'm just not a big fan of making technical decisions based solely on whatever happens to be in style at the moment. This chapter will address some of the reasons for using a Web Services architecture, as well as explore some of the options to consider when integrating systems with the outside world.</para><para>In this chapter, I'll walk you through a real-life project that involves exposing a set of services to a business partner, and discuss some design choices that were made along the way. Technologies that were used included Java (J2EE), XML, the Rosettanet E-Business protocol, and a function library used to communicate with a program running on an AS/400 system. I will also cover the use of interfaces and the factory design pattern as I show how I made the system extensible for future distributors who may use different protocols and may need to access different services.</para><sect1 id="project_background" label="27.1"><title>Project Background</title><para>The project I'll be discussing in this chapter began with a call from one of our clients: "We need a set of Web Services to integrate our systems with one of our distributors." The client was a large manufacturer of electrical components. The system they were referring to was MAPICS, a manufacturing system written in RPG and running on their AS/400 machines. Their main distributor was upgrading its own <indexterm id="idx-CHP-27-2372" significance="normal"><primary>business partners</primary></indexterm>business systems and needed to modify the way it tied into the order management system to check product availability and order status.</para><para>Previously, an operator at the distributor simply connected remotely to the manufacturer's AS/400 system and pressed a "hot key" to access the necessary screens (F13 or F14 as I recall). As you'll see in the code later, the new system I developed for them was named <emphasis>hotkey</emphasis>, since that had become part of their common language, much like the way <emphasis>google</emphasis> has become a modern-day verb.</para><para>Now that the distributor was implementing a new e-business system, it required an automated way to integrate manufacturer data with its own system. Since this was just a single distributor for this client, albeit the largest, the system also needed to allow for the future addition of other distributors and whatever protocols and requirements they might have. Another factor was the relatively low skill level of the staff that would maintain and extend this software. While they were very good in other areas, Java development (as well as any kind of web development) was still very new to them. So, I knew that whatever I built had to be simple and easy to extend.</para></sect1><sect1 id="exposing_services_to_external_clients" label="27.2"><title>Exposing Services to External Clients</title><para>Prior to this project, I had delivered several technical presentations to user groups and conferences regarding <indexterm id="idx-CHP-27-2373" significance="normal"><primary>SOAP</primary></indexterm>SOAP (<indexterm id="idx-CHP-27-2374" significance="normal"><primary>Simple Object Access Protocol (SOAP)</primary></indexterm>Simple Object Access Protocol) and web service architecture. So, when the call came in, it seemed I'd be a natural fit for what the client was looking to accomplish. Once I understood what they really needed, though, I decided that they would be much better off with a set of services exposed through simple <indexterm id="idx-CHP-27-2375" significance="normal"><primary>GET and POST requests over HTTP</primary></indexterm>GET and POST requests over HTTP, exchanging XML data describing the requests and responses. Although I didn't know it at the time, this architectural style is now commonly referred to as <emphasis>REST</emphasis>, or <emphasis>Representational State Transfer</emphasis>.<indexterm class="startofrange" id="idx-CHP-27-2376" significance="normal"><primary>REST (Representational State Transfer)</primary><secondary>exposing services to external clients</secondary></indexterm><indexterm id="idx-CHP-27-2377" significance="normal"><primary>external clients</primary></indexterm><indexterm class="startofrange" id="idx-CHP-27-2378" significance="normal"><primary>REST (Representational State Transfer)</primary></indexterm><indexterm class="startofrange" id="idx-CHP-27-2379" significance="normal"><primary>services</primary><secondary>exposing to external clients</secondary></indexterm></para><para>How did I decide to use REST over SOAP? Here are a few of the decision points to consider when choosing a <indexterm id="idx-CHP-27-2380" significance="normal"><primary>Web Services architecture</primary></indexterm>Web Services architecture:</para><variablelist><varlistentry><term><emphasis>How many different systems will require access to these services, and are all of them known at this time?</emphasis></term><listitem><para>This manufacturer knew of a single distributor that needed to access its systems, but also acknowledged that others might decide to do the same in the future.</para></listitem></varlistentry><varlistentry><term><emphasis>Do you have a tight set of end users that will have advance knowledge of these services, or do these services need to be self-describing for anonymous users to automatically connect to?</emphasis></term><listitem><para>Because there has to be a defined relationship between the manufacturer and all its distributors, it is guaranteed that each of the potential users will have advance knowledge of how to access the manufacturer's systems.</para></listitem></varlistentry><varlistentry><term><emphasis>What kind of state needs to be maintained throughout a single transaction? Will one request depend on the results of a previous one?</emphasis></term><listitem><para>In our case, each transaction will consist of a single request and a corresponding result that doesn't depend on anything else.</para></listitem></varlistentry></variablelist><para>Answering the above questions for this project yielded the obvious choice of simply <indexterm id="idx-CHP-27-2381" significance="normal"><primary>REST (Representational State Transfer)</primary><secondary>exposing services to external clients</secondary></indexterm>exposing a set of known services over the HTTP protocol and exchanging <indexterm id="idx-CHP-27-2382" significance="normal"><primary>XML</primary><secondary>request/response data via HTTP POST</secondary></indexterm>data using a standard e-<indexterm id="idx-CHP-27-2383" significance="normal"><primary>business partners</primary></indexterm>business protocol that both systems could understand. If the manufacturer would have liked to allow anonymous users to query product availability, then I might have opted for a full SOAP solution because that would allow systems to discover the services and programmatically interface with them without prior knowledge of the systems.</para><para>I currently work in the field of bioinformatics, where there is a definite need for <indexterm id="idx-CHP-27-2384" significance="normal"><primary>bioinformatics</primary><secondary>SOAP-style web service architectures</secondary></indexterm>SOAP-style Web Service architectures. We make use of a project called <indexterm id="idx-CHP-27-2385" significance="normal"><primary>BioMoby project</primary></indexterm>BioMoby (<ulink url="http://www.biomoby.org"/>) to define Web Services and publish them to a central repository that allows other groups to literally drag and drop our services into a workflow that builds data pipelines to help biologists integrate diverse sets of data and perform varied analysis on the results. This is a perfect example of why someone would choose SOAP over <indexterm id="idx-CHP-27-2386" significance="normal"><primary>REST (Representational State Transfer)</primary></indexterm>REST. Anonymous users can access our data and tools without any prior knowledge that they even existed.</para><sect2 id="define_the_service_interface" label="27.2.1"><title>Define the Service Interface</title><para>The first step, as I decided how to implement this software, was to determine how the users will make requests and receive responses. After speaking with a technical representative from the distributor (the primary user), I learned that its new system can send XML documents via an <indexterm id="idx-CHP-27-2387" significance="normal"><primary>HTTP POST method</primary></indexterm>HTTP POST request and examine the results as an XML document. The XML had to be in a format following the <indexterm id="idx-CHP-27-2388" significance="normal"><primary>Rosettanet e-business protocol</primary></indexterm>Rosettanet e-business protocol (more on that later), but for now it was enough to know that it can communicate over HTTP by posting XML-formatted requests and responses. <xref linkend="service_interface_to_backend_systems"/> illustrates the general interaction between each of the systems.<indexterm id="idx-CHP-27-2389" significance="normal"><primary>REST (Representational State Transfer)</primary><secondary>exposing services to external clients</secondary><tertiary>defining service interface</tertiary></indexterm></para><para>The manufacturer had recently been acquired by a larger corporation that dictated the use of IBM products throughout the organization. Therefore, I already knew what application server and corresponding technology to use. I implemented the service interface as a <indexterm id="idx-CHP-27-2390" significance="normal"><primary>Java Servlet running on IBM WebSphere application server</primary></indexterm>Java Servlet running on an <indexterm id="idx-CHP-27-2391" significance="normal"><primary>IBM WebSphere application server</primary></indexterm>IBM WebSphere application server. This decision was made easier by my knowledge that the software would need to access functions running on an AS/400 server using a Java-based <indexterm id="idx-CHP-27-2392" significance="normal"><primary>Java</primary><secondary>API to access functions running on AS/400 server</secondary></indexterm>API.</para><figure id="service_interface_to_backend_systems" label="27-1" float="0"><title>Service interface to backend systems</title><mediaobject id="I_mediaobject27_tt642"><imageobject role="print"><imagedata fileref="figs/print/beauty_2701.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2701.png" format="PNG"/></imageobject></mediaobject></figure><para>The following code is found in the <emphasis>web.xml</emphasis> file describing the servlet that will provide the necessary interface to the users:<indexterm id="idx-CHP-27-2393" significance="normal"><primary>Service class (example)</primary></indexterm><indexterm id="idx-CHP-27-2394" significance="normal"><primary>services</primary><secondary>exposing to external clients</secondary></indexterm><indexterm id="idx-CHP-27-2395" significance="normal"><primary>web.xml file for servlet providing user interface</primary></indexterm></para><programlisting id="I_programlisting27_tt643" format="linespecific">
	&lt;servlet&gt;
	    &lt;servlet-name&gt;<indexterm id="idx-CHP-27-2396" significance="normal"><primary>REST (Representational State Transfer)</primary><secondary>exposing services to external clients</secondary><tertiary>defining service interface</tertiary></indexterm>HotKeyService&lt;/servlet-name&gt;
	    &lt;display-name&gt;HotKeyService&lt;/display-name&gt;
	    &lt;servlet-class&gt;com.xxxxxxxxxxxx.hotkey.Service&lt;/servlet-class&gt;
	&lt;/servlet&gt;
	&lt;servlet-mapping&gt;
	    &lt;servlet-name&gt;HotKeyService&lt;/servlet-name&gt;
	    &lt;url-pattern&gt;/HotKeyService&lt;/url-pattern&gt;
	&lt;/servlet-mapping&gt;
</programlisting><para>The servlet itself handles only POST requests, which it does by overriding the <literal moreinfo="none">doPost</literal> method of the <literal moreinfo="none">Servlet</literal> interface and providing default implementations of the standard life cycle methods. The following code shows the complete implementation of the service, but when I first start breaking down a problem and designing a solution, I typically write a series of comments in the code as placeholders where I'll insert the real code later. I then systematically attack each pseudocode comment until I have a working implementation. This helps keep me focused on how each piece relates to the entire solution:</para><programlisting id="I_programlisting27_tt644" format="linespecific">
	<userinput moreinfo="none">public class</userinput> Service <userinput moreinfo="none">extends</userinput> HttpServlet <userinput moreinfo="none">implements</userinput> Servlet {

	    <userinput moreinfo="none">public void</userinput> doPost(HttpServletRequest req, HttpServletResponse resp)
	        <userinput moreinfo="none">throws</userinput> ServletException, IOException {

	        // Read in request data and store in a StringBuffer
	        BufferedReader in = req.getReader();
	        StringBuffer sb = <userinput moreinfo="none">new</userinput> StringBuffer();
	        String line;
	        <userinput moreinfo="none">while</userinput> ((line = in.readLine())!= <userinput moreinfo="none">null</userinput>) {
	            sb.append(line);
	        }

	        HotkeyAdaptor hotkey = <userinput moreinfo="none">null;</userinput>

	        <userinput moreinfo="none">if</userinput> (sb.toString().indexOf("Pip3A2PriceAndAvailabilityRequest") &gt; 0) {
	             // Price and Availability Request
	            hotkey = HotkeyAdaptorFactory.getAdaptor(
	                HotkeyAdaptorFactory.ROSETTANET,
	                HotkeyAdaptorFactory.PRODUCTAVAILABILITY);

	        }
	        <userinput moreinfo="none">else if</userinput> (sb.<indexterm id="idx-CHP-27-2397" significance="normal"><primary>services</primary><secondary>exposing to external clients</secondary></indexterm>toString().indexOf("Pip3A5PurchaseOrderStatusQuery ") &gt; 0) {
	            // Order Status
	            hotkey = HotkeyAdaptorFactory.getAdaptor(
	                HotkeyAdaptorFactory.ROSETTANET,
	                HotkeyAdaptorFactory.ORDERSTATUS);
	        }

	        <userinput moreinfo="none">boolean</userinput> success = <userinput moreinfo="none">false;</userinput>

	        <userinput moreinfo="none">if</userinput> (hotkey != <userinput moreinfo="none">null</userinput>) {
	            /* Pass in the XML request data */
	            hotkey.setXML(sb.toString());
	            /* Parse the request data */
	            <userinput moreinfo="none">if</userinput> (hotkey.parseXML()) {
	                /* Execute AS/400 Program */
	                <userinput moreinfo="none">if</userinput> (hotkey.executeQuery()) {
	                    /* Return response XML */
	                    resp.setContentType("text/xml");
	                    PrintWriter out = resp.getWriter();
	                    out.println(hotkey.getResponseXML());
	                    out.close();
	                    success = <userinput moreinfo="none">true;</userinput>
	                }
	            }
	        }

	        <userinput moreinfo="none">if</userinput> (!success) {
	            resp.setContentType("text/xml");
	            PrintWriter out = resp.getWriter();
	            out.println("Error retrieving product availability.");
	            out.close();
	        }
	    }
	}
</programlisting><para>Looking through this code, you can see that it first reads in the request data and stores it for later use. It then searches this data to determine which type of request this is: pricing and availability, or an order status inquiry. Once it determines the type of request, the appropriate helper object is created. Notice how I used an interface, <literal moreinfo="none">HotkeyAdaptor</literal>, to allow multiple implementations without having to write a bunch of duplicate code for each type of request.</para><para>The <indexterm id="idx-CHP-27-2398" significance="normal"><primary>REST (Representational State Transfer)</primary></indexterm>rest of this method involves parsing the XML request data, executing the appropriate query on the AS/400 system, creating an XML response, and writing it back to the user via HTTP. In the next section, you'll see how I hid the implementation details using interfaces and the very popular factory design pattern.<indexterm id="I_indexterm27_tt645" class="endofrange" startref="idx-CHP-27-2376" significance="normal"><primary>REST (Representational State Transfer)</primary><secondary>exposing services to external clients</secondary></indexterm><indexterm id="I_indexterm27_tt646" class="endofrange" startref="idx-CHP-27-2379" significance="normal"><primary>services</primary><secondary>exposing to external clients</secondary></indexterm></para></sect2></sect1><sect1 id="routing_the_service_using_the_factory_pattern" label="27.3"><title>Routing the Service Using the Factory Pattern</title><para>One of the requirements of this system was that it be able to accommodate a wide variety of future requests from several different types of systems with minimal programming effort. I believe I accomplished this by simplifying the implementation down to a single command interface that exposed the basic methods needed to respond to a wide variety of requests:<indexterm id="idx-CHP-27-2399" significance="normal"><primary>business partners</primary><secondary>routing services using factory pattern</secondary></indexterm><indexterm id="idx-CHP-27-2400" significance="normal"><primary>factory pattern</primary></indexterm><indexterm id="idx-CHP-27-2401" significance="normal"><primary>REST (Representational State Transfer)</primary><secondary>exposing services to external clients</secondary><tertiary>defining service interface</tertiary></indexterm></para><programlisting id="I_programlisting27_tt647" format="linespecific">
	<userinput moreinfo="none">public interface</userinput> <indexterm id="idx-CHP-27-2402" significance="normal"><primary>HotkeyAdaptor interface (example)</primary></indexterm>HotkeyAdaptor {
	
	    <userinput moreinfo="none">public void</userinput> setXML(String _xml);
	    <userinput moreinfo="none">public boolean</userinput> parseXML();
	    <userinput moreinfo="none">public boolean</userinput> executeQuery();
	    <userinput moreinfo="none">public</userinput> String getResponseXML();

	}
</programlisting><para>So, how does the servlet decide which concrete implementation of the interface to instantiate? It first looks inside the request data for a specific string to tell it what type of request it is. Then, it uses a static method of a factory object to pick the appropriate implementation.</para><para>As far as the servlet knows, whatever implementation we're using will provide appropriate responses to each of these methods. By using an interface in the main servlet, we only have to write the execution code once, without any regard to which type of request it's dealing with or who may have made the request. All of the details are encapsulated in each individual implementation of this interface. Here's that snippet of code again from the servlet:</para><programlisting id="I_programlisting27_tt648" format="linespecific">
	HotkeyAdaptor hotkey = <userinput moreinfo="none">null;</userinput>

	<userinput moreinfo="none">if</userinput> (sb.toString().indexOf("Pip3A2PriceAndAvailabilityRequest") &gt; 0) {
	    // Price and Availability Request
	    hotkey = <indexterm id="idx-CHP-27-2403" significance="normal"><primary>HotkeyAdaptorFactory class (example)</primary></indexterm>HotkeyAdaptorFactory.getAdaptor(
	        HotkeyAdaptorFactory.ROSETTANET,
	        HotkeyAdaptorFactory.PRODUCTAVAILABILITY);
	}
	<userinput moreinfo="none">else if</userinput> (sb.toString().indexOf("Pip3A5PurchaseOrderStatusQuery ") &gt; 0) {
	    // Order Status
	    hotkey = HotkeyAdaptorFactory.getAdaptor(
	        HotkeyAdaptorFactory.ROSETTANET,
	        HotkeyAdaptorFactory.ORDERSTATUS);
	}
</programlisting><para>The factory object, <literal moreinfo="none">HotkeyAdaptorFactory</literal>, has a static method that takes two parameters telling it which XML protocol to use and what type of request it is. These are defined as static constants in the factory object itself. As you can see by the following code, the factory object simply uses a <literal moreinfo="none">switch</literal> statement to select the appropriate implementation:</para><programlisting id="I_programlisting27_tt649" format="linespecific">
	<userinput moreinfo="none">public class</userinput> <indexterm id="idx-CHP-27-2404" significance="normal"><primary>factory pattern</primary></indexterm>HotkeyAdaptorFactory {
	    <userinput moreinfo="none">public static final int</userinput> ROSETTANET = 0;
	    <userinput moreinfo="none">public static final int</userinput> BIZTALK = 1;
	    <userinput moreinfo="none">public static final int</userinput> EBXML = 2;

	    <userinput moreinfo="none">public static final int</userinput> PRODUCTAVAILABILITY = 0;
	    <userinput moreinfo="none">public static final int</userinput> ORDERSTATUS = 1;

	    <userinput moreinfo="none">public static</userinput> HotkeyAdaptor getAdaptor(int _vocab, int _target) {

	        <userinput moreinfo="none">switch</userinput> (_vocab) {
	            <userinput moreinfo="none">case</userinput> (ROSETTANET) :
	               <userinput moreinfo="none">switch</userinput> (_target) {
	                   <userinput moreinfo="none">case</userinput> (PRODUCTAVAILABILITY) :
	                      <userinput moreinfo="none">return new</userinput> HotkeyAdaptorRosProdAvailImpl();
	                   <userinput moreinfo="none">case</userinput> (ORDERSTATUS) :
	                      <userinput moreinfo="none">return new</userinput> HotkeyAdaptorRosOrdStatImpl();
	                   <userinput moreinfo="none">default</userinput> :
	                       <userinput moreinfo="none">return null;</userinput>
	               }
	            <userinput moreinfo="none">case</userinput> (BIZTALK) :
	            <userinput moreinfo="none">case</userinput> (EBXML) :
	            <userinput moreinfo="none">default</userinput> :
	                <userinput moreinfo="none">return null</userinput>;
	        }
	    }
	}
</programlisting><para>While this may seem to be a <indexterm id="idx-CHP-27-2405" significance="normal"><primary>REST (Representational State Transfer)</primary><secondary>routing the service using factory pattern</secondary></indexterm>rather simple abstraction, it goes a long way in making the code readable and understandable by an inexperienced programming staff. When it comes time to add a new distributor that happens to be using Microsoft's BizTalk product and wants to place orders electronically, the programmer has a simple template for adding this new requirement.</para></sect1><sect1 id="exchanging_data_using_e-business_protocols" label="27.4"><title>Exchanging Data Using E-Business Protocols</title><para>Something that was new to me on this project was the use of standard e-business protocols. When the distributor informed me of the requirement to exchange requests and responses using the Rosettanet standard, I had to do a little research. I started by going to the Rosettanet <indexterm id="idx-CHP-27-2406" significance="normal"><primary>Rosettanet e-business protocol</primary><secondary>web site</secondary></indexterm>web site (<ulink url="http://www.rosettanet.org"/>) and downloading the specific standards I was <indexterm id="idx-CHP-27-2407" significance="normal"><primary>REST (Representational State Transfer)</primary></indexterm>interested in. I found a diagram detailing a typical exchange between <indexterm id="idx-CHP-27-2408" significance="normal"><primary>business partners</primary></indexterm>business partners, along with a specification for the XML request and response.<indexterm class="startofrange" id="idx-CHP-27-2409" significance="normal"><primary>e-business protocols</primary><secondary>exchanging data with</secondary></indexterm><indexterm class="startofrange" id="idx-CHP-27-2410" significance="normal"><primary>Rosettanet e-business protocol</primary><secondary>exchanging requests and responses using</secondary></indexterm><indexterm id="idx-CHP-27-2411" significance="normal"><primary>business partners$ integrating using REST</primary><secondary>exchanging data with e-business</secondary><tertiary>protocols</tertiary></indexterm></para><para>Since I had a lot of trial-and-error type work to do, the first thing I did was set up a test that I could run myself to simulate an interaction with the distributor without having to coordinate testing with their staff for each iteration of development. I used the <indexterm id="idx-CHP-27-2412" significance="normal"><primary>Apache Commons HttpClient</primary></indexterm>Apache Commons <literal moreinfo="none">HttpClient</literal> to manage the <indexterm id="idx-CHP-27-2413" significance="normal"><primary>HTTP exchanges</primary></indexterm>HTTP exchanges:</para><programlisting id="I_programlisting27_tt650" format="linespecific">
	<userinput moreinfo="none">public class</userinput> TestHotKeyService {

	    <userinput moreinfo="none">public static void</userinput> main (String[] args) throws Exception {

	        String strURL = "http://xxxxxxxxxxx/HotKey/HotKeyService";
	        String strXMLFilename = "SampleXMLRequest.xml";
	        File input = <userinput moreinfo="none">new</userinput> File(strXMLFilename);

	        PostMethod post = <userinput moreinfo="none">new</userinput> PostMethod(strURL);
	        post.setRequestBody(<userinput moreinfo="none">new</userinput> FileInputStream(input));
	        <userinput moreinfo="none">if</userinput> (input.length( ) &lt; Integer.MAX_VALUE) {
	            post.setRequestContentLength((<userinput moreinfo="none">int</userinput>)input.length());
	        } <userinput moreinfo="none">else</userinput> {
	              post.setRequestContentLength(
	                  EntityEnclosingMethod.CONTENT_LENGTH_CHUNKED);
	        }

	        post.setRequestHeader("Content-type", "text/xml; charset=ISO-8859-1");

	        HttpClient httpclient = <userinput moreinfo="none">new</userinput> HttpClient();
	        System.out.println("[Response status code]: " +
	               httpclient.executeMethod(post));
	        System.out.println("\n[Response body]: ");
	        System.out.println("\n" + post.getResponseBodyAsString( ));

	        post.releaseConnection();
	    }
	}
</programlisting><para>This allowed me to accelerate my learning curve as I tried out several different types of requests and examined the results. I'm a firm believer in diving right into coding as soon as possible. You can only learn so much from a book, an article on a web site, or a set of API documents. By getting your hands dirty early on in the process, you'll uncover a lot of things you may not have thought about by simply studying the problem.</para><para>The Rosettanet standard, like many others, is very detailed and complete. Chances are, you'll end up needing and using only a small fraction of it to accomplish any given task. For this project, I only needed to set a few standard identification fields, along with a product number and availability date for pricing inquiries, or an order number for order status inquiries.</para><sect2 id="parsing_the_xml_using_xpath" label="27.4.1"><title>Parsing the XML Using XPath</title><para>The XML request <indexterm id="idx-CHP-27-2414" significance="normal"><primary>e-business protocols</primary><secondary>exchanging data with</secondary></indexterm>data was far from simple XML. As mentioned earlier, the Rosettanet standard is very detailed and thorough. Parsing such a document could have proved to be quite a nightmare if it were not for XPath. Using XPath mappings, I was able to define the exact path to each node that I was <indexterm id="idx-CHP-27-2415" significance="normal"><primary>REST (Representational State Transfer)</primary></indexterm>interested in and easily pull out the necessary data. I chose to implement these mappings as a <literal moreinfo="none">HashMap</literal>, which I later iterated over, grabbing the specified nodes and creating a new <literal moreinfo="none">HashMap</literal> with the values. These values were then used later in both the <literal moreinfo="none">executeQuery</literal> and <literal moreinfo="none">getResponseXML</literal> methods that I'll describe next:<indexterm id="idx-CHP-27-2416" significance="normal"><primary>business partners$ integrating using REST</primary><secondary>exchanging data with e-business</secondary><tertiary>parsing XML using XPath</tertiary></indexterm><indexterm class="startofrange" id="idx-CHP-27-2417" significance="normal"><primary>XML</primary><secondary>parsing data using XPath</secondary></indexterm></para><programlisting id="I_programlisting27_tt651" format="linespecific">
	<userinput moreinfo="none">public class</userinput> HotkeyAdaptorRosProdAvailImpl <userinput moreinfo="none">implements</userinput> HotkeyAdaptor {

	    String inputFile;           // request <indexterm id="idx-CHP-27-2418" significance="normal"><primary>business partners$ integrating using REST</primary><secondary>exchanging data with e-business</secondary><tertiary>parsing XML using XPath</tertiary></indexterm>XML
	    HashMap requestValues;       // stores parsed XML values from request
	    HashMap as400response;       // stores return parameter from RPG call

	    /* Declare XPath mappings and populate with a static initialization block */
	    <userinput moreinfo="none">public static</userinput> HashMap xpathmappings = <userinput moreinfo="none">new</userinput> HashMap();
	    <userinput moreinfo="none">static</userinput> {
	        xpathmappings.put("from_ContactName",
	"//Pip3A2PriceAndAvailabilityRequest/fromRole/PartnerRoleDescription/
	ContactInformation/contactName/FreeFormText");
	        xpathmappings.put("from_EmailAddress", "//Pip3A2PriceAndAvailabilityRequest/
	fromRole/PartnerRoleDescription/ContactInformation/EmailAddress");
	    }
	       // Remaining xpath mappings omitted for brevity...

	    <userinput moreinfo="none">public</userinput> HotkeyAdaptorRosProdAvailImpl() {
	        <userinput moreinfo="none">this</userinput>.requestValues = <userinput moreinfo="none">new</userinput> HashMap();
	        <userinput moreinfo="none">this</userinput>.as400response = <userinput moreinfo="none">new</userinput> HashMap();
	    }

	    <userinput moreinfo="none">public void</userinput> setXML(String _xml) {
	        <userinput moreinfo="none">this</userinput>.inputFile = _xml;

	    }

	    <userinput moreinfo="none">public boolean</userinput> parseXML() {

	        <userinput moreinfo="none">try</userinput> {
	            Document doc = <userinput moreinfo="none">null;</userinput>
	            DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();
	            DocumentBuilder db = dbf.newDocumentBuilder();
	            StringReader r = <userinput moreinfo="none">new</userinput> StringReader(this.inputFile);
	            org.xml.sax.InputSource is = <userinput moreinfo="none">new</userinput> org.xml.sax.InputSource(r);
	            doc = db.parse(is);

	            Element root = doc.getDocumentElement();

	            Node node = <userinput moreinfo="none">null;</userinput>

	            Iterator xpathvals = xpathmappings.values().iterator( );
	            Iterator xpathvars = xpathmappings.keySet().iterator( );
	            <userinput moreinfo="none">while</userinput> (xpathvals.hasNext() &amp;&amp; xpathvars.hasNext( )) {
	                node = XPathAPI.selectSingleNode(root, String)xpathvals.next( ));
	                requestValues.put((String)xpathvars.next( ),
	                        node.getChildNodes().item(0).getNodeValue( ));
	            }

	        }
	        <userinput moreinfo="none">catch</userinput> (Exception e) {
	            System.out.println(e.toString( ));
	        }

	        <userinput moreinfo="none">return true;</userinput>
	    }
	    <userinput moreinfo="none">public boolean</userinput> executeQuery() {
	         // Code omitted...
	    }

	    <userinput moreinfo="none">public</userinput> String <indexterm id="idx-CHP-27-2419" significance="normal"><primary>business partners$ integrating using REST</primary><secondary>exchanging data with e-business</secondary><tertiary>parsing XML using XPath</tertiary></indexterm>getResponseXML() {
	        // Code omitted...
	    }

	}
</programlisting><para>The <literal moreinfo="none">executeQuery</literal> method contains all of the code necessary to access the <indexterm id="idx-CHP-27-2420" significance="normal"><primary>RPG legacy systems</primary></indexterm>RPG code running on the AS/400 systems, in order to get the necessary response <indexterm id="idx-CHP-27-2421" significance="normal"><primary>e-business protocols</primary><secondary>exchanging data with</secondary></indexterm>data we'll use later to construct the response XML document. Many years ago, I worked on a project that integrated a MAPICS system (RPG on the AS/400) with a new system that I wrote using Visual Basic. I had written code for both sides of the exchange, in RPG and CL on the AS/400, and Visual Basic on the PC. This led to several speaking engagements where I attempted to show legions of RPG programmers how to integrate their legacy systems with modern client/server software. At the time, it really was a complicated and almost mystical thing to do.</para><para>Since then, <indexterm id="idx-CHP-27-2422" significance="normal"><primary>IBM Java function library to integrate RPG systems with client/server software</primary></indexterm>IBM has made it very easy and provided us with a <indexterm id="idx-CHP-27-2423" significance="normal"><primary>Java</primary><secondary>library for integrating RPG legacy systems with client/server software</secondary></indexterm>library of Java functions that do all the work for us. (So much for all the consulting gigs and book deals I could have had with that one!) Here's the code, using the much better Java library from IBM:</para><programlisting id="I_programlisting27_tt652" format="linespecific">
	<userinput moreinfo="none">public boolean</userinput> executeQuery() {
	    StringBuffer sb = <userinput moreinfo="none">new</userinput> StringBuffer();

	    sb.append(requestValues.get("from_ContactName")).append("|");
	    sb.append(requestValues.get("from_EmailAddress")).append("|");
	    sb.append(requestValues.get("from_TelephoneNumber")).append("|");
	    sb.append(requestValues.get("from_<indexterm id="idx-CHP-27-2424" significance="normal"><primary>business partners</primary></indexterm>BusinessIdentifier")).append("|");
	    sb.append(requestValues.get("prod_BeginAvailDate")).append("|");
	    sb.append(requestValues.get("prod_EndAvailDate")).append("|");
	    sb.append(requestValues.get("prod_Quantity")).append("|");
	    sb.append(requestValues.get("prod_ProductIdentifier")).append("|");

	    <userinput moreinfo="none">try</userinput> {
	        AS400 sys = <userinput moreinfo="none">new</userinput> AS400("SS100044", "ACME", "HOUSE123");

	        CharConverter ch = <userinput moreinfo="none">new</userinput> CharConverter();
	        <userinput moreinfo="none">byte[]</userinput> as = ch.stringToByteArray(sb.toString( ));

	        ProgramParameter[] parmList = <userinput moreinfo="none">new</userinput> ProgramParameter[2];
	        parmList[0] = <userinput moreinfo="none">new</userinput> ProgramParameter(as);
	        parmList[1] = <userinput moreinfo="none">new</userinput> ProgramParameter(255);

	        ProgramCall pgm = <userinput moreinfo="none">new</userinput> ProgramCall(sys,
	               "/QSYS.LIB/DEVOBJ.LIB/J551231.PGM", parmList);
	        <userinput moreinfo="none">if</userinput> (pgm.run( ) != true) {
	            AS400Message[] msgList = pgm.getMessageList();	
	            <userinput moreinfo="none">for</userinput> (<userinput moreinfo="none">int</userinput> i=0; i &lt; msgList.length; i++) {
	                System.out.println(msgList[i].getID( ) + " : " +
	                         msgList[i].getText());
	            }
	                   }
	        <userinput moreinfo="none">else</userinput> {
	            CharConverter chconv = <userinput moreinfo="none">new</userinput> CharConverter();
	            String response =
	                    chconv.byteArrayToString(parmList[1].<indexterm id="idx-CHP-27-2425" significance="normal"><primary>e-business protocols</primary><secondary>exchanging data with</secondary></indexterm>getOutputData( ));

	            StringTokenizer st = <userinput moreinfo="none">new</userinput> StringTokenizer(response, "|");

	            String status = (String) st.nextToken().trim( );
	            as400response.put("Status", status);
	            String error = (String) st.nextToken().trim( );
	            as400response.put("ErrorCode", error);
	            String quantity = (String) st.nextToken().trim( );
	            as400response.put("Quantity",
	                    String.valueOf(Integer.parseInt(quantity)));

	            <userinput moreinfo="none">if</userinput> (status.toUpperCase( ).equals("ER")) {
	                <userinput moreinfo="none">if</userinput> (error.equals("1")) {
	                    as400response.put("ErrorMsg",
	                             "Account not authorized for item availability.");
	                }
	                <userinput moreinfo="none">if</userinput> (error.equals("2")) {
	                    as400response.put("ErrorMsg", "Item not found.");
	                }
	                <userinput moreinfo="none">if</userinput> (error.equals("3")) {
	                    as400response.put("ErrorMsg", "Item is obsolete.");
	                    as400response.put("Replacement",
	                             (String) st.nextToken().trim( ));
	                }
	                <userinput moreinfo="none">if</userinput> (error.equals("4")) {
	                    as400response.put("ErrorMsg",
	                             "Invalid quantity amount.");
	                }
	                <userinput moreinfo="none">if</userinput> (error.equals("5")) {
	                as400response.put("ErrorMsg",
	                         "Preference profile processing error.");
	                }
	                <userinput moreinfo="none">if</userinput> (error.equals("6")) {
	                    as400response.put("ErrorMsg",
	                             "ATP processing error.");
	                }
	            }
	        }
	    }
	    <userinput moreinfo="none">catch</userinput> (Exception e) {
	        System.out.println(e.toString( ));
	    }

	    <userinput moreinfo="none">return true;</userinput>
	}
</programlisting><para>This method begins by assembling a parameter string (pipe-delimited) that gets passed into the AS/400 program, where it parses the string, retrieves the requested <indexterm id="idx-CHP-27-2426" significance="normal"><primary>XML</primary><secondary>parsing data using XPath</secondary></indexterm>data, and returns a pipe-delimited string with a status and error code as well as the result of the operation.</para><para>Assuming there isn't an error, the results of this AS/400 interaction get stored in another <literal moreinfo="none">HashMap</literal>, which we'll use when constructing the XML response document. If there is an error, then that gets written to the response instead.</para></sect2><sect2 id="assembling_the_xml_response" label="27.4.2"><title>Assembling the XML Response</title><para>I've always enjoyed seeing the many ways people have tried to create XML documents programmatically. What I always tell people is that XML documents are just big text strings. Therefore, it's usually easier to just write one out using a <literal moreinfo="none">StringBuffer</literal> rather than trying to build a DOM (Document Object Model) or using a special XML generator library.</para><para>For this project, I simply created a <literal moreinfo="none">StringBuffer</literal> object and appended each individual line of the XML document following the Rosettanet standard. In the following code example, I omitted several lines of code, but this should give you an idea of how the response was constructed:</para><programlisting id="I_programlisting27_tt653" format="linespecific">
	   <userinput moreinfo="none">public</userinput> String getResponseXML() {
	       StringBuffer response = <userinput moreinfo="none">new</userinput> StringBuffer();
	       response.append("&lt;Pip3A2PriceAndAvailabilityResponse&gt;").append("\n");
	       response.append("    &lt;ProductAvailability&gt;").append("\n");
	       response.append("   &lt;ProductQuantity&gt;").append(as400response.get("Quantity")).
	append("&lt;/ProductQuantity&gt;").append("\n");
	        response.append("   &lt;/ProductAvailability&gt;").append("\n");
	        response.append("   &lt;ProductIdentification&gt;").append("\n");
	        response.append("     &lt;PartnerProductIdentification&gt;").append("\n");
	        response.append("       &lt;GlobalPartnerClassificationCode&gt;Manufacturer&lt;/
	GlobalPartnerClassificationCode&gt;").append("\n");
	        response.append("       &lt;ProprietaryProductIdentifier&gt;").append(requestValues.
	get("prod_ProductIdentifier")).append("&lt;/ProprietaryProductIdentifier&gt;").append("\n");
	        response.append("      &lt;/PartnerProductIdentification&gt;").append("\n");
	        response.append("    &lt;/ProductIdentification&gt;").append("\n");
	        response.append("  &lt;/ProductPriceAndAvailabilityLineItem&gt;").append("\n");
	        response.append("&lt;/Pip3A2PriceAndAvailabilityResponse&gt;").append("\n");

	        <userinput moreinfo="none">return</userinput> response.toString();
	   }
</programlisting></sect2></sect1><sect1 id="conclusion-id015" label="27.5"><title>Conclusion</title><para>In looking back on this code I wrote over two years ago, I think it's pretty normal to second-guess myself and think of better ways I could have written it. While I may have written some of the implementation code differently, I think I'd still design the overall solution the same way. This code has stood the test of time, as the client has since added new distributors and new request types all on its own, with minimal help from outside service providers like me.</para><para>Currently, as director of a bioinformatics department, I have used this code to demonstrate several things to my staff as I teach them object-oriented design principles and XML parsing techniques. I could have written about code I have developed more recently, but I think this demonstrates several basic principles that are important for any young software developer to understand.<indexterm id="I_indexterm27_tt654" class="endofrange" startref="idx-CHP-27-2378" significance="normal"><primary>REST (Representational State Transfer)</primary></indexterm><indexterm id="I_indexterm27_tt655" class="endofrange" startref="idx-CHP-27-2409" significance="normal"><primary>e-business protocols</primary><secondary>exchanging data with</secondary></indexterm><indexterm id="I_indexterm27_tt656" class="endofrange" startref="idx-CHP-27-2410" significance="normal"><primary>Rosettanet e-business protocol</primary><secondary>exchanging requests and responses using</secondary></indexterm><indexterm id="I_indexterm27_tt657" class="endofrange" startref="idx-CHP-27-2417" significance="normal"><primary>XML</primary><secondary>parsing data using XPath</secondary></indexterm></para></sect1></chapter><chapter id="beautiful_debugging" label="28" role=""><title>Beautiful Debugging</title><para><emphasis>Andreas Zeller</emphasis><indexterm class="startofrange" id="idx-CHP-28-2427" significance="normal"><primary>debugging</primary></indexterm><indexterm id="idx-CHP-28-2428" significance="normal"><primary>Zeller</primary></indexterm></para><para><emphasis>My name is andreas, and i have been debugging</emphasis>." Welcome to Debuggers Anonymous, where you can tell your debugging story and find relief in the stories of others. So you have spent another night away from home? Good thing you've only been in front of the debugger. So you still cannot tell your manager when that showstopper will be fixed? Let's hope for the best! The fellow in the cubicle next to you brags about searching for a bug for 36 consecutive hours? Now that's impressive!</para><para>No, there is nothing glamorous about debugging. It is the ugly duckling of our profession, the admission that we are far from perfect, the one activity that is the least predictable or accountable—and a constant impetus to feelings of remorse and guilt: "If only we had done better right from the start, we wouldn't be stuck in this mess." The defect is the crime; debugging is the punishment.</para><para>Let us assume, though, that we have done all we can to prevent errors. Yet, from time to time, we will find ourselves in a situation where we need to debug. And as with all other activities, we need to handle debugging in the most professional, maybe even "beautiful" way.</para><para>So, can there be any beauty in <indexterm id="idx-CHP-28-2429" significance="normal"><primary>debugging</primary></indexterm>debugging? I believe there can. In my own life as a programmer, there have been a number of moments when I encountered true beauty in debugging. These moments not only helped me solve a problem at hand, but actually evolved into new approaches to debugging as a whole—approaches that are not only "beautiful" in some way, but actually boost your productivity in debugging. This is because they are <emphasis>systematic</emphasis>—they guarantee to guide you toward the problem solution—and partly even <emphasis>automatic</emphasis>—they do all the work while you pursue other tasks.</para><para>Curious? Read on.</para><sect1 id="debugging_a_debugger" label="28.1"><title>Debugging a Debugger</title><para>My first experience of beauty in debugging was granted by one of my students. In her 1994 Master's thesis, Dorothea Lütkehaus built a visual debugger interface that provided a textbook visualization of data structures. <xref linkend="the_ddd_debugger_in_action"/> <indexterm id="idx-CHP-28-2430" significance="normal"><primary>ddd (data display debugger)</primary></indexterm>shows a screenshot of her tool, called the <emphasis>data display debugger</emphasis>, or <emphasis>ddd</emphasis> for short. As Dorothea demoed her debugger, the audience and myself were amazed: one could grasp complex data within seconds, and explore and manipulate it just by using the mouse.<indexterm id="idx-CHP-28-2431" significance="normal"><primary>debugging</primary><secondary>a debugger</secondary></indexterm><indexterm id="idx-CHP-28-2432" significance="normal"><primary>data display debugger (ddd)</primary></indexterm></para><para><emphasis>ddd</emphasis> was a wrapper for the command-line debuggers in use at this time (in particular <emphasis>gdb</emphasis>, the GNU debugger), which were very powerful tools but difficult to use. Since graphical user interfaces for programming tools were still scarce, <emphasis>ddd</emphasis> was a small revolution. In the following months, Dorothea and I did our best to make <emphasis>ddd</emphasis> the most beautiful debugger interface around, and it eventually became part of the GNU ecosystem.<indexterm id="idx-CHP-28-2433" significance="normal"><primary>gdb (GNU debugger)</primary></indexterm></para><para>While debugging with <emphasis>ddd</emphasis> is usually more fun than using a command-line tool, it does not necessarily make you a more efficient debugger. For this, the debugging <emphasis>process</emphasis> is far more important than the tool. Incidentally, I learned this through <emphasis>ddd</emphasis> as well. It all started with a <emphasis>ddd</emphasis> bug report I received on July 31, 1998, which started my second experience of beauty in debugging. Here is the bug report:</para><blockquote><para>When using DDD with GDB 4.16, the run command correctly uses any prior command-line arguments, or the value of set args. However, when I switched to GDB 4.17, this no longer worked: If I entered a run command in the console window, the prior command-line options would be lost.</para></blockquote><para>Those <emphasis>gdb</emphasis> developers had done it again—releasing a new <emphasis>gdb</emphasis> version that behaved slightly differently from the earlier version. Because <emphasis>ddd</emphasis> was a frontend, it actually sent commands to <emphasis>gdb</emphasis>, just like a human would do, and parsed the <emphasis>gdb</emphasis> replies to present its information in the user interface. Something in this process had apparently failed.</para><para>All I needed to do was grab and install the new <emphasis>gdb</emphasis> version, run <emphasis>ddd</emphasis> as its frontend, and see whether I could reproduce the problem. If I could, I would have to launch another debugger instance to walk through the problem. All in all, this was business as usual.</para><para>It turned out, though, that at this time, I was pretty fed up with running debuggers, debugging our own debugger, and in particular debugging because of third-party changes.</para><figure id="the_ddd_debugger_in_action" label="28-1" float="0"><title>The ddd debugger in action</title><mediaobject id="I_mediaobject28_tt658"><imageobject role="print"><imagedata fileref="figs/print/beauty_2801.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2801.png" format="PNG"/></imageobject></mediaobject></figure><para>So, I sat back and wondered: is there a way to solve this problem without actually launching the debugger? Or: <emphasis>can I debug something without debugging?</emphasis><indexterm id="idx-CHP-28-2434" significance="normal"><primary>debugging</primary></indexterm></para><para>Since the problem was caused by a change to the <emphasis>gdb</emphasis> source code, I could simply look into the <emphasis>gdb</emphasis> code—or, more precisely, at the <indexterm id="idx-CHP-28-2435" significance="normal"><primary>diff tool</primary></indexterm>differences between the two releases. The code <indexterm id="idx-CHP-28-2436" significance="normal"><primary>gdb (GNU debugger)</primary><secondary>debugging</secondary><tertiary>running diff on source code</tertiary></indexterm>difference, so I thought, would point me directly to the failure-inducing change. All I needed to do was to run the two code bases through <emphasis>diff</emphasis>, a tool for detecting text differences. And this I did.</para><para>The <emphasis>diff</emphasis> results surprised me. The log had a length of 178,200 lines, which was enormous—especially considering that the total <emphasis>gdb</emphasis> source code contained roughly 600,000 lines of code. In no less than 8,721 locations, developers had inserted, deleted, or changed the source code. This was quite a lot for a "minor" release and, of course, far more than I could handle. Even if it took me just 10 seconds to check a single location, I would still spend 24 hours searching for the troublesome change. I sighed, invoked the debugger, and braced myself for yet another boring <indexterm id="idx-CHP-28-2437" significance="normal"><primary>debugging</primary></indexterm>debugging session. Still, I thought, there must be a better way to do this—a more "beautiful" way.</para></sect1><sect1 id="a_systematic_process" label="28.2"><title>A Systematic Process</title><para>When programmers debug a program, they search for a failure cause, which could lie in the code, the input, or the environment. This cause must be found and eliminated. Once the cause is eliminated, the program works. (Should the program still fail once the cause is eliminated, we may need to revise our beliefs about the cause.)<indexterm id="idx-CHP-28-2438" significance="normal"><primary>minimizing input</primary><secondary>systematic process of</secondary></indexterm><indexterm id="idx-CHP-28-2439" significance="normal"><primary>systematic debugging</primary></indexterm></para><para>The general process for finding causes is called the <emphasis>scientific method</emphasis>. Applied to program failures, it works as follows:<indexterm id="idx-CHP-28-2440" significance="normal"><primary>scientific method</primary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Observe a program failure.</para></listitem><listitem><para>Invent a <emphasis>hypothesis</emphasis> for the failure cause that is <indexterm id="idx-CHP-28-2441" significance="normal"><primary>minimizing input</primary><secondary>systematic process of</secondary><tertiary>consistent</tertiary></indexterm>consistent with the observations.</para></listitem><listitem><para>Use the hypothesis to make <emphasis>predictions</emphasis>.</para></listitem><listitem><para>Put your predictions to the test by experiments and further observations:</para><orderedlist role="alpha" inheritnum="ignore" continuation="restarts"><listitem><para>If experiment and observation satisfy the prediction, refine the hypothesis.</para></listitem><listitem><para>If not, find an alternate hypothesis.</para></listitem></orderedlist></listitem><listitem><para>Repeat steps 3 and 4 until the hypothesis can no longer be refined.</para></listitem></orderedlist><para>Eventually, the hypothesis thus becomes a <emphasis>theory</emphasis>. This means that you have a conceptual framework that explains (and predicts) some aspect of the universe. Your failing program may be a very small aspect of the universe, but still, the resulting theory should neatly predict where you should fix your program.</para><para>To obtain such a theory, programmers apply the scientific method as they walk back through the cause-effect-chain that led to the failure. They:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Observe a failure ("The output is wrong").</para></listitem><listitem><para>Come up with a hypothesis about the failure cause ("The problem may be that <literal moreinfo="none">y</literal> has a wrong value").</para></listitem><listitem><para>Make a prediction ("If <literal moreinfo="none">y</literal> is wrong, its value may come from <literal moreinfo="none">f()</literal> in line 632").</para></listitem><listitem><para>Put their prediction to the test ("Indeed, <literal moreinfo="none">y</literal> has a wrong value in line 632").</para></listitem><listitem><para>Draw appropriate conclusions ("This means that <literal moreinfo="none">f()</literal> returns a wrong value. Now where does this come from?").</para></listitem></orderedlist><para>Among all methods, hints, and tricks, the consistent and disciplined use of the scientific method is the key to becoming a debugging master. This means three things:</para><variablelist><varlistentry><term>Be explicit</term><listitem><para>Formulate your hypothesis explicitly. Write it down or explain your problem to other people. Keep a written track of your hypotheses and observations so you can interrupt your work and start the next morning with a fresh mind.<indexterm id="idx-CHP-28-2442" significance="normal"><primary>explicit formulation of hypothesis (in debugging)</primary></indexterm></para></listitem></varlistentry><varlistentry><term>Be systematic</term><listitem><para>Make sure you know what you're doing. Don't investigate (or change) something at random without having a clear hypothesis and a resulting prediction. Be sure you do not miss possible failure causes.</para></listitem></varlistentry><varlistentry><term>Look for the most likely causes first</term><listitem><para>The scientific method guarantees you will find a cause, but it does not tell you when. Identify possible failure causes first, and then focus on those where the product of likelihood and effort is minimal.<indexterm id="idx-CHP-28-2443" significance="normal"><primary>likeliest causes first</primary></indexterm></para></listitem></varlistentry></variablelist><para>Unfortunately, interactive debuggers as they stand do not support the scientific method. To be sure, debuggers are great tools to poke around and investigate code and its results at will. This is a good thing—but only for skilled programmers who know how to use debuggers systematically. I'd rather see programmers trained in systematic <indexterm id="idx-CHP-28-2444" significance="normal"><primary>debugging</primary></indexterm>debugging methods than in fancy debugging tools. (And I still feel guilty having written a fancy debugging tool myself.)</para></sect1><sect1 id="a_search_problem" label="28.3"><title>A Search Problem</title><para>Let's come back to our initial problem of debugging the debugger. Even after isolating and fixing the bug, I wondered: is there a way to find the failure-inducing change automatically? What one would need is a test that is automatically invoked each time the programmer changes something. As soon as the test broke, we would know what had changed most recently so we could immediately fix it. (A few years later, David Saff and Michael Ernst implemented this idea under the name <emphasis>continuous testing</emphasis>.)<indexterm id="idx-CHP-28-2445" significance="normal"><primary>minimizing input</primary><secondary>search problem</secondary></indexterm><indexterm id="idx-CHP-28-2446" significance="normal"><primary>continuous testing</primary></indexterm></para><para>In my situation, I knew the change that had caused the test to fail—it was the change from <emphasis>gdb</emphasis> 4.16 to <emphasis>gdb</emphasis> 4.17. The problem was that the change was so <emphasis>huge</emphasis>, affecting 8,721 locations. There should be a way to break down this change into smaller pieces.</para><para>What if I tried to split it into 8,721 smaller changes, each affecting just one location? This way, I could apply and test one change after the other until the test failed—and the last change applied would be the one that broke the test. In other words, I would simulate the 4.17 version's development history. (Actually, it would not be me who would simulate the history; instead, it would be a tool I built. And while I would be sitting sipping my tea, playing a game with my kids, or catching up my email stream, this nifty little tool would search and find the failure-inducing change. Neat.)</para><para>There was a catch, though. <emphasis>I had no clue about the order in which the changes had to be applied</emphasis>. And this was crucial because the individual changes may depend on each other. For instance, change A may introduce a variable that would be used in new code included in other changes B or C. Whenever B or C are applied, A must be applied, too; otherwise, building <emphasis>gdb</emphasis> would fail. Likewise, change X may rename some function definition; other changes (Y, Z) in other locations may reflect this renaming. If X is applied, Y and Z must be applied as well, because again, otherwise, <emphasis>gdb</emphasis> would not build.</para><para>How does one determine whether one change depends upon another? This problem looked quite hard—and almost intractable without very fancy (and not yet existing) multiversion program analysis.</para><para>How about just trying out various orderings of changes? 8,721 individual changes can be ordered in 8,721 x 8,720 x 8,719 x … x 1 = 8,721! <indexterm id="idx-CHP-28-2447" significance="normal"><primary>minimizing input</primary><secondary>search problem</secondary><tertiary>determining if one change depends on another</tertiary></indexterm>different ways. No way anyone could test all of them. Trying out all subsets is somewhat better: 8,721 changes mean 2<superscript>8,721</superscript> =10<superscript>2,625</superscript> possible subsets, which means a lot fewer tests than 8,721 orderings. I could try to console myself with the thought that by the time these computations had ended on my machine, quantum computing, time travel, and universally correct programs would long have gone mainstream, eliminating the need for such futile attempts.</para><para>So, I made another try. How about good old <indexterm id="idx-CHP-28-2448" significance="normal"><primary>minimizing input</primary><secondary>search problem</secondary><tertiary>divide and conquer strategy</tertiary></indexterm>divide and conquer? We could start applying the first half of changes to the <emphasis>gdb</emphasis> 4.16 source and test it. If <emphasis>ddd</emphasis> failed, we would know that the failure-inducing change was in that first half; if it did not fail, we'd keep on searching in the other half. With each test, we'd reduce the search space by one-half, and thus finally end up in the failure-inducing change. That's it, I thought: an automatic application of the scientific method, systematically creating, testing, and refining hypotheses.</para><para>But again—what do we do if applying a set of changes ends in inconsistent code? I had no idea.</para></sect1><sect1 id="finding_the_failure_cause_automatically" label="28.4"><title>Finding the Failure Cause Automatically</title><para>It took me three months to come up with a solution—which came to me, incidentally, lying in my bed at six in the morning. The sun was rising, the birds were singing, and I finally had an idea. The reasoning was as follows:<indexterm id="idx-CHP-28-2449" significance="normal"><primary>debugging</primary><secondary>finding failure cause automatically</secondary></indexterm></para><itemizedlist><listitem><para>Applying <emphasis>half</emphasis> of the changes has a small chance of getting a consistent build; the risk of skipping a dependent change is simply too high. On the other hand, if we get a consistent build (or a "resolved" outcome), we can very quickly narrow down the set of changes.</para></listitem><listitem><para>On the other hand, applying <emphasis>individual</emphasis> changes has a far greater chance of getting something meaningful—in particular, if the version being changed was already consistent. As an example, think of changing a single function; unless its interface changes, we will most likely get a running program. On the other hand, trying out one change after the other would still take ages.</para></listitem></itemizedlist><para>Therefore, I'd call for a <emphasis>compromise</emphasis>: I would start with two halves. If neither half of the changes would result in a testable build, I would split the set of changes into <emphasis>four</emphasis> subsets instead, and then apply each subset individually to the <emphasis>gdb</emphasis> 4.16 source. In addition, I would also <emphasis>unapply</emphasis> the subset from the <emphasis>gdb</emphasis> 4.17 source (which would be realized by applying the complement of the subset to the <emphasis>gdb</emphasis> 4.16 source).</para><para><indexterm id="idx-CHP-28-2450" significance="normal"><primary>gdb (GNU debugger)</primary><secondary>debugging</secondary><tertiary>splitting changes into four or more subsets</tertiary></indexterm>Splitting in four (rather than two) would mean that <emphasis>smaller</emphasis> change sets would be applied, which means that the changed versions would be closer to the (working) original versions—and which would imply higher chances of getting a consistent build.</para><para>And if four subsets would not suffice, then I would go for 8, 16, 32, and so on, until, eventually, I would apply each single change individually, one after the other—which should give me the greatest chance of getting a consistent build. As soon as I had a testable build, the algorithm would restart from scratch.</para><para>I calculated that in the worst case, the algorithm would still require 8,721<superscript>2</superscript> = 76,055,841 tests. This number was still way too high, but much lower than the exponential-approaches thought of earlier. At the other extreme, if all builds succeeded, the algorithm would work as a binary search, and require just log<subscript>2</subscript> 8,721 = 14 tests. Given the odds, was it worth doing?</para><para>I implemented a simple Python script with a very crude version of the preceding algorithm. The key part was the testing function. It would take a set of changes, run <emphasis>patch</emphasis> to apply the changes to the <emphasis>gdb</emphasis> 4.16 source, and then invoke <emphasis>make</emphasis> to build the changed <emphasis>gdb</emphasis>. Finally, it would run <emphasis>gdb</emphasis> and see whether the failure occurred (returning "fail" if it did) or not (returning "pass"). As any of these steps could fail, the testing function could also return "unresolved" as a test result.</para><para>As I started the script, it quickly turned out that "unresolved" was still by far the most frequent return value. Actually, for the first 800 tests or so, the testing function returned nothing but "unresolved." The number of change subsets had gone up from two to four to eight…until we had 64 subsets, each containing 136 changes. And these tests took some time. As one <emphasis>gdb</emphasis> build took about six minutes, I was already waiting for three days. (Actually, I was not waiting, but writing my Ph.D. thesis. But still….)</para><para>I was just examining the log as something unusual happened. A test had just failed! Now, finally, I would see how the algorithm would focus on the smaller set, narrowing the search space. But when I checked the results, it turned out that the test printed the following message on the screen and stopped:</para><programlisting id="I_programlisting28_tt659" format="linespecific">
	NameError: name 'next_c_fial' is not defined
</programlisting><para>After three days of constant calculation, my script had stumbled on a dumb misspelling. I truly wished I had used a language with static checking rather than Python.</para><para>I fixed the problem and ran the script again. Now, finally, it would work. After five more days, and roughly 1,200 tests, the script finally isolated the failure-inducing change: the change to <emphasis>gdb</emphasis> that had caused <emphasis>ddd</emphasis> to fail. It was a one-line change—and it was not even a change to program code, but instead a change to some built-in text:</para><programlisting id="I_programlisting28_tt660" format="linespecific">
	diff -r gdb-4.16/gdb/infcmd.c gdb-4.17/gdb/infcmd.c
	1239c1278
	&lt; "Set arguments to give program being debugged when it is started.\n\
	---
	&gt; "Set argument list to give program being debugged when it is started.\n\
</programlisting><para>This change from <literal moreinfo="none">arguments</literal> to <literal moreinfo="none">argument list</literal> was the cause for <emphasis>gdb</emphasis> 4.17 no longer working with <emphasis>ddd</emphasis>. This text is output by <emphasis>gdb</emphasis> when the user requests help for the <literal moreinfo="none">set args</literal> command. However, it is also used in other places. When given the command <literal moreinfo="none">show args</literal>, <emphasis>gdb</emphasis> 4.16 replies:</para><programlisting id="I_programlisting28_tt661" format="linespecific">
	Arguments to give program being debugged is "11 14"
</programlisting><para><emphasis>gdb</emphasis> 4.17, however, replies:</para><programlisting id="I_programlisting28_tt662" format="linespecific">
	Argument list to give program being debugged is "11 14"
</programlisting><para>This new reply was what confused <emphasis>ddd</emphasis> because it expected the reply to start with <literal moreinfo="none">Arguments</literal>. Thus, my script had actually determined the failure-inducing change—after five days of work, but yet in a fully automatic version.</para></sect1><sect1 id="delta_debugging" label="28.5"><title>Delta Debugging</title><para>Over the next several months, I refined and optimized the algorithm as well as the tool, such that eventually it would need just one hour to find the failure-inducing change. I eventually published the algorithm under the name <emphasis>delta debugging</emphasis> because it "debugs" programs by isolating a delta, or difference between two versions.<indexterm class="startofrange" id="idx-CHP-28-2451" significance="normal"><primary>delta debugging</primary></indexterm><indexterm class="startofrange" id="idx-CHP-28-2452" significance="normal"><primary>debugging</primary><secondary>delta debugging</secondary></indexterm><indexterm id="idx-CHP-28-2453" significance="normal"><primary>debugging</primary></indexterm></para><para>Here I'll show my Python implementation of the delta debugging algorithm. The function <literal moreinfo="none">dd()</literal> takes three arguments—two lists of changes as well as a test:</para><itemizedlist><listitem><para>The list <literal moreinfo="none">c_pass</literal> contains the "working" configuration—in our case, the list of changes that must be applied to make the program work. In our case (which is typical), this is the empty list.</para></listitem><listitem><para>The list <literal moreinfo="none">c_fail</literal> contains the "failing" configuration—in our case, the list of changes required to make the program fail. In our case, this would be a list of 8,721 changes (which we would encapsulate in, say, <literal moreinfo="none">Change</literal> objects).</para></listitem><listitem><para>The <literal moreinfo="none">test</literal> function accepts a list of changes, applies them, and runs a test. It returns <literal moreinfo="none">PASS, FAIL</literal>, or <literal moreinfo="none">UNRESOLVED</literal> as the outcome, depending on whether the test was successful, failed, or had an unresolved outcome. In our case, the <literal moreinfo="none">test</literal> function would apply the changes via <emphasis>patch</emphasis> and run the test as just described.</para></listitem><listitem><para>The <literal moreinfo="none">dd( )</literal> function systematically narrows down the difference between <literal moreinfo="none">c_pass</literal> and <literal moreinfo="none">c_fail</literal>, and eventually returns a triple of values. The first of these values would be the isolated <literal moreinfo="none">delta</literal>—in our case, a single <literal moreinfo="none">Change</literal> object containing the one-line change to the <emphasis>gdb</emphasis> source code.</para></listitem></itemizedlist><para>If you plan to implement <literal moreinfo="none">dd()</literal> yourself, you can easily use the code shown here (and included on the O'Reilly web site for this book). You also need three supporting functions:</para><variablelist><varlistentry><term><literal moreinfo="none">split</literal>(<replaceable>list, n</replaceable>)</term><listitem><para>Splits a list into <replaceable>n</replaceable> sublists of equal length (except for possibly the last). Thus:</para><programlisting id="I_programlisting28_tt663" format="linespecific">
	split([1, 2, 3, 4, 5], 3)
</programlisting><para>yields:</para><programlisting id="I_programlisting28_tt664" format="linespecific">
	[[1, 2], [3, 4], [5]]
</programlisting></listitem></varlistentry><varlistentry><term><literal moreinfo="none">listminus() and listunion( )</literal></term><listitem><para>Return the difference or union of two sets represented as lists, respectively. Thus:</para><programlisting id="I_programlisting28_tt665" format="linespecific">
	listminus([1, 2, 3], [1, 2])
</programlisting><para>yields:</para><programlisting id="I_programlisting28_tt666" format="linespecific">
	[3]
</programlisting><para>whereas:</para><programlisting id="I_programlisting28_tt667" format="linespecific">
	listunion([1, 2, 3], [3, 4])
</programlisting><para>yields:</para><programlisting id="I_programlisting28_tt668" format="linespecific">
	[1, 2, 3, 4]
</programlisting></listitem></varlistentry></variablelist><para>The Python code is shown in <xref linkend="an_implementation_of_the_delta_debugging_algorithm"/>.<indexterm id="idx-CHP-28-2454" significance="normal"><primary>Python</primary><secondary>delta debugging algorithm</secondary><tertiary>implementation</tertiary></indexterm><indexterm id="idx-CHP-28-2455" significance="normal"><primary>debugging</primary></indexterm></para><example id="an_implementation_of_the_delta_debugging_algorithm" label="28-1"><title>An implementation of the delta debugging algorithm</title><programlisting format="linespecific">
def dd(c_pass, c_fail, test):
    """Return a triple (DELTA, C_PASS', C_FAIL') such that
       - C_PASS subseteq C_PASS' subset C_FAIL' subseteq C_FAIL holds
       - DELTA = C_FAIL' - C_PASS' is a minimal difference
         between C_PASS' and C_FAIL' that is relevant with respect
         to TEST."""

    n = 2 # Number of subsets

    while 1:
        assert test(c_pass) == PASS # Invariant
        assert test(c_fail) == FAIL # Invariant
        assert n &gt;= 2

        delta = listminus(c_fail, c_pass)

        if n &gt; len(delta):
            # No further minimizing
            return (delta, c_pass, c_fail)

        deltas = split(delta, n)
        assert len(deltas) == n

        offset = 0
        j = 0
        while j &lt; n:
            i = (j + offset) % n
            next_c_pass = listunion(c_pass, deltas[i])
            next_c_fail = listminus(c_fail, deltas[i])

            if test(next_c_fail) == FAIL and n == 2:
                c_fail = next_c_fail
                n = 2; offset = 0; break
            elif test(next_c_fail) == PASS:
                c_pass = next_c_fail
                n = 2; offset = 0; break
            elif test(next_c_pass) == FAIL:
                c_fail = next_c_pass
                n = 2; offset = 0; break
            elif test(next_c_fail) == FAIL:
                c_fail = next_c_fail
                n = max(n - 1, 2); offset = i; break
            elif test(next_c_pass) == PASS:
                c_pass = next_c_pass
                n = max(n - 1, 2); offset = i; break
            else:
                j = j + 1

        if j &gt;= n:
            if n &gt;= len(delta):
                return (delta, c_pass, c_fail)
            else:
                n = min(len(delta), n * 2)
</programlisting></example></sect1><sect1 id="minimizing_input" label="28.6"><title>Minimizing Input</title><para>The interesting thing about delta <indexterm id="idx-CHP-28-2456" significance="normal"><primary>debugging</primary></indexterm>debugging (or any other automation of the scientific method) is that it is very general. Rather than search for causes in a set of changes, you can also search for causes in other search spaces. For instance, you can easily apply <indexterm id="idx-CHP-28-2457" significance="normal"><primary>delta debugging</primary></indexterm>delta debugging to search for failure causes in program input, which Ralf Hildebrandt and I did in 2002.<indexterm id="idx-CHP-28-2458" significance="normal"><primary>delta debugging</primary></indexterm><indexterm id="idx-CHP-28-2459" significance="normal"><primary>minimizing input</primary></indexterm><indexterm id="idx-CHP-28-2460" significance="normal"><primary>delta debugging</primary><secondary>searching for failure causes in program</secondary><tertiary>input</tertiary></indexterm></para><para>When searching for causes in program input, the program code stays the same: no application of changes, no reconstruction, just execution. Instead, it is the input that changes. Think of a program that works on most inputs, but fails on one specific input. One can easily have <indexterm id="idx-CHP-28-2461" significance="normal"><primary>debugging</primary><secondary>delta debugging</secondary></indexterm>delta debugging isolate the failure-inducing difference between the two inputs: "The cause of the web browser crashing is the <literal moreinfo="none">&lt;SELECT&gt;</literal> tag in line 40."</para><para>One can also modify the algorithm so that it returns a minimized input: "To have the web browser crash, just feed it a web page containing <literal moreinfo="none">&lt;SELECT&gt;</literal>." In minimized input, every single remaining character is relevant for the failure to occur. Minimized inputs can be very valuable for debuggers because they make things simple: they lead to shorter executions and smaller states to be examined. As an important (and perhaps beautiful) side effect, they capture the essence of the failure.</para><para>I once met some programmers who were dealing with bugs in a third-party database. They had very complex, machine-generated SQL queries that sometimes would cause the database to fail. The vendor did not categorize these bugs as high priority because "you are our only customer dealing with such complex queries." Then the programmers simplified a one-page SQL query to a single line that still triggered the failure. Faced with this single line, the vendor immediately gave the bug the highest priority and fixed it.<indexterm id="I_indexterm28_tt669" class="endofrange" startref="idx-CHP-28-2451" significance="normal"><primary>delta debugging</primary></indexterm><indexterm id="I_indexterm28_tt670" class="endofrange" startref="idx-CHP-28-2452" significance="normal"><primary>debugging</primary><secondary>delta debugging</secondary></indexterm></para><para>How does one achieve minimization? The easiest way is to feed <literal moreinfo="none">dd()</literal> with an empty <literal moreinfo="none">c_pass</literal>, and to have a passing test return "pass" only if the input is empty, and "unresolved" otherwise. <literal moreinfo="none">c_pass</literal> remains unchanged while <literal moreinfo="none">c_fail</literal> becomes smaller and smaller with each failing test.</para><para>Again, all that is required to isolate such <indexterm id="idx-CHP-28-2462" significance="normal"><primary>debugging</primary><secondary>hunting the defect</secondary><tertiary>finding failure causes in program state</tertiary></indexterm>failure causes is an <indexterm id="idx-CHP-28-2463" significance="normal"><primary>minimizing input</primary><secondary>automated testing and splitting input into smaller pieces</secondary></indexterm>automated test and a means to split the input into smaller pieces—that is, a splitting function that has some basic knowledge about the syntax of the input.</para></sect1><sect1 id="hunting_the_defect" label="28.7"><title>Hunting the Defect</title><para>In principle, delta <indexterm id="idx-CHP-28-2464" significance="normal"><primary>debugging</primary></indexterm>debugging could also minimize an entire program code so as to keep only what is relevant. Suppose your web browser crashes while printing a HTML page. Applying delta debugging on the program code means that only the bare code required to reproduce the failure would remain. Doesn't this sound neat? Unfortunately, it would hardly work in practice. The reason is that the elements of program code are heavily dependent on each other. Remove one piece, and everything breaks apart. The chances of getting something meaningful by randomly removing parts are very slim. Therefore, delta debugging would almost certainly require a quadratic number of tests. Even for a 1,000-line program, this would already mean a million tests—and years and years of waiting. We never had that much time, so we never implemented that feat.<indexterm class="startofrange" id="idx-CHP-28-2465" significance="normal"><primary>debugging</primary><secondary>hunting the defect</secondary></indexterm></para><para>Nonetheless, we still wanted to hunt down failure causes not only in the input or the set of changes, but in the actual source code—in other words, we wanted to have the statements that caused the program to fail. (And, of course, we wanted to get them automatically.)</para><para>Again, this was a task that turned out to be achievable by delta debugging. However, we did not get there directly. We wanted to make a detour via <indexterm id="idx-CHP-28-2466" significance="normal"><primary>gdb (GNU debugger)</primary><secondary>searching program states for failure cause</secondary></indexterm>program states—that is, the set of all program variables and their values. In this set, we wanted to determine failure causes automatically, as in "At the call to <literal moreinfo="none">shell_sort()</literal>, variable size causes the failure." How would that work?</para><para>Let us recapitulate what we had done so far. We had done delta debugging on program versions—one that worked and one that failed—and isolated the minimal difference that caused the failure. We had done delta debugging on program inputs—again, one that worked and one that failed—and isolated minimal differences that caused the failure. If we applied delta debugging <indexterm id="idx-CHP-28-2467" significance="normal"><primary>delta debugging</primary><secondary>on program states</secondary></indexterm>on program states, we would take one program state from a working run, and one program state from a failing run, and eventually obtain the minimal difference that caused the failure.</para><para>Now, there are three problems in here. Problem number one: <emphasis>How does one obtain a program state?</emphasis> Eventually, I would instrument the <emphasis>gdb</emphasis> debugger to query all named variables first, and then <emphasis>unfold</emphasis> all data structures. If I encountered an array or a structure, I would query its elements; if I found a pointer, I would query the variable it pointed to, and so on—until I reached a fix point, or the set of all accessible variables. This program state would be represented as a graph of variables (vertices) and references (edges), as shown in <xref linkend="a_program_state_of_the_gnu_compiler"/>, abstracting away concrete memory addresses.</para><figure id="a_program_state_of_the_gnu_compiler" label="28-2" float="0"><title>A program state of the GNU compiler</title><mediaobject id="I_mediaobject28_tt671"><imageobject role="print"><imagedata fileref="figs/print/beauty_2802.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_2802.png" format="PNG"/></imageobject></mediaobject></figure><para>Next problem: <emphasis>How does one compare two program states?</emphasis> This was rather easy: there are known algorithms for computing common subgraphs between two graphs—and anything that would not be part of the subgraph became a difference. With such an algorithm properly implemented, we now could actually extract and determine the difference between two program states.<indexterm id="idx-CHP-28-2468" significance="normal"><primary>debugging</primary><secondary>hunting the defect</secondary></indexterm></para><para>Third and last problem: <emphasis>How does one apply differences between states?</emphasis> This was a real challenge, as it involved not only observing but actually manipulating program states. To apply a difference in program state, we would have to set variables to new values, but also to replicate entire complex data structures, including allocating and deleting elements. Once this was done, we could do something quite fun; we could arbitrarily transfer program states between running processes. And not only entire program states, but also partial pro-gram states—ranging from small changes to a single variable to large changes of, say, half of a symbol table.</para><para>This idea of transferring program states while the program is executing is something that one needs time getting used to. I remember one of my first presentations at IBM where I explained the algorithm, its application on states, and came to the ultimate example: "We now have 879 differences between these two states. We now let delta <indexterm id="idx-CHP-28-2469" significance="normal"><primary>debugging</primary></indexterm>debugging narrow down the failure cause. To this end, the algorithm takes half of the differences, that is, 439 state differences, and applies them. This means that in the passing run, 439 variables are now set to the values found in the failing run…."</para><para>At this moment, a fellow from the audience stepped up and said: "But doesn't this sound like a very insane thing to do?"</para><para>Of course, he was right. Nothing meaningful came out of setting 439 variables to values found in <indexterm id="idx-CHP-28-2470" significance="normal"><primary>debugging</primary><secondary>hunting the defect</secondary></indexterm>another run; nor did it help setting the other 440 variables. But this is just the situation in which delta <indexterm id="idx-CHP-28-2471" significance="normal"><primary>debugging</primary></indexterm>debugging comes up with the idea of making smaller changes—that is, it tries 220 variables, 110, and so on. Eventually, it isolates the variable that caused the failure: "The compiler crash was caused by a loop in the abstract syntax tree." And this end, of course, justifies the means—in particular, for the people at IBM, who were all pretty busy developing (and debugging) compilers.</para><para>Thus, the demonstration that it worked helped people forget it was a pretty weird approach. Still, my first publication on the topic had a hard time getting accepted. One reviewer frankly admitted he was so appalled by the weird approach, he would not even bother to read on toward the results.</para><para>Nonetheless, finding failure causes in program state was only a detour toward the ultimate end. It was Holger Cleve who gave this technique the ultimate touch. Since he knew the <indexterm id="idx-CHP-28-2472" significance="normal"><primary>debugging</primary><secondary>hunting the defect</secondary><tertiary>tracing failure-causing variables back to statements causing them</tertiary></indexterm>failure-causing variables, he would simply trace back their values to the statements that caused them—and presto! We would end up in the statements that caused the failure: "The statement in line 437 caused a loop, which again caused the failure." Now this was true magic—and this paper had no trouble getting published, either.</para><para>So, as we had a complete automatic debugging solution on our hands, why do people today still use interactive debuggers? Why didn't we go public and become millionaires with automated debugging?</para></sect1><sect1 id="a_prototype_problem" label="28.8"><title>A Prototype Problem</title><para>There is a difference between what you can do in a lab and what you can do in production. The main trouble with our approach was that it was fragile. Very fragile. Extracting accurate program states is a tricky business. Suppose you are working on a C program that just stopped in a debugger. You find a pointer. Does it point to something? If so, what is the C data type of the variable is it pointing to? And how many elements does it point to? In C, all this is left to the discretion of the programmer—and it's awfully hard to guess the memory management used in the program at hand.<indexterm id="idx-CHP-28-2473" significance="normal"><primary>minimizing input</primary><secondary>prototype problem with fragile approach</secondary></indexterm></para><para>Another problem is to determine where the program state ends and the system state begins. Some state is shared between applications, or between applications and the system. Where would we stop extracting and comparing?</para><para>For lab experiments, these issues could be addressed and confined, but for a full-fledged, robust industrial approach, we found them insurmountable. And this is why, today, people still have to use interactive debuggers.<indexterm id="I_indexterm28_tt672" class="endofrange" startref="idx-CHP-28-2465" significance="normal"><primary>debugging</primary><secondary>hunting the defect</secondary></indexterm></para><para>The future is not that bleak, though. Command-line tools that implement delta debugging on input are available. The <emphasis>ddchange</emphasis> plug-in for Eclipse brings delta debugging on changes to your desktop. Researchers apply delta debugging on method calls, nicely integrating capture/replay with test case minimization. And finally, through all these automated approaches, we have gained a much better understanding of how debugging works and how it can be done in a systematic, sometimes even automatic way—a way that is hopefully most effective, and maybe even "beautiful."<indexterm id="idx-CHP-28-2474" significance="normal"><primary>ddchange plug-in for Eclipse</primary></indexterm></para></sect1><sect1 id="conclusion-id016" label="28.9"><title>Conclusion</title><para>If by any chance, you are forced to debug something, you can strive to make your debugging experience as painless as possible. Being systematic (by following the scientific method) helps a lot. Automating the scientific method helps even more. The best thing you can do, though, is invest effort into your code and your development process. By following the advice in this very book, you will write beautiful code—and, as a side effect, also achieve the most beautiful debugging. And what is the most beautiful debugging? Of course: no debugging at all!</para></sect1><sect1 id="acknowledgments-id005" label="28.10"><title>Acknowledgments</title><para>I'd like to thank the students with whom I have experienced beauty in debugging tools. Martin Burger took great part in the AskIgor effort and implemented the <emphasis>ddchange</emphasis> plug-in for Eclipse. Holger Cleve researched and implemented automated isolation of failure-inducing statements. Ralf Hildebrandt implemented isolation of failure-inducing input. Karsten Lehmann contributed to AskIgor and implemented isolation of failure-inducing program states for Java. Dorothea Lütkehaus wrote the original version of <emphasis>ddd</emphasis>. Thomas Zimmermann implemented the graph-comparison algorithms. Christian Lindig and Andrzey Wasylkowski provided helpful comments on earlier revisions of this chapter.</para></sect1><sect1 id="further_reading-id002" label="28.11"><title>Further Reading</title><para>I have compiled my experiences on systematic and automatic debugging in a university course. This is where you can learn more about the scientific method and delta debugging—but also about many more debugging and analysis techniques, such as statistical debugging, automated testing, or static bug detection. All lecture slides and references are available at <ulink url="http://www.whyprogramsfail.com"/>.</para><para>If you are looking specifically for scientific publications of my group, see the delta debugging home page at <ulink url="http://www.st.cs.uni-sb.de/dd"/>.</para><para>Finally, a web search on "delta debugging" will point you to a variety of resources, including further publications and implementations.<indexterm id="I_indexterm28_tt673" class="endofrange" startref="idx-CHP-28-2427" significance="normal"><primary>debugging</primary></indexterm></para></sect1></chapter><chapter id="treating_code_as_an_essay" label="29" role=""><title>Treating Code As an Essay</title><para><emphasis>Yukihiro Matsumoto</emphasis><indexterm id="idx-CHP-29-2475" significance="normal"><primary>errors</primary><secondary>essay</secondary></indexterm><indexterm id="idx-CHP-29-2476" significance="normal"><primary>Matsumoto</primary></indexterm></para><para><emphasis>Programs share some attributes with essays</emphasis>. For essays, the most important question readers ask is, "What is it about?" For programs, the main question is, "What does it do?" In fact, the purpose should be sufficiently clear that neither question ever needs to be uttered. Still, for both essays and computer code, it's always important to look at how each one is written. Even if the idea itself is good, it will be difficult to transmit to the desired audience if it is difficult to understand. The style in which they are written is just as important as their purpose. Both essays and lines <indexterm class="startofrange" id="idx-CHP-29-2477" significance="normal"><primary>readability of code</primary></indexterm>of code are meant—before all else—to be read and understood by human beings.<footnote id="CHP-29-FNOTE-1"><para>This chapter was translated from the Japanese by Nevin Thompson.</para></footnote></para><para>You may ask: "Are human beings actually supposed to be the ones reading computer programs?" The assumption is that people use programs to tell computers what to do, and computers then use compilers or interpreters to compile and understand the code. At the end of the process, the program is translated into machine language that is normally read only by the CPU. That is, of course, the way things work, but this explanation only describes one aspect of computer programs.</para><para>Most programs are not write-once. They are reworked and rewritten again and again in their lives. Bugs must be debugged. Changing requirements and the need for increased functionality mean the program itself may be modified on an ongoing basis. During this process, human beings must be able to read and understand the original code; it is therefore more important by far for humans to be able to understand the program than it is for the computer.</para><para>Computers can, <indexterm id="idx-CHP-29-2478" significance="normal"><primary>readability of code</primary></indexterm>of course, deal with complexity <indexterm id="idx-CHP-29-2479" significance="normal"><primary>brevity in code</primary><secondary>leaving out unnecessary information</secondary></indexterm>without complaint, but this is not the case for human beings. Unreadable code will reduce most people's productivity significantly. On the other hand, easily understandable code will increase it. And we see beauty in such code.</para><para>What makes a computer program readable? In other words, what is beautiful code? Although different people have different standards about what a beautiful program might be, judging the attributes of computer code is not simply a matter of aesthetics. Instead, computer programs are judged according to how well they execute their intended tasks. In other words, "beautiful code" is not an abstract virtue that exists independent of its programmers' efforts. Rather, beautiful code is really meant to help the programmer be happy and productive. This is the metric I use to evaluate the beauty of a program.</para><para><emphasis>Brevity</emphasis> is one element that helps make code beautiful. As Paul Graham says, "Succinctness is power." In the vocabulary of programming, <indexterm id="idx-CHP-29-2480" significance="normal"><primary>Ruby programming language</primary><secondary>beautiful code support</secondary><tertiary>brevity (Hello World example)</tertiary></indexterm>brevity is a virtue. Because there is a definite cost involved in scanning code with the human eye, programs should ideally contain no unnecessary information.<indexterm id="idx-CHP-29-2481" significance="normal"><primary>brevity in code</primary></indexterm></para><para>For example, when type <indexterm id="idx-CHP-29-2482" significance="normal"><primary>declarations</primary></indexterm>declarations are unnecessary, or when the design does not require class <indexterm id="idx-CHP-29-2483" significance="normal"><primary>data types</primary><secondary>skipping declarations when unnecessary</secondary></indexterm>declarations and main routine definitions, brevity mandates that it should be possible to simply avoid them. To illustrate this principle, <xref linkend="hello_world_in_java_versus_ruby"/> shows a <indexterm id="idx-CHP-29-2484" significance="normal"><primary>Java</primary><secondary>Hello World program</secondary></indexterm>Hello World program in Java and Ruby.</para><example id="hello_world_in_java_versus_ruby" label="29-1"><title>"Hello World" in Java versus Ruby</title><informaltable><tgroup cols="2"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><thead><row><entry><para>Java</para></entry><entry><para>Ruby</para></entry></row></thead><tbody><row><entry><para>
<programlisting id="I_programlisting29_tt674" format="linespecific">
class Sample {}
public static void main(String[] argv) {
System.out.println("Hello World");
}
</programlisting></para></entry><entry><para>
<programlisting id="I_programlisting29_tt675" format="linespecific">
print "Hello World\n"
</programlisting></para></entry></row></tbody></tgroup></informaltable></example><para>Both programs accomplish exactly the same task—simply displaying the words "Hello World"—but Java and Ruby approach it in radically different ways. In Ruby's version of the program, all that's necessary is to describe the essence of the task. Print "Hello World". No declaration. No data type. In Java, though, it is necessary to include a variety of descriptions that are not immediately related to our intent. Of course, there is merit in including all of the things that Java does. However, because it is impossible to omit anything, brevity is lost. (To digress a little, Ruby's "Hello World" is trilingual: it also works in Perl and Python.)</para><para>Brevity can also mean the <indexterm id="idx-CHP-29-2485" significance="normal"><primary>brevity in code</primary><secondary>elimination of redundancy</secondary></indexterm>elimination of <indexterm id="idx-CHP-29-2486" significance="normal"><primary>redundancy</primary></indexterm>redundancy. Redundancy is defined as the <indexterm id="idx-CHP-29-2487" significance="normal"><primary>duplication of information in code</primary></indexterm>duplication of information. When information is duplicated, the cost of maintaining consistency can be quite high. And because a considerable amount of time can be spent maintaining consistency, redundancy will lower programming productivity.</para><para>Although it could be argued that redundancy lowers costs when interpreting meaning, the truth is actually the opposite because redundant code contains so much surplus information. One consequence of this extra weight is that the redundant approach relies on the use of supporting tools. Although relying on IDEs to input information has become popular recently, these tools are not intended to help interpret meaning. The real shortcut for developing elegant code is to choose an elegant programming language. Ruby and other lightweight languages like it support this approach.</para><para>In order to eliminate redundancy, we follow the <indexterm id="idx-CHP-29-2488" significance="normal"><primary>DRY principle (Don't Repeat Yourself)</primary></indexterm>DRY principle: <indexterm id="idx-CHP-29-2489" significance="normal"><primary>Don't Repeat Yourself (DRY principle)</primary></indexterm>Don't Repeat Yourself. If the same code exists in multiple places, whatever you're trying to say becomes obscured.</para><para>The concept of DRY is the antithesis of copy-and-paste coding. In the past, some organizations measured productivity by the number of lines <indexterm id="idx-CHP-29-2490" significance="normal"><primary>readability of code</primary></indexterm>of code a programmer produced, so redundancy was actually tacitly encouraged. I've even heard that copying as much code as possible was sometimes considered a virtue. But this is wrong.</para><para>The real virtue, I believe, lies in brevity. The recent popularity of Ruby on <indexterm id="idx-CHP-29-2491" significance="normal"><primary>Rails</primary></indexterm>Rails is driven by its dogged pursuit of <indexterm id="idx-CHP-29-2492" significance="normal"><primary>Ruby programming language</primary><secondary>beautiful code support</secondary><tertiary>brevity and DRY</tertiary></indexterm>brevity and DRY. The Ruby language is serious about "never writing the same thing twice" and "making descriptions concise." Rails inherits this philosophy from the Ruby language.</para><para>A more controversial aspect of beautiful code may be its <emphasis>familiarity</emphasis>. Human beings are more conservative than you might think; most people find it difficult to embrace new concepts or change their ways of thinking. Instead, many prefer to continue suffering rather than change. Most people are unwilling to replace familiar tools or learn a new language without a good reason. Whenever they can, human beings will compare new processes they are trying to learn with what they have always regarded as common sense, with a resulting negative assessment of the new process that may be undeserved.<indexterm id="idx-CHP-29-2493" significance="normal"><primary>familiarity (of beautiful code)</primary></indexterm></para><para>The cost of changing one's ways of thinking is far higher than is commonly thought. In order to easily switch between totally different concepts (for example, from procedural programming to logical or functional programming), it is necessary to become acquainted with a wide variety of concepts. Steep learning curves create pain in humans' brains. Therefore, they reduce programmers' productivity.</para><para>According to this point of view, because Ruby supports the concept of "beautiful code," it is an extremely conservative programming language. While called a pure object-oriented language, Ruby does not use innovative control structures based on object message passing like Smalltalk. Instead, Ruby sticks to traditional control structures programmers are familiar with, such as <literal moreinfo="none">if</literal>, <literal moreinfo="none">while</literal>, etc. It even inherits the <literal moreinfo="none">end</literal> keyword to terminate code blocks from good old Algol-family languages.</para><para>Compared to other contemporary programming languages, <indexterm id="idx-CHP-29-2494" significance="normal"><primary>simplicity in code</primary><secondary>Ruby programming language</secondary></indexterm>Ruby does sometimes look old-fashioned. But it's important to keep in mind that "never be too innovative" is also a key to creating beautiful code.</para><para><emphasis>Simplicity</emphasis> is the next element <indexterm id="idx-CHP-29-2495" significance="normal"><primary>readability of code</primary></indexterm>of beautiful code. We often feel beauty in simple code. If a program is hard to understand, it cannot be considered beautiful. And when programs are obscure rather than comprehensible, the results are bugs, mistakes, and confusion.<indexterm id="idx-CHP-29-2496" significance="normal"><primary>Ruby programming language</primary><secondary>beautiful code support</secondary><tertiary>simplicity</tertiary></indexterm></para><para>Simplicity is one of most misunderstood concepts in programming. People who design languages frequently want to keep those languages simple and clean. While the sentiment is noble, doing this can make programs written in that language more complex. Mike Cowlishaw, who designed the Rexx scripting language at IBM, once pointed out that because language users are more common than language implementers, the needs of the latter must give way to those of the former:</para><blockquote><para>The general principle is that very few people have to implement interpreters or compilers for a language, whereas millions of people have to use and live with the language. One should therefore optimize for the millions, rather than the few. Compiler writers didn't love me for that, because Rexx got to be a hard language to interpret or compile, but I think it has paid off for people in general, certainly programmers in general. <footnote id="CHP-29-FNOTE-2"><para><emphasis>Dr. Dobb's Journal</emphasis>, March 1996.</para></footnote></para></blockquote><para>I agree from the bottom of my heart. Ruby is meant to be the personification of this ideal, and while it is far from simple, it supports simple solutions for programming. Because Ruby is not simple, the programs that use it can be. This is true of other lightweight languages as well; they are not lightweight in the sense of ease of implementation, but they are called lightweight because of their intention to lighten the workload of the programmer.</para><para>To see what this means in practice, consider <indexterm id="idx-CHP-29-2497" significance="normal"><primary>Rake (build tool)</primary></indexterm>Rake, a build tool like <emphasis>make</emphasis> that is widely used by Ruby programmers. Unlike <emphasis>Makefiles</emphasis>, which are written in a single-purpose file format, <emphasis>Rakefiles</emphasis> are written in Ruby, as sort of Domain Specific Language (DSL) with full-featured programmability. <xref linkend="sample_rakefile"/> shows a <emphasis>Rakefile</emphasis> that runs a set of tests.<indexterm id="idx-CHP-29-2498" significance="normal"><primary>Rakefile (example)</primary></indexterm></para><example id="sample_rakefile" label="29-2"><title>Sample Rakefile</title><programlisting format="linespecific">
task :default =&gt; [:test] 
task :test do
  ruby "test/unittest.rb"
end
</programlisting></example><para>The <emphasis>Rakefile</emphasis> takes advantage of the following shortcuts in Ruby syntax:</para><itemizedlist><listitem><para>Parentheses for method arguments can be eliminated.</para></listitem><listitem><para>Unbraced hash key/value pairs can appear at the end of methods.</para></listitem><listitem><para>Code blocks can be attached at the tails of method calls.</para></listitem></itemizedlist><para>You can program in Ruby without these syntax elements, so in theory, they are redundant. They are often criticized for making language more complex. However, <xref linkend="rakefile_without_abbreviated_syntax"/> shows how <xref linkend="sample_rakefile"/> would be written without using these features.</para><example id="rakefile_without_abbreviated_syntax" label="29-3"><title>Rakefile without abbreviated syntax</title><programlisting format="linespecific">
task({:default =&gt; [:test]})
task(:test, &amp;lambda(){
  ruby "test/unittest.rb"
})
</programlisting></example><para>As you can see, if Ruby's syntax were stripped of redundancies, Ruby the language might become more elegant, but programmers would have to do more work, and their programs would be harder to read. So, when simpler tools are used to solve a complex problem, complexity is merely shifted to the programmer, which is really putting the cart before the horse.</para><para>The next important element in the concept of "beautiful code" is flexibility. I define flexibility here as <emphasis>freedom from enforcement from tools</emphasis>. When programmers are forced to do something against their intentions, for the tools' sake, the result is stress. This stress negatively affects the programmer. The end result is far from happiness, and far from beauty as well, according to our definitions of beauty in code. Humans are more valuable than any tools or languages. Computers should serve programmers to maximize their productivity and happiness, but in reality, they often increase the burden instead of lightening it.</para><para><emphasis>Balance</emphasis> is the final element of beautiful code. So far I have talked about brevity, conservatism, simplicity, and flexibility. No element by itself will ensure a beautiful program. When balanced together and kept in mind from the very beginning, each element will work harmoniously with the others to create beautiful code. And if you also make sure to have fun writing and reading code, you will experience happiness as a programmer.</para><para>Happy Hacking!<indexterm id="I_indexterm29_tt676" class="endofrange" startref="idx-CHP-29-2477" significance="normal"><primary>readability of code</primary></indexterm></para></chapter><chapter id="when_a_button_is_all_that_connects_you_to_the_world" label="30" role=""><title>When a Button Is All That Connects You to the World</title><para><emphasis>Arun Mehta</emphasis><indexterm id="idx-CHP-30-2499" significance="normal"><primary>Mehta</primary></indexterm></para><para><emphasis>Professor stephen hawking can only press one button</emphasis>," was the one-line spec we were given.<indexterm id="idx-CHP-30-2500" significance="normal"><primary>Hawking</primary></indexterm></para><para>Professor Hawking, the eminent theoretical physicist, has ALS. This disease is "marked by gradual degeneration of the nerve cells in the central nervous system that control voluntary muscle movement. The disorder causes muscle weakness and atrophy throughout the body."<footnote id="CHP-30-FNOTE-1"><para><ulink url="http://en.wikipedia.org/wiki/Amyotrophic_lateral_sclerosis"/>.</para></footnote> He writes and speaks using the software <indexterm id="idx-CHP-30-2501" significance="normal"><primary>Equalizer</primary></indexterm>Equalizer, which he operates via a single button. It uses an external box for text-to-speech, which is no longer manufactured. The source code for Equalizer has also been lost.</para><para>In order to continue to be able to function should his outdated hardware fail, he approached some software companies, requesting that they write software that might allow persons <indexterm class="startofrange" id="idx-CHP-30-2502" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with extreme <indexterm id="idx-CHP-30-2503" significance="normal"><primary>motor disabilities</primary></indexterm>motor disabilities to access computers. Radiophony, the company that Vickram Crishna and I started, was happy to take up this challenge. We named the software <indexterm class="startofrange" id="idx-CHP-30-2504" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor<footnote id="CHP-30-FNOTE-2"><para>Downloadable from <ulink url="http://holisticit.com/eLocutor/elocutorv3.htm"/><indexterm class="startofrange" id="idx-CHP-30-2505" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>.</para></footnote> and decided to make it free and open source, so that the problem with Equalizer should never reoccur.</para><para>The importance of such software in the life of a disabled person can hardly be overstated. Indeed, Professor Hawking himself is the best example of this. He has been able to become not only one of our leading scientists, but also an immensely successful author and motivator, only because software allows him to write and to speak. Who knows how much genius we have left undiscovered, simply because a child could not speak or write clearly enough for the teacher to understand.</para><para>Professor Hawking still continues to use the software Equalizer, which he has been familiar with for decades. Meanwhile, however, <indexterm id="idx-CHP-30-2506" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor is proving to be useful for persons with a variety of <indexterm id="idx-CHP-30-2507" significance="normal"><primary>motor disabilities</primary></indexterm>disabilities, particularly since it is easily customizable to the changing needs of the individual.</para><para>Our first question, and that of every engineer we explained this problem to, was: could we not find a way to increase the number of inputs Professor Hawking could provide? But his assistant was steadfast: Equalizer worked with a single button, and they saw no reason to change. We too saw the wisdom in writing software for the most extreme case of physical disability, for there were many kinds of binary switch that even a severely disabled person could press, operated by a shoulder, eyebrow, or tongue, or even directly by the brain.<footnote id="CHP-30-FNOTE-3"><para>See, for instance, <ulink url="http://www.brainfingers.com/"/>.</para></footnote> Having devised a solution that the largest possible number of people could use, we might then see how to speed up input for those with greater dexterity.</para><para>We also saw a <indexterm id="idx-CHP-30-2508" significance="normal"><primary>eLocutor</primary><secondary>niche market for wider community</secondary></indexterm>niche market for an adaptation of <indexterm id="idx-CHP-30-2509" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor for a wider community. Software that could be operated using a single button might come in quite handy for mobile phones, for instance: the hands-free attachment typically has only one button. With appropriate text-to-speech conversion to eliminate dependence on the screen, it could also be operated by the driver of a car. Or, for another scenario, imagine sitting in a meeting with a client, and, without taking your eyes off her, you might be able to Google a name she dropped and have the search result unobtrusively spoken into your ear.</para><para>Of course, for a software writer, devising an <indexterm id="idx-CHP-30-2510" significance="normal"><primary>editor operated with a single button</primary></indexterm>editor that functioned efficiently using only a single button was quite an interesting technical challenge. First, we had to pick a basic set of functions for eLocutor to perform. We selected file retrieval and storage, typing, deleting, speaking, scrolling, and searching.</para><para>Next, we had to find ways to perform all these activities using only a single button. This was the most exciting part, for it is not often that a programmer gets to work at the level of designing basic communication paradigms. This is also the activity that takes up most of this chapter.</para><sect1 id="basic_design_model" label="30.1"><title>Basic Design Model</title><para>Needless to say, the software needed to be efficient, so that the user can type quickly without having to click too often. It sometimes takes Professor Hawking minutes to type a single word, so every improvement in editing speed would be useful for a busy man.<indexterm class="startofrange" id="idx-CHP-30-2511" significance="normal"><primary>eLocutor</primary><secondary>basic design model</secondary></indexterm></para><para>The software certainly needed to be highly customizable. The nature and size of the vocabulary of our users might vary vastly. The software would need to be able to adapt to these. Further, we were keen to ensure that the disabled person could change as many settings and configurations as possible herself, without the intervention of a helper.</para><para>Since we had so little by way of job specification to go on, and no experience in writing such software, we expected to make fairly serious changes in the design as our understanding grew. Keeping all these requirements in mind, we decided to write the software in Visual <indexterm id="idx-CHP-30-2512" significance="normal"><primary>eLocutor</primary><secondary>basic design model</secondary></indexterm>Basic version 6, an excellent rapid prototyping tool <indexterm id="idx-CHP-30-2513" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with a large variety of ready-made controls. <indexterm id="idx-CHP-30-2514" significance="normal"><primary>VB (Visual Basic)</primary></indexterm>VB made it easy to build a graphical user interface and provided convenient access to database features.</para><para>Unique to this problem was the unusually high asymmetry in data flow. A user who could see reasonably well would have a large capacity for taking in information. From persons with extreme <indexterm id="idx-CHP-30-2515" significance="normal"><primary>motor disabilities</primary></indexterm>motor disability, however, very little data flowed in the other direction: just the occasional bit.</para><para>The software offers choices one by one to the user, who accepts a choice by clicking when the desired one is presented. The problem is, of course, that there are so many choices at any point. She may wish to type any one of dozens of characters, or save, scroll, find, or delete text. It would take too long if <indexterm id="idx-CHP-30-2516" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor were to cycle through all choices, so it organizes them in <indexterm id="idx-CHP-30-2517" significance="normal"><primary>typing in eLocutor</primary><secondary>speeding up</secondary></indexterm>groups and subgroups, structured as a tree.</para><para>To speed up typing, <indexterm id="idx-CHP-30-2518" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor looks ahead, offering ways to complete the <indexterm id="idx-CHP-30-2519" significance="normal"><primary>word completion in eLocutor</primary></indexterm>word being typed, and choices for the next word and the rest of the phrase. The user needs to be kept aware of these guesses, so that he can spot opportunities for a shortcut, should one become available.</para><para>We therefore decided to create a visual interface in which the elements are dynamically resized or even hidden, depending on what we thought the user might wish to see, in order to present shortcuts that would help her key in the desired sentence speedily. So, when the user is typing, the eLocutor screen contains a window with suggestions for how she might complete the current word, and another window that helps her select the following word. (Groups of punctuation characters are treated as words, too.) If the start of the sentence she is typing is identical to any sentences in the database, they are displayed, too. <xref linkend="the_elocutor_screen"/> shows a typical eLocutor display.</para><para>Sometimes the choices are far too many to fit into a small window. A scan feature helps the user quickly select among them. This opens up a large window, showing all the choices, with smaller groups out of these successively appearing in a smaller window. A word appearing in the large window informs the user that eLocutor is able to offer him a shortcut to typing that word. He now waits for it to appear in the smaller window, when he clicks. The large window disappears, and the choices from the smaller window, about a dozen, now become available to the user through the tree, as usual.</para><figure id="the_elocutor_screen" label="30-1" float="0"><title>The eLocutor screen</title><mediaobject id="I_mediaobject30_tt677"><imageobject role="print"><imagedata fileref="figs/print/beauty_3001.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3001.png" format="PNG"/></imageobject></mediaobject></figure><para>Screen real estate is again rezoned when the user stops typing and starts to scroll the text, at which time the screen displays as much text as it can before and after the insertion point.<indexterm id="idx-CHP-30-2520" significance="normal"><primary>caching</primary><secondary>in eLocutor</secondary></indexterm><indexterm id="idx-CHP-30-2521" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm></para><para>We needed to be as smart in prediction as we could manage, so as to make best possible use of the clicks a disabled user laboriously produces. The intelligence we built in is of three kinds:</para><variablelist><varlistentry><term><emphasis>A relational database</emphasis></term><listitem><para>When the user enters the first few characters of a <indexterm id="idx-CHP-30-2522" significance="normal"><primary>word count program (example)</primary><secondary>parallelized word count program with partitioned processors</secondary><tertiary>word groupings in eLocutor</tertiary></indexterm>word, a search in the dictionary table provides suggestions for how to complete it. An analysis of previous text produced by the user also indicates what word the user might select next.</para></listitem></varlistentry><varlistentry><term><emphasis>A cache</emphasis></term><listitem><para>This takes advantage of patterns in user behavior. We cache not only frequently used words, but also filenames, search terms, spoken text, and paths in decision-making, so that the user can easily reproduce a sequence of steps.</para></listitem></varlistentry><varlistentry><term><emphasis>Special groupings</emphasis></term><listitem><para>This kind of intelligence takes advantage of natural grouping of words, such as city names, food items, parts of speech, etc. These groupings allow the user to construct new sentences out of old ones, by quickly replacing words in commonly used phrases <indexterm id="idx-CHP-30-2523" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with others that are similar. For instance, if the sentence "Please bring me some salt" is in the database, a few clicks allow the construction of "Please take her some sugar."<indexterm id="idx-CHP-30-2524" significance="normal"><primary>groupings of words (eLocutor)</primary></indexterm></para></listitem></varlistentry></variablelist><para>Uniting all the available options is the tree, similar to a menu hierarchy. In the tree, the choices are highlighted one after another, revolving at a fixed rate. The <indexterm id="idx-CHP-30-2525" significance="normal"><primary>tree structure presenting options in eLocutor</primary></indexterm>tree structure also extends naturally to subsets of options, such as the special groupings of words just described.</para><para>The various elements of the screen in <xref linkend="the_elocutor_screen"/> <indexterm id="idx-CHP-30-2526" significance="normal"><primary>eLocutor</primary></indexterm>need some explanation. The active portion of text that the user wishes to edit is shown in the middle box, while the contents of the boxes above and below it adapt to what the user is doing. To the right, and below, are predictions the software makes about what you might wish to type next.</para><para>The text in the upper-righthand corner (shown in red on the user's screen) consists of suggestions for replacing the last word, which are useful if you have typed a few characters of a word and would like <indexterm id="idx-CHP-30-2527" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor to guess the rest. Below that, in black, are suggestions for the next word if you have finished typing the last one. Groups of punctuation characters are treated as words, too, and since the last word consists of alphanumeric characters, the next one will be punctuation characters, as shown on the right side of <xref linkend="the_elocutor_screen"/>.</para><para>When the user is typing sentences similar to ones already typed, the suggestions at the bottom come in handy. The attention of the user, however, is mostly on the tree to the left, which is the only way she can take advantage of all the information on offer to influence the text in the middle box.</para><para>Below the tree, the user can see how many choices of various kinds are available to her, as well as other useful information discussed later.</para><para>The interface moves through the tree sequentially. <indexterm id="idx-CHP-30-2528" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>With the one button at her disposal, the user clicks at the right time when the item she wishes to select is highlighted. The different windows in the screen show the user the options available for the next word, word completion, phrase completion, etc. To take advantage of these options, she must navigate until the corresponding choice is offered to her in the menu tree.</para></sect1><sect1 id="input_interface" label="30.2"><title>Input Interface</title><para>As the single binary input, we selected the <indexterm id="idx-CHP-30-2529" significance="normal"><primary>right mouse button as single binary input for eLocutor</primary></indexterm>right mouse button. This allowed a variety of buttons to easily be connected to eLocutor. By opening up the mouse and soldering the desired button in parallel with the right mouse button, any electrician or hobbyist should be able to make the connection.<indexterm class="startofrange" id="idx-CHP-30-2530" significance="normal"><primary>input interface (eLocutor)</primary></indexterm></para><para><xref linkend="connecting_professor_hawkings_switch_in_parallel_to_the_right_m"/> shows how we made a temporary connection for Professor Hawking's special switch: the circuit board at the left bottom is taken from the inside of a mouse, and the points at which the external switch was soldered are the ones where the right mouse button is connected.<indexterm id="I_indexterm30_tt678" class="endofrange" startref="idx-CHP-30-2511" significance="normal"><primary>eLocutor</primary><secondary>basic design model</secondary></indexterm></para><figure id="connecting_professor_hawkings_switch_in_parallel_to_the_right_m" label="30-2" float="0"><title>Connecting Professor Hawking's switch in parallel to the right mouse button</title><mediaobject id="I_mediaobject30_tt679"><imageobject role="print"><imagedata fileref="figs/print/beauty_3002.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3002.png" format="PNG"/></imageobject></mediaobject></figure><sect2 id="the_tree" label="30.2.1"><title>The Tree</title><para>If you can provide the software only a single binary <indexterm id="idx-CHP-30-2531" significance="normal"><primary>input interface (eLocutor)</primary></indexterm>input, one part of the graphic user interface is obvious: all choices have to be presented turn by turn in the form of a binary tree. At each node, if the user clicks <indexterm id="idx-CHP-30-2532" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>within a fixed time, the interface selects it, which might open up further choices in the form of a subtree. If the user does not click, the software automatically takes him to the next sibling of the node and waits again for a click.<indexterm id="idx-CHP-30-2533" significance="normal"><primary>tree structure presenting options in eLocutor</primary></indexterm></para><para>To implement this tree, we used the Visual Basic <indexterm id="idx-CHP-30-2534" significance="normal"><primary>VB (Visual Basic)</primary><secondary>TreeView control</secondary></indexterm>TreeView control.<footnote id="CHP-30-FNOTE-4"><para><ulink url="http://www.virtualsplat.com/tips/visual-basic-treeview-control.asp"/>.</para></footnote> This should be looked upon as a tree that grows from left to right. If, at any node, you click within a user-selected time interval—which is set using a Timer control—you expand the node and climb up the tree (i.e., move to the right), or, if it is a leaf node, carry out some action. If you don't click, <indexterm id="idx-CHP-30-2535" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor shifts its focus to the next sibling of the node. If the bottom is reached without a click, <indexterm id="idx-CHP-30-2536" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor starts again with the node at the top.</para><para>We populated the tree such that it provides, at each level in the tree, a node called Up that, if selected, takes the highlight to its parent, one level closer to the root.</para><para>The top-level nodes are Type, Scroll, Edit (the primary editing functions), and Commands (miscellaneous). Leaf nodes in the Type subtree enter text into the typing buffer. Those in the Edit subtree delete or copy text from this buffer, while those in the Scroll buffer control the movement of text between buffers.</para><para>The intelligence of eLocutor expresses itself by dynamically repopulating the tree, so that you can relatively quickly find the next action you wish to take: it learns in several different ways from your actions, to be better able to predict in the future.</para><para>The biggest problem <indexterm id="idx-CHP-30-2537" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with binary <indexterm id="idx-CHP-30-2538" significance="normal"><primary>input interface (eLocutor)</primary></indexterm>input is navigation. If you are in the middle of typing and need to delete something at the start of the sentence, it takes a long time to wait for Up many times to get to the root, then down into Scroll to find the correct position to start deleting, then Up several times again to get to the root, then down into Edit for the deletion, then up and down again to scroll to the end, and again to return to typing. We were very relieved to find an answer to this dilemma.</para></sect2><sect2 id="the_long_click" label="30.2.2"><title>The Long Click</title><para>From observing Professor Hawking use Equalizer, I discovered a new mode of operation: besides simply just clicking the button, he could hold down the button and release it at a strategic moment. The button, in effect, is not merely a binary input device, but actually an analog one, for it can provide a signal of varying duration. We thought long and hard about how best to use this new power we were presented with: we could now get more information out of a click than a simple bit. We could, for instance, allow the user to pick from a list of choices. A short click would now be used for the default action, while a <indexterm id="idx-CHP-30-2539" significance="normal"><primary>eLocutor</primary><secondary>input interface</secondary><tertiary>long click</tertiary></indexterm>long click opened up many other options.<indexterm class="startofrange" id="idx-CHP-30-2540" significance="normal"><primary>input interface (eLocutor)</primary><secondary>long click</secondary></indexterm></para><para>Clearly, we wanted to use this newfound power for some extra choices for rapid navigation. We also were delighted with the ability to perform different operations on the text highlighted in the tree, such as to type it, copy it into the filter, etc. Without the long-click ability, we were limited to one action per leaf node, whereas now we could offer the user other choices regarding what to do with the highlighted tree node, which need not even be a leaf node.</para><para>The list of extra choices could not be too large, for that would require the user to hold down the button for relatively long periods of time. Consequently, we wanted these choices to change depending on where in the tree we were. "Type this" for instance, made no sense when we were in the Scroll subtree but was quite handy in the Speller.</para><para>What we came up with was a simple, easy-to-understand mode of operation. Clicking a node performs its default action. But if you keep the button pressed, a separate menu opens up whose options roll by one by one, from which you pick one by releasing the button when the desired choice shows up. We use this a bit like the right-click button under Microsoft Windows, to present the user <indexterm class="startofrange" id="idx-CHP-30-2541" significance="normal"><primary>context-sensitive menu selection in eLocutor long click</primary></indexterm>context-sensitive menu choices. These typically include a jump to the root node of the tree, reverse traversal, etc.</para><para>The importance of this extra mode of operation can hardly be overstated: not only did it substantially increase the speed of text entry and correction, it provided tremendous flexibility to the developers.</para><para>An elegant solution was needed to make the long-click menu context-sensitive, for it would have been too cumbersome to create a special long-click menu for each node of the binary tree. Like the tree, long-click menus are stored in the form of text files, which are editable in <indexterm id="idx-CHP-30-2542" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor. In selecting the appropriate long-click menu, <indexterm id="idx-CHP-30-2543" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor looks to see which node is highlighted. If a text file exists with the same name as the node in the long-click directory, it is picked up as the menu. If it doesn't, eLocutor looks for the name of the node one level above in the tree, and so on.</para><para>In this way, each subtree can have its own long-click menu, entirely under the control of the user. Another way to present this design is to say that unless a child menu item chooses to override the long-click menu defined for its parent, the child automatically inherits the parent's menu.</para><para>Partial code for implementing the <indexterm id="idx-CHP-30-2544" significance="normal"><primary>input interface (eLocutor)</primary><secondary>long click</secondary></indexterm>long click is shown in <xref linkend="implementing_context-sensitive_menu_selection_for_the_long_clic"/>. OpenLongClick-File looks for and opens a file <indexterm id="idx-CHP-30-2545" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with the same name as the parameter passed to it, and if that is not found, recursively looks for one with the name of its parent. Each time the long-click timer times out, a fresh line from this file is displayed in the text box <emphasis>tblongclick</emphasis>. When the button is released, the command in <emphasis>tblongclick</emphasis> is selected. Depending on how long the button is held pressed, the long-click timer runs out repeatedly. Each time the timer runs out, it causes the code in <xref linkend="implementing_context-sensitive_menu_selection_for_the_long_clic"/> to check and set the Boolean variable <literal moreinfo="none">ThisIsALongClick</literal>, and then to execute some code that needs to run only once in each <indexterm id="idx-CHP-30-2546" significance="normal"><primary>eLocutor</primary><secondary>input interface</secondary><tertiary>long click</tertiary></indexterm>long click in order to select and open the appropriate long-click file for reading.</para><para>The portion that repeats upon each expiration of the long-click timer reads a line from the file and displays it in the <emphasis>tblongclick</emphasis> text box. When the file reaches the end, it is closed and reopened, and the first line is read in. When the button is released, <literal moreinfo="none">ThisIsALongClick</literal> is reset.</para><example id="implementing_context-sensitive_menu_selection_for_the_long_clic" label="30-1"><title>Implementing context-sensitive menu selection for the long click</title><programlisting format="linespecific">
Private Sub longclick_Timer()
Dim st As String
Dim filenum As Long
    If Not ThisIsALongClick Then
        ThisIsALongClick = True
        If MenuTree.SelectedItem.Text = stStart Then
        'we are at the root already
            OpenLongClickFile MenuTree.SelectedItem
        Else
            OpenLongClickFile MenuTree.SelectedItem.Parent
'find the list of long-click menu choices suited for this context
        End If
    End If
    If EOF(longclickfilenum) Then
'list of choices finished, cycle to the first one by reopening file
        Close #longclickfilenum
        Open stlongclickfilename For <indexterm id="idx-CHP-30-2547" significance="normal"><primary>input interface (eLocutor)</primary></indexterm>Input As #longclickfilenum
    End If
    Line Input #longclickfilenum, st
    tblongclick = st
End Sub
</programlisting></example><para>Commands made available using the long click include:<indexterm id="idx-CHP-30-2548" significance="normal"><primary>context-sensitive menu selection in eLocutor long click</primary></indexterm></para><variablelist><varlistentry><term><literal moreinfo="none">&gt;Start</literal></term><listitem><para>Takes you to the root of the tree (the &gt; indicates a "go to").</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">Upwards</literal></term><listitem><para>Moves the cursor backward and upward in the tree until the right mouse button is clicked. Useful when you did not press the button when the desired menu choice was highlighted—i.e., you missed your turn.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">Type This</literal></term><listitem><para>Types whatever is highlighted in the tree into the middle box. Available only under the Type subtree.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">Set Filter</literal></term><listitem><para>Copies whatever is highlighted in the tree into the filter; useful for searching text. Also available as a long-click option only when the highlighted item is under the Type subtree.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">Words Up, Words Down</literal></term><listitem><para>For rapid scrolling during typing, described later.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">Pause</literal></term><listitem><para>Useful when a command has to be executed repeatedly. When the user holds the button down for a <indexterm id="idx-CHP-30-2549" significance="normal"><primary>input interface (eLocutor)</primary><secondary>long click</secondary></indexterm>long click, the menu tree freezes, with one of its items highlighted. Selecting the long-click <literal moreinfo="none">Pause</literal> option maintains this state of suspension. Now, each time the user clicks, the command highlighted in the menu tree is executed. To come out of pause, a <indexterm id="idx-CHP-30-2550" significance="normal"><primary>eLocutor</primary><secondary>input interface</secondary><tertiary>long click</tertiary></indexterm>long click must again be used.</para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">Help</literal></term><listitem><para>Opens up and plays a <indexterm id="idx-CHP-30-2551" significance="normal"><primary>context-sensitive menu selection in eLocutor long click</primary></indexterm>context-sensitive <emphasis>.avi</emphasis> video file that explains the choices the tree is offering the user. The Help subdirectory contains a bunch of <emphasis>.avi</emphasis> files. It must contain at least one file, which is called <emphasis>Start.avi</emphasis>. When the Help long-click item is selected, the appropriate <emphasis>.avi</emphasis> file is played, based on where the user currently is in the menu tree.</para></listitem></varlistentry></variablelist><para>The correct file to play is found in a fashion similar to the long-click menu. The software first looks for a file <indexterm id="idx-CHP-30-2552" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with an <emphasis>.avi</emphasis> extension in the <emphasis>helpvideos</emphasis> subdirectory of <emphasis>C:\eLocutor</emphasis>. If such a file is found, it is played; otherwise, <indexterm id="idx-CHP-30-2553" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor looks for an <emphasis>.avi</emphasis> file with the name of the parent of the highlighted node. If an <emphasis>.avi</emphasis> file with this name is not found in the <emphasis>helpvideos</emphasis> directory, eLocutor climbs recursively up the menu tree until it finds a node with a corresponding help video. This feature allowed us to ship only overview videos to start with, and gradually add more and more detailed videos, which the user only needed to copy into the <emphasis>helpvideos</emphasis> subdirectory for eLocutor to start showing them.<indexterm id="idx-CHP-30-2554" significance="normal"><primary>eLocutor</primary></indexterm></para><para>Some help videos are available at <ulink url="http://www.holisticit.com/eLocutor/helpvideos.zip"/>. Given the <indexterm id="idx-CHP-30-2555" significance="normal"><primary>tree structure presenting options in eLocutor</primary><secondary>dynamic repopulation</secondary></indexterm>dynamic nature of this software, watching some videos will help the reader understand this chapter faster and more thoroughly.</para></sect2><sect2 id="dynamic_tree_repopulation" label="30.2.3"><title>Dynamic Tree Repopulation</title><para>The contents of the tree are stored on disk in the form of text files. The big advantage of this approach is that these files can be edited dynamically both by eLocutor and by the user. In other words, they gave us an easy way to meet one of our design criteria: to allow the user herself to adapt eLocutor to her own needs, by making data structures transparent and easily user-editable.<indexterm id="idx-CHP-30-2556" significance="normal"><primary>dynamic tree repopulation in eLocutor</primary></indexterm><indexterm id="I_indexterm30_tt680" class="endofrange" startref="idx-CHP-30-2541" significance="normal"><primary>context-sensitive menu selection in eLocutor long click</primary></indexterm><indexterm id="I_indexterm30_tt681" class="endofrange" startref="idx-CHP-30-2540" significance="normal"><primary>input interface (eLocutor)</primary><secondary>long click</secondary></indexterm></para><para>Because eLocutor tries to predict what you may wish to do next, the binary tree needs to be dynamic; subtrees such as Next Word are frequently repopulated. The name of each file is the same as that of a node (with a <emphasis>.txt</emphasis> extension), and contains a list of names of its immediate children. If any of the node names end in <emphasis>.txt</emphasis>, they represent the root of a sub-tree, and the names of its children can be found in the corresponding file. For instance, the root file is named <emphasis>Start.txt</emphasis> and contains the lines <emphasis>type.txt, edit.txt, scroll.txt</emphasis>, and <emphasis>commands.txt</emphasis>, each line corresponding to a set of options displayed to the user for one of the menus described in the earlier section "The Tree."</para><para>A node name not ending in <emphasis>.txt</emphasis> represents a leaf node. Selecting it results in some action being taken. For instance, if the leaf node is in the Type subtree, its selection results in the corresponding text being typed into the buffer.</para><para>To indicate nodes that are dynamically repopulated, the prefix ^ is used. For instance, the following list shows the contents of <emphasis>type.txt</emphasis>, which form the child nodes of Type in the tree shown in <xref linkend="the_elocutor_screen"/>:<indexterm id="idx-CHP-30-2557" significance="normal"><primary>eLocutor</primary></indexterm></para><programlisting id="I_programlisting30_tt682" format="linespecific">
	commonwords.txt
	speller
	^word completion.txt
	^next word.txt
	suffixes.txt
	^justsaid.txt
	^clipboard.txt
	^phrase completion.txt
	^templates.txt
	vocabularytree.txt
</programlisting><para>Subtrees whose names are prefixed <indexterm id="idx-CHP-30-2558" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with ^ are populated only when the user clicks on the corresponding root node.</para><para>The Visual Basic TreeView control has an <indexterm id="idx-CHP-30-2559" significance="normal"><primary>indexing feature</primary></indexterm>indexing feature to speed up retrieval. This feature made us think of creating nodes in the tree with words as names, grouped together such that siblings in a tree might replace one another in a sentence without making it sound absurd. For instance, a sentence including the word "London" could easily appear in another context with the word "Boston" in its place.</para><para>Using the index in this fashion allowed us to implement two critical features of <indexterm id="idx-CHP-30-2560" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor, Replace and Template, which are discussed shortly. The downside, though, was that we had to live with the limitations of the <indexterm id="idx-CHP-30-2561" significance="normal"><primary>VB (Visual Basic)</primary><secondary>TreeView control</secondary><tertiary>indexing feature speeding up retrieval</tertiary></indexterm>indexing feature of the Tree View control, which does not allow duplicate keys. Nothing prevented us from inserting more than one node with the same name into the tree. Only one of those, however, could be indexed.</para><para>The subnode vocabulary tree of Type is the root node of a large subtree, which groups words that might meaningfully replace one other in a sentence. For Replace and Template to work, these need to be indexed. However, the same word might show up at other places in the tree, perhaps as a suggestion for word completion or a next word. Those instances cannot be indexed. To keep it simple, we decided not to index the contents of dynamically repopulated subtrees.</para><para>Speller is treated as a special case. Its contents are not dynamic. However, the large number of leaf nodes it contains, besides the fact that it contains every word in the vocabulary tree, means it could not be indexed either. It is populated only as needed—i.e., the children of a node in the speller subtree are created only when it is selected.</para></sect2><sect2 id="simple_typing" label="30.2.4"><title>Simple Typing</title><para>The Type subtree contains three nodes that help you do plain typing. Under Speller appear all the letters from a through z, which allow you to pick the first letter of the word you desire. You are then presented similar choices for the next letter, but only if that combination occurs at the start of a word in the dictionary. In this way, you pick letter by letter, until you have the full word. At this point, the node at which you find yourself may or may not be a leaf node. If it is a leaf node, you can type it by simply clicking it. But often it is not.<indexterm id="idx-CHP-30-2562" significance="normal"><primary>eLocutor</primary><secondary>typing</secondary></indexterm><indexterm id="idx-CHP-30-2563" significance="normal"><primary>input interface (eLocutor)</primary><secondary>simple typing</secondary></indexterm><indexterm id="idx-CHP-30-2564" significance="normal"><primary>typing in eLocutor</primary></indexterm></para><para>"Vocabularytree" and "commonwords," described later, are other nodes that make it easy for you to type. However, if the system's prediction feature is working well, which happens if you are trying to make a sentence similar to one in the database, you do not need these facilities often.</para></sect2><sect2 id="prediction_word_completion_and_next_word" label="30.2.5"><title>Prediction: Word Completion and Next Word</title><para>In the <indexterm id="idx-CHP-30-2565" significance="normal"><primary>relational databases</primary><secondary>in eLocutor</secondary><tertiary>predictor databases</tertiary></indexterm>predictor database are several tables. One is a simple list of roughly 250,000 words used to populate the <indexterm id="idx-CHP-30-2566" significance="normal"><primary>prediction</primary><secondary>word completion and next word in eLocutor</secondary></indexterm>Word Completion subtree. A user who has typed one or more starting characters of a word can use this list to type the rest of the word, suggestions for which are shown to the right of the screen, in the above half, as shown in <xref linkend="the_elocutor_screen"/><indexterm id="idx-CHP-30-2567" significance="normal"><primary>eLocutor</primary></indexterm>. This table is available to the user in its entirety via the Speller subtree.<indexterm id="idx-CHP-30-2568" significance="normal"><primary>word completion in eLocutor</primary></indexterm><indexterm id="idx-CHP-30-2569" significance="normal"><primary>next word (in eLocutor)</primary></indexterm></para><para>Say you wish to type the word <emphasis>instant</emphasis>. This is not a leaf node because words such as <emphasis>instantaneous</emphasis> exist that begin <indexterm id="idx-CHP-30-2570" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with <emphasis>instant</emphasis>. Hence, to type <emphasis>instant</emphasis>, you select each of the seven characters in turn, and then when <emphasis>instant</emphasis> is highlighted, you use a long click to invoke the Type This option.</para><para>Another table has the fields <emphasis>word1, word2</emphasis>, and <emphasis>frequency</emphasis>. To populate this table, a long list of sentences are provided to a piece of companion software, <emphasis>dbmanager</emphasis>, which tabulates how often each word follows each other word. Once you have typed a word, this table is queried and the Next Word subtree populated, so that it provides the user a list of words that are likely to follow this one.</para><para>Each sentence entered by the user through <indexterm id="idx-CHP-30-2571" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor is copied into the file <emphasis>mailtomehtaatvsnldotcom.txt</emphasis>. The reason for this filename was to gently encourage the user to mail me samples of text he had generated using eLocutor, so that I might get some ideas about how to make it more efficient. Users are advised to edit this file and remove whatever is inappropriate before feeding it to <emphasis>dbmanager</emphasis>, so that with time, prediction gets better. In case a software writer wishes to implement a better method of predicting the next word, all she has to do is to alter the query in the Access database; there is no need to delve into the eLocutor code for this.<indexterm id="idx-CHP-30-2572" significance="normal"><primary>Mehta</primary></indexterm></para><para>A separate table lists combinations of punctuation characters occurring in the text supplied to the database, which are treated by eLocutor more or less as words.</para><para>It is hard for software to predict what the user might wish to type next, <indexterm id="idx-CHP-30-2573" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>without a knowledge of semantics. We tried talking to linguists to see whether there was a reasonably easy way to make such predictions, but soon gave up. What we did instead was laboriously combine words into semantic groups under the "Vocabulary tree" subtree. For instance, the ancestry of "Boston" in the vocabulary tree is Nouns → Places → Cities. Of course, the user can use this subtree to actually type in words, but that isn't very convenient. The semantic subgroups are better for allowing the user to "fill in the blanks" in the Template and <indexterm id="idx-CHP-30-2574" significance="normal"><primary>Replace feature (eLocutor)</primary></indexterm>Replace features.</para></sect2><sect2 id="templates_and_replace" label="30.2.6"><title>Templates and Replace</title><para>The user can select any sentence out of the database as a template to create new ones. This is done by first typing its starting word or words, and then looking under the Template subtree. At the bottom of the screen in <xref linkend="the_elocutor_screen"/> <indexterm id="idx-CHP-30-2575" significance="normal"><primary>eLocutor</primary></indexterm>are suggestions for completing the phrase or sentence. To populate this list, <indexterm id="idx-CHP-30-2576" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor looks in its database for sentences beginning with what has already been typed since the last sentence terminator. The same suggestions are also available under the Template subtree, with which the user can create new sentences by simply filling in the blanks in old ones. Should there be too many suggestions, a word or phrase can be put into the filter. Only phrases or sentences containing what is in the filter show up.<indexterm id="idx-CHP-30-2577" significance="normal"><primary>input interface (eLocutor)</primary><secondary>Templates and Replace</secondary></indexterm><indexterm id="idx-CHP-30-2578" significance="normal"><primary>Templates (in eLocutor)</primary></indexterm></para><para>eLocutor processes templates by looking at the phrase selected as a template, word by word. Any word in the template not found in the vocabulary tree is directly typed into the buffer. For each word found in the vocabulary tree, using the TreeView indexing feature, eLocutor takes the user to that part of the tree, allowing him to pick it or one of its siblings. So, if the sentence "How are you?" is in the database, the user needs just a few rapid clicks to type, "How is she?" While such "fill in the blanks" is taking place, the portion of the template not yet used is visible in the Template box under the tree.</para><para>The Template feature takes advantage of the logical grouping of words under the vocabulary tree to transform the contents of an entire sentence or phrase. The Replace feature allows the user a similar facility on just a single word, the last one found in the middle box. However, not all words are listed under the vocabulary tree. A text box on the screen is therefore needed to tell the user which category, if any, the word in question is found under. On the screen is a box captioned <literal moreinfo="none">Replace</literal>. If the last word in the buffer is found in the vocabulary tree, the name of its parent is written into the Replace text box.</para><para>For instance, if the last word in the buffer is Boston, the Replace text box contains the word <literal moreinfo="none">Cities</literal>. This tells the user that the software has recognized the category of the last word. If she then selects the Replace command (under the Word Completion subtree), the last word is deleted from the buffer and the user is taken to the place in the vocabulary tree where it was found, allowing her to easily find another city name to replace it with.</para><para>In <xref linkend="the_elocutor_screen"/>, the last word typed is <literal moreinfo="none">We</literal>. The Replace box shows <literal moreinfo="none">subjectpronoun</literal> (which doesn't entirely fit in the space provided). Selecting <literal moreinfo="none">Replace</literal> deletes the <literal moreinfo="none">We</literal> and takes the user to the <literal moreinfo="none">subjectpronoun</literal> subtree, where she could easily select <literal moreinfo="none">You</literal>, for instance.</para></sect2><sect2 id="the_cache_implementation" label="30.2.7"><title>The Cache Implementation</title><para><indexterm id="idx-CHP-30-2579" significance="normal"><primary>caching</primary><secondary>in eLocutor</secondary></indexterm>Caching in <indexterm id="idx-CHP-30-2580" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor relies on the subroutine <indexterm id="idx-CHP-30-2581" significance="normal"><primary>caching</primary><secondary>in eLocutor</secondary><tertiary>SaveReverse subroutine</tertiary></indexterm>SaveReverse, which takes two parameters: the name of the file in which the text is to be saved, and the text itself. The subroutine replaces the file <indexterm id="idx-CHP-30-2582" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with a fresh one, in which the text passed to SaveReverse is the first line of the file, followed by the first 19 lines of the original contents that do not match the first line.<indexterm id="idx-CHP-30-2583" significance="normal"><primary>input interface (eLocutor)</primary><secondary>cache implementation</secondary></indexterm></para><para>This is achieved by first writing the text represented by the variable <literal moreinfo="none">stringtoadd</literal> into the first element of <literal moreinfo="none">starray</literal>, then filling the rest of the array with lines from the file as long as they are not the same as <literal moreinfo="none">stringtoadd (HistoryLength</literal> is a constant of value 20). Finally, the file is opened for writing, which causes its previous contents to be deleted, and the entire contents of <literal moreinfo="none">starray</literal> are copied to the file.</para><para>Thus, if a city name already listed in <emphasis>favouritecities.txt</emphasis> is used, it simply changes position to become the first name in the file. If a new city name is used, it also becomes the first name, followed by the first 19 lines of the previous contents of the file. In other words, the last line of the file is dropped, and it gets a new first line. As the name of the routine suggests, lines of text are saved in reverse, so the last used word becomes the first.</para><para>The code for SaveReverse is shown in <xref linkend="adding_text_to_the_start_of_a_text_file_without_duplication"/>.</para><example id="adding_text_to_the_start_of_a_text_file_without_duplication" label="30-2"><title>Adding text to the start of a text file, without duplication</title><programlisting format="linespecific">
Sub SaveReverse(ByVal filest As String, ByVal stringtoadd As String) 'not
'an append, a prepend...
'with elimination of duplicates
    Dim starray(HistoryLength) As String
    Dim i As Long
    Dim arrlength As Long
    Dim st As String
    Dim filenum As Long
    starray(0) = stringtoadd
    filenum = FreeFile
    i = 1
    On Error GoTo err1
    Open filest For <indexterm id="idx-CHP-30-2584" significance="normal"><primary>input interface (eLocutor)</primary></indexterm>Input As #filenum
    While Not EOF(filenum) And (i &lt; HistoryLength)
        Line Input #filenum, st
        If (st &lt;&gt; stringtoadd) Then 'only save non-duplicates
            starray(i) = st
            i = i + 1
        End If
    Wend
    arrlength = i - 1
    Close #filenum
    Open filest For Output As #filenum       'this deletes the existing file contents
    For i = 0 To arrlength
        Print #filenum, starray(i)
    Next
    Close #filenum
    Exit Sub
err1:
'    MsgBox "error <indexterm id="idx-CHP-30-2585" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with file " + filest
    Open filest For Output As #filenum
    Close #filenum
    Open filest For <indexterm id="idx-CHP-30-2586" significance="normal"><primary>input interface (eLocutor)</primary></indexterm>Input As #filenum        'this creates an empty file if one does 'not
exist
    Resume Next
End Sub
</programlisting></example></sect2><sect2 id="common_words_and_favorites" label="30.2.8"><title>Common Words and Favorites</title><para><indexterm id="idx-CHP-30-2587" significance="normal"><primary>frequently used words in eLocutor</primary></indexterm>Frequently used words are collected in the "<indexterm id="idx-CHP-30-2588" significance="normal"><primary>input interface (eLocutor)</primary><secondary>common words and favorites</secondary></indexterm>common words" subtree, which has two components. Part of this subtree is static, consisting of very frequently used words such as <emphasis>a, and, but</emphasis>, etc. The dynamic part contains additional words frequently used by the user, which are found under its "favouritechoices" subtree.<indexterm id="idx-CHP-30-2589" significance="normal"><primary>common words (in eLocutor)</primary></indexterm><indexterm id="idx-CHP-30-2590" significance="normal"><primary>words</primary></indexterm><indexterm id="idx-CHP-30-2591" significance="normal"><primary>favorites in eLocutor (frequently used words)</primary></indexterm></para><para>The last 20 words found by the user in Speller can be found under its "favouritespeller" subtree. Likewise, if a node exists in the vocabulary tree called "cities," the user needs only to create a blank file, <emphasis>favouritecities.txt</emphasis>. Thereafter, the last 20 selections made by the user of words found under the cities subtree will be available under "favouritecities" in the "favouritechoices" subtree. In this way, the user can decide himself what kind of words, if used frequently, are worth remembering, and how they should be slotted.</para><para><xref linkend="how_elocutor_files_words_already_typed_under_favourites"/> shows the subroutine that creates a new "favourites" and inserts it into the tree. Please note that stfavourite is the constant favorite, and MakeFullFileName returns a proper filename including the path, filename, and <emphasis>.txt</emphasis> extension.</para><example id="how_elocutor_files_words_already_typed_under_favourites" label="30-3"><title>How eLocutor files words already typed under "favourites"</title><programlisting format="linespecific">
Public Sub AddToFavourites(parentnode As Node, stAdd As String)
Dim tempfilename As String
    If parentnode.Text = stStart Then
        Exit Sub
    End If
    tempfilename = MakeFullFileName(App.Path, stfavourite + parentnode.Text)
    If FileExists(tempfilename) Then
        SaveReverse tempfilename, stAdd
    Else
        AddToFavourites parentnode.Parent, stAdd
    End If
End Sub
</programlisting></example><para>Whenever a word is typed, eLocutor looks to see whether it also can be found in the vocabulary tree. Suppose the word Boston has just been typed. In that case, Boston is inserted at the top of the file <emphasis>favouritecities.txt</emphasis>, if it exists, using the subroutine SaveReverse. If not, eLocutor looks for <emphasis>favouriteplaces.txt</emphasis>, because the parent of Cities is Places. If that file doesn't exist, eLocutor tries a higher ancestor. If <emphasis>favouriteplaces.txt</emphasis> does exist, Boston is added to that file using the same subroutine. This provides the user with some control over what the software should consider her "favourites." By creating a file called <emphasis>favouritecities.txt</emphasis>, she is telling eLocutor that she uses city names a lot.<indexterm id="idx-CHP-30-2592" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm><indexterm id="idx-CHP-30-2593" significance="normal"><primary>eLocutor</primary></indexterm></para></sect2><sect2 id="retracing_paths" label="30.2.9"><title>Retracing Paths</title><para>To aid in rapid <indexterm id="idx-CHP-30-2594" significance="normal"><primary>navigation in eLocutor</primary></indexterm>navigation in a rather large tree, <indexterm id="idx-CHP-30-2595" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor automatically remembers, for each subtree in which the user has made a selection, what the user did the last 20 times after making a selection here. These destinations are presented conveniently to the user. Each parent node <literal moreinfo="none">x</literal> has a subtree <literal moreinfo="none">x_</literal>Next. After selecting a leaf node, the user should look under the sibling _Next node and select a destination close to where she wants to go next. Effectively, <indexterm id="idx-CHP-30-2596" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor detects patterns in operations performed by the user and allows her to repeat them easily. The software also remembers the last 20 files that were opened, the last 20 items of text searched for, and the last 20 statements spoken by the user. All of these were easily implemented using SaveReverse.<indexterm id="idx-CHP-30-2597" significance="normal"><primary>input interface (eLocutor)</primary><secondary>retracing paths</secondary></indexterm></para></sect2><sect2 id="the_typing_buffer_editing_and_scrolling" label="30.2.10"><title>The Typing Buffer, Editing, and Scrolling</title><para>There were several different ways we could have handled the scrolling of text, and its selection for cutting and pasting. Most <indexterm id="idx-CHP-30-2598" significance="normal"><primary>editor operated with a single button</primary></indexterm>editors work with a single window. In the case of a large document, of course, the entire text does not fit in the window displayed, and scrollbars are used to navigate through the text. When text needs to be copied or cut, it has to be first selected. The selected text is highlighted using different foreground and background colors. We had some problems with this standard approach.<indexterm id="idx-CHP-30-2599" significance="normal"><primary>input interface (eLocutor)</primary><secondary>typing buffer</secondary></indexterm><indexterm id="idx-CHP-30-2600" significance="normal"><primary>typing in eLocutor</primary></indexterm><indexterm id="idx-CHP-30-2601" significance="normal"><primary>editing text in eLocutor</primary></indexterm></para><para>We wanted eLocutor to also be usable by persons with cerebral palsy, who often have severe <indexterm id="idx-CHP-30-2602" significance="normal"><primary>motor disabilities</primary></indexterm>motor disabilities resulting in speech and vision impairment. For them, we needed to show at least part of the text in a very large font. If we were to use this for all text on the screen, we wouldn't have much on the screen at all. We felt it would be awkward to use a substantially larger font for part of the text in a window. Text highlighted for cutting and pasting by changing background color was found by some to be distracting and difficult to read. Our experience in, and fondness of, audio editing led us to select a different paradigm.</para><para>In the old days, when audio recording was done using spools of tape, the editor would listen to the tape until he found the start of the portion he wanted to cut, clamp it there, then listen for the end of the portion that was to be deleted, and clamp there again. Now, the portion in between the clamps could easily be cut, or replaced with something else. The tape, therefore, is divided by the two clamps into three sections: that before clamp 1, that after clamp 2, and the portion between clamps.</para><para>We adopted the same approach with text, dividing it into three text boxes, with gates between them. Typing is all done at the end of the text in the middle box. This is where the text actually gets inserted and deleted. The Backspace option under Edit deletes text in the middle box from the end. You can decide whether you want to get rid of a character, word, phrase, sentence, paragraph, or the entire middle box.</para><para>If you select Cut or Copy under Edit, the entire text in the middle box is copied into the clipboard. Cut, of course, leaves the middle box empty. To compare this with conventional editors, which allow you to set the beginning and the ending of the block of text you wish to cut or copy, imagine that the block begins at the boundary between the upper and the middle box, and ends at the boundary between the middle box and the lower box. Cut or Copy always lifts the entire contents of the middle box.</para><para>Having the text in multiple boxes in this way allowed us to make more intensive use of screen real estate. We showed the text in the upper box only during <indexterm id="idx-CHP-30-2603" significance="normal"><primary>scrolling in eLocutor</primary></indexterm>scrolling. At other times, we could use it to show the highlighted tree item in large font, as in <xref linkend="the_elocutor_screen"/>, <indexterm id="idx-CHP-30-2604" significance="normal"><primary>eLocutor</primary></indexterm>or the contents of lower levels of the tree to provide the user <indexterm id="idx-CHP-30-2605" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm>with a "look ahead." Similarly, we reused the space for the lower box to display the long-click menu at the appropriate time.</para><para>There was much trial and error in figuring out what worked best, in use of screen real estate. When individual users make special requests with regard to what they wish to view on the screen, we try to accommodate those in the spaces for the upper and lower boxes.</para><para>Analogous to the clamps in audio editing, we have gates. If you wish to cut out a large segment of text, you first scroll until the start of the segment is at the beginning of the middle box. We now close the gate between it at the upper box, so that scrolling does not move text past this boundary: the text is "clamped" at this point. You continue scrolling up or down until the end of the segment you wish to cut is at the end of the middle box. You can now select Cut under Edit.</para><para>Menu choices under Scroll allow one or both gates to be opened. Red and green circles show the status of the gates. In <xref linkend="the_elocutor_screen"/>, <indexterm id="idx-CHP-30-2606" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>both gates are open, indicated by green circles to the left and right of the middle box. Two commands, Text Up and Text Down, are available to move text between the boxes. For text to be able to move between the top and the middle box, or between the middle box and the bottom box, the corresponding gate must be open.</para><para>The amount of text moved by the text up/down commands depends on the marker selected by the user, which can be character, word, punctuation mark, sentence, or paragraph. The scroll marker currently selected is shown on the screen below the tree. Commands are also available to move the entire contents of the text boxes from one to the other.</para><para>In order to be able to scroll a small amount during typing, Words Down and Words Up options are available using the long click. When one of these is selected, words scroll in the selected direction until the right mouse button is clicked again. Note that combinations of punctuation characters are treated as words, too. This allows the user to make quick corrections in the immediate vicinity of the point of insertion or deletion of text, to rapidly scroll a bit while typing.</para></sect2><sect2 id="the_clipboard" label="30.2.11"><title>The Clipboard</title><para>When the user selects Cut or Copy in the Edit subtree, SaveReverse is invoked to prepend the contents of the middle box to the file <emphasis>clipboard.txt</emphasis>, keeping a total of 20 paragraphs. The advantage of this approach is that it allows paragraphs to be easily rearranged, and older cuts to be pasted again and again. In most text <indexterm id="idx-CHP-30-2607" significance="normal"><primary>editor operated with a single button</primary></indexterm>editors, each time Cut or Copy is selected, the previous contents of the clipboard are lost. In <indexterm id="idx-CHP-30-2608" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor, older clipboard information hangs around for a while.<indexterm id="idx-CHP-30-2609" significance="normal"><primary>input interface (eLocutor)</primary><secondary>clipboard</secondary></indexterm><indexterm id="idx-CHP-30-2610" significance="normal"><primary>eLocutor</primary><secondary>input interface</secondary><tertiary>clipboard</tertiary></indexterm><indexterm id="idx-CHP-30-2611" significance="normal"><primary>clipboard</primary></indexterm></para></sect2><sect2 id="searching" label="30.2.12"><title>Searching</title><para>No self-respecting editor can lack a <indexterm id="idx-CHP-30-2612" significance="normal"><primary>eLocutor</primary><secondary>search function</secondary></indexterm>search function, but <indexterm id="idx-CHP-30-2613" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>eLocutor allowed us to look at this basic function afresh. We realized that searching is indeed just a special case of scrolling, so we merely extended our scroll implementation. The user can copy text from the middle box into the filter buffer, or select Set Filter with the desired text highlighted in the tree via a long click. When text is present in the filter, and a scroll command is given, scrolling does not stop until the contents of the filter are also found in the middle box, or the end of text reached.<indexterm id="idx-CHP-30-2614" significance="normal"><primary>eLocutor</primary><secondary>input interface</secondary><tertiary>searching</tertiary></indexterm><indexterm id="idx-CHP-30-2615" significance="normal"><primary>input interface (eLocutor)</primary><secondary>searching</secondary></indexterm></para></sect2><sect2 id="macros" label="30.2.13"><title>Macros</title><para>An interesting point came up in one of our discussions with Professor Hawking's office. They told me he sometimes had problems with Equalizer when delivering a speech, if the lighting made it hard for him to read the screen. Without being able to read the screen, he found it hard to alternately scroll the text, then issue a speak command.<indexterm id="idx-CHP-30-2616" significance="normal"><primary>eLocutor</primary><secondary>input interface</secondary><tertiary>macros</tertiary></indexterm><indexterm id="idx-CHP-30-2617" significance="normal"><primary>input interface (eLocutor)</primary><secondary>macros</secondary></indexterm></para><para>In <indexterm id="idx-CHP-30-2618" significance="normal"><primary>macros</primary><secondary>eLocutor</secondary></indexterm>eLocutor, it already was possible to put the entire text of the speech in the middle box and issue a command to the software to say it, but that was insufficient. People might clap or laugh in the middle, so he needed to be able to wait for them to subside before continuing to deliver the lecture.</para><para>It would not have been hard to build in a function to scroll and speak a sentence each time the user selected a particular menu item, but rather than hardcode this, we thought it would be better to address this problem at a more general level, by providing a macro function that would allow other such combinations to be made in the future.</para><para>In the Commands subtree is a node called Macros, under which all files in the subdirectory <emphasis>C:\eLocutor\macros</emphasis> are listed. If any of these is selected, the file is opened, and the commands listed in it are executed one by one. No complexities are possible in macro design: no jumps, loops, or branching.</para><para>For <indexterm id="idx-CHP-30-2619" significance="normal"><primary>speech delivery in eLocutor</primary></indexterm>speech delivery, we created two short macros, <literal moreinfo="none">preparespeech</literal> and <literal moreinfo="none">scrollspeak</literal>. <literal moreinfo="none">preparespeech</literal> opens both gates if they aren't already, and pushes the entire text into the lower box. Having executed this macro, the user then selects Pause via a long click when <literal moreinfo="none">scrollspeak</literal> is highlighted. All this could be done in advance.</para><para>Once on stage, the user does not need to look at the screen. Each time he now clicks, he executes <literal moreinfo="none">scrollclick</literal>, so that effectively two commands are executed. First is a Text Up command, which sends as much text as decided by the scroll marker from the lower box into the middle box, and from the middle box to the top box. The second command speaks the contents of the middle box. Typically, for speech delivery, the scroll marker would be set to a sentence, so that the speech is delivered a sentence at a time, but if greater flexibility were desired, it could be set to a paragraph as well.<indexterm id="I_indexterm30_tt683" class="endofrange" startref="idx-CHP-30-2530" significance="normal"><primary>input interface (eLocutor)</primary></indexterm></para></sect2></sect1><sect1 id="efficiency_of_the_user_interface" label="30.3"><title>Efficiency of the User Interface</title><para>In order to help in <indexterm id="idx-CHP-30-2620" significance="normal"><primary>prediction</primary><secondary>evaluating efficiency of for typing in eLocutor</secondary></indexterm>evaluating the efficiency of <indexterm id="idx-CHP-30-2621" significance="normal"><primary>eLocutor</primary></indexterm>eLocutor in helping you type, the bottom right of the screen shows two numbers (see <xref linkend="connecting_professor_hawkings_switch_in_parallel_to_the_right_m"/>). These indicate the number of clicks and the number of seconds between the last click and the first, since the middle box was last empty.<indexterm id="idx-CHP-30-2622" significance="normal"><primary>eLocutor</primary><secondary>efficiency of user interface</secondary></indexterm><indexterm id="idx-CHP-30-2623" significance="normal"><primary>input interface (eLocutor)</primary></indexterm></para><para>We found that when the prediction worked reasonably well, the ratio of clicks to characters typed was better than 0.8—i.e., it usually required significantly fewer clicks than an able-bodied person would have needed using a full keyboard. When prediction was poor—for instance when constructing a sentence radically different from any in the database—it required up to twice as many clicks as characters typed.</para></sect1><sect1 id="download" label="30.4"><title>Download</title><para><indexterm id="idx-CHP-30-2624" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm>ELocutor is free, open source software downloadable from <ulink url="http://holisticit.com/eLocutor/elocutorv3.htm"/>. A discussion list is located at <ulink url="http://groups.yahoo.com/group/radiophony"/>.</para><para>Part of the download is the entire source code. I might warn you, though, that it bears some resemblance to a bowl of spaghetti, for which I bear full responsibility. I hadn't programmed for more than 10 years when I started this project, so my skills were outdated and rusty. I did not have a design, only a few hints now and then on the direction in which it should evolve. The code grew with my understanding of the problem, and the results show it. Very simple programming techniques have been used, as is obvious from the code shown in this chapter.</para></sect1><sect1 id="future_directions" label="30.5"><title>Future Directions</title><para>eLocutor was always intended as a rapid application development (RAD) project,<footnote id="CHP-30-FNOTE-5"><para><ulink url="http://en.wikipedia.org/wiki/Rapid_application_development"/>.</para></footnote> something that would allow me to show Professor Hawking during our infrequent and short meetings how far the design had progressed. The intention was to rewrite it some time, after the design could be frozen in the shape of a working prototype that people had actually been using and providing feedback on. At that point, I would pick a programming language that worked across platforms, so that Macs or Linux should also be accessible to those severely <indexterm id="idx-CHP-30-2625" significance="normal"><primary>motor disabilities</primary></indexterm>motor disabled.<indexterm id="idx-CHP-30-2626" significance="normal"><primary>disabled persons</primary><secondary>future directions</secondary></indexterm></para><para>However, inspired by what T. V. Raman achieved with <indexterm id="idx-CHP-30-2627" significance="normal"><primary>Emacs</primary><secondary>Emacspeak</secondary></indexterm>Emacspeak (covered in <xref linkend="emacspeak_the_complete_audio_desktop"/>), I am now considering an entirely different kind of project. Emacs is, of course, not just an <indexterm id="idx-CHP-30-2628" significance="normal"><primary>editor operated with a single button</primary></indexterm>editor, but a very versatile platform that people have extended over the years to allow you to read mail, handle appointments, browse the <indexterm id="idx-CHP-30-2629" significance="normal"><primary>eLocutor</primary><secondary>web sites for download and discussion list</secondary></indexterm>Web, execute shell commands, etc. By merely adding on a smart text-to-speech capability and context-sensitive commands, Raman brilliantly made everything that could be accessed through Emacs accessible to the blind.<indexterm id="I_indexterm30_tt684" class="endofrange" startref="idx-CHP-30-2504" significance="normal"><primary>eLocutor</primary></indexterm><indexterm id="I_indexterm30_tt685" class="endofrange" startref="idx-CHP-30-2505" significance="normal"><primary>disabled persons</primary><secondary>eLocutor</secondary></indexterm></para><para>So, I'm wondering whether the same can be done for the motor disabled. Advantages of this approach are:</para><itemizedlist><listitem><para>Designers would no longer have to worry about the mouse, for Emacs allows you to do everything without it.</para></listitem><listitem><para>eLocutor wouldn't just be an accessible editor, but would rather make all the capabilities of the computer accessible.</para></listitem><listitem><para>I might also find more support this way among the open source developer community, which seems to be far better on platforms historically associated closely with Emacs use than in the MS Windows world.</para></listitem></itemizedlist><para>I am therefore appealing to readers of this chapter to teach me how to extend Emacs such that the same one-button navigation of a tree becomes possible. Better still would be someone wishing to take up this project with whatever help I might be able to provide.</para><para>Another direction to take this software would be to address the enormous problem of children who become disabled in the first years of life, such as those with cerebral palsy and severe autism, who typically do not get an education because they cannot communicate back to the teacher in a normal classroom. If such a child could communicate via software, she might be able to attend normal school.</para><para>Here, the challenge for the software writer is even greater. Normally, you assume that a person using a computer is literate. In this case, the child has to be able to use a computer in order to <emphasis>become</emphasis> literate. The software we write must appeal to a child enough to entice her to use it as her primary means of communicating with the world, before she can read. What a daunting, yet hugely interesting task! Of course, the software would be great in teaching any child how to use a computer at a very early age, not just disabled kids. Anyone willing to collaborate?<indexterm id="I_indexterm30_tt686" class="endofrange" startref="idx-CHP-30-2502" significance="normal"><primary>software</primary><secondary>operated with a single button</secondary></indexterm></para></sect1></chapter><chapter id="emacspeak_the_complete_audio_desktop" label="31" role=""><title>Emacspeak: The Complete Audio Desktop</title><para><emphasis>T. V. Raman</emphasis><indexterm id="idx-CHP-31-2630" significance="normal"><primary>Raman</primary></indexterm></para><para><emphasis>A desktop is a workspace that one uses to organize the tools of one's trade</emphasis>. Graphical desktops provide rich visual interaction for performing day-to-day computing tasks; the goal of the <emphasis>audio desktop</emphasis> is to enable similar efficiencies in an eyes-free environment. Thus, the primary goal of an audio desktop is to use the expressiveness of auditory output (both verbal and nonverbal) to enable the end user to perform a full range of computing tasks:</para><itemizedlist><listitem><para>Communication through the full range of electronic messaging services</para></listitem><listitem><para>Ready access to local documents on the client and global documents on the Web</para></listitem><listitem><para>Ability to develop software effectively in an eyes-free environment</para></listitem></itemizedlist><para>The <indexterm class="startofrange" id="idx-CHP-31-2631" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak audio desktop was motivated by the following insight: to provide effective auditory renderings of information, one needs to start from the actual information being presented, rather than a visual presentation of that information. This had earlier led me to develop <indexterm id="idx-CHP-31-2632" significance="normal"><primary>AsTeR (Audio System For Technical Readings)</primary></indexterm>AsTeR, Audio System For Technical Readings (<ulink url="http://emacspeak.sf.net/raman/aster/aster-toplevel.html"/>). The primary motivation then was to apply the lessons learned in the context of aural documents to user interfaces—after all, the document <emphasis>is</emphasis> the interface.</para><para>The primary goal was not to merely carry the visual interface over to the auditory modality, but rather to create an eyes-free user interface that is both pleasant and productive to use.</para><para>Contrast this with the traditional screen-reader approach where GUI widgets such as sliders and tree controls are directly translated to <indexterm id="idx-CHP-31-2633" significance="normal"><primary>spoken output</primary></indexterm>spoken output. Though such direct translation can give the appearance of providing full eyes-free access, the resulting auditory user interface can be inefficient to use.</para><para>These prerequisites meant that the environment selected for the audio desktop needed:</para><itemizedlist><listitem><para>A core set of speech and nonspeech audio output services</para></listitem><listitem><para>A rich suite of pre-existing applications to speech-enable</para></listitem><listitem><para>Access to application context to produce contextual feedback</para></listitem></itemizedlist><sect1 id="producing_spoken_output" label="31.1"><title>Producing Spoken Output</title><para>I started implementing <indexterm id="idx-CHP-31-2634" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak in October 1994. The target environments were a Linux laptop and my office workstation. To produce speech output, I used a <indexterm id="idx-CHP-31-2635" significance="normal"><primary>DECTalk Express</primary></indexterm>DECTalk Express (a <indexterm id="idx-CHP-31-2636" significance="normal"><primary>hardware speech synthesizer (DECTalk Express)</primary></indexterm>hardware speech synthesizer) on the laptop and a software version of the DECTalk on the office workstation.<indexterm id="idx-CHP-31-2637" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>producing spoken output</secondary></indexterm></para><para>The most natural way to design the system to leverage both speech options was to first implement a speech server that abstracted away the distinction between the two output solutions. The speech server abstraction has withstood the test of time well; I was able to add support for the IBM ViaVoice engine later, in 1999. Moreover, the simplicity of the client/server API has enabled open source programmers to implement <indexterm id="idx-CHP-31-2638" significance="normal"><primary>speech servers</primary></indexterm>speech servers for other speech engines.</para><para><indexterm id="idx-CHP-31-2639" significance="normal"><primary>client/server software</primary><secondary>Emacspeak speech servers and Emacspeak client</secondary></indexterm>Emacspeak speech servers are implemented in the <indexterm id="idx-CHP-31-2640" significance="normal"><primary>TCL language</primary></indexterm>TCL language. The speech server for the DECTalk Express communicated with the hardware synthesizer over a serial line. As an example, the command to speak a string of text was a <literal moreinfo="none">proc</literal> that took a string argument and wrote it to the serial device. A simplified version of this looks like:</para><programlisting id="I_programlisting31_tt687" format="linespecific">
	proc tts_say {text} {puts -nonewline $tts(write) "$text"}
</programlisting><para>The speech server for the software DECTalk implemented an equivalent, simplified <literal moreinfo="none">tts_say</literal> version that looks like:</para><programlisting id="I_programlisting31_tt688" format="linespecific">
	proc say {text} {_say "$text"}
</programlisting><para>where <literal moreinfo="none">_say</literal> calls the underlying C implementation provided by the DECTalk software.</para><para>The net result of this design was to create separate speech servers for each available engine, where each speech server was a simple script that invoked TCL's default readeval-print loop after loading in the relevant definitions. The client/server API therefore came down to the client (Emacspeak) launching the appropriate speech server, caching this connection, and invoking server commands by issuing appropriate procedure calls over this connection.</para><para>Notice that so far I have said nothing explicit about how this client/server connection was opened; this late-binding proved beneficial later when it came to making Emacspeak network-aware. Thus, the initial implementation worked by the <indexterm id="idx-CHP-31-2641" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak client communicating to the speech server using <literal moreinfo="none">stdio</literal>. Later, making this client/server communication go over the network required the addition of a few lines of code that opened a server socket and connected <literal moreinfo="none">stdin/stdout</literal> to the resulting connection.</para><para>Thus, designing a clean client/server abstraction, and relying on the power of Unix I/O, has made it trivial to later run Emacspeak on a remote machine and have it connect back to a speech server running on a local client. This enables me to run Emacspeak inside <emphasis>screen</emphasis> on my work machine, and access this running session from anywhere in the world. Upon connecting, I have the remote Emacspeak session connect to a speech server on my laptop, the audio equivalent of setting up X to use a remote display.</para></sect1><sect1 id="speech-enabling_emacs" label="31.2"><title>Speech-Enabling Emacs</title><para>The simplicity of the speech server abstraction described above meant that version 0 of the speech server was running within an hour after I started <indexterm id="idx-CHP-31-2642" significance="normal"><primary>speech-enabling Emacs</primary><secondary>implementing event queue in speech server</secondary></indexterm>implementing the system. This meant that I could then move on to the more interesting part of the project: producing good quality spoken output. Version 0 of the speech server was by no means perfect; it was improved as I built the Emacspeak speech client.<indexterm class="startofrange" id="idx-CHP-31-2643" significance="normal"><primary>speech-enabling Emacs</primary></indexterm></para><sect2 id="a_simple_first-cut_implementation" label="31.2.1"><title>A Simple First-Cut Implementation</title><para>A friend of mine had pointed me at the marvels of Emacs Lisp <emphasis>advice</emphasis> a few weeks earlier. Som when I sat down to speech-enable Emacs, <emphasis>advice</emphasis> was the natural choice. The first task was to have Emacs automatically speak the line under the cursor whenever the user pressed the up/down arrow keys.<indexterm id="idx-CHP-31-2644" significance="normal"><primary>speech-enabling Emacs</primary><secondary>first-cut implementation</secondary></indexterm><indexterm id="idx-CHP-31-2645" significance="normal"><primary>advice (Emacs LISP)</primary></indexterm><indexterm id="idx-CHP-31-2646" significance="normal"><primary>LISP</primary><secondary>advice</secondary></indexterm></para><para>In Emacs, all user actions invoke appropriate Emacs Lisp functions. In standard editing modes, pressing the down arrow invokes function <literal moreinfo="none">next-line</literal>, while pressing the up arrow invokes <literal moreinfo="none">previous-line</literal>. To speech-enable these commands, version 0 of Emacspeak implemented the following rather simple advice fragment:</para><programlisting id="I_programlisting31_tt689" format="linespecific">
	(defadvice next-line (after emacspeak)
	  "Speak line after moving."
	  (when (interactive-p) (<indexterm id="idx-CHP-31-2647" significance="normal"><primary>emacspeak-speak-line function</primary></indexterm>emacspeak-speak-line)))
</programlisting><para>The <literal moreinfo="none">emacspeak-speak-line</literal> function implemented the necessary logic to grab the text of the line under the cursor and send it to the speech server. With the previous definition in place, Emacspeak 0.0 was up and running; it provided the scaffolding for building the actual system.</para></sect2><sect2 id="iterating_on_the_first-cut_implementation" label="31.2.2"><title>Iterating on the First-Cut Implementation</title><para>The next iteration returned to the speech server to enhance it with a well-defined <indexterm id="idx-CHP-31-2648" significance="normal"><primary>event queue</primary></indexterm>eventing loop. Rather than simply executing each speech command as it was received, the speech server queued client requests and provided a <literal moreinfo="none">launch</literal> command that caused the server to execute queued requests.<indexterm id="idx-CHP-31-2649" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>speech-enabling Emacs</secondary><tertiary>first-cut implementation</tertiary></indexterm></para><para>The server used the <literal moreinfo="none">select</literal> system call to check for newly arrived commands after sending each clause to the speech engine. This enabled immediate silencing of speech; with the somewhat naïve implementation described in version 0 of the speech server, the command to stop speech would not take immediate effect since the speech server would first process previously issued <literal moreinfo="none">speak</literal> commands to completion. With the speech queue in place, the client application could now queue up arbitrary amounts of <indexterm id="idx-CHP-31-2650" significance="normal"><primary>text</primary></indexterm>text and still get a high degree of responsiveness when issuing higher-priority commands such as requests to stop speech.</para><para>Implementing an event queue inside the speech server also gave the client application finer control over how text was split into chunks before synthesis. This turns out to be crucial for producing good <indexterm id="idx-CHP-31-2651" significance="normal"><primary>intonation in speech</primary></indexterm>intonation structure. The rules by which text should be split up into clauses varies depending on the nature of the text being spoken. As an example, newline characters in programming languages such as Python are statement delimiters and determine clause boundaries, but newlines do not constitute clause delimiters in English text.</para><para>As an example, a clause boundary is inserted after each line when speaking the following Python code:</para><programlisting id="I_programlisting31_tt690" format="linespecific">
	i=1
	j=2
</programlisting><para>See the section "Augmenting <indexterm id="idx-CHP-31-2652" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>Emacs to create aural display lists," later in this chapter, for details on how Python code is distinguished and its semantics are transferred to the speech layer.</para><para>With the speech server now capable of smart text handling, the <indexterm id="idx-CHP-31-2653" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak client could become more sophisticated with respect to its handling of text. The <literal moreinfo="none">emacspeak-speak-line</literal> function turned into a library of speech-generation functions that implemented the following steps:</para><itemizedlist><listitem><para>Parse text to split it into a sequence of clauses.</para></listitem><listitem><para>Preprocess text—e.g., handle repeated strings of punctuation marks.</para></listitem><listitem><para>Carry out a number of other functions that got added over time.</para></listitem><listitem><para>Queue each clause to the speech server, and issue the <literal moreinfo="none">launch</literal> command.</para></listitem></itemizedlist><para>From here on, the rest of Emacspeak was implemented using Emacspeak as the development environment. This has been significant in how the code base has evolved. New features are tested immediately because badly implemented features can render the entire system unusable. Lisp's incremental code development fits naturally with the former; to cover the latter, the Emacspeak code base has evolved to be "bushy"—i.e., most parts of the higher-level system are mutually independent and depend on a small core that is carefully maintained.</para></sect2><sect2 id="a_brief_advice_tutorial" label="31.2.3"><title>A Brief advice Tutorial</title><para>Lisp <emphasis>advice</emphasis> is key to the <indexterm id="idx-CHP-31-2654" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak implementation, and this chapter would not be complete without a brief overview. The <emphasis>advice</emphasis> facility allows one to modify existing functions <emphasis>without changing the original implementation</emphasis>. What's more, once a function <literal moreinfo="none">f</literal> has been modified by <emphasis>advice</emphasis> <literal moreinfo="none">m</literal>, all calls to function <literal moreinfo="none">f</literal> are affected by <emphasis>advice</emphasis>.<indexterm id="idx-CHP-31-2655" significance="normal"><primary>speech-enabling Emacs</primary><secondary>advice tutorial</secondary></indexterm><indexterm id="idx-CHP-31-2656" significance="normal"><primary>advice (Emacs LISP)</primary><secondary>tutorial</secondary></indexterm></para><para><emphasis>advice</emphasis> comes in three flavors:</para><variablelist><varlistentry><term><literal moreinfo="none">before</literal></term><listitem><para>The advice body is run <emphasis>before</emphasis> the original function is invoked.<indexterm id="idx-CHP-31-2657" significance="normal"><primary>before advice (Emacs LISP)</primary></indexterm></para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">after</literal></term><listitem><para>The advice body is run <emphasis>after</emphasis> the original function has completed.<indexterm id="idx-CHP-31-2658" significance="normal"><primary>after advice (Emacs LISP)</primary></indexterm></para></listitem></varlistentry><varlistentry><term><literal moreinfo="none">around</literal></term><listitem><para>The advice body is run <emphasis>instead of</emphasis> the original function. The <literal moreinfo="none">around</literal> advice can call the original function if desired.<indexterm id="idx-CHP-31-2659" significance="normal"><primary>around advice (Emacs LISP)</primary></indexterm></para></listitem></varlistentry></variablelist><para>All <emphasis>advice</emphasis> forms get access to the arguments of the <emphasis>adviced</emphasis> function; in addition, <literal moreinfo="none">around</literal> and after get access to the return value computed by the original function. The Lisp implementation achieves this magic by:<indexterm id="idx-CHP-31-2660" significance="normal"><primary>adviced function (LISP)</primary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Caching the original implementation of the function</para></listitem><listitem><para>Evaluating the advice form to generate a new function definition</para></listitem><listitem><para>Storing this definition as the <emphasis>adviced</emphasis> function</para></listitem></orderedlist><para>Thus, when the <emphasis>advice</emphasis> fragment shown in the earlier section "A Simple First-Cut Implementation" is evaluated, <indexterm id="idx-CHP-31-2661" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>Emacs' original <literal moreinfo="none">next-line</literal> function is replaced by a modified version that speaks the current line <emphasis>after</emphasis> the original <literal moreinfo="none">next-line</literal> function has completed its work.</para></sect2><sect2 id="generating_rich_auditory_output" label="31.2.4"><title>Generating Rich Auditory Output</title><para>At this point in its evolution, here is what the overall design looked like:<indexterm class="startofrange" id="idx-CHP-31-2662" significance="normal"><primary>speech-enabling Emacs</primary><secondary>generating rich auditory output</secondary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Emacs' interactive commands are speech-enabled or <emphasis>adviced</emphasis> to produce auditory output.</para></listitem><listitem><para><emphasis>advice</emphasis> definitions are collected into modules, one each for every Emacs application being speech-enabled.</para></listitem><listitem><para>The <emphasis>advice</emphasis> forms forward text to core speech functions.</para></listitem><listitem><para>These functions extract the text to be spoken and forward it to the <literal moreinfo="none">tts-speak</literal> function.<indexterm id="idx-CHP-31-2663" significance="normal"><primary>tts-speak function</primary></indexterm></para></listitem><listitem><para>The <literal moreinfo="none">tts-speak</literal> function produces auditory output by preprocessing its <literal moreinfo="none">text</literal> argument and sending it to the speech server.</para></listitem><listitem><para>The speech server handles queued requests to produce perceptible output.</para></listitem></orderedlist><para>Text is preprocessed by placing the text in a special scratch buffer. Buffers acquire specialized behavior via buffer-specific <emphasis>syntax tables</emphasis> that define the <emphasis>grammar</emphasis> of buffer contents and buffer-local variables that affect behavior. When text is handed off to the <indexterm id="idx-CHP-31-2664" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak core, all of these buffer-specific settings are propagated to the special scratch buffer where the text is preprocessed. This automatically ensures that text is meaningfully parsed into clauses based on its underlying grammar.</para><sect3 id="audio_formatting_using_voice-lock" label="31.2.4.1"><title>Audio formatting using voice-lock</title><para><indexterm id="idx-CHP-31-2665" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>Emacs uses <literal moreinfo="none">font-lock</literal> to syntactically color text. For creating the visual presentation, Emacs adds a text property called <literal moreinfo="none">face</literal> to text strings; the value of this <literal moreinfo="none">face</literal> property specifies the font, color, and style to be used to display that text. Text strings with <literal moreinfo="none">face</literal> properties can be thought of as a conceptual <emphasis>visual display list</emphasis>.<indexterm id="idx-CHP-31-2666" significance="normal"><primary>audio formatting using voice-lock (Emacspeak)</primary></indexterm></para><para>Emacspeak augments these visual display lists with <literal moreinfo="none">personality</literal> text properties whose values specify the auditory properties to use when rendering a given piece of text; this is called <literal moreinfo="none">voice-lock</literal> in Emacspeak. The value of the <literal moreinfo="none">personality</literal> property is an Aural CSS (ACSS) setting that encodes various voice properties—e.g., the pitch of the speaking voice. Notice that such ACSS settings are not specific to any given TTS engine. Emacspeak implements ACSS-to-TTS <indexterm id="idx-CHP-31-2667" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>mappings to TTS engines</secondary></indexterm>mappings in engine-specific modules that take care of mapping high-level aural properties—e.g., mapping <literal moreinfo="none">pitch</literal> or <literal moreinfo="none">pitch-range</literal> to engine-specific control codes.<indexterm id="idx-CHP-31-2668" significance="normal"><primary>personality text properties (Emacspeak)</primary></indexterm></para><para>The next few sections describe how Emacspeak augments Emacs to create aural display lists and to process these aural display lists to produce engine-specific output.</para></sect3><sect3 id="augmenting_emacs_to_create_aural_display_lists" label="31.2.4.2"><title>Augmenting Emacs to create aural display lists</title><para>Emacs modules that implement <literal moreinfo="none">font-lock</literal> call the Emacs built-in function <literal moreinfo="none">put-text-property</literal> to attach the relevant <literal moreinfo="none">face</literal> property. Emacspeak defines an advice fragment that <emphasis>advices</emphasis> the <literal moreinfo="none">put-text-property</literal> function to add in the corresponding <literal moreinfo="none">personality</literal> property when it is asked to add a face property. Note that the value of both display properties (<literal moreinfo="none">face</literal> and <literal moreinfo="none">personality</literal>) can be lists; values of these properties are thus designed to <emphasis>cascade</emphasis> to create the final (visual or auditory) presentation. This also means that different parts of an application can progressively add display property values.<indexterm class="startofrange" id="idx-CHP-31-2669" significance="normal"><primary>aural display lists</primary><secondary>augmenting Emacs to create</secondary></indexterm><indexterm id="idx-CHP-31-2670" significance="normal"><primary>put-text-property function</primary></indexterm></para><para>The <literal moreinfo="none">put-text-property</literal> function has the following signature:</para><programlisting id="I_programlisting31_tt691" format="linespecific">
	(put-text-property START END PROPERTY VALUE &amp;optional OBJECT)
</programlisting><para>The <emphasis>advice</emphasis> implementation is:</para><programlisting id="I_programlisting31_tt692" format="linespecific">
	(defadvice put-text-property (after emacspeak-personality pre act)
	  "Used by emacspeak to augment font lock."
	  (let ((start (ad-get-arg 0)) ;; Bind arguments
	        (end (ad-get-arg 1 ))
	        (prop (ad-get-arg 2)) ;; name of property being added
	        (value (ad-get-arg 3 ))
	        (object (ad-get-arg 4))
	        (voice nil))                   ;; voice it maps to
	    (when (and (eq prop 'face)      ;; avoid infinite recursion
	               (not (= start end))  ;; non-nil text range
	               <indexterm id="idx-CHP-31-2671" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>emacspeak-personality-voiceify-faces)
	      (condition-case nil ;; safely look up face mapping
	          (progn
	            (cond
	             ((symbolp value)
	              (setq voice (voice-setup-get-voice-for-face value)))
	             ((ems-plain-cons-p value)) ;;pass on plain cons
	             ( (listp value)
	               (setq voice
	                     (delq nil
	                           (mapcar   #'voice-setup-get-voice-for-face value))))
	             (t (message "Got %s" value)))
	            (when voice ;; voice holds list of personalities
	              (funcall <indexterm id="idx-CHP-31-2672" significance="normal"><primary>emacspeak-personality-voiceify-faces variable</primary></indexterm>emacspeak-personality-voiceify-faces start end voice object)))
	        (error nil)))))
</programlisting><para>Here is a brief explanation of this <emphasis>advice</emphasis> definition:</para><variablelist><varlistentry><term><emphasis>Bind arguments</emphasis></term><listitem><para>First, the function uses the <emphasis>advice</emphasis> built-in <literal moreinfo="none">ad-get-arg</literal> to locally bind a set of lexical variables to the arguments being passed to the <emphasis>adviced</emphasis> function.</para></listitem></varlistentry><varlistentry><term><emphasis>Personality setter</emphasis></term><listitem><para>The mapping of faces to personalities is controlled by user customizable variable <literal moreinfo="none">emacspeak-personality-voiceify-faces</literal>. If non-nil, this variable specifies a function with the following signature:<indexterm id="idx-CHP-31-2673" significance="normal"><primary>speech-enabling Emacs</primary></indexterm></para><programlisting id="I_programlisting31_tt693" format="linespecific">
	(<indexterm id="idx-CHP-31-2674" significance="normal"><primary>aural display lists</primary><secondary>augmenting Emacs to create</secondary></indexterm>emacspeak-personality-put START END PERSONALITY OBJECT)
</programlisting><para>Emacspeak provides different implementations of this function that either append or prepend the new personality value to any existing personality properties.</para></listitem></varlistentry><varlistentry><term><emphasis>Guard</emphasis></term><listitem><para>Along with checking for a non-nil <literal moreinfo="none">emacspeak-personality-voiceify-faces</literal>, the function performs additional checks to determine whether this advice definition should do anything. The function continues to act if:</para><itemizedlist><listitem><para>The text range is non-nil.</para></listitem><listitem><para>The property being added is a <literal moreinfo="none">face</literal>.</para></listitem></itemizedlist><para>The first of these checks is required to avoid edge cases where <literal moreinfo="none">put-text-property</literal> is called with a zero-length text range. The second ensures that we attempt to add the <literal moreinfo="none">personality</literal> property only when the property being added is <literal moreinfo="none">face</literal>. Notice that failure to include this second test would cause infinite recursion because the eventual <literal moreinfo="none">put-text-property</literal> call that adds the <literal moreinfo="none">personality</literal> property also triggers the advice definition.</para></listitem></varlistentry><varlistentry><term><emphasis>Get mapping</emphasis></term><listitem><para>Next, the function <emphasis>safely</emphasis> looks up the voice mapping of the face (or faces) being applied. If applying a single <literal moreinfo="none">face</literal>, the function looks up the corresponding personality mapping; if applying a list of faces, it creates a corresponding list of personalities.</para></listitem></varlistentry><varlistentry><term><emphasis>Apply personality</emphasis></term><listitem><para>Finally, the function checks that it found a valid voice mapping and, if so, calls <literal moreinfo="none">emacspeak-personality-voiceify-faces</literal> with the set of personalities saved in the <literal moreinfo="none">voice</literal> variable.<indexterm id="idx-CHP-31-2675" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm></para></listitem></varlistentry></variablelist></sect3><sect3 id="audio-formatted_output_from_aural_display_lists" label="31.2.4.3"><title>Audio-formatted output from aural display lists</title><para>With the <emphasis>advice</emphasis> definitions from the previous section in place, text fragments that are visually styled acquire a corresponding <literal moreinfo="none">personality</literal> property that holds an ACSS setting for audio formatting the content. The result is to turn text in <indexterm id="idx-CHP-31-2676" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>Emacs into <indexterm id="idx-CHP-31-2677" significance="normal"><primary>speech-enabling Emacs</primary><secondary>generating rich auditory output</secondary></indexterm>rich aural display lists. This section describes how the output layer of <indexterm id="idx-CHP-31-2678" significance="normal"><primary>aural display lists</primary><secondary>augmenting Emacs to create</secondary></indexterm>Emacspeak is enhanced to convert these aural display lists into perceptible spoken output.<indexterm id="idx-CHP-31-2679" significance="normal"><primary>aural display lists</primary><secondary>audio-formatted output from</secondary></indexterm></para><para>The Emacspeak <literal moreinfo="none">tts-speak</literal> module handles <indexterm id="idx-CHP-31-2680" significance="normal"><primary>text preprocessing before sending to speech server (Emacspeak tts-speak)</primary></indexterm>text preprocessing before finally sending it to the speech server. As described earlier, this preprocessing comprises a number of steps, including:<indexterm id="idx-CHP-31-2681" significance="normal"><primary>tts-speak module (Emacspeak)</primary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Applying <indexterm id="idx-CHP-31-2682" significance="normal"><primary>pronunciation rules (text preprocessing in Emacspeak)</primary></indexterm>pronunciation rules</para></listitem><listitem><para>Processing repeated strings of <indexterm id="idx-CHP-31-2683" significance="normal"><primary>punctuation characters</primary></indexterm>punctuation characters</para></listitem><listitem><para><indexterm id="idx-CHP-31-2684" significance="normal"><primary>splitting text into appropriate clauses (Emacspeak)</primary></indexterm>Splitting text into appropriate clauses based on context</para></listitem><listitem><para><indexterm id="idx-CHP-31-2685" significance="normal"><primary>personality text properties (Emacspeak)</primary><secondary>converting into audio formatting codes</secondary></indexterm>Converting the <literal moreinfo="none">personality</literal> property into <indexterm id="idx-CHP-31-2686" significance="normal"><primary>audio formatting codes</primary></indexterm>audio formatting codes</para></listitem></orderedlist><para>This section describes the <literal moreinfo="none">tts-format-text-and-speak</literal> function, which handles the conversion of aural display lists into audio-formatted output. First, here is the code for the function <literal moreinfo="none">tts-format-text-and-speak</literal>:<indexterm id="idx-CHP-31-2687" significance="normal"><primary>tts-format-text-and-speak function (Emacspeak)</primary></indexterm><indexterm id="I_indexterm31_tt694" class="endofrange" startref="idx-CHP-31-2669" significance="normal"><primary>aural display lists</primary><secondary>augmenting Emacs to create</secondary></indexterm></para><programlisting id="I_programlisting31_tt695" format="linespecific">
	(defsubst tts-format-text-and-speak (start end )
	  "Format and speak text between start and end."
	  (when (and emacspeak-use-auditory-icons
	             (get-text-property start 'auditory-icon)) ;;queue icon
	    (emacspeak-queue-auditory-icon (get-text-property start 'auditory-icon)))
	  (tts-interp-queue (format "%s\n" tts-voice-reset-code))
	  (cond
	   (voice-lock-mode ;; audio format only if voice-lock-mode is on
	    (let ((last nil) ;; initialize
	          (personality (get-text-property start 'personality )))
	      (while (and (
	&lt; start end ) ;; chunk at personality changes
	                      (setq last
	                            (next-single-property-change start 'personality
	                                                         (current-buffer) end)))
	           (if personality ;; audio format chunk
	               (tts-speak-using-voice personality (buffer-substring start last ))
	             (tts-interp-queue (buffer-substring start last)))
	           (setq start last ;; prepare for next chunk
	                 personality (get-text-property last 'personality)))))
	      ;; no voice-lock just send the text
	      (t (tts-interp-queue (buffer-substring start end )))))
</programlisting><para>The <literal moreinfo="none">tts-format-text-and-speak</literal> function is called one clause at a time, with arguments <literal moreinfo="none">start</literal> and <literal moreinfo="none">end</literal> set to the start and end of the clause. If <literal moreinfo="none">voice-lock-mode</literal> is turned on, this function further splits the clause into chunks at each point in the text where there is a change in value of the <literal moreinfo="none">personality</literal> property. Once such a transition point has been determined, <literal moreinfo="none">tts-format-text-and-speak</literal> calls the function <literal moreinfo="none">tts-speak-using-voice</literal>, passing the personality to use and the text to be spoken. This function, described next, looks up the appropriate device-specific codes before dispatching the audio-formatted output to the speech server:<indexterm id="idx-CHP-31-2688" significance="normal"><primary>tts-speak-using-voice function</primary></indexterm></para><programlisting id="I_programlisting31_tt696" format="linespecific">
	(defsubst tts-speak-using-voice (voice text)
	  "Use voice VOICE to speak text TEXT."
	  (unless (or (eq '<indexterm id="idx-CHP-31-2689" significance="normal"><primary>inaudible (Emacspeak personality)</primary></indexterm>inaudible voice ) ;; not spoken if voice inaudible
	              (and (listp voice) (member 'inaudible voice)))
	    (tts-interp-queue
	     (format
	      "%s%s %s \n"
	      (cond
	       ((symbolp voice)
	        (tts-get-voice-command
	         (if (boundp voice ) (symbol-value voice ) voice)))
	       ((listp voice)
	        (mapconcat #'(lambda (v)
	                       (tts-get-voice-command
	                        (if (boundp v ) (symbol-value v ) v)))
	                   voice
	                   " "))
	       (t      ""))
	      text tts-voice-reset-code))))
</programlisting><para>The <literal moreinfo="none">tts-speak-using-voice</literal> function returns immediately if the specified voice is <literal moreinfo="none">inaudible</literal>. Here, <literal moreinfo="none">inaudible</literal> is a special personality that <indexterm id="idx-CHP-31-2690" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak uses to prevent pieces of text from being spoken. The <literal moreinfo="none">inaudible</literal> personality can be used to advantage when selectively hiding portions of text to produce more succinct output.</para><para>If the specified voice (or list of voices) is not <literal moreinfo="none">inaudible</literal>, the function looks up the speech codes for the voice and queues the result of wrapping the text to be spoken between <literal moreinfo="none">voice-code</literal> and <literal moreinfo="none">tts-reset-code</literal> to the speech server.</para></sect3></sect2><sect2 id="using_aural_css_acss_for_styling_speech_output" label="31.2.5"><title>Using Aural CSS (ACSS) for Styling Speech Output</title><para>I first formalized audio formatting within AsTeR, where rendering rules were written in a specialized language called <indexterm id="idx-CHP-31-2691" significance="normal"><primary>Audio Formatting Language (AFL)</primary></indexterm>Audio Formatting Language (<indexterm id="idx-CHP-31-2692" significance="normal"><primary>AFL (Audio Formatting Language)</primary></indexterm>AFL). AFL structured the available parameters in auditory space—e.g., the pitch of the speaking voice—into a multidimensional space, and encapsulated the state of the rendering engine as a point in this multidimensional space.<indexterm id="idx-CHP-31-2693" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>Aural CSS (ACSS)</secondary></indexterm><indexterm id="idx-CHP-31-2694" significance="normal"><primary>speech output</primary></indexterm><indexterm class="startofrange" id="idx-CHP-31-2695" significance="normal"><primary>ACSS (Aural CSS)</primary></indexterm></para><para>AFL provided a block-structured language that encapsulated the current rendering state by a lexically scoped variable, and provided operators to move within this structured space. When these notions were later mapped to the declarative world of HTML and CSS, dimensions making up the AFL rendering state became Aural CSS parameters, provided as accessibility measures in <indexterm id="idx-CHP-31-2696" significance="normal"><primary>CSS2</primary></indexterm>CSS2 (<ulink url="http://www.w3.org/Press/1998/CSS2-REC"/>).<indexterm id="I_indexterm31_tt697" class="endofrange" startref="idx-CHP-31-2662" significance="normal"><primary>speech-enabling Emacs</primary><secondary>generating rich auditory output</secondary></indexterm></para><para>Though designed for styling HTML (and, in general, XML) markup trees, <indexterm id="idx-CHP-31-2697" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>Aural CSS (ACSS)</secondary></indexterm>Aural CSS turned out to be a good abstraction for building <indexterm id="idx-CHP-31-2698" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak's audio formatting layer while keeping the implementation independent of any given TTS engine.</para><para>Here is the definition of the <indexterm id="idx-CHP-31-2699" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>data structure encapsulating ACSS settings</secondary></indexterm>data structure that encapsulates <indexterm id="idx-CHP-31-2700" significance="normal"><primary>ACSS (Aural CSS)</primary></indexterm>ACSS settings:</para><programlisting id="I_programlisting31_tt698" format="linespecific">
	(defstruct acss
	  family gain left-volume right-volume
	  average-<indexterm id="idx-CHP-31-2701" significance="normal"><primary>pitch setting for flat voice (Emacspeak)</primary></indexterm>pitch <indexterm id="idx-CHP-31-2702" significance="normal"><primary>pitch-range setting (Emacspeak)</primary></indexterm>pitch-range stress richness <indexterm id="idx-CHP-31-2703" significance="normal"><primary>punctuations setting (Emacspeak)</primary></indexterm>punctuations)
</programlisting><para><indexterm id="idx-CHP-31-2704" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>Emacspeak provides a collection of predefined <emphasis>voice overlays</emphasis> for use within <indexterm id="idx-CHP-31-2705" significance="normal"><primary>speech output</primary></indexterm>speech extensions. Voice overlays are designed to <emphasis>cascade</emphasis> in the spirit of Aural CSS. As an example, here is the ACSS setting that corresponds to <literal moreinfo="none">voice-monotone</literal>:<indexterm id="idx-CHP-31-2706" significance="normal"><primary>voice overlays (Emacspeak)</primary></indexterm><indexterm id="idx-CHP-31-2707" significance="normal"><primary>voice-monotone</primary></indexterm></para><programlisting id="I_programlisting31_tt699" format="linespecific">
	[cl-struct-acss nil nil nil nil nil 0 0 nil all]
</programlisting><para>Notice that most fields of this <literal moreinfo="none">acss</literal> structure are <literal moreinfo="none">nil</literal>—that is, unset. The setting creates a voice overlay that:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Sets <literal moreinfo="none">pitch</literal> to 0 to create a flat voice.</para></listitem><listitem><para>Sets <literal moreinfo="none">pitch-range</literal> to 0 to create a <indexterm id="idx-CHP-31-2708" significance="normal"><primary>monotone voice with no inflection (Emacspeak)</primary></indexterm>monotone voice with no inflection.</para><para>This setting is used as the value of the <literal moreinfo="none">personality</literal> property for audio formatting comments in all programming language modes. Because its value is an overlay, it can interact effectively with other aural display properties. As an example, if portions of a comment are displayed in a bold font, those portions can have the <literal moreinfo="none">voice-bolden</literal> personality (another predefined overlay) added; this results in setting the <literal moreinfo="none">personality</literal> property to a list of two values: (<literal moreinfo="none">voice-bolden voice-monotone</literal>). The final effect is for the text to get spoken with a distinctive voice that conveys both aspects of the text: namely, a sequence of words that are emphasized within a comment.</para></listitem><listitem><para>Sets <literal moreinfo="none">punctuations</literal> to <literal moreinfo="none">all</literal> so that all punctuation marks are spoken.</para></listitem></orderedlist></sect2><sect2 id="adding_auditory_icons" label="31.2.6"><title>Adding Auditory Icons</title><para>Rich visual user interfaces contain both text and icons. Similarly, once Emacspeak had the ability to speak intelligently, the next step was to increase the bandwidth of aural communication by augmenting the output with auditory icons.<indexterm id="idx-CHP-31-2709" significance="normal"><primary>auditory icons</primary></indexterm><indexterm id="idx-CHP-31-2710" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>adding auditory icons</secondary></indexterm></para><para>Auditory icons in Emacspeak are short sound snippets (no more than two seconds in duration) and are used to indicate frequently occurring events in the user interface. As an example, every time the user saves a file, the system plays a confirmatory sound. Similarly, opening or closing an object (anything from a file to a web site) produces a corresponding auditory icon. The set of auditory icons were arrived at iteratively and cover common events such as objects being opened, closed, or deleted. This section describes how these auditory icons are injected into Emacspeak's output stream.</para><para>Auditory icons are produced by the following <indexterm id="idx-CHP-31-2711" significance="normal"><primary>auditory icons</primary><secondary>user interactions producing</secondary></indexterm>user interactions:</para><itemizedlist><listitem><para>To cue explicit user actions</para></listitem><listitem><para>To add additional cues to spoken <indexterm id="idx-CHP-31-2712" significance="normal"><primary>speech output</primary></indexterm>output</para></listitem></itemizedlist><para><indexterm id="idx-CHP-31-2713" significance="normal"><primary>advice (Emacs LISP)</primary><secondary>auditory icons confirming user actions</secondary></indexterm>Auditory icons that confirm user actions—e.g., a file being saved successfully—are produced by adding an <literal moreinfo="none">after</literal> <emphasis>advice</emphasis> to the various <indexterm id="idx-CHP-31-2714" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>Emacs built-ins. To provide a consistent sound and feel across the <indexterm id="idx-CHP-31-2715" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak desktop, such extensions are attached to code that is called from many places in Emacs.</para><para>Here is an example of such an extension, implemented via an <emphasis>advice</emphasis> fragment:</para><programlisting id="I_programlisting31_tt700" format="linespecific">
	(defadvice save-buffer (after emacspeak pre act)
	  "Produce an auditory icon if possible."
	  (when (interactive-p) (emacspeak-auditory-icon 'save-object)
	    (or emacspeak-last-message (message "Wrote %s" (buffer-file-name)))))
</programlisting><para>Extensions can also be implemented via an Emacs-provided hook. As explained in the brief <emphasis>advice</emphasis> tutorial given earlier, <emphasis>advice</emphasis> allows the behavior of existing software to be extended or modified without having to modify the underlying source code. Emacs is itself an extensible system, and well-written Lisp code has a tradition of providing appropriate extension hooks for common use cases. As an example, Emacspeak attaches auditory feedback to Emacs' default prompting mechanism (the Emacs minibuffer) by adding the function <literal moreinfo="none">emacspeak-minibuffer-setup-hook</literal> to Emacs' <literal moreinfo="none">minibuffer-setup-hook</literal>:<indexterm id="idx-CHP-31-2716" significance="normal"><primary>emacspeak-minibuffer-setup-hook function</primary></indexterm></para><programlisting id="I_programlisting31_tt701" format="linespecific">
	(defun emacspeak-minibuffer-setup-hook ()
	  "Actions to take when entering the minibuffer."
	  (let ((inhibit-field-text-motion t))
	    (when emacspeak-minibuffer-enter-auditory-icon
	      (emacspeak-auditory-icon 'open-object))
	    (tts-with-punctuations 'all (emacspeak-speak-buffer))))
	(add-hook 'minibuffer-setup-hook 'emacspeak-minibuffer-setup-hook)
</programlisting><para>This is a good example of using built-in extensibility where available. However, Emac-speak uses <emphasis>advice</emphasis> in a lot of cases because the Emacspeak requirement of adding auditory feedback to <emphasis>all</emphasis> of Emacs was not originally envisioned when Emacs was implemented. Thus, the Emacspeak implementation demonstrates a powerful technique for <emphasis>discovering</emphasis> <indexterm id="idx-CHP-31-2717" significance="normal"><primary>extension points</primary></indexterm>extension points.</para><para>Lack of an <emphasis>advice</emphasis>-like feature in a programming language often makes experimentation difficult, especially when it comes to discovering useful <indexterm id="idx-CHP-31-2718" significance="normal"><primary>LISP</primary><secondary>advice</secondary><tertiary>extension points</tertiary></indexterm>extension points. This is because software engineers are faced with the following trade-off:</para><itemizedlist><listitem><para>Make the system arbitrarily extensible (and arbitrarily complex)</para></listitem><listitem><para>Guess at some reasonable extension points and hardcode these</para></listitem></itemizedlist><para>Once extension points are implemented, experimenting with new ones requires rewriting existing code, and the resulting inertia often means that over time, such extension points remain mostly undiscovered. Lisp <emphasis>advice</emphasis>, and its Java counterpart Aspects, offer software engineers the opportunity to experiment without worrying about adversely affecting an existing body of source code.</para></sect2><sect2 id="producing_auditory_icons_while_speaking_content" label="31.2.7"><title>Producing Auditory Icons While Speaking Content</title><para>In addition to using auditory icons to cue the results of user interaction, <indexterm id="idx-CHP-31-2719" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak uses auditory icons to augment what is being spoken. Examples of such auditory icons include:<indexterm id="idx-CHP-31-2720" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>producing auditory icons while speaking content</secondary></indexterm></para><itemizedlist><listitem><para>A short icon at the beginning of paragraphs</para></listitem><listitem><para>The auditory icon <literal moreinfo="none">mark-object</literal> when moving across source lines that have a breakpoint set on them<indexterm id="idx-CHP-31-2721" significance="normal"><primary>mark-object auditory icon</primary></indexterm></para></listitem></itemizedlist><para>Auditory icons are implemented by attaching the text property <literal moreinfo="none">emacspeak-auditory-icon</literal> with a value equal to the name of the auditory icon to be played on the relevant text.<indexterm id="idx-CHP-31-2722" significance="normal"><primary>emacspeak-auditory-icon property</primary></indexterm></para><para>As an example, commands to set breakpoints in the Grand Unified Debugger <indexterm id="idx-CHP-31-2723" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>Emacs package (GUD) are <emphasis>adviced</emphasis> to add the property <literal moreinfo="none">emacspeak-auditory-icon</literal> to the line containing the breakpoint. When the user moves across such a line, the function <literal moreinfo="none">tts-format-text-and-speak</literal> queues the auditory icon at the right point in the output stream.</para></sect2><sect2 id="the_calendar_enhancing_spoken_output_with_context-sensitive_sem" label="31.2.8"><title>The Calendar: Enhancing Spoken Output with Context-Sensitive Semantics</title><para>To summarize the story so far, Emacspeak has the ability to:<indexterm class="startofrange" id="idx-CHP-31-2724" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>enhancing spoken output with contextsensitive semantics</secondary></indexterm><indexterm id="idx-CHP-31-2725" significance="normal"><primary>context-sensitive semantics</primary></indexterm></para><itemizedlist><listitem><para>Produce auditory output from within the context of an application</para></listitem><listitem><para>Audio-format output to increase the bandwidth of spoken communication</para></listitem><listitem><para>Augment spoken output with auditory icons</para></listitem></itemizedlist><para>This section explains some of the enhancements that the design makes possible.</para><para>I started implementing Emacspeak in October 1994 as a quick means of developing a <indexterm id="idx-CHP-31-2726" significance="normal"><primary>speech output</primary></indexterm>speech solution for Linux. It was when I speech-enabled the Emacs Calendar in the first week of November 1994 that I realized that in fact I had created something far better than any other speech-access solution I had used before.</para><para>A calendar is a good example of using a specific type of visual layout that is optimized both for the visual medium as well as for the information that is being conveyed. We intuitively think in terms of weeks and months when reasoning about dates; using a tabular layout that organizes dates in a grid with each week appearing on a row by itself matches this perfectly. With this form of layout, the human eye can rapidly move by days, weeks, or months through the calendar and easily answer such questions as "What day is it tomorrow?" and "Am I free on the third Wednesday of next month?"</para><para>Notice, however, that simply speaking this two-dimensional layout does not transfer the efficiencies achieved in the visual context to auditory interaction. This is a good example of where the right auditory feedback has to be generated directly from the underlying information being conveyed, rather than from its visual representation. When <indexterm id="idx-CHP-31-2727" significance="normal"><primary>auditory icons</primary><secondary>producing while speaking content</secondary></indexterm>producing auditory output from visually formatted information, one has to <emphasis>rediscover</emphasis> the underlying semantics of the information before speaking it.</para><para>In contrast, when producing <indexterm id="idx-CHP-31-2728" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>enhancing spoken output with contextsensitive semantics</secondary></indexterm>spoken feedback via <emphasis>advice</emphasis> definitions that extend the under-lying application, one has full access to the application's runtime context. Thus, rather than <emphasis>guessing</emphasis> based on visual layout, one can essentially instruct the underlying application to <emphasis>speak the right thing</emphasis>!</para><para>The <literal moreinfo="none">emacspeak-calendar</literal> module <indexterm id="idx-CHP-31-2729" significance="normal"><primary>speech output</primary></indexterm>speech-enables the <indexterm id="idx-CHP-31-2730" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>Emacs Calendar by defining utility functions that speak calendar information and advising all calendar navigation commands to call these functions. Thus, Emacs Calendar produces specialized behavior by binding the arrow keys to calendar navigation commands rather than the default cursor navigation found in regular editing modes. Emacspeak specializes this behavior by advising the calendar-specific commands to speak the relevant information in the context of the calendar.<indexterm id="idx-CHP-31-2731" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm><indexterm id="idx-CHP-31-2732" significance="normal"><primary>Calendar (Emacs)</primary></indexterm></para><para>The net effect is that from an end user's perspective, <emphasis>things just work</emphasis>. In regular editing modes, pressing up/down arrows speaks the current line; pressing up/down arrows in the calendar navigates by weeks and speaks the current date.</para><para>The <literal moreinfo="none">emacspeak-calendar-speak-date</literal> function, defined in the <literal moreinfo="none">emacspeak-calendar</literal> module, is shown here. Notice that it uses all of the facilities described so far to access and audio-format the relevant contextual information from the calendar:<indexterm id="idx-CHP-31-2733" significance="normal"><primary>emacspeak-calendar module</primary></indexterm></para><programlisting id="I_programlisting31_tt702" format="linespecific">
	(defsubst <indexterm id="idx-CHP-31-2734" significance="normal"><primary>emacspeak-calendar-entry-marked-p function</primary></indexterm>emacspeak-calendar-entry-marked-p( )
	  (member 'diary (mapcar #'overlay-face (overlays-at (point)))))
	(defun <indexterm id="idx-CHP-31-2735" significance="normal"><primary>emacspeak-calendar-speak-date function</primary></indexterm>emacspeak-calendar-speak-date( )
	  "Speak the date under point when called in Calendar Mode. "
	  (let ((date (calendar-date-string (calendar-cursor-to-date t))))
	    (cond
	     ((emacspeak-calendar-entry-marked-p) (tts-speak-using-voice mark-personality
	date))
	     (t (tts-speak date)))))
</programlisting><para>Emacs marks dates that have a diary entry with a special overlay. In the previous definition, the helper function <literal moreinfo="none">emacspeak-calendar-entry-marked-p</literal> checks this overlay to implement a predicate that can be used to test if a date has a diary entry. The <literal moreinfo="none">emacspeak-calendar-speak-date</literal> function uses this predicate to decide whether the date needs to be rendered in a different voice; dates that have calendar entries are spoken using the <literal moreinfo="none">mark-personality</literal> voice. Notice that the <literal moreinfo="none">emacspeak-calendar-speak-date</literal> function accesses the calendar's runtime context in the call:</para><programlisting id="I_programlisting31_tt703" format="linespecific">
	(calendar-date-string (calendar-cursor-to-date t))
</programlisting><para>The <literal moreinfo="none">emacspeak-calendar-speak-date</literal> function is called from <emphasis>advice</emphasis> <indexterm id="idx-CHP-31-2736" significance="normal"><primary>advice (Emacs LISP)</primary><secondary>definitions attached to calendar navigation functions</secondary></indexterm>definitions attached to all calendar navigation functions. Here is the <emphasis>advice</emphasis> definition for function <literal moreinfo="none">calendar-forward-week</literal>:<indexterm id="idx-CHP-31-2737" significance="normal"><primary>calendar-forward-week function</primary></indexterm></para><programlisting id="I_programlisting31_tt704" format="linespecific">
	(defadvice calendar-forward-week (after emacspeak pre act)
	  "Speak the date. "
	  (when (interactive-p) (emacspeak-speak-calendar-date )
	    (emacspeak-auditory-icon 'large-movement)))
</programlisting><para>This is an <literal moreinfo="none">after</literal> <emphasis>advice</emphasis>, because we want the spoken feedback to be produced <emphasis>after</emphasis> the original navigation command has done its work.</para><para>The body of the <emphasis>advice</emphasis> definition first calls the function <literal moreinfo="none">emacspeak-calendar-speak-date</literal> to speak the date under the cursor; next, it calls <literal moreinfo="none">emacspeak-auditory-icon</literal> to produce a short sound indicating that we have successfully moved.<indexterm id="idx-CHP-31-2738" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm></para></sect2></sect1><sect1 id="painless_access_to_online_information" label="31.3"><title>Painless Access to Online Information</title><para>With all the necessary affordances to generate rich auditory output in place, <indexterm id="idx-CHP-31-2739" significance="normal"><primary>speech output</primary></indexterm>speech-enabling Emacs applications using Emacs Lisp's <emphasis>advice</emphasis> facility requires surprisingly small amounts of specialized code. With the TTS layer and the Emacspeak core handling the complex details of producing good quality output, the <indexterm id="idx-CHP-31-2740" significance="normal"><primary>speech-enabling Emacs</primary></indexterm>speech-enabling extensions focus purely on the specialized <indexterm id="idx-CHP-31-2741" significance="normal"><primary>context-sensitive semantics</primary></indexterm>semantics of individual applications; this leads to simple and consequently <emphasis>beautiful</emphasis> code. This section illustrates the concept with a few choice examples taken from Emacspeak's rich suite of information access tools.<indexterm class="startofrange" id="idx-CHP-31-2742" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>online information access</secondary></indexterm></para><para>Right around the time I started Emacspeak, a far more profound revolution was taking place in the world of computing: the World Wide Web went from being a tool for academic research to a mainstream forum for everyday tasks. This was 1994, when writing a browser was still a comparatively easy task. The complexity that has been progressively added to the Web in the subsequent 12 years often tends to obscure the fact that the Web is still a fundamentally simple design where:</para><itemizedlist><listitem><para>Content creators publish web resources addressable via URIs.</para></listitem><listitem><para>URI-addressable content is retrievable via open protocols.</para></listitem><listitem><para>Retrieved content is in HTML, a well-understood markup language.</para></listitem></itemizedlist><para>Notice that the basic architecture just sketched out says little to nothing about how the content is made available to the end user. The mid-1990s saw the Web move toward increasingly complex visual interaction. The commercial Web with its penchant for flashy visual interaction increasingly moved away from the simple data-oriented interaction that had characterized early web sites. By 1998, I found that the Web had a lot of useful interactive sites; to my dismay, I also found that I was using progressively fewer of these sites because of the time it took to complete tasks when using <indexterm id="idx-CHP-31-2743" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>enhancing spoken output with contextsensitive semantics</secondary></indexterm>spoken output.</para><para>This led me to create a suite of <indexterm class="startofrange" id="idx-CHP-31-2744" significance="normal"><primary>web-oriented tools in Emacspeak</primary></indexterm>web-oriented tools within Emacspeak that went back to the basics of web interaction. Emacs was already capable of rendering simple HTML into interactive hypertext documents. As the Web became complex, Emacspeak acquired a collection of interaction wizards built on top of Emacs' HTML rendering capability that progressively factored out the complexity of web interaction to create an auditory interface that allowed the user to quickly and painlessly listen to desired information.<indexterm id="I_indexterm31_tt705" class="endofrange" startref="idx-CHP-31-2695" significance="normal"><primary>ACSS (Aural CSS)</primary></indexterm><indexterm id="I_indexterm31_tt706" class="endofrange" startref="idx-CHP-31-2643" significance="normal"><primary>speech-enabling Emacs</primary></indexterm><indexterm id="I_indexterm31_tt707" class="endofrange" startref="idx-CHP-31-2724" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>enhancing spoken output with contextsensitive semantics</secondary></indexterm></para><sect2 id="basic_html_with_emacs_w3_and_aural_css" label="31.3.1"><title>Basic HTML with Emacs W3 and Aural CSS</title><para>Emacs W3 is a bare-bones web browser first implemented in the mid-1990s. Emacs W3 implemented CSS (Cascading Style Sheets) <indexterm id="idx-CHP-31-2745" significance="normal"><primary>CSS2</primary><secondary>early implementation by Emacs W3 browser</secondary></indexterm>early on, and this was the basis of the first Aural CSS implementation, which was released at the time I wrote the Aural CSS draft in February 1996. <indexterm id="idx-CHP-31-2746" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak speech-enables Emacs W3 via the <literal moreinfo="none">emacspeak-w3</literal> module, which implements the following extensions:<indexterm id="idx-CHP-31-2747" significance="normal"><primary>ACSS (Aural CSS)</primary><secondary>basic HTML using Emacs W3 and ACSS</secondary></indexterm><indexterm id="idx-CHP-31-2748" significance="normal"><primary>Emacs</primary><secondary>W3 web browser</secondary></indexterm><indexterm id="idx-CHP-31-2749" significance="normal"><primary>emacspeak-w3 module</primary></indexterm></para><itemizedlist><listitem><para>An <literal moreinfo="none">aural media</literal> section in the default stylesheet for Aural CSS.</para></listitem><listitem><para><emphasis>advice</emphasis> added to all interactive commands to produce auditory feedback.</para></listitem><listitem><para>Special patterns to recognize and silence decorative images on web pages.</para></listitem><listitem><para>Aural rendering of HTML form fields along with the associated <literal moreinfo="none">label</literal>, which underlay the design of the <literal moreinfo="none">label</literal> element in HTML 4.</para></listitem><listitem><para>Context-sensitive rendering rules for HTML form controls. As an example, given a group of radio buttons for answering the question:</para><simplelist type="vert"><member>Do you accept?</member></simplelist><para>Emacspeak extends Emacs W3 to produce a spoken message of the form:</para><simplelist type="vert"><member>Radio group <literal moreinfo="none">Do you accept?</literal> has <literal moreinfo="none">Yes</literal> pressed.</member></simplelist><para>and:</para><simplelist type="vert"><member>Press this to change radio group <literal moreinfo="none">Do you accept?</literal> from <literal moreinfo="none">Yes</literal> to <literal moreinfo="none">No</literal>.</member></simplelist></listitem><listitem><para>A <literal moreinfo="none">before</literal> advice defined for the Emacs W3 function <literal moreinfo="none">w3-parse-buffer</literal> that applies user-requested XSLT transforms to HTML pages.</para></listitem></itemizedlist></sect2><sect2 id="the_emacspeak-websearch_module_for_task-oriented_search" label="31.3.2"><title>The emacspeak-websearch Module for Task-Oriented Search</title><para><indexterm id="idx-CHP-31-2750" significance="normal"><primary>HTML</primary><secondary>rendered by speech-enabled Emacs W3 and ACSS</secondary></indexterm>By 1997, interactive sites on the Web, ranging from Altavista for searching to Yahoo! Maps for <indexterm id="idx-CHP-31-2751" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>online information access</secondary></indexterm>online directions, required the user to go through a highly visual process that included:<indexterm class="startofrange" id="idx-CHP-31-2752" significance="normal"><primary>searches</primary><secondary>emacspeak-websearch module for taskoriented search</secondary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Filling in a set of form fields</para></listitem><listitem><para>Submitting the resulting form</para></listitem><listitem><para>Spotting the results in the resulting complex HTML page</para></listitem></orderedlist><para>The first and third of these steps were the ones that took time when using spoken output. I needed to first locate the various form fields on a visually busy page and wade through a lot of complex boilerplate material on result pages before I found the answer.</para><para>Notice that from the software design point of view, these steps neatly map into <emphasis>pre-action</emphasis> and <emphasis>post-action</emphasis> hooks. Because web interaction follows a very simple architecture based on URIs, the pre-action step of prompting the user for the right pieces of input can be factored out of a web site and placed in a small piece of code that runs locally; this obviates the need for the user to open the initial launch page and seek out the various input fields.<indexterm id="idx-CHP-31-2753" significance="normal"><primary>pre-action and post-action hooks</primary></indexterm></para><para>Similarly, the post-action step of spotting the actual results amid the rest of the noise on the resulting page can also be delegated to software.</para><para>Finally, notice that even though these pre-action and post-action steps are each specific to particular web sites, the overall design pattern is one that can be generalized. This insight led to the <literal moreinfo="none">emacspeak-websearch</literal> module, a collection of task-oriented web <indexterm id="idx-CHP-31-2754" significance="normal"><primary>web-oriented tools in Emacspeak</primary></indexterm>tools that:<indexterm id="idx-CHP-31-2755" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Prompted the user</para></listitem><listitem><para>Constructed an appropriate URI and pulled the content at that URI</para></listitem><listitem><para>Filtered the result before rendering the relevant content via Emacs W3</para></listitem></orderedlist><para>Here is the <literal moreinfo="none">emacspeak-websearch</literal> tool for accessing directions from <indexterm id="idx-CHP-31-2756" significance="normal"><primary>Yahoo! Maps</primary></indexterm>Yahoo! Maps:<indexterm id="idx-CHP-31-2757" significance="normal"><primary>emacspeak-websearch tool for accessing directions from Yahoo! Maps</primary></indexterm></para><programlisting id="I_programlisting31_tt708" format="linespecific">
	(defsubst <indexterm id="idx-CHP-31-2758" significance="normal"><primary>searches</primary><secondary>emacspeak-websearch module for taskoriented search</secondary></indexterm>emacspeak-websearch-yahoo-map-directions-get-locations ( )
	  "Convenience <indexterm id="idx-CHP-31-2759" significance="normal"><primary>emacspeak-websearch-yahoo-map-directionsget-locations function</primary></indexterm>function for prompting and constructing the route component."
	  (concat
	   (format "&amp;newaddr=%s"
	           (emacspeak-url-encode (read-from-minibuffer "Start Address: ")))
	   (format "&amp;newcsz=%s"
	           (emacspeak-url-encode (read-from-minibuffer "City/State or Zip:")))
	   (format "&amp;newtaddr=%s"
	           (emacspeak-url-encode (read-from-minibuffer "Destination Address: ")))
	   (format "&amp;newtcsz=%s"
	           (emacspeak-url-encode (read-from-minibuffer "City/State or Zip:")))))
	(defun emacspeak-websearch-yahoo-map-directions-search (query )
	  "Get driving directions from Yahoo."
	  (interactive
	   (list (emacspeak-websearch-yahoo-map-directions-get-locations))
	   (emacspeak-w3-extract-table-by-match
	    "Start"
	    (concat emacspeak-websearch-yahoo-maps-uri query))))
</programlisting><para>A brief explanation of the previous code follows:</para><variablelist><varlistentry><term><emphasis>Pre-action</emphasis></term><listitem><para>The <literal moreinfo="none">emacspeak-websearch-yahoo-map-directions-get-locations</literal> function prompts the user for the start and end locations. Notice that this function hardwires the names of the query parameters used by Yahoo! Maps. On the surface, this looks like a kluge that is guaranteed to break. In fact, this kluge has not broken since it was first defined in 1997. The reason is obvious: once a web application has published a set of query parameters, those parameters get hardcoded in a number of places, including within a large number of HTML pages on the originating web site. Depending on parameter names may feel brittle to the software architect used to structured, top-down APIs, but the use of such URL parameters to define bottom-up web services leads to the notion of RESTful web APIs.</para></listitem></varlistentry><varlistentry><term><emphasis>Retrieve content</emphasis></term><listitem><para>The URL for retrieving directions is constructed by concatenating the user input to the <emphasis>base URI</emphasis> for Yahoo! Maps.</para></listitem></varlistentry><varlistentry><term><emphasis>Post-action</emphasis></term><listitem><para>The resulting URI is passed to the function <literal moreinfo="none">emacspeak-w3-extract-table-by-match</literal> along with a search pattern <literal moreinfo="none">Start</literal> to:<indexterm id="idx-CHP-31-2760" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm></para><itemizedlist><listitem><para>Retrieve the content using Emacs W3.</para></listitem><listitem><para>Apply an XSLT transform to extract the table containing <literal moreinfo="none">Start</literal>.</para></listitem><listitem><para>Render this table using Emacs W3's HTML formatter.</para></listitem></itemizedlist><para>Unlike the query parameters, the layout of the results page <emphasis>does</emphasis> change about once a year, on average. But keeping this tool current with Yahoo! Maps comes down to maintaining the post-action portion of this utility. In over eight years of use, I have had to modify it about half a dozen times, and given that the underlying platform provides many of the <indexterm id="idx-CHP-31-2761" significance="normal"><primary>web-oriented tools in Emacspeak</primary></indexterm>tools for filtering the result page, the actual lines of code that need to be written for each layout change is minimal.</para><para>The <literal moreinfo="none">emacspeak-w3-extract-table-by-match</literal> function uses an XSLT transformation that filters a document to return tables that contain a specified search pattern. For this example, the function constructs the following XPath expression:<indexterm id="idx-CHP-31-2762" significance="normal"><primary>emacspeak-w3-extract-table-by-match function</primary></indexterm></para><programlisting id="I_programlisting31_tt709" format="linespecific">
	(/descendant::table[contains(., Start)])[last( )]
</programlisting><para>This effectively picks out the list of tables that contain the string <literal moreinfo="none">Start</literal> and returns the last element of that list.</para></listitem></varlistentry></variablelist><para>Seven years after this utility was written, Google launched <indexterm id="idx-CHP-31-2763" significance="normal"><primary>Google Maps</primary></indexterm>Google Maps to great excitement in February 2005. Many blogs on the Web put Google Maps under the microscope and quickly discovered the query parameters used by that application. I used that to build a corresponding Google Maps tool in Emacspeak that provides similar functionality. The user experience is smoother with the Google Maps tool because the start and end locations can be specified within the same parameter. Here is the code for the Google Maps wizard:</para><programlisting id="I_programlisting31_tt710" format="linespecific">
	(defun <indexterm id="idx-CHP-31-2764" significance="normal"><primary>searches</primary><secondary>emacspeak-websearch module for taskoriented search</secondary></indexterm>emacspeak-websearch-emaps-search (query &amp;optional use-near)
	  "Perform EmapSpeak search. Query is in plain English."
	  (interactive
	   (list
	    (emacspeak-websearch-read-query
	     (if current-prefix-arg
	         (format "Find what near %s: "
	                 emacspeak-websearch-emapspeak-my-location)
	       "EMap Query: "))
	    current-prefix-arg))
	  (let ((near-p ;; determine query type
	         (unless use-near
	           (save-match-data (and (string-match "near" query) (match-end 0)))))
	        (near nil)
	        (uri nil))
	    (when near-p ;; determine location from query
	      (setq near (substring query near-p))
	      (setq emacspeak-websearch-emapspeak-my-location near))
	    (setq uri
	          (cond
	           (use-near
	            (format <indexterm id="idx-CHP-31-2765" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>emacspeak-websearch-google-maps-uri
	                    (emacspeak-url-encode
	                     (format "%s near %s" query near))))
	           (t (format <indexterm id="idx-CHP-31-2766" significance="normal"><primary>searches</primary><secondary>emacspeak-websearch module for taskoriented search</secondary></indexterm>emacspeak-websearch-google-maps-uri
	                     (emacspeak-url-encode query)))))
	    (add-hook 'emacspeak-w3-post-process-hook 'emacspeak-speak-buffer)
	    (add-hook 'emacspeak-w3-post-process-hook
	              #'(lambda nil
	                  (emacspeak-pronounce-add-buffer-local-dictionary-entry
	                   "ðmi" " miles ")))
	    (browse-url-of-buffer
	     (emacspeak-xslt-xml-url
	      (expand-file-name "kml2html.xsl" emacspeak-xslt-directory)
	      uri))))
</programlisting><para>A brief explanation of the code follows:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Parse the input to decide whether it's a direction or a search query.</para></listitem><listitem><para>In case of search queries, cache the user's location for future use.</para></listitem><listitem><para>Construct a URI for retrieving results.</para></listitem><listitem><para>Browse the results of filtering the contents of the URI through the XSLT filter <literal moreinfo="none">kml2html</literal>, which converts the retrieved content into a simple hypertext document.</para></listitem><listitem><para>Set up custom pronunciations in the results to pronounce <literal moreinfo="none">mi</literal> as "miles."</para></listitem></orderedlist><para>Notice that, as before, most of the code focuses on application-specific tasks. Rich spoken output is produced by creating the results as a well-structured HTML document with the appropriate Aural CSS rules producing an audio-formatted presentation.</para></sect2><sect2 id="the_web_command_line_and_url_templates" label="31.3.3"><title>The Web Command Line and URL Templates</title><para>With more and more services becoming available on the Web, another useful pattern emerged by early 2000: <indexterm id="idx-CHP-31-2767" significance="normal"><primary>JavaScript</primary><secondary>web sites creating smart client-side interaction via</secondary></indexterm>web sites started creating smart client-side interaction via Java-Script. One typical use of such scripts was to construct URLs on the clientside for accessing specific pieces of content based on user input. As examples, Major League Baseball constructs the URL for retrieving scores for a given game by piecing together the date and the names of the home and visiting teams, and NPR creates URLs by piecing together the date with the program code of a given NPR show.<indexterm id="idx-CHP-31-2768" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>Web command line and URL templates</secondary></indexterm><indexterm id="idx-CHP-31-2769" significance="normal"><primary>URL templates (Emacspeak)</primary></indexterm></para><para>To enable fast access to such services, I added an <literal moreinfo="none">emacspeak-url-template</literal> module in late 2000. This module has become a powerful companion to the <literal moreinfo="none">emacspeak-websearch</literal> module described in the previous section. Together, these modules turn the Emacs minibuffer into a powerful web command line that provides rapid access to web content.<indexterm id="idx-CHP-31-2770" significance="normal"><primary>emacspeak-url-template module</primary></indexterm></para><para>Many web services require the user to specify a date. One can usefully default the date by using the user's calendar to provide the context. Thus, Emacspeak <indexterm id="idx-CHP-31-2771" significance="normal"><primary>web-oriented tools in Emacspeak</primary></indexterm>tools for playing an NPR program or retrieving MLB scores default to using the date under the cursor when invoked from within the Emacs calendar buffer.<indexterm id="I_indexterm31_tt711" class="endofrange" startref="idx-CHP-31-2752" significance="normal"><primary>searches</primary><secondary>emacspeak-websearch module for taskoriented search</secondary></indexterm></para><para>URL templates in <indexterm id="idx-CHP-31-2772" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak are implemented using the following data structure:</para><programlisting id="I_programlisting31_tt712" format="linespecific">
	(defstruct (emacspeak-url-template (:constructor emacspeak-ut-constructor))
	  name                                  ;; Human-readable name
	  template                              ;; template URL string
	  generators;; list of param generator
	  post-action                    ;; action to perform after opening
	  documentation                         ;; resource documentation
	  fetcher)
</programlisting><para>Users invoke URL templates via the Emacspeak command <literal moreinfo="none">emacspeak-url-template-fetch</literal> command, which prompts for a URL template and:<indexterm id="idx-CHP-31-2773" significance="normal"><primary>emacspeak-url-template-fetch command</primary></indexterm></para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Looks up the named template.</para></listitem><listitem><para>Prompts the user by calling the specified <literal moreinfo="none">generator</literal>.</para></listitem><listitem><para>Applies the Lisp function <literal moreinfo="none">format</literal> to the template string and the collected arguments to create the final URI.</para></listitem><listitem><para>Sets up any <emphasis>post actions</emphasis> performed after the content has been rendered.</para></listitem><listitem><para>Applies the specified fetcher to render the content.</para></listitem></orderedlist><para>The use of this structure is best explained with an example. The following is the URL template for playing <indexterm id="idx-CHP-31-2774" significance="normal"><primary>NPR programs</primary></indexterm>NPR programs:</para><programlisting id="I_programlisting31_tt713" format="linespecific">
	(emacspeak-url-template-define
	 "NPR On Demand"
	 "http://www.npr.org/dmg/dmg.php?prgCode=%s&amp;showDate=%s&amp;segNum=%s&amp;mediaPref=RM"
	 (list
	  #'(lambda ( ) (upcase (read-from-minibuffer "Program code:")))
	  #'(lambda ( )
	      (emacspeak-url-template-collect-date "Date:" "%d-%b-%Y"))
	  "Segment:")
	 nil; no post actions
	 "Play NPR shows on demand.
	Program is specified as a program code:
	ME              Morning Edition
	ATC             All Things Considered
	day             Day To Day
	newsnotes       News And Notes
	totn            Talk Of The Nation
	fa              Fresh Air
	wesat           Weekend Edition Saturday
	wesun           Weekend Edition Sunday
	fool            The Motley Fool
	Segment is specified as a two digit number --specifying a blank value
	plays entire program."
	 #'(lambda (url)
	     (funcall emacspeak-media-player url 'play-list)
	     (emacspeak-w3-browse-xml-url-with-style
	      (expand-file-name "smil-anchors.xsl" emacspeak-xslt-directory)
	      url)))
</programlisting><para>In this example, the custom <literal moreinfo="none">fetcher</literal> performs two actions:</para><orderedlist inheritnum="ignore" continuation="restarts"><listitem><para>Launches a media player to start playing the audio stream.</para></listitem><listitem><para>Filters the associated SMIL document via the XSLT file <emphasis>smil-anchors.xsl</emphasis>.</para></listitem></orderedlist></sect2><sect2 id="the_advent_of_feed_readers" label="31.3.4"><title>The Advent of Feed Readers</title><para>When I implemented the <literal moreinfo="none">emacspeak-websearch</literal> and <literal moreinfo="none">emacspeak-url-template</literal> modules, Emacspeak needed to screen-scrape HTML pages to speak the relevant <indexterm id="idx-CHP-31-2775" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>online information access</secondary></indexterm>information. But as the Web grew in complexity, the need to readily get beyond the superficial presentation of pages to the real content took on a wider value than eyes-free access. Even users capable of working with complex visual interfaces found themselves under a serious information overload. This led to the advent of RSS and <indexterm id="idx-CHP-31-2776" significance="normal"><primary>Atom feeds</primary></indexterm>Atom feeds, and the concomitant arrival of <indexterm id="idx-CHP-31-2777" significance="normal"><primary>feed reading software</primary></indexterm>feed reading software.<indexterm id="idx-CHP-31-2778" significance="normal"><primary>web-oriented tools in Emacspeak</primary><secondary>feed readers</secondary></indexterm></para><para>These developments have had a very positive effect on the Emacspeak code base. During the past few years, the code has become <emphasis>more beautiful</emphasis> as I have progressively deleted screen-scraping logic and replaced it with direct content access. As an example, here is the Emacspeak URL template for <indexterm id="idx-CHP-31-2779" significance="normal"><primary>URL templates (Emacspeak)</primary><secondary>retrieving weather for a city or state</secondary></indexterm>retrieving the weather for a given city/state:</para><programlisting id="I_programlisting31_tt714" format="linespecific">
	(emacspeak-url-template-define
	 "rss weather from wunderground"
	 "http://www.wunderground.com/auto/rss_full/%s.xml?units=both"
	 (list "State/City e.g.: MA/Boston") nil
	 "Pull RSS weather feed for specified state/city."
	 'emacspeak-rss-display)
</programlisting><para>And here is the URL template for <indexterm id="idx-CHP-31-2780" significance="normal"><primary>Google News searches via Atom feeds</primary></indexterm>Google News searches via Atom feeds:</para><programlisting id="I_programlisting31_tt715" format="linespecific">
	(emacspeak-url-template-define
	 "Google News Search"
	 "http://news.google.com/news?hl=en&amp;ned=tus&amp;q=%s&amp;btnG=Google+Search&amp;output=atom"
	 (list "Search news for: ") nil "Search Google news."
	 'emacspeak-atom-display )
</programlisting><para>Both of these <indexterm id="idx-CHP-31-2781" significance="normal"><primary>web-oriented tools in Emacspeak</primary></indexterm>tools use all of the facilities provided by the <literal moreinfo="none">emacspeak-url-template</literal> module and consequently need to do very little on their own. Finally, notice that by relying on standardized feed formats such as <indexterm id="idx-CHP-31-2782" significance="normal"><primary>RSS and Atom feeds</primary></indexterm>RSS and Atom, these templates now have very little in the way of site-specific kluges, in contrast to older tools like the Yahoo! Maps wizard, which hardwired specific patterns from the results page.</para></sect2></sect1><sect1 id="summary" label="31.4"><title>Summary</title><para>Emacspeak was conceived as a full-fledged, eyes-free user interface to everyday computing tasks. To be <emphasis>full-fledged</emphasis>, the system needed to provide direct access to every aspect of computing on desktop workstations. To enable fluent <emphasis>eyes-free</emphasis> interaction, the system needed to treat spoken output and the auditory medium as a first-class citizen—i.e., merely reading out information displayed on the screen was not sufficient.<indexterm id="I_indexterm31_tt716" class="endofrange" startref="idx-CHP-31-2744" significance="normal"><primary>web-oriented tools in Emacspeak</primary></indexterm><indexterm id="I_indexterm31_tt717" class="endofrange" startref="idx-CHP-31-2742" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>online information access</secondary></indexterm></para><para>To provide a <emphasis>complete audio desktop</emphasis>, the target environment needed to be an interaction framework that was both widely deployed and fully extensible. To be able to do more than just speak the screen, the system needed to build interactive speech capability into the various applications.</para><para>Finally, this had to be done without modifying the source code of any of the underlying applications; the project could not afford to fork a suite of applications in the name of adding eyes-free interaction, because I wanted to limit myself to the task of maintaining the speech extensions.</para><para>To meet all these design requirements, I picked Emacs as the user interaction environment. As an interaction framework, Emacs had the advantage of having a very large developer community. Unlike other popular interaction frameworks available in 1994 when I began the project, it had the significant advantage of being a free software environment. (Now, 12 years later, Firefox affords similar opportunities.)</para><para>The enormous flexibility afforded by Emacs Lisp as an extension language was an essential prerequisite in speech-enabling the various applications. The open source nature of the platform was just as crucial; even though I had made an explicit decision that I would modify no existing code, being able to study how various applications were implemented made speech-enabling them tractable. Finally, the availability of a high-quality <emphasis>advice</emphasis> implementation for Emacs Lisp (note that Lisp's <emphasis>advice</emphasis> facility was the prime motivator behind Aspect Oriented Programming) made it possible to speech-enable applications authored in Emacs Lisp without modifying the original source code.</para><para><indexterm id="idx-CHP-31-2783" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak is a direct consequence of the matching up of the needs previously outlined and the affordances provided by Emacs as a user interaction environment.</para><sect2 id="managing_code_complexity_over_time" label="31.4.1"><title>Managing Code Complexity Over Time</title><para>The Emacspeak code base has evolved over a period of 12 years. Except for the first six weeks of development, the code base has been developed and maintained using Emacspeak itself. This section summarizes some of the lessons learned with respect to <indexterm id="idx-CHP-31-2784" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>managing code complexity over time</secondary></indexterm>managing code complexity over time.<indexterm id="idx-CHP-31-2785" significance="normal"><primary>code complexity</primary></indexterm></para><para>Throughout its existence, Emacspeak has <emphasis>always</emphasis> remained a spare-time project. Looking at the code base across time, I believe this has had a significant impact on how it has evolved. When working on large, complex software systems as a full-time project, one has the luxury of focusing one's entire concentration on the code base for reasonable stretches of time—e.g., 6 to 12 weeks. This results in tightly implemented code that creates <emphasis>deep</emphasis> code bases.</para><para>Despite one's best intentions, this can also result in code that becomes hard to understand with the passage of time. Large software systems where a single engineer focuses exclusively on the project for a number of years are almost nonexistent; that form of single-minded focus usually leads to rapid burnout!</para><para>In contrast, <indexterm id="idx-CHP-31-2786" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm>Emacspeak is an example of a large software system that has had a single engineer focused on it over a period of 12 years, but only in his spare time. A consequence of developing the system single-handedly over a number of years is that the code base has tended to be naturally "bushy." Notice the distribution of files and lines of code summarized in <xref linkend="summary_of_emacspeak_codebase"/>.</para><table id="summary_of_emacspeak_codebase" label="31-1"><title>Summary of Emacspeak codebase</title><tgroup cols="4"><colspec colnum="1" colname="col1"/><colspec colnum="2" colname="col2"/><colspec colnum="3" colname="col3"/><colspec colnum="4" colname="col4"/><thead><row><entry><para>Layer</para></entry><entry><para>Files</para></entry><entry><para>Lines</para></entry><entry><para>Percentage</para></entry></row></thead><tbody><row><entry><para>TTS core</para></entry><entry><para>6</para></entry><entry><para>3866</para></entry><entry><para>6.0</para></entry></row><row><entry><para>Emacspeak core</para></entry><entry><para>16</para></entry><entry><para>12174</para></entry><entry><para>18.9</para></entry></row><row><entry><para>Emacspeak extensions</para></entry><entry><para>160</para></entry><entry><para>48339</para></entry><entry><para>75.0</para></entry></row><row><entry><para>Total</para></entry><entry><para>182</para></entry><entry><para>64379</para></entry><entry><para>99.9</para></entry></row></tbody></tgroup></table><para><xref linkend="summary_of_emacspeak_codebase"/> highlights the following points:</para><itemizedlist><listitem><para>The TTS core responsible for high-quality speech output is isolated in 6 out of 182 files, and makes up six percent of the code base.</para></listitem><listitem><para>The Emacspeak core—which provides high-level speech services to Emacspeak extensions, in addition to speech-enabling all basic Emacs functionality—is isolated to 16 files, and makes up about 19 percent of the code base.</para></listitem><listitem><para>The rest of the system is split across 160 files, which can be independently improved (or broken) without affecting the rest of the system. Many modules, such as <literal moreinfo="none">emacspeak-url-template</literal>, are themselves bushy—i.e., an individual URL template can be modified without affecting any of the other URL templates.</para></listitem><listitem><para><emphasis>advice</emphasis> reduces code size. The Emacspeak code base, which has approximately 60,000 lines of Lisp code, is a fraction of the size of the underlying system being speech-enabled. A rough count at the end of December 2006 shows that Emacs 22 has over a million lines of Lisp code; in addition, Emacspeak speech-enables a large number of applications not bundled by default with Emacs.</para></listitem></itemizedlist></sect2><sect2 id="conclusion-id017" label="31.4.2"><title>Conclusion</title><para>Here is a brief summary of the <indexterm id="idx-CHP-31-2787" significance="normal"><primary>Emacspeak audio desktop</primary><secondary>insights gained from implementing and using</secondary></indexterm>insights gained from implementing and using Emacspeak:</para><itemizedlist><listitem><para>Lisp <emphasis>advice</emphasis>, and its object-oriented equivalent Aspect Oriented Programming, are very effective means for implementing cross-cutting concerns—e.g., speech-enabling a visual interface.</para></listitem><listitem><para><emphasis>advice</emphasis> is a powerful means for discovering potential points of extension in a complex software system.</para></listitem><listitem><para>Focusing on basic web architecture, and relying on a data-oriented web backed by standardized protocols and formats, leads to powerful spoken web access.</para></listitem><listitem><para>Focusing on the final user experience, as opposed to individual interaction widgets such as sliders and tree controls, leads to a highly efficient, eyes-free environment.</para></listitem><listitem><para>Visual interaction relies heavily on the human eye's ability to rapidly scan the visual display. Effective eyes-free interaction requires transferring some of this responsibility to the computer because listening to large amounts of information is time-consuming. Thus, search in every form is critical for delivering effective eyes-free interaction, on the continuum from the smallest scale (such as Emacs' incremental search to find the right item in a local document) to the largest (such as a Google search to quickly find the right document on the global Web).</para></listitem><listitem><para>Visual complexity, which may become merely an irritant for users capable of using complex visual interfaces, is a show-stopper for eyes-free interaction. Conversely, tools that emerge early in an eyes-free environment eventually show up in the mainstream when the nuisance value of complex visual interfaces crosses a certain threshold. Two examples of this from the Emacspeak experience are:</para></listitem></itemizedlist><simplelist type="vert"><member>—RSS and Atom feeds replacing the need for screen-scraping just to retrieve essential information such as the titles of articles.</member><member>—Emacspeak's use of XSLT to filter content in 2000 parallels the advent of Grease-monkey for applying custom client-side JavaScript to web pages in 2005.</member></simplelist></sect2></sect1><sect1 id="acknowledgments-id006" label="31.5"><title>Acknowledgments</title><para>Emacspeak would not exist without Emacs and the ever-vibrant Emacs developer community that has made it possible to do everything from within Emacs. The Emacspeak implementation would not have been possible without Hans Chalupsky's excellent advice implementation for Emacs Lisp.</para><para>Project <emphasis>libxslt</emphasis> from the GNOME project has helped breathe fresh life into William Perry's Emacs W3 browser; Emacs W3 was one of the early HTML rendering engines, but the code has not been updated in over eight years. That the W3 code base is still usable and extensible bears testimony to the flexibility and power afforded by Lisp as the implementation language.<indexterm id="I_indexterm31_tt718" class="endofrange" startref="idx-CHP-31-2631" significance="normal"><primary>Emacspeak audio desktop</primary></indexterm></para></sect1></chapter><chapter id="code_in_motion" label="32" role=""><title>Code in Motion</title><para><emphasis>Laura Wingerd and Christopher Seiwald</emphasis><indexterm id="idx-CHP-32-2788" significance="normal"><primary>Wingerd</primary></indexterm><indexterm id="idx-CHP-32-2789" significance="normal"><primary>Seiwald</primary></indexterm></para><blockquote><para>The main point is that every successful piece of software has an extended life in which it is worked on by a succession of programmers and designers….</para></blockquote><para><emphasis>Bjarne Stroustrup</emphasis></para><para><emphasis>Early in the planning of this book, greg wilson asked contributors</emphasis> whether <emphasis>Beautiful Code</emphasis> was an apt title. "Much of what you're going to discuss is software design and architecture, rather than code <emphasis>per se</emphasis>," he wrote us.</para><para>But this chapter <emphasis>is</emphasis> about the code. It's not about what the code does, nor is it about how beautifully it does it. Instead, this chapter is about how the code <emphasis>looks</emphasis>: specifically, how certain human-visible traits of coding make serial collaboration possible. It's about the beauty of "code in motion."</para><para>What you're about to read is borrowed largely from Christopher Seiwald's article, "The Seven Pillars of Pretty Code."<footnote id="CHP-32-FNOTE-1"><para>The article is available on the Perforce web site: <ulink url="http://www.perforce.com/perforce/papers/prettycode.html"/></para></footnote> In a nutshell, the Seven Pillars are:</para><itemizedlist><listitem><para>Being "bookish"</para></listitem><listitem><para>Making alike look alike</para></listitem><listitem><para>Overcoming indentation</para></listitem><listitem><para>Disentangling code blocks</para></listitem><listitem><para>Commenting code blocks</para></listitem><listitem><para>Decluttering</para></listitem><listitem><para>Blending in with existing style</para></listitem></itemizedlist><para>While these may sound like mere coding conventions, they're more than that. They're the outward manifestations of a coding practice that keeps product evolution in mind.</para><para>In this chapter, we'll see how the Seven Pillars have supported a piece of code that has been part of a commercial software system for over 10 years. That piece of code is DiffMerge, a component of the Perforce software configuration management system. DiffMerge's job is to produce a classic three-way merge, comparing two versions of a text file ("leg 1" and "leg 2") to a reference version ("the base"). The output interleaves lines of the input files with placeholders marking the lines that conflict. If you've used Perforce, you've seen DiffMerge at work in the <emphasis>p4 resolve</emphasis> command and in Perforce's graphical merge tools.</para><para>DiffMerge was originally written in 1996. Despite its simple goal, a three-way text merge function turns out to be fraught with intricacy. It's a melting pot of special cases arising from the idiosyncrasies of user interfaces, character encodings, programming languages, and programmers themselves. ("That's not a conflict." "Yes, it is." "No, it's not!")</para><para>Over the years DiffMerge has become a locus of significant development at Perforce Software. So, it's not good enough that DiffMerge is simply a correct piece of code. It has to be a piece of code that "plays nice" with the tools we use for coding, debugging, and change management. And it has to be a piece of code that anticipates being changed.</para><para>The road from DiffMerge's first implementation to its present-day form has been uneven, to say the least. It's probably no coincidence that the further we strayed from the Seven Pillars, the rockier the road became. Later in this chapter, we'll reveal some of the potholes (and one major wreck) that beset DiffMerge's 10-year journey.</para><para>All's well that ends well, however. Today's DiffMerge, reprinted at <ulink url="http://www.perforce.com/beautifulcode"/>, is stable and accepts enhancements with ease. It is a demonstration of how coding in anticipation of future change can produce a beautiful piece of code in motion.</para><sect1 id="on_being_bookish" label="32.1"><title>On Being "Bookish"</title><para>"The Seven Pillars of Pretty Code" describes guidelines we use at Perforce Software. The Seven Pillars<footnote id="CHP-32-FNOTE-2"><para>And no, we don't call them "The Seven Pillars" back at the office. In fact, we don't really think of them as separate from our language- or component-specific coding guidelines. But when we strip out the latter, they are what's left.</para></footnote> aren't the only coding guidelines we use, nor are they applied to all of our development projects. We apply them to components such as DiffMerge where the same code is likely to be active in several concurrently supported releases and modified by many programmers. The effect of the Seven Pillars is to make code more comprehensible to the programmers who read it, in more of the contexts in which they find themselves reading it.</para><para>Take, for example, the Seven Pillars' advice to be "bookish." Book and magazine text is composed in columns, usually in columns far narrower than the page. Why? Because narrowness reduces the back-and-forth scanning our eyes must do as we read—reading is easier when our eyes work less. Reading is also easier when what we've just read and what we're about to read are both within our visual range. Research shows that as our eyes change focus from word to word, our brains can take cues from surrounding, unfocused shapes. The more our brains can glean "advance warning" from shapes within the visual periphery, the better they're able to direct our eyes for maximum comprehension.</para><para>Research also seems to show that, when it comes to line lengths of text, there's a difference between reading speed and reading comprehension. Longer lines can be read faster, but shorter lines are easier to comprehend.</para><para>Chunked text is also easier to comprehend than a continuous column of text. That's why columns in books and magazines are divided into paragraphs. Paragraphs, verses, lists, sidebars, and footnotes are the "transaction markers" of text, saying to our brains, "Have you grokked everything so far? Good, please go on."</para><para>Code is not strictly text, of course, but for the purpose of human readability, the same principles apply. Bookish code—that is, code formatted in book-like columns and chunks—is easier to comprehend.</para><para>Bookishness is more than simply keeping lines short. It's the difference between code that looks like this:</para><programlisting id="I_programlisting32_tt719" format="linespecific">
	if( bf-&gt;end == bf-&gt;Lines() &amp;&amp; lf1-&gt;end == lf1-&gt;Lines( ) &amp;&amp;
	    lf2-&gt;end == lf2-&gt;Lines( ) ) return( DD_EOF );
</programlisting><para>and code that looks like this:</para><programlisting id="I_programlisting32_tt720" format="linespecific">
	if( bf-&gt;end == bf-&gt;Lines( ) &amp;&amp;
	    lf1-&gt;end == lf1-&gt;Lines( ) &amp;&amp;
	    lf2-&gt;end == lf2-&gt;Lines( ) )
	        return( DD_EOF );
</programlisting><para>The second of these code snippets is taken from DiffMerge. When we read it, our brains sense the scope of the logic at hand, and our eyes don't have to scan very far from side to side to take it in. (The fact that there's a visual pattern created by the choice of line breaks is also important; we'll get to that in a moment.) Being more bookish, the second snippet is easier to comprehend than the first.</para></sect1><sect1 id="alike_looking_alike" label="32.2"><title>Alike Looking Alike</title><para>The DiffMerge snippet in the previous section also illustrates another principle of writing for comprehensibility: code that <emphasis>is</emphasis> alike <emphasis>looks</emphasis> alike. We see this throughout the DiffMerge code. For example:</para><programlisting id="I_programlisting32_tt721" format="linespecific">
	while( d.diffs == DD_CONF &amp;&amp; ( bf-&gt;end != bf-&gt;Lines( ) ||
	                               lf1-&gt;end != lf1-&gt;Lines( ) ||
	                               lf2-&gt;end != lf2-&gt;Lines( ) ) )
</programlisting><para>The preceding demonstrates how line breaks can create a visual pattern that makes it easier for our brains to recognize a logical pattern. We can tell at a glance that three of the four tests in this <literal moreinfo="none">while</literal> statement are essentially the same.</para><para>Here's one more example of alike looking alike. This one illustrates coding that lets our brains do a successful "one of these is not the same" operation:</para><programlisting id="I_programlisting32_tt722" format="linespecific">
	case MS_BASE:               /* dumping the original */

	    if( selbits = selbitTab[ DL_BASE ][ diffDiff ] )
	    {
	        readFile = bf;
	        readFile-&gt;SeekLine( bf-&gt;start );
	        state = MS_LEG1;
	        break;
	    }

	case MS_LEG1:               /* dumping leg1 */

	    if( selbits = selbitTab[ DL_LEG1 ][ diffDiff ] )
	    {
	        readFile = lf1;
	        readFile-&gt;SeekLine( lf1-&gt;start );
	        state = MS_LEG2;
	        break;
	    }

	case MS_LEG2:               /* dumping leg2 */

	    if( selbits = selbitTab[ DL_LEG2 ][ diffDiff ] )
	    {
	        readFile = lf2;
	        readFile-&gt;SeekLine( lf2-&gt;start );
	    }

	    state = MS_DIFFDIFF;
	    break;
</programlisting><para>Even if you don't know what this code is about, it's clear to see, for example, that <literal moreinfo="none">readfile</literal> and <literal moreinfo="none">state</literal> are set in all three cases, but only in the third case is <literal moreinfo="none">state</literal> set unconditionally. The programmer who wrote this paid attention to making alike look alike; those of us reading it later can see at a glance where the essential logic is.</para></sect1><sect1 id="the_perils_of_indentation" label="32.3"><title>The Perils of Indentation</title><para>We've all been taught to use indentation to show the depth of nesting in logical blocks of code. The deeper the nesting, the farther to the right of the page the nested code appears. Formatting code this way is a good idea, but not because it makes the code any easier to read.</para><para>If anything, deeply indented code is harder to read. Important logic is crowded off to the right, submerged to almost footnote-like insignificance by the layers of if-then-else code that surrounds it, while trivial tests applied in outer blocks seem elevated in importance. So, while indentation is useful for showing where blocks begin and end, it doesn't make the code any easier for us to comprehend.</para><para>The greater peril is not the indentation, however: it's the nesting. Nested code strains human comprehension, plain and simple. Edward Tufte was not being complimentary when he wrote that "Sometimes [PowerPoint] bullet hierarchies are so complex and intensely nested that they resemble computer code." In <emphasis>Code Complete</emphasis> (see "Further Reading," at the end of this chapter), Steve McConnell warns against using nested <literal moreinfo="none">if</literal> statements—not because they're inefficient or ineffective, but because they're hard on human comprehension. "To understand the code, you have to keep the whole set of nested <literal moreinfo="none">if</literal>s in your mind at once," he says. It's no surprise that research points to nested conditionals as the most bug-prone of all programming constructs. We have a bit of anecdotal evidence for this, as you'll read in the section "DiffMerge's Checkered Past."</para><para>So the value of indenting each nesting level is not in making code more comprehensible, but in making the coder more aware of incomprehensibility. "Seven Pillars" advises coders to "overcome indentation"—that is, to code without deep nesting. "This is the most difficult of these practices," admits <indexterm id="idx-CHP-32-2790" significance="normal"><primary>Seiwald</primary></indexterm>Seiwald, "as it requires the most artifice and can often influence the implementation of individual functions."</para><para>Steve McConnell demonstrates some useful implementations in the "Taming Dangerously Deep Nesting" section of <literal moreinfo="none">Code Complete</literal>. DiffMerge makes heavy use of two of them: <literal moreinfo="none">case</literal> statements and decision tables. The end result, as you can see in the DiffMerge source, is that the code itself takes on an outline form that lets us discern the big-picture logic by scanning down the left side of the page. Our brains, conditioned to reading outlines in natural-language text, find this easier to comprehend than the sideways-V form of deeply nested code.</para></sect1><sect1 id="navigating_code" label="32.4"><title>Navigating Code</title><para>All Seven Pillars are illustrated in DiffMerge, to one extent or another. For example, the DiffMerge code is constructed of discrete, logical blocks. Each block does a single thing or single kind of thing, and what it does is either self-evident or described in a comment that prefaces the block. Code like this is the result of the Seven Pillars' advice to disentangle and comment code blocks. It's analogous to well-organized expository writing, where definition lists and titled sections help readers navigate densely packed technical information.</para><para>The lack of clutter also makes the DiffMerge code easier to navigate. One of DiffMerge's clutter-reducing tricks is to use tiny names for variables that are referenced repeatedly throughout the code. This goes against sage advice to use meaningful and descriptive variable names, to be sure. But there's a point at which overuse of long names creates so much clutter that it only impedes comprehension. Writers know this; it's why we use pronouns, surnames, and acronyms in our prose.</para><para>The comments in DiffMerge are also clutter-free. In 10-year-old code, it's easy to end up with as many comments that describe how the code <emphasis>used</emphasis> to work—along with additional comments about what changed—as comments that describe the current code. But there isn't really any reason to keep a running history of the program's evolution in the code itself; your source control management system has all that information and offers much better ways to track it. (We'll show examples in the next section.) The programmers working on DiffMerge have done a good job keeping the closets clean, as it were. The same goes for code. In DiffMerge, the old code isn't simply commented out, it's <emphasis>gone</emphasis>. The remaining code and comments are uncluttered with the distractions of history.<footnote id="CHP-32-FNOTE-3"><para>One comment in DiffMerge does describe a change: "2-18-97 (<indexterm id="idx-CHP-32-2791" significance="normal"><primary>Seiwald</primary></indexterm>seiwald) - translated to C++." This comment remains in the code as a historical curiosity.</para></footnote></para><para>The DiffMerge code also makes liberal use of whitespace. In addition to reducing the appearance of clutter, whitespace increases comprehensibility. When bookish chunks and alike patterns are set off by whitespace, they take on visual shapes our brains can recognize. As we read through the code, our brains index these shapes; later, we unconsciously use these shapes to find code we remember having read.</para><para>Even though it has been changed repeatedly over the years, by many different programmers, the DiffMerge code is largely consistent in its visual appearance, DiffMerge's contributors have each made an effort to "blend in." That is, each one has subjugated personal style and preferences to make his DiffMerge code look like the rest of DiffMerge's code. Blending in produces a consistency that reduces the work our brains have to do. It effectively amplifies all of the readability tricks we've just discussed.</para><para>If you've visited <ulink url="http://www.perforce.com/beautifulcode"/>, you will have noticed that the DiffMerge code isn't perfect, even by the Seven Pillars' standards. There are places where it could be more bookish, or where code could blend in more, for example. Sure, we'd like to clean those up, but while we like pretty code, we like clean merges even better. Changes to variable names, whitespace, line breaks, and so forth can be more of an obstacle to merging than logic changes. When we make changes like these in one branch, we increase the risk that merging bug fixes from other branches will <emphasis>create</emphasis> bugs. Any benefit to be gained by rewriting DiffMerge's ugly parts has to be weighed against the resources it could take to recover from a bad merge. In the section "DiffMerge's Checkered Past," we'll relate what happens when that scale tips.</para></sect1><sect1 id="the_tools_we_use" label="32.5"><title>The Tools We Use</title><para>Certainly we need code to be understandable when we read the source files directly. We also need the code to be understandable when we encounter it in diffs, merges, patches, debuggers, code inspections, compiler messages, and a variety of other contexts and tools. As it turns out, code written with the Seven Pillars in mind is more readable in more of the tools we use to manage code.</para><para>For example, DiffMerge code is human-readable even without syntax highlighting. In other words, we don't have to depend on context-sensitive source code editors to read it. It's just as readable when displayed as plain text by debuggers, compilers, and web browsers. Here's a snippet of DiffMerge in <emphasis>gdb</emphasis>:</para><programlisting id="I_programlisting32_tt723" format="linespecific">
	Breakpoint 3, DiffMerge::DiffDiff (this=0x80e10c0) at diff/diffmerge.cc:510
	510             Mode initialMode = d.mode;
	(gdb) <userinput moreinfo="none">list 505,515</userinput>
	505             DiffGrid d = diffGrid
	506                     [ df1-&gt;StartLeg() == 0 ][ df1-&gt;StartBase( ) == 0 ]
	507                     [ df2-&gt;StartLeg() == 0 ][ df2-&gt;StartBase( ) == 0 ]
	508                     [ df3-&gt;StartL1() == 0 ][ df3-&gt;StartL2( ) == 0 ];
	509
	510             Mode initialMode = d.mode;
	511
	512             // Pre-process rules, typically the outer snake information
	513             // contradicts the inner snake, its not perfect, but we use
	514             // the length of the snake to determine the best outcome.
	515
	(gdb) <userinput moreinfo="none">print d</userinput>
	$1 = {mode = CONF, diffs = DD_CONF}
	(gdb)
</programlisting><para>When working on code that changes as often as DiffMerge (it has been changed 175 times since it was first written), programmers spend considerable time looking at it in diff and merge tools. What these tools have in common is that they restrict the horizontal view of source files, and they add a certain amount of clutter of their own. Code like DiffMerge's is readable even in these conditions. In command-line diffs, its lines don't wrap. In graphical diff tools, we don't have to fiddle with the horizontal scroll bar to see the bulk of its lines, as <xref linkend="diffmerge_code_viewed_in_a_graphical_diff_tool"/> demonstrates.<footnote id="CHP-32-FNOTE-4"><para>This is a screenshot from P4Merge, a graphical tool built on DiffMerge itself.</para></footnote></para><figure id="diffmerge_code_viewed_in_a_graphical_diff_tool" label="32-1" float="0"><title>DiffMerge code viewed in a graphical diff tool</title><mediaobject id="I_mediaobject32_tt724"><imageobject role="print"><imagedata fileref="figs/print/beauty_3201.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3201.png" format="PNG"/></imageobject></mediaobject></figure><para>And as <xref linkend="diffmerge_code_in_an_annotated_history_viewer"/> shows, a margin-hungry annotated history viewer is positively roomy when displaying the bookish DiffMerge code.</para><figure id="diffmerge_code_in_an_annotated_history_viewer" label="32-2" float="0"><title>DiffMerge code in an annotated history viewer</title><mediaobject id="I_mediaobject32_tt725"><imageobject role="print"><imagedata fileref="figs/print/beauty_3202.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3202.png" format="PNG"/></imageobject></mediaobject></figure><para>Bookishness not only makes code more readable in merge tools, it makes the code itself easier to merge. For one thing, the scope of an edit is easier to control when logical blocks are set off by whitespace. And for another, having less nested code means having proportionally fewer instances of inverted and leapfrogged block delimiters to sort out.</para></sect1><sect1 id="diffmerges_checkered_past" label="32.6"><title>DiffMerge's Checkered Past</title><para>We have a record of every change, branch, and merge involving DiffMerge throughout its 10-year history. And it's an interesting record. <xref linkend="diffmerges_release_branches"/> offers a thumbnail view of changes to the released versions of DiffMerge. It shows that DiffMerge originated in the mainline (the lowest line on the diagram) and has been branched into over 20 releases. Changes to DiffMerge have occured in the mainline, for the most part. But the thumbnail shows peculiar activity in some of the most recent releases.</para><figure id="diffmerges_release_branches" label="32-3" float="0"><title>DiffMerge's release branches</title><mediaobject id="I_mediaobject32_tt726"><imageobject role="print"><imagedata fileref="figs/print/beauty_3203.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3203.png" format="PNG"/></imageobject></mediaobject></figure><para>A count of DiffMerge's patches per release branch, seen in <xref linkend="number_of_patches_applied_to_diffmerge_per_release"/>, is even more intriguing. It shows that DiffMerge was rarely patched after it was released—until the 2004.2 release, that is. Then the post-release patch rate soars, only to abate again in the 2006.2 release. Why are releases 2004.2 through 2006.1 so riddled with patches?</para><para>Here's the backstory: DiffMerge started out as a serviceable but simple program. In its early life, it did little to discriminate between actual merge conflicts and nonconflicting, adjacent-line changes. In 2004, we enhanced DiffMerge to be smarter about detecting and resolving conflicts. As of the 2004.2 release, DiffMerge was certainly more capable, but it was buggy. We got lots of bug reports in 2004.2 and 2005.1—hence the large number of patches. We tried to clean up the code for release 2005.2, but the cleanup resulted in a bug so intractable that we had to restore the 2005.1 version into the 2005.2 release. Then, in 2006, we rewrote the troublesome parts of DiffMerge completely. The rewrite was quite successful, although we did have to tweak it in release 2006.1. Since then, DiffMerge been very stable, and its post-release patch rate is back down to zero.</para><figure id="number_of_patches_applied_to_diffmerge_per_release" label="32-4" float="0"><title>Number of patches applied to DiffMerge per release</title><mediaobject id="I_mediaobject32_tt727"><imageobject role="print"><imagedata fileref="figs/print/beauty_3204.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3204.png" format="PNG"/></imageobject></mediaobject></figure><para>So, what went wrong when we rewrote DiffMerge in 2004? We believe it was that we had let the code become incomprehensible. Perhaps our code reviews at the time had lost sight of the Seven Pillars, or perhaps we had skipped some reviews entirely. At any rate, although it continued to pass regression testing, DiffMerge sailed into release branches full of bugs we hadn't seen coming on board.</para><para>We have no way to measure how readable source code is or how well it conforms to the Seven Pillars. But in retrospect, we see a clue that would have leapt out at us had we been looking for it at the time. <xref linkend="number_of_diffmerges_if_statements_at_successive_indentation_de"/> shows a count of <literal moreinfo="none">if</literal> statements and their successive nesting levels (as inferred from their indentation depths) in each initial branch of Diff-Merge. By the time we branched DiffMerge for 2004.2, apparently, we had doubled the number of <literal moreinfo="none">if</literal> statements in the code. And for the first time, there were <literal moreinfo="none">if</literal>s nested more three levels deep.</para><figure id="number_of_diffmerges_if_statements_at_successive_indentation_de" label="32-5" float="0"><title>Number of DiffMerge's if statements at successive indentation depths per release</title><mediaobject id="I_mediaobject32_tt728"><imageobject role="print"><imagedata fileref="figs/print/beauty_3205.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3205.png" format="PNG"/></imageobject></mediaobject></figure><para>Correlation is not causation, as they say, and of course there could have been other contributing factors. The design of the enhancements, the test cases, the other coding constructs—even the size of the source code file—any or all of these could have contributed to the higher rate of errors. But given what we know about deeply nested conditionals and comprehensibility, it's hard not to take this glaring correlation at face value.</para><para>The 2006 overhaul of DiffMerge was driven by a mandate to overcome indentation. The overhaul replaced deeply nested conditionals with <literal moreinfo="none">switch</literal> statements whose <literal moreinfo="none">case</literal> options were values defined in the new <literal moreinfo="none">diffGrid</literal> decision table. The table, whose layout was designed to be human-readable, itemized all the conditions we were currently handing <emphasis>and</emphasis> gave us placeholders for conditions we might eventually want to handle. Thus, we not only replaced troublesome code, we gave ourselves headroom for future enhancements.</para></sect1><sect1 id="conclusion-id018" label="32.7"><title>Conclusion</title><para>To a programmer working on code in motion, beauty is code that can be modified with a minimum of fuss. You read the code, determine what it does, and change it. Your success depends as much on how well you understood the code to start with as it does on your ability to code. It also depends on how well your code is understood by the <emphasis>next</emphasis> programmers to tackle it; if you're never called in to help them out, you've done well.</para><para>Were we to trim the narrative from this chapter, all we'd really have left to say is that the success of code in motion depends on how comprehensible it is to the programmers who read it. But this is not news to anyone.</para><para>What <emphasis>is</emphasis> news is that programmers read code in diffs, patches, merges, compiler errors, and debuggers—not just in syntax-colored text editors—and that they frequently, if unconsciously, infer logic from the visual appearance of code as well as from the code itself. In other words, there's more to comprehending code than meets the eye.</para><para>In this chapter, we've examined the effect of using "The Seven Pillars of Pretty Code" as guidelines to make code more comprehensible in more contexts. We've had success with the Seven Pillars. We've used them to write code that can move with the flow of change, and we think that's beautiful.</para></sect1><sect1 id="acknowledgments-id007" label="32.8"><title>Acknowledgments</title><para>Christopher <indexterm id="idx-CHP-32-2792" significance="normal"><primary>Seiwald</primary></indexterm>Seiwald, James Strickland, Jeff Anton, Mark Mears, Caedmon Irias, Leigh Brasington, and Michael Bishop contributed to DiffMerge. Perforce Software holds the copyright to the DiffMerge source code.</para></sect1><sect1 id="further_reading-id003" label="32.9"><title>Further Reading</title><para>Kim, S., <emphasis>Adaptive Bug Prediction by Analyzing Project History</emphasis>, Ph.D. Dissertation, Department of Computer Science, University of California Santa Cruz, 2006.</para><para>McConnell, S., <emphasis>Code Complete</emphasis>, Microsoft Press, 1993.</para><para>McMullin, J., Varnhagen, C. K., Heng, P., and Apedoe, X., "Effects of Surrounding Information and Line Length on Text Comprehension from the Web," <emphasis>Canadian Journal of Learning and Technology</emphasis>, Vol. 28, No. 1, Winter/hiver, 2002.</para><para>O'Brien, M. P., <emphasis>Software Comprehension - A Review and Direction</emphasis>, Department of Computer Science and Information Systems, University of Limerick, Ireland, 2003.</para><para>Pan, K., <emphasis>Using Evolution Patterns to Find Duplicated Bugs</emphasis>, Ph.D. Dissertation, Department of Computer Science, University of California Santa Cruz, 2006.</para><para>Reichle, E.D., Rayner, K., and Pollatsek, A., <emphasis>The E-Z Reader Model of Eye Movement Control in Reading: Comparisons to Other Models</emphasis>, Behavioral and Brain Sciences, Vol. 26, No. 4, 2003.</para><para>Seiwald, C., "The Seven Pillars of Pretty Code," Perforce Software, 2005, <ulink url="http://www.perforce.com/perforce/papers/prettycode.html"/>.</para><para>Tufte, Edward R., <emphasis>The Cognitive Style of PowerPoint</emphasis>, Graphics Press LLC, 2004.</para><para>Whitehead, J., and Kim, S., <emphasis>Predicting Bugs in Code Changes</emphasis>, Google Tech Talks, 2006.</para></sect1></chapter><chapter id="writing_programs_for_the_book" label="33" role=""><title>Writing Programs for "The Book"</title><para><emphasis>Brian Hayes</emphasis><indexterm id="idx-CHP-33-2793" significance="normal"><primary>Hayes</primary></indexterm></para><para><emphasis>The mathematician paul erdös often spoke of the book</emphasis>, a legendary volume (not to be found on the shelves of any earthly library) in which are inscribed the best possible proofs of all mathematical theorems. Perhaps there is also a <emphasis>Book</emphasis> for programs and algorithms, listing the best solution to every computational problem. To earn a place in those pages, a program must be more than just correct; it must also be lucid, elegant, concise, even witty.</para><para>We all strive to create such gems of algorithmic artistry. And we all struggle, now and then, with a stubborn bit of code that just won't shine, no matter how hard we polish it. Even if the program produces correct results, there's something strained and awkward about it. The logic is a tangle of special cases and exceptions to exceptions; the whole structure seems brittle and fragile. Then, unexpectedly, inspiration strikes, or else a friend from down the hall shows you a new trick, and suddenly you've got one for <emphasis>The Book</emphasis>.</para><para>In this chapter I tell the story of one such struggle. It's a story with a happy ending, although I'll leave it to readers to decide whether the final program deserves a place in <emphasis>The Book</emphasis>. I wouldn't be brash enough even to suggest the possibility except that this is one of those cases where the crucial insight came not from me but from a friend down the hall—or, rather, from a friend across the continent.</para><sect1 id="the_nonroyal_road" label="33.1"><title>The Nonroyal Road</title><para>The program I'll be talking about comes from the field of <indexterm class="startofrange" id="idx-CHP-33-2794" significance="normal"><primary>computational geometry</primary></indexterm>computational geometry, which seems <indexterm id="idx-CHP-33-2795" significance="normal"><primary>errors</primary><secondary>Euclid</secondary><tertiary>advice to student</tertiary></indexterm>to be peculiarly rich in problems that look simple on first acquaintance but turn out to be real stinkers when you get into the details. What do I mean by computational geometry? It's not the same as computer graphics, although there are close connections. Algorithms in computational geometry live not in the world of pixels but in that idealized ruler-and-compass realm where points are dimensionless, lines have zero thickness, and circles are perfectly round. Getting exact results is often essential in these algorithms, because even the slightest inaccuracy can utterly transform the outcome of a computation. Changing a digit far to the right of the decimal point might turn the world inside out.</para><para>Euclid supposedly told a princely student, "There is no royal road to geometry." Among the nonroyal roads, the computational pathway is notably muddy, rutty, and potholed. The difficulties met along the way sometimes have to do with computational efficiency: keeping a program's running time and memory consumption within reasonable bounds. But efficiency is not the main issue with the geometric algorithms that concern me here; instead, the challenges are conceptual and aesthetic. Can we get it right? Can we make it beautiful?</para><para>The program presented below in several versions is meant to answer a very elementary question: given three points in the plane, do all of the points lie along the same line? This is such a simple-sounding problem, it ought to have a simple solution as well. A few months ago, when I needed a routine to answer the collinearity question (as a component of a larger program), the task looked so straightforward that I didn't even pause to consult the literature and see how others might have solved it. I don't exactly regret that haste—wrestling with the problem on my own must have taught me something, or at least built some character—but I admit it was not the royal road to the right answer. I wound up repeating the steps of many who went before me. (Maybe that's why the road is so rutted!)</para></sect1><sect1 id="warning_to_parenthophobes" label="33.2"><title>Warning to Parenthophobes</title><para>I present the code in <indexterm id="idx-CHP-33-2796" significance="normal"><primary>computational geometry</primary><secondary>LISP</secondary></indexterm>Lisp. I'm not going to apologize for my choice of programming language, but neither do I want to turn this chapter into a tract for recruiting Lisp converts. I'll just say that I believe multilingualism is a good thing. If reading the code snippets below teaches you something about an unfamiliar language, the experience will do you no harm. All of the <indexterm id="idx-CHP-33-2797" significance="normal"><primary>LISP</primary><secondary>procedure definition</secondary></indexterm>procedures are very short—half a dozen lines or so. <xref linkend="bits_and_pieces_of_a_lisp_procedure_definition"/> offers a thumbnail guide to the structure of a Lisp procedure.</para><para>Incidentally, the algorithm implemented by the program in the figure is surely in <emphasis>The Book</emphasis>. It is Euclid's <indexterm id="idx-CHP-33-2798" significance="normal"><primary>errors</primary><secondary>Euclid</secondary><tertiary>algorithm for calculating greatest common divisor of two numbers</tertiary></indexterm>algorithm for calculating the greatest common divisor of two numbers.</para><figure id="bits_and_pieces_of_a_lisp_procedure_definition" label="33-1" float="0"><title>Bits and pieces of a Lisp procedure definition</title><mediaobject id="I_mediaobject33_tt729"><imageobject role="print"><imagedata fileref="figs/print/beauty_3301.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3301.png" format="PNG"/></imageobject></mediaobject></figure></sect1><sect1 id="three_in_a_row" label="33.3"><title>Three in a Row</title><para>If you were working out a <indexterm class="startofrange" id="idx-CHP-33-2799" significance="normal"><primary>computational geometry</primary><secondary>collinearity problem</secondary></indexterm>collinearity problem with pencil and paper, how would you go about it? One natural approach is to plot the positions of the three points on graph paper, and then, if the answer isn't obvious by inspection, draw a line through two of the points and see whether the line passes through the third point (see <xref linkend="three_noncollinear_points"/>). If it's a close call, accuracy in placing the points and drawing the line becomes critical.</para><figure id="three_noncollinear_points" label="33-2" float="0"><title>Three noncollinear points</title><mediaobject id="I_mediaobject33_tt730"><imageobject role="print"><imagedata fileref="figs/print/beauty_3302.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3302.png" format="PNG"/></imageobject></mediaobject></figure><para>A computer program can do the same thing, although for the computer nothing is ever "obvious by inspection." To draw a line through two points, the program derives the equation of that line. To see whether the third point lies on the line, the program tests whether or not the coordinates of the point satisfy the equation. (Exercise: For any set of three given points, there are three pairs of points you could choose to connect, in each case leaving a different third point to be tested for collinearity. Some choices may make the task easier than others, in the sense that less precision is needed. Is there some simple criterion for making this decision?)</para><para>The equation of a line takes the form <emphasis>y=mx+b</emphasis>, where <emphasis>m</emphasis> is the slope and <emphasis>b</emphasis> is the <emphasis>y</emphasis>-intercept, the point (if there is one) where the line crosses the <emphasis>y</emphasis>-axis. So, given three points <emphasis>p</emphasis>, <emphasis>q</emphasis>, and <emphasis>r</emphasis>, you want to find the values of <emphasis>m</emphasis> and <emphasis>b</emphasis> for the line that passes through two of them, and then test the <emphasis>x</emphasis>-and <emphasis>y</emphasis>-coordinates of the third point to see if the same equation holds.</para><para>Here's the code:</para><programlisting id="I_programlisting33_tt731" format="linespecific">
	(defun naive-collinear (px py qx qy rx ry)
	  (let ((m (slope px py qx qy))
	        (b (<indexterm id="idx-CHP-33-2800" significance="normal"><primary>y-intercept of a vertical line</primary></indexterm>y-intercept px py qx qy)))
	    (= ry (+ (* m rx) b))))
</programlisting><para>The procedure is a predicate: it returns a Boolean value of true or false (in Lisp argot, <literal moreinfo="none">t</literal> or <literal moreinfo="none">nil</literal>). The six arguments are the <emphasis>x</emphasis>-and <emphasis>y</emphasis>-coordinates of the points <emphasis>p</emphasis>, <emphasis>q</emphasis>, and <emphasis>r</emphasis>. The <literal moreinfo="none">let</literal> form introduces local variables named <literal moreinfo="none">m</literal> and <literal moreinfo="none">b</literal>, binding them to values returned by the procedures <literal moreinfo="none">slope</literal> and <literal moreinfo="none">y-intercept</literal>. I'll return shortly to the definitions of those procedures, but their <indexterm id="idx-CHP-33-2801" significance="normal"><primary>naïve-collinear function</primary></indexterm>functions should be apparent from their names. Finally, the last line of the procedure does all the work, posing the question: is the <emphasis>y</emphasis>-coordinate of point <emphasis>r</emphasis> equal to <emphasis>m</emphasis> times the <emphasis>x</emphasis>-coordinate of <emphasis>r</emphasis>, plus <emphasis>b</emphasis>? The answer is returned as the value of the <literal moreinfo="none">naive-collinear</literal> function.</para><para>Could it be simpler? Well, we'll see. Does it work? Often. If you were to set the procedure loose on a large collection of points generated at random, it would probably run without error for a very long time. Nevertheless, it's easy to break it. Just try applying it to points with (<emphasis>x y</emphasis>) coordinates (0 0), (0 1), and (0 2). These points are surely collinear—they all lie on the <emphasis>y</emphasis>-axis—and yet the <literal moreinfo="none">naive-collinear</literal> procedure can't be expected to return a sensible value when given them as arguments.</para><para>The root cause of this failure is lurking inside the definition of <literal moreinfo="none">slope</literal>. Mathematically, the slope <emphasis>m</emphasis> is Δ<emphasis>y</emphasis>/Δ<emphasis>x</emphasis>, which the program calculates as follows:</para><programlisting id="I_programlisting33_tt732" format="linespecific">
	(defun slope (px py qx qy)
	  (/ (- qy py) (- qx px))))
</programlisting><para>If <emphasis>p</emphasis> and <emphasis>q</emphasis> happen to have the same <emphasis>x</emphasis>-coordinate, then Δ<emphasis>x</emphasis> is zero, and Δ<emphasis>y</emphasis>/Δ<emphasis>x</emphasis> is undefined. If you insist on trying to calculate the slope, you'll get no further than a divide-by-zero error. There are lots of ways of coping with this annoyance. The method I chose as I first assembled the pieces of this little program was to have <literal moreinfo="none">slope</literal> return a special signal value if <literal moreinfo="none">px</literal> is equal to <literal moreinfo="none">qx</literal>. The Lisp custom is to use the value <literal moreinfo="none">nil</literal> for this purpose:</para><programlisting id="I_programlisting33_tt733" format="linespecific">
	(defun slope (px py qx qy)
	  (if (= px qx)
	      nil
	      (/ (- qy py) (- qx px))))
</programlisting><para>Like the slope, the <emphasis>y</emphasis>-intercept of a <indexterm id="idx-CHP-33-2802" significance="normal"><primary>vertical line</primary></indexterm>vertical line is also undefined because the line crosses the <emphasis>y</emphasis>-axis either nowhere or (if <emphasis>x</emphasis>=0) everywhere. The same <literal moreinfo="none">nil</literal> trick applies:</para><programlisting id="I_programlisting33_tt734" format="linespecific">
	(defun y-intercept (px py qx qy)
	  (let ((m (slope px py qx qy)))
	    (if (not m)
	        nil
	        (- py (* m px)))))
</programlisting><para>Now, I also had to re-rig the calling procedure to handle the possibility that the slope <literal moreinfo="none">m</literal> is not a number but a bogus value:</para><programlisting id="I_programlisting33_tt735" format="linespecific">
	(defun less-naive-collinearp (px py qx qy rx ry)
	  (let ((m (slope px py qx qy))
	        (b (y-intercept px py qx qy)))
	    (if (numberp m)
	        (= ry (+ (* m rx) b))
	        (= px rx))))
</programlisting><para>If <emphasis>m</emphasis> is numeric—if the predicate (<literal moreinfo="none">numberp m</literal>) returns t—then I proceed as before. Otherwise, I know that <emphasis>p</emphasis> and <emphasis>q</emphasis> share the same <emphasis>x</emphasis>-coordinate. It follows that the three points are collinear if <emphasis>r</emphasis> also has this same <emphasis>x</emphasis> value.</para><para>As the program evolved, the need to make special provisions for vertical lines was a continual irritation. It began to look like every procedure I wrote would have some ugly patch bolted on to deal with the possibility that a line is parallel to the <emphasis>y</emphasis>-axis. Admittedly, the patch was just an <literal moreinfo="none">if</literal> expression, an extra line or two of code, not a major issue of software engineering. Conceptually, though, it seemed a needless complication, and perhaps a sign that I was doing something wrong or making life harder than it had to be. Vertical lines are not fundamentally any different from horizontal ones, or from lines that wander across the plane at any other angle. It's an arbitrary convention to measure slope with respect to the <emphasis>y</emphasis>-axis; the universe would look no different if we all adopted a different reference direction.</para><para>This observation suggests a way around the problem: rotate the whole coordinate frame. If a set of points are collinear in one frame, they must be collinear in all other frames as well. Tilt the axes by a few degrees one way or the other, and the divide-by-zero impasse disappears. The rotation is not difficult or <indexterm id="idx-CHP-33-2803" significance="normal"><primary>computational geometry</primary></indexterm>computationally expensive; it's just a matrix multiplication. On the other hand, taking this approach means I still have to write that <literal moreinfo="none">if</literal> expression somewhere, testing to see whether <literal moreinfo="none">px</literal> is equal to <literal moreinfo="none">qx</literal>. What I'd really prefer is to streamline the logic and get rid of the branch point altogether. Shouldn't it be possible to test for <indexterm id="idx-CHP-33-2804" significance="normal"><primary>computational geometry</primary><secondary>collinearity problem</secondary></indexterm>collinearity by means of some simple calculation on the coordinates of the points, without any kind of case analysis?</para><para>Here's a solution recommended (in a slightly different context) by one web site, which I shall allow to remain anonymous: when Δ<emphasis>x</emphasis> is 0, just set Δ<emphasis>y</emphasis>/Δ<emphasis>x</emphasis> to 10<superscript>10</superscript>, a value "close enough to infinity." As a practical matter, I suspect that this policy might actually work quite well, most of the time. After all, if the input to the program derives in any way from <indexterm id="idx-CHP-33-2805" significance="normal"><primary>slopes</primary><secondary>measurement with respect to the y-axis</secondary></indexterm>measurements made in the real world, there will be errors far larger than 1 part in 10<superscript>10</superscript>. All the same, this is a strategy I did not consider seriously. I may not know what the <emphasis>Book</emphasis> version of <literal moreinfo="none">collinear</literal> looks like, but I refuse to believe it has a constant defined as "close enough to infinity."<indexterm id="I_indexterm33_tt736" class="endofrange" startref="idx-CHP-33-2799" significance="normal"><primary>computational geometry</primary><secondary>collinearity problem</secondary></indexterm></para></sect1><sect1 id="the_slippery_slope" label="33.4"><title>The Slippery Slope</title><para>Instead of drawing a line through two points and seeing whether the third point is on the line, suppose I drew all three lines and checked to see whether they are really the same line. Actually, I would need to draw only two of the lines, because if line <mediaobject id="I_mediaobject33_tt737"><imageobject role="print"><imagedata fileref="figs/print/pq.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/pq.png" format="PNG"/></imageobject></mediaobject> is identical to line <mediaobject id="I_mediaobject33_tt738"><imageobject role="print"><imagedata fileref="figs/print/qr.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/qr.png" format="PNG"/></imageobject></mediaobject>, it must also be equal to <mediaobject id="I_mediaobject33_tt739"><imageobject role="print"><imagedata fileref="figs/print/pr.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/pr.png" format="PNG"/></imageobject></mediaobject>. Furthermore, it turns out I need to compare only the slopes, not the <emphasis>y</emphasis>-intercepts. (Do you see why?) Judging by eye whether two lines are really coincident or form a narrow scissors angle might not be the most reliable procedure, but in the <indexterm id="idx-CHP-33-2806" significance="normal"><primary>computational geometry</primary></indexterm>computational world, it comes down to a simple comparison of two numbers, the <emphasis>m</emphasis> values (see <xref linkend="testing_collinearity_by_comparing_slopes"/>)<indexterm id="idx-CHP-33-2807" significance="normal"><primary>computational geometry</primary><secondary>collinearity</secondary></indexterm><indexterm id="idx-CHP-33-2808" significance="normal"><primary>slopes</primary><secondary>comparing to test collinearity</secondary></indexterm>.</para><figure id="testing_collinearity_by_comparing_slopes" label="33-3" float="0"><title>Testing collinearity by comparing slopes</title><mediaobject id="I_mediaobject33_tt740"><imageobject role="print"><imagedata fileref="figs/print/beauty_3303.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3303.png" format="PNG"/></imageobject></mediaobject></figure><para>I wrote a new version of <literal moreinfo="none">collinear</literal> as follows:</para><programlisting id="I_programlisting33_tt741" format="linespecific">
	(defun mm-collinear (px py qx qy rx ry)
	  (equalp (slope px py qx qy)
	          (slope qx qy rx ry)))
</programlisting><para>What an improvement! This looks much simpler. There's no <literal moreinfo="none">if</literal> expression calling attention to the distinguished status of vertical lines; all sets of points are treated the same way.</para><para>I must confess, however, that the simplicity and the apparent uniformity are an illusion, based on some Lisp trickery going on behind the scenes. Note that I compare the slopes not with <literal moreinfo="none">=</literal> but with the generic equality predicate <literal moreinfo="none">equalp</literal>. The procedure works correctly only because <literal moreinfo="none">equalp</literal> happens to do the right thing whether <literal moreinfo="none">slope</literal> returns a number or <literal moreinfo="none">nil</literal>. (That is, the two slopes are considered equal if they are both the same number or if they are both <literal moreinfo="none">nil</literal>.) In a language with a fussier type system, the definition would not be so sweetly concise. It would have to look something like this:</para><programlisting id="I_programlisting33_tt742" format="linespecific">
	(defun typed-mm-collinear (px py qx qy rx ry)
	  (let ((pq-slope (slope px py qx qy))
	        (qr-slope (slope qx qy rx ry)))
	    (or (and (numberp pq-slope)
	             (numberp qr-slope)
	             (= pq-slope qr-slope))
	        (and (not pq-slope)
	             (not qr-slope)))))
</programlisting><para>This is not nearly as pretty, although even in this more-explicit form, the logic seems <indexterm id="idx-CHP-33-2809" significance="normal"><primary>slopes</primary><secondary>comparing to test collinearity</secondary></indexterm>to me less tortured than the "naïve" version. The reasoning is that <mediaobject id="I_mediaobject33_tt743"><imageobject role="print"><imagedata fileref="figs/print/pq.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/pq.png" format="PNG"/></imageobject></mediaobject> and <mediaobject id="I_mediaobject33_tt744"><imageobject role="print"><imagedata fileref="figs/print/qr.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/qr.png" format="PNG"/></imageobject></mediaobject> are the same line if the slopes are both numbers and those numbers are equal, or if both slopes are <literal moreinfo="none">nil</literal>. And, anyway, should one penalize a clever Lisp program just because other languages can't do the same trick?</para><para>I would have been willing to call it quits at this point and accept <literal moreinfo="none">mm-collinear</literal> as the final version of the program, but for another anomaly that turned up in testing. Both <literal moreinfo="none">mm-collinear</literal> and <literal moreinfo="none">less-naive-collinear</literal> could successfully discriminate between collinear points and near misses; a case like <emphasis>p</emphasis>=(0 0), <emphasis>q</emphasis>=(1 0), <emphasis>r</emphasis>=(1000000 1) was not a challenge. But both procedures failed on this set of points: <emphasis>p</emphasis>=(0 0), <emphasis>q</emphasis>=(0 0), <emphasis>r</emphasis>=(1 1).</para><para>A first question is what <emphasis>should</emphasis> happen in this instance. The program is supposed to be testing the <indexterm id="idx-CHP-33-2810" significance="normal"><primary>computational geometry</primary><secondary>collinearity</secondary></indexterm>collinearity of three points, but here <emphasis>p</emphasis> and <emphasis>q</emphasis> are actually the same point. My own view is that such points are indeed collinear because a single line can be drawn through all of them. I suppose the opposite position is also defensible, on the grounds that a line of <emphasis>any</emphasis> slope could be drawn through two coincident points. Unfortunately, the two procedures, as written, do not conform to <emphasis>either</emphasis> of these rules. They return nil for the example given above but <literal moreinfo="none">t</literal> for the points <emphasis>p</emphasis>=(0 0), <emphasis>q</emphasis>=(0 0), and <emphasis>r</emphasis>=(0 1). Surely this is pathological behavior by anyone's standards.</para><para>I could solve this problem by edict, declaring that the three arguments to the procedure must be distinct points. But then I'd have to write code to catch violations of the rule, raise exceptions, return error values, scold criminals, etc. It's not worth the bother.</para></sect1><sect1 id="the_triangle_inequality" label="33.5"><title>The Triangle Inequality</title><para>Here's yet another way of rethinking the problem. Observe that if <emphasis>p</emphasis>, <emphasis>q</emphasis>, and <emphasis>r</emphasis> are <emphasis>not</emphasis> collinear, they define a triangle (<xref linkend="testing_collinearity_by_the_triangle_inequality"/>). It's a property of any triangle that the longest side is shorter than the sum of the smaller sides. If the three points are collinear, however, the triangle collapses on itself, and the longest "side" is exactly equal to the sum of the smaller "sides."<indexterm id="idx-CHP-33-2811" significance="normal"><primary>triangle inequality</primary></indexterm></para><figure id="testing_collinearity_by_the_triangle_inequality" label="33-4" float="0"><title>Testing collinearity by the triangle inequality</title><mediaobject id="I_mediaobject33_tt745"><imageobject role="print"><imagedata fileref="figs/print/beauty_3304.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3304.png" format="PNG"/></imageobject></mediaobject></figure><para>(For the example shown in this figure, the long side is shorter than the sum of the other two sides by about 0.067.)<indexterm id="idx-CHP-33-2812" significance="normal"><primary>computational geometry</primary><secondary>testing collinearity by triangle inequality</secondary></indexterm></para><para>The code for this version of the function is not quite so compact as the others, but what's going on inside is simple enough:</para><programlisting id="I_programlisting33_tt746" format="linespecific">
	(defun <indexterm id="idx-CHP-33-2813" significance="normal"><primary>triangle-collinear function</primary></indexterm>triangle-collinear (px py qx qy rx ry)
	  (let ((pq (<indexterm id="idx-CHP-33-2814" significance="normal"><primary>distance procedure (Lisp)</primary></indexterm>distance px py qx qy))
	        (pr (distance px py rx ry))
	        (qr (distance qx qy rx ry)))
	    (let ((sidelist (sort (list pq pr qr) #'&gt;)))
	      (= (first sidelist)
	         (+ (second sidelist) (third sidelist))))))
</programlisting><para>The idea is to calculate the three side lengths, put them in a list, sort them in descending order of magnitude, and then compare the first (longest) side with the sum of the other two. If and only if these lengths are equal are the points collinear. This approach has a lot to recommend it. The calculation depends only on the geometric relations among the points themselves; it's independent of their position and orientation on the plane. Slopes and intercepts are not even mentioned. As a bonus, this version of the procedure also gives consistent and sensible answers when two or three of the points are coincident: all such point sets are considered collinear.</para><para>Unfortunately, there is a heavy price to be paid for this simplicity. Up to this point, all computations have been done with exact arithmetic. If the original coordinates are specified by means of integers or rational numbers, then the slopes and intercepts are calculated without round-off or other error. For example, the line passing through (1 1) and (4 2) has slope <emphasis>m</emphasis>=1/3 and <emphasis>y</emphasis>-intercept <emphasis>b</emphasis>=2/3 (not decimal approximations such as 0.33 and 0.67). With numbers represented in this way, comparisons are guaranteed to give the mathematically correct answer. But exactness is unattainable in measuring distances. The procedure distance invoked by <literal moreinfo="none">triangle-collinear</literal> is defined like this:</para><programlisting id="I_programlisting33_tt747" format="linespecific">
	(defun distance (px py qx qy)
	  (<indexterm id="idx-CHP-33-2815" significance="normal"><primary>sqrt returning an irrational result</primary></indexterm>sqrt (+ (square (- qx px))
	           (square (- qy py)))))
</programlisting><para>The square root is the culprit, of course. If sqrt returns an irrational result, there's no hope of finding an exact, finite, numeric representation. When distances are calculated with <indexterm id="idx-CHP-33-2816" significance="normal"><primary>double-precision IEEE floating-point arithmetic</primary></indexterm>double-precision IEEE floating-point arithmetic, <literal moreinfo="none">triangle-collinear</literal> gives trustworthy answers for points whose coordinates are no larger than about 10<superscript>5</superscript>. Go much beyond that threshold, and the procedure inevitably starts to mistake very skinny triangles for degenerate ones, incorrectly reporting that the vertices are collinear.</para><para>There is no quick and easy fix for this failing. Tricks like rotating or scaling the coordinate frame will not help. It's just a bug (or feature?) of our universe: rational points can give rise to irrational distances. Getting exact and reliable results under these circumstances is not quite impossible, but it takes an industrial-strength effort. Where the three points really are collinear, this fact can be proved algebraically without evaluating the square roots. For example, given the collinear points (0 0), (3 3), and (5 5), the distance equation is <emphasis>sqrt</emphasis>(50) = <emphasis>sqrt</emphasis>(18) + <emphasis>sqrt</emphasis>(8), which reduces to 5 x<emphasis>sqrt</emphasis>(2) = 3 x<emphasis>sqrt</emphasis>(2) + 2 x<emphasis>sqrt</emphasis>(2). When the points are <emphasis>not</emphasis> collinear, numerical evaluation will eventually reveal an inequality, if you calculate enough digits of the roots. But I don't relish the idea of implementing a symbolic algebra system and an adaptive multiprecision arithmetic module just to test trios of points for collinearity. There's gotta be an easier way. In the <emphasis>Book</emphasis> version of the algorithm, I expect greater economy of means.</para></sect1><sect1 id="meandering_on" label="33.6"><title>Meandering On</title><para>To tell the rest of this story, I need to mention the context in which it took place. Some months ago I was playing with a simple model of <indexterm id="idx-CHP-33-2817" significance="normal"><primary>river meandering</primary></indexterm>river meandering—the formation of those giant horseshoe bends you see in the Lower Mississippi. The model decomposed the smooth curve of the river's course into a chain of short, straight segments. I needed to measure curvature along the river in terms of the bending angles between these segments, and in particular, I wanted to detect regions of zero curvature—hence the collinearity predicate.</para><para>Another part of the program gave me even more trouble. As meanders grow and migrate, one loop sometimes runs into the next one, at which point the river takes a shortcut and leaves behind a stranded "oxbow" lake. (You don't want to be standing in the way when this happens on the Mississippi.) To detect such events in the model, I needed to scan for <indexterm id="idx-CHP-33-2818" significance="normal"><primary>intersections of segments</primary></indexterm>intersections of segments. Again, I was able to get a routine working, but it seemed needlessly complex, with a decision tree sprouting a dozen branches. As in the case of collinearity, vertical segments and coincident points required special handling, and I also had to worry about parallel segments.</para><para>For the intersection problem, I eventually spent some time in the library and checked out what the Net had to offer. I learned a lot. That's where I found the tip that 1010 is close enough to infinity. And Bernard Chazelle and Herbert Edelsbrunner suggested a subtler way of finessing the singularities and degeneracies I had run into. In a 1992 review article on <indexterm id="idx-CHP-33-2819" significance="normal"><primary>line-segment intersection algorithms</primary></indexterm>line-segment intersection algorithms (see the "Further Reading" section at the end of this chapter), they wrote:</para><blockquote><para>For the ease of exposition, we shall assume that no two endpoints have the same <emphasis>x</emphasis>-or <emphasis>y</emphasis>-coordinates. This, in particular, applies to the two endpoints of the same segment, and thus rules out the presence of vertical or horizontal segments…Our rationale is that the key ideas of the algorithm are best explained without having to worry about special cases every step of the way. Relaxing the assumptions is very easy (no new ideas are required) but tedious. That's for the theory. Implementing the algorithm so that the program works in all cases, however, is a daunting task. There are also numerical problems that alone would justify writing another paper. Following a venerable tradition, however, we shall try not to worry too much about it.</para></blockquote><para>Perhaps the most important lesson learned from this foray into the literature was that others have also found meaty challenges in this field. It's not just that I'm a code wimp. This was a reassuring discovery; on the other hand, it did nothing to actually solve my problem.</para><para>Later, I wrote an item about line-segment intersection algorithms on my weblog at <ulink url="http://bit-player.org"/>. This was essentially a plea for help, and help soon came pouring in—more than I could absorb at the time. One reader suggested polar coordinates as a remedy for undefined slopes, and another advocated rewriting the linear equations in parametric form, so that <emphasis>x</emphasis>-and <emphasis>y</emphasis>-coordinates are given as functions of a new variable <emphasis>t</emphasis>. Barry Cipra proposed a somewhat different parametric scheme, and then came up with yet another algorithm, based on the idea of applying an affine transformation to shift one of the segments onto the interval (–1 0),(1 0). David Eppstein advocated removing the problem from Euclidean <indexterm id="idx-CHP-33-2820" significance="normal"><primary>computational geometry</primary></indexterm>geometry and solving it on the projective plane, where the presence of "a point at infinity" helps in dealing with singularities. Finally, Jonathan Richard Shewchuk gave me a pointer to his lecture notes, papers, and working code; I'll return to Shewchuk's ideas below.</para><para>I was impressed—and slightly abashed—by this flood of thoughtful and creative suggestions. There were several viable candidates for a segment-intersection procedure. Furthermore, I also found an answer to the collinearity problem. Indeed, I believe the solution that was handed to me may well be the <emphasis>Book</emphasis> algorithm.</para></sect1><sect1 id="duhmdashi_mean_aha" label="33.7"><title>"Duh!"—I Mean "Aha!"</title><para>In cartoons, the moment of discovery is depicted as a light bulb turning on in a thought balloon. In my experience, that sudden flash of understanding feels more like being thumped in the back of the head with a two-by-four. When you wake up afterwards, you've learned something, but by then your new insight is so blindingly obvious that you can't quite believe you didn't know it all along. After a few days more, you begin to suspect that maybe you <emphasis>did</emphasis> know it; you <emphasis>must</emphasis> have known it; you just needed reminding. And when you pass the discovery along to the next person, you'll begin, "As everyone knows…."</para><para>That was my reaction on reading Jonathan Shewchuk's "Lecture Notes on Geometric Robustness." He gives a collinearity algorithm that, once I understood it, seemed so natural and sensible that I'm sure it must have been latent within me somewhere. The key idea is to work with the <indexterm id="idx-CHP-33-2821" significance="normal"><primary>area of a triangle</primary></indexterm>area of a triangle rather than the perimeter, as in <literal moreinfo="none">triangle-collinear</literal>. Clearly, the area of a triangle is zero if and only if the triangle is a degenerate one, with collinear vertices. But measuring a function of the area rather a function of the perimeter has two big advantages. First, it can be done without square roots or other operations that would take us outside the field of rational numbers. Second, it is much less dependent on numerical precision.</para><para>Consider a family of isosceles triangles with vertices (0 0), (<emphasis>x</emphasis> 1), and (2<emphasis>x</emphasis> 0). As <emphasis>x</emphasis> increases, the difference between the length of the base and the sum of the lengths of the two legs gets steadily smaller, and so it becomes difficult to distinguish this very shallow triangle from a totally flattened one with vertices (0 0), (<emphasis>x</emphasis> 0), and (2<emphasis>x</emphasis> 0). The area calculation doesn't suffer from this problem. On the contrary, the area grows steadily as the triangle gets longer (see <xref linkend="testing_collinearity_by_measuring_area"/>). Numerically, even without exact arithmetic, the computation is much more robust.</para><figure id="testing_collinearity_by_measuring_area" label="33-5" float="0"><title>Testing collinearity by measuring area</title><mediaobject id="I_mediaobject33_tt748"><imageobject role="print"><imagedata fileref="figs/print/beauty_3305.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/beauty_3305.png" format="PNG"/></imageobject></mediaobject></figure><para>How to measure the area? The Euclidean formula 1/2<emphasis>bh</emphasis> is not the best answer, and neither is the trigonometric approach. A far better plan is to regard the sides of a triangle as vectors; the two vectors emanating from any one vertex define a parallelogram, whose area is given by the cross product of the vectors. The area of the triangle is just one-half of the area of the parallelogram. Actually, this computation gives the "signed area": the result is positive if the vertices of the triangle are taken in counterclockwise order, and negative if taken in clockwise order. What's most important for present purposes, the signed area is zero if and only if the vertices are collinear.</para><para>The vector <indexterm id="idx-CHP-33-2822" significance="normal"><primary>errors</primary><secondary>Euclid</secondary><tertiary>formula for area of a triangle</tertiary></indexterm>formula for the area is expressed most succinctly in terms of the determinant of a two-by-two matrix:</para><para><mediaobject id="I_mediaobject33_tt749"><imageobject role="print"><imagedata fileref="figs/print/equation10.pdf" format="PDF"/></imageobject><imageobject role="web"><imagedata fileref="figs/web/equation10.png" format="PNG"/></imageobject></mediaobject></para><para>Because I'm interested only in the case where the determinant is zero, I can ignore the factor of 1/2 and code the collinearity predicate in this simple form:</para><programlisting id="I_programlisting33_tt750" format="linespecific">
	(defun area-collinear (px py qx qy rx ry)
	  (= (* (- px rx) (- qy ry))
	     (* (- qx rx) (- py ry))))
</programlisting><para>So, here it is: a simple arithmetical function of the <emphasis>x</emphasis>-and <emphasis>y</emphasis>-coordinates, requiring four subtractions, two multiplications, and an equality predicate, but nothing else—no <literal moreinfo="none">ifs</literal>, no slopes, no intercepts, no square roots, no hazard of divide-by-zero errors. If executed with exact rational arithmetic, the procedure always produces exact and correct results. Characterizing the behavior with floating-point arithmetic is more difficult, but it is far superior to the version based on comparing distances on the perimeter. Shewchuk provides highly tuned C code that uses floating-point when possible and switches to exact arithmetic when necessary.</para></sect1><sect1 id="conclusion-id019" label="33.8"><title>Conclusion</title><para>My adventures and misadventures searching for the ideal collinearity predicate do not make a story with a tidy moral. In the end, I believe I stumbled upon the correct solution to my specific problem, but the larger question of how best to find such solutions in general remains unsettled.</para><para>One lesson that <emphasis>might</emphasis> be drawn from my experience is to seek help without delay: some-body out there knows more than you do. You may as well take advantage of the cumulative wisdom of your peers and predecessors. In other words, Google can probably find the algorithm you want, or even the source code, so why waste time reinventing it?</para><para>I have mixed feelings about this advice. When an engineer is designing a bridge, I expect her to have a thorough knowledge of how others in the profession have solved similar problems in the past. Yet expertise is not merely skill in finding and applying other people's bright ideas; I want my bridge designer to have solved a few problems on her own as well.</para><para>Another issue is how long to keep an ailing program on life support. In this chapter, I have been discussing the tiniest of programs, so it cost very little to rip it up and start over whenever I encountered the slightest unpleasantness. For larger projects, the decision to throw one away is never so easy. And doing so is not necessarily prudent: you are trading known problems for unknown ones.</para><para>Finally, there is the question of just how much the quest for "beautiful code" should be allowed to influence the process of programming or software development. The mathematician G. H. Hardy proclaimed, "There is no permanent place in the world for ugly mathematics." Do aesthetic principles carry that much weight in computer science as well? Here's another way of asking the same question: do we have any guarantee that a <emphasis>Book</emphasis>-quality program exists for every well-formulated <indexterm id="idx-CHP-33-2823" significance="normal"><primary>computational geometry</primary></indexterm>computational problem? Maybe <emphasis>The Book</emphasis> has some blank pages.</para></sect1><sect1 id="further_reading-id004" label="33.9"><title>Further Reading</title><para>Avnaim, F., J.-D. Boissonnat, O. Devillers, F. P. Preparata, and M. Yvinec. "Evaluating signs of determinants using single-precision arithmetic." <emphasis>Algorithmica</emphasis>, Vol. 17, pp. 111–132, 1997.</para><para>Bentley, Jon L., and Thomas A. Ottmann. "Algorithms for reporting and counting geometric intersections." <emphasis>IEEE Transactions on Computers</emphasis>, Vol. C-28, pp. 643–647, 1979.</para><para>Braden, Bart. "The surveyor's area formula." <emphasis>The College Mathematics Journal</emphasis>, Vol. 17, No. 4, pp. 326–337, 1986.</para><para>Chazelle, Bernard, and Herbert Edelsbrunner. "An optimal algorithm for intersecting line segments in the plane." <emphasis>Journal of the Association for Computing Machinery</emphasis>, Vol. 39, pp. 1–54, 1992.</para><para>Forrest, A. R. "Computational geometry and software engineering: Towards a geometric computing environment." In <emphasis>Techniques for Computer Graphics</emphasis> (edited by D. F. Rogers and R. A. Earnshaw), pp. 23–37. New York: Springer-Verlag, 1987.</para><para>Forrest, A. R. "Computational geometry and uncertainty." In <emphasis>Uncertainty in Geometric Computations</emphasis> (edited by Joab Winkler and Mahesan Niranjan), pp. 69–77. Boston: Kluwer Academic Publishers, 2002.</para><para>Fortune, Steven, and Christopher J. Van Wyk. "Efficient exact arithmetic for computational geometry." In <emphasis>Proceedings of the Ninth Annual Symposium on Computational Geometry</emphasis>, pp. 163–172. New York: Association for Computing Machinery, 1993.</para><para>Guibas, Leonidas, and Jorge Stolfi. "Primitives for the manipulation of general subdivisions and the computation of Voronoi diagrams." <emphasis>ACM Transactions on Graphics</emphasis>, Vol. 4, No. 2, pp. 74–123, 1985.</para><para>Hayes, Brian. "Only connect!" <ulink url="http://bit-player.org/2006/only-connect"/>. [Weblog item, posted September 14, 2006.]</para><para>Hayes, Brian. "Computing science: Up a lazy river." <emphasis>American Scientist</emphasis>, Vol. 94, No. 6, pp. 490–494, 2006. (<ulink url="http://www.americanscientist.org/AssetDetail/assetid/54078"/>)</para><para>Hoffmann, Christoph M., John E. Hopcroft and Michael S. Karasick. "Towards implementing robust geometric computations." <emphasis>Proceedings of the Fourth Annual Symposium on Computational Geometry</emphasis>, pp. 106–117. New York: Association for Computing Machinery, 1988.</para><para>O'Rourke, Joseph. <emphasis>Computational Geometry</emphasis> in C. Cambridge: Cambridge University Press, 1994.</para><para>Preparata, Franco P., and Michael I. Shamos. <emphasis>Computational Geometry: An Introduction</emphasis>. New York: Springer-Verlag, 1985.</para><para>Qian, Jianbo, and Cao An Wang. "How much precision is needed to compare two sums of square roots of integers?" <emphasis>Information Processing Letters</emphasis>, Vol. 100, pp. 194–198, 2006.</para><para>Shewchuk, Jonathan Richard. "Adaptive precision floating-point arithmetic and fast robust geometric predicates." <emphasis>Discrete and Computational Geometry</emphasis>, Vol. 18, pp. 305–363, 1997. Preprint available at <ulink url="http://www.cs.cmu.edu/afs/cs/project/quake/public/papers/robustarithmetic.ps"/>.</para><para>Shewchuk, Jonathan Richard. Lecture notes on geometric robustness. [Version of October 26, 2006.] (<ulink url="http://www.cs.berkeley.edu/~jrs/meshpapers/robnotes.ps.gz"/>. See also source code at <ulink url="http://www.cs.cmu.edu/afs/cs/project/quake/public/code/predicates.c"/>.)</para></sect1></chapter><colophon id="afterword"><title>Afterword</title><para><emphasis>Andy Oram</emphasis></para><para><emphasis>Beautiful code surveys the range of human invention and ingenuity</emphasis> in one area of endeavor: the development of computer systems. The beauty in each chapter comes from the discovery of unique solutions, a discovery springing from the authors' power to look beyond set boundaries, to recognize needs overlooked by others, and to find surprising solutions to troubling problems.</para><para>Many of the authors confronted limitations—in the physical environment, in the resources available, or in the very definition of their requirements—that made it hard even to imagine solutions. Others entered domains where solutions already existed, but brought in a new vision and a conviction that something much better could be achieved.</para><para>All the authors in this book have drawn lessons from their projects. But we can also draw some broader lessons after making the long and eventful journey through the whole book.</para><para>First, there are times when tried and true rules really do work. So, often one encounters difficulties when trying to maintain standards for robustness, readability, or other tenets of good software engineering. In such situations, it is not always necessary to abandon the principles that hold such promise. Sometimes, getting up and taking a walk around the problem can reveal a new facet that allows one to meet the requirements without sacrificing good technique.</para><para>On the other hand, some chapters confirm the old cliché that one must know the rules before one can break them. Some of the authors built up decades of experience before taking a different path toward solving one thorny problem—and this experience gave them the confidence to break the rules in a constructive way.</para><para>On the other hand, cross-disciplinary studies are also championed by the lessons in this book. Many authors came into new domains and had to fight their way in relative darkness. In these situations, a particularly pure form of creativity and intelligence triumphed.</para><para>Finally, we learn from this book that beautiful solutions don't last for all time. New circumstances always require a new look. So, if you read the book and thought, "I can't use these authors' solutions on any of my own projects," don't worry—next time these authors have projects, they will use different solutions, too.</para><para>For about two months I worked intensively on this book by helping authors hone their themes and express their points. This immersion in the work of superbly talented inventors proved to be inspiring and even uplifting. It gave me the impulse to try new things, and I hope this book does the same for its readers.<indexterm id="I_indexterm_tt751" class="endofrange" startref="idx-CHP-33-2794" significance="normal"><primary>computational geometry</primary></indexterm></para></colophon><colophon id="contributors"><title>Contributors</title><para><emphasis role="smaller">Jon bentley is a computer scientist at avaya labs research</emphasis>. His research interests include programming techniques, algorithm design, and the design of software tools and interfaces. He has written books on programming, and articles on a variety of topics, ranging from the theory of algorithms to software engineering. He received a B.S. from Stanford in 1974, and an M.S. and Ph.D. from the University of North Carolina in 1976, then taught Computer Science at Carnegie Mellon University for six years. He joined Bell Labs Research in 1982, and retired in 2001 to join Avaya. He has been a visiting faculty member at West Point and Princeton, and he has been a member of teams that have shipped software tools, telephone switches, telephones, and web services.</para><para><emphasis role="strong">Tim Bray</emphasis> managed the Oxford English Dictionary project at the University of Waterloo in Ontario, Canada in 1987–1989, co-founded Open Text Corporation in 1989, launched one of the first public web search engines in 1995, co-invented XML 1.0 and co-edited "Namespaces in XML" between 1996 and 1999, founded Antarctica Systems in 1999, and served as a Tim Berners-Lee appointee on the W3C Technical Architecture Group in 2002–2004. Currently, he serves as Director of Web Technologies at Sun Microsystems, publishes a popular weblog, and co-chairs the IETF AtomPub Working Group.</para><para><emphasis role="strong">Bryan Cantrill</emphasis> is a Distinguished Engineer at Sun Microsystems, where he has spent most of his career working on the Solaris kernel. Most recently he, along with colleagues Mike Shapiro and Adam Leventhal, designed and implemented DTrace, a facility for dynamic instrumentation of production systems that won the <emphasis>Wall Street Journal's</emphasis> top award for innovation in 2006.</para><para><emphasis role="strong">Douglas Crockford</emphasis> is a product of our public school system. A registered voter, he owns his own car. He has developed office automation systems. He did research in games and music at Atari. He was Director of Technology at Lucasfilm Ltd. He was Director of New Media at Paramount. He was the founder and CEO of Electric Communities. He was founder and CTO of State Software, where he discovered JSON. He is now an architect at Yahoo! Inc.</para><para><emphasis role="strong">Rogerio Atem de Carvalho</emphasis> is a teacher and researcher at the Federal Center for Technological Education of Campos (CEFET Campos), Brazil. He was awarded with the 2006 IFIP Distinguished Academic Leadership Award in Vienna, Austria, for his research on Free/ Open Source Enterprise Resources Planning (ERP). His research and consulting interests also include Decision Support Systems and Software Engineering.</para><para><emphasis role="strong">Jeff Dean</emphasis> joined Google in 1999 and is currently a Google Fellow in Google's Systems Infrastructure Group. While at Google, he has worked on Google's crawling, indexing, query serving, and advertising systems, implemented several search quality improvements, and built various pieces of Google's distributed computing infrastructure. Prior to joining Google, he was at DEC/Compaq's Western Research Laboratory, where he worked on profiling tools, microprocessor architecture, and information retrieval. He received a Ph.D. from the University of Washington in 1996, working with Craig Chambers on compiler optimization techniques for object-oriented languages. Prior to graduate school, he worked at the World Health Organization's Global Programme on AIDS.</para><para><emphasis role="strong">Jack Dongarra</emphasis> received a B.S. in Mathematics from Chicago State University in 1972, and an M.S. in Computer Science from the Illinois Institute of Technology in 1973. He received his Ph.D. in Applied Mathematics from the University of New Mexico in 1980. He worked at the Argonne National Laboratory until 1989, becoming a senior scientist. He now holds an appointment as University Distinguished Professor of Computer Science in the Computer Science Department at the University of Tennessee. He has the position of a Distinguished Research Staff member in the Computer Science and Mathematics Division at Oak Ridge National Laboratory (ORNL), Turing Fellow in the Computer Science and Mathematics Schools at the University of Manchester, and an Adjunct Professor in the Computer Science Department at Rice University. He specializes in numerical algorithms in linear algebra, parallel computing, the use of advanced-computer architectures, programming methodology, and tools for parallel computers. His research includes the development, testing, and documentation of high-quality mathematical software. He has contributed to the design and implementation of the following open source software packages and systems: EISPACK, LINPACK, the BLAS, LAPACK, ScaLAPACK, Netlib, PVM, MPI, NetSolve, Top500, ATLAS, and PAPI. He has published approximately 200 articles, papers, reports, and technical memoranda, and he is co-author of several books. He was awarded the IEEE Sid Fernbach Award in 2004 for his contributions in the application of high-performance computers using innovative approaches. He is a Fellow of the AAAS, ACM, and the IEEE, and a member of the National Academy of Engineering.</para><para><emphasis role="strong">R. Kent Dybvig</emphasis> is a professor of Computer Science at Indiana University. He received his Ph.D. in Computer Science from the University of North Carolina in 1987, two years after joining the faculty at Indiana. His research in the design and implementation of programming languages has led to significant contributions involving control operators, syntactic abstraction, program analysis, compiler optimization, register allocation, multithreading, and automatic storage management. In 1984, he created <emphasis>Chez Scheme</emphasis> and remains its principal developer. Known for fast compile times and reliability as well as for its ability to run even complex programs with large memory footprints efficiently, <emphasis>Chez Scheme</emphasis> has been used to build commercial systems for enterprise integration, web serving, virtual reality, robotic drug testing, circuit layout, and more. It is also used for computer science education at all levels, as well as research in a variety of areas. Dybvig is author of <emphasis>The Scheme Programming Language</emphasis>, Third Edition (MIT Press), and is an editor of the forthcoming Revised<superscript>6</superscript> Report on Scheme.</para><para><emphasis role="strong">Michael Feathers</emphasis> is a consultant with Object Mentor. He has been active in the Agile community for the past seven years, balancing his time between working with, training, and coaching various teams around the world. Prior to joining Object Mentor, Michael designed a proprietary programming language and wrote a compiler for it. He also designed a large multiplatform class library and a framework for instrumentation control. Publicly, Michael developed CppUnit, the initial port of JUnit to C++; and FitCpp, a port of FIT for C++. In 2005, Michael wrote the book <emphasis>Working Effectively with Legacy Code</emphasis> (Prentice Hall). When he isn't engaged with a team, he spends most of his time investigating ways of altering design over time in large code bases.</para><para><emphasis role="strong">Karl Fogel</emphasis>, in 1995, together with Jim Blandy, co-founded Cyclic Software, the first company offering commercial CVS support. In 1997, Karl added support for CVS anonymous read-only repository access, thus allowing easy access to development code in open source projects. In 1999, he wrote <emphasis>Open Source Development with CVS</emphasis> (Coriolis). From 2000–2006, he worked for CollabNet, Inc., managing the creation and development of Subversion, an open source version control system written from scratch by CollabNet and a team of open source volunteers. In 2005, he wrote <emphasis>Producing Open Source Software: How to Run a Successful Free Software Project</emphasis> (O'Reilly; also online at <ulink url="http://producingoss.com"/>). After a brief stint as an Open Source Specialist at Google in 2006, he left to become full-time editor of Question-Copyright.org. He continues to participate in various open source projects, including Sub-version and GNU Emacs.</para><para><emphasis role="strong">Sanjay Ghemawat</emphasis> is a Google Fellow who works in the Systems Infrastructure Group at Google. He has designed and implemented distributed storage systems, text-indexing systems, performance tools, a data representation language, an RPC system, a malloc implementation, and many other libraries. Prior to joining Google, he was a member of the research staff at DEC Systems Research Center, where he worked on a profiling system and an optimizing compiler for Java, and implemented a Java virtual machine. He received a Ph.D. from MIT in 1995 concerning the implementation of object-oriented databases.</para><para><emphasis role="strong">Ashish Gulhati</emphasis> is Chief Developer of Neomailbox, an Internet privacy service, and the developer of Cryptonite, an OpenPGP-compatible secure webmail system. A commercial software developer for more than 15 years, and one of India's first digital rights activists and F/OSS hackers, he has written numerous open source Perl modules, which are available from CPAN. His 1993–1994 articles in <emphasis>PC Quest</emphasis> and <emphasis>DataQuest</emphasis> magazines were the first in the mainstream Indian computing press to introduce readers to Free Software, GNU/ Linux, the Web, and the Internet, many years before the availability of commercial Internet access in India, and formed an important part of the PC Quest Linux Initiative, which resulted in a million Linux CDs being distributed in India since 1995. He is rapidly evolving into a cyborg thanks to an eclectic collection of wearable computers.</para><para><emphasis role="strong">Elliotte Rusty Harold</emphasis> is originally from New Orleans, to which he returns periodically in search of a decent bowl of gumbo. However, he currently resides in the Prospect Heights neighborhood of Brooklyn with his wife Beth, dog Shayna, and cats Charm (named after the quark) and Marjorie (named after his mother-in-law). He's an adjunct professor of computer science at Polytechnic University, where he teaches Java, XML, and object-oriented programming. His Cafe au Lait web site (<ulink url="http://www.cafeaulait.org"/>) has become one of the most popular independent Java sites on the Internet; his spin-off site, Cafe con Leche (<ulink url="http://www.cafeconleche.org"/>), has become one of the most popular XML sites. His books include <emphasis>Java I/O, Java Network Programming, XML in a Nutshell</emphasis> (all O'Reilly), and <emphasis>XML Bible</emphasis> (Wiley). He's currently working on the XOM Library for processing XML with Java, the Jaxen XPath engine, and the Amateur media player.</para><para><emphasis role="strong">Brian Hayes</emphasis> writes the Computing Science column in <emphasis>American Scientist</emphasis> magazine and also has a weblog at <ulink url="http://bit-player.org"/>. In the past, he wrote similar columns on mathematics and computer science for <emphasis>Scientific American, Computer Language</emphasis>, and <emphasis>The Sciences</emphasis>. His book <emphasis>Infrastructure: A Field Guide to the Industrial Landscape</emphasis> (Norton) was published in 2005.</para><para><emphasis role="strong">Simon Peyton Jones, M.A., MBCS</emphasis>, C.Eng., graduated from Trinity College Cambridge in 1980. After two years in industry, he spent seven years as a lecturer at University College London, and nine years as a professor at Glasgow University before moving to Microsoft Research in 1998. His main research interest is in functional programming languages, their implementation, and their application. He has led a succession of research projects focused on the design and implementation of production-quality functional-language systems for both uniprocessors and parallel machines. He was a key contributor to the design of the now-standard functional language Haskell, and is the lead designer of the widely used Glasgow Haskell Compiler (GHC). He has written two textbooks about the implementation of functional languages.</para><para><emphasis role="strong">Jim Kent</emphasis> is a research scientist at the Genome Bioinformatics Group at the University of California Santa Cruz. Jim has been programming professionally since 1983. During the first half of his career, he focused on paint and animation software, authoring among other works the award-winning programs Aegis Animator, Cyber Paint, and Autodesk Animator. In 1996, tired of keeping up with the Windows API treadmill, he decided to pursue his interest in biology, earning a Ph.D. in 2002. As a graduate student, he wrote GigAssembler—a program that produced the first assembly of the human genome—one day ahead of Celera's first genome assembly, helping assure that the bulk of the genome would remain free of patents and other legal entanglements. Jim is an author of 40 scientific papers. His work today is primarily in creating programs, databases, and web sites that help scientists analyze and understand the genome.</para><para><emphasis role="strong">Brian Kernighan</emphasis> received his B.Sc. from the University of Toronto in 1964, and a Ph.D. in electrical engineering from Princeton in 1969. He was in the Computing Science Research center at Bell Labs until 2000, and is now in the Computer Science Department at Princeton. He is the author of eight books and a number of technical papers, and holds four patents. His research areas include programming languages, tools, and interfaces that make computers easier to use, often for nonspecialist users. He is also interested in technology education for nontechnical audiences.</para><para><emphasis role="strong">Adam Kolawa</emphasis> is the co-founder and CEO of Parasoft, a leading provider of Automated Error Prevention (AEP) software solutions. Kolawa's years of experience with various software development processes has resulted in his unique insight into the high-tech industry and the uncanny ability to successfully identify technology trends. As a result, he has orchestrated the development of several successful commercial software products to meet growing industry needs to improve software quality—often before the trends have been widely accepted. Kolawa, co-author of <emphasis>Bulletproofing Web Applications</emphasis> (Hungry Minds), has contributed to and written more than 100 commentary pieces and technical articles for publications such as <emphasis>The Wall Street Journal, CIO, Computerworld, Dr. Dobb's Journal, and IEEE Computer</emphasis>; he has also authored numerous scientific papers on physics and parallel processing. His recent media engagements include CNN, CNBC, BBC, and NPR. Kolawa holds a Ph.D. in theoretical physics from the California Institute of Technology, and has been granted 10 patents for his recent inventions. In 2001, Kolawa was awarded the Los Angeles Ernst &amp; Young's Entrepreneur of the Year Award in the software category.</para><para><emphasis role="strong">Greg Kroah-Hartman</emphasis> is the current Linux kernel maintainer for more driver subsystems than he wants to admit, along with the driver core, <emphasis>sysfs, kobject, kref</emphasis>, and <emphasis>debugfs</emphasis> code. He also helped start the linux-hotplug and <emphasis>udev</emphasis> projects, and is one half of the kernel stable maintainer team. He works for SuSE Labs/Novell and does various kernel-related things for them. He is the author of the book <emphasis>Linux Kernel in a Nutshell</emphasis> (O'Reilly) and the co-author of <emphasis>Linux Device Drivers</emphasis>, Third Edition (O'Reilly).</para><para><emphasis role="strong">Andrew Kuchling</emphasis> has 11 years of experience as a software developer and is a longtime member of the Python development community. Some of his Python-related work includes writing and maintaining several standard library modules, writing a series of "What's new in Python 2.x" articles and other documentation, planning the 2006 and 2007 PyCon conferences, and acting as a director of the Python Software Foundation. Andrew graduated with a B.Sc. in Computer Science from McGill University in 1995. His web page is at <ulink url="http://www.amk.ca"/>.</para><para><emphasis role="strong">Piotr Luszczek</emphasis> received his M.Sc. degree from the University of Mining and Metallurgy in Krakow, Poland for work on parallel out-of-core libraries. He earned his doctorate degree for the innovative use of dense matrix computational kernels in sparse direct and iterative numerical linear algebra algorithms. He applied this experience to develop fault-tolerant libraries that used out-of-core techniques. Currently, he is a Research Professor at the University of Tennessee, Knoxville. His work involves standardization of benchmarking of large supercomputer installations. He is an author of self-adapting software libraries that automatically choose the best algorithm to efficiently utilize available hardware and can optimally process the input data. He is also involved in high-performance programming language design and implementation.</para><para><emphasis role="strong">Ronald Mak</emphasis> was a senior scientist at the Research Institute for Advanced Computer Science when he was on contract to NASA Ames as the architect and lead developer of the middleware for the Collaborative Information Portal. After the rovers landed on Mars, he provided mission support at JPL and at Ames. He then received an academic appointment with the University of California Santa Cruz, and he was again on contract to NASA, this time to design and develop enterprise software to help return astronauts to the moon. Ron is co-founder and CTO of Willard &amp; Lowe Systems, Inc. (<ulink url="http://www.willardlowe.com">www.willardlowe.com</ulink>), a consulting company that specializes in enterprise information management systems. He has written several books on computer software, and he has degrees in the mathematical sciences and computer science from Stanford University.</para><para><emphasis role="strong">Yukihiro "Matz" Matsumoto</emphasis> is a programmer, a Japanese open source evangelist, and the creator of the recently popular Ruby language. He started development of Ruby in 1993, so it's actually as old as Java. Now he works for Network Applied Communication Laboratory, Inc. (NaCl, also known as netlab.jp), which has sponsored Ruby development since 1997. Because his real name is too long to remember and is difficult for non-Japanese speakers to pronounce right, on the Net he uses the nickname Matz.</para><para><emphasis role="strong">Arun Mehta</emphasis> is an electrical engineer and computer scientist who has studied and taught in India, the U.S., and Germany. He is one of India's early telecom and cyber-activists, trying to obtain consumer-friendly policies that will help the spread of modern communications in rural areas and among the poor. His current passions include village radio and technology for the disabled. He is a professor and chairman of the Computer Engineering Department of JMIT, Radaur, Haryana, India. His web sites include <ulink url="http://india-gii.org"/>, <ulink url="http://radiophony.com"/>, and <ulink url="http://holisticit.com"/>.</para><para><emphasis role="strong">Rafael Manhaes Monnerat</emphasis> is an IT Analyst at CEFET CAMPOS, and an offshore consultant for Nexedi SARL. His interests include Free/Open Source Systems, ERP, and cool programming languages.</para><para><emphasis role="strong">Travis E. Oliphant</emphasis> received a B.S. in Electrical and Computer Engineering and Mathematics from Brigham Young University in 1995, and an M.S. in Electrical and Computer Engineering from the same institution in 1996. In 2001, he received a Ph.D. in Biomedical Engineering from the Mayo Graduate School in Rochester, Minnesota. He is a principal author for SciPy and NumPy, which are scientific computing libraries for the Python language. His research interests include micro-scale impedance imaging, MRI reconstruction in inhomogeneous fields, and general biomedical inverse problems. He is currently an Assistant Professor in the Electrical and Computer Engineering Department at Brigham Young University.</para><para><emphasis role="strong">Andy Oram</emphasis> is an editor at O'Reilly Media. An employee of the company since 1992, Andy currently specializes in free software and open source technologies. His work for O'Reilly includes the first books ever released by a U.S. publisher on Linux, and the 2001 title <emphasis>Peer-to-Peer</emphasis>. His modest programming and system administration skills are mostly self-taught. Andy is also a member of Computer Professionals for Social Responsibility and writes often for the O'Reilly Network (<ulink url="http://oreillynet.com"/>) and other publications on policy issues related to the Internet, and on trends affecting technical innovation and its effects on society. His web site is <ulink url="http://www.praxagora.com/andyo"/>.</para><para><emphasis role="strong">William R. Otte</emphasis> is a Ph.D. student in the Department of Electrical Engineering and Computer Science (EECS) at Vanderbilt University in Tennessee. His research focuses on middleware for distributed real-time and embedded (DRE) systems. He is currently involved in several aspects of developing a Deployment and Configuration Engine (DAnCE) for CORBA Components. This work involves investigation of techniques for runtime planning, and adaptation for component-based applications, as well as specification and enforcement of application quality-of-service and fault-tolerance requirements. Before joining as a graduate student, William worked for a year as a staff engineer at the Institute for Software Integrated Systems after graduating in 2005 with a B.S. in Computer Science from Vanderbilt University.</para><para><emphasis role="strong">Andrew Patzer</emphasis> is the Director of the Bioinformatics Program at the Medical College of Wisconsin. Andrew has been a software developer for the past 15 years and has written several articles and books, including <emphasis>Professional Java Server Programming</emphasis> (Peer Information, Inc.) and <emphasis>JSP Examples and Best Practices</emphasis> (Apress). Andrew's current interest lies in the field of Bioinformatics, using dynamic languages such as Groovy to mine the enormous amounts of available biological data and help perform analysis for scientific researchers.</para><para><emphasis role="strong">Charles Petzold</emphasis> is a freelance writer who specializes in Windows application programming. He is the author of <emphasis>Programming Windows</emphasis> (Microsoft Press), which in its five editions between 1988 and 1999 taught a generation of programmers about the Windows API. His most recent book is <emphasis>Applications = Code + Markup: A Guide to the Microsoft Windows Presentation Foundation</emphasis> (Microsoft Press), and he is also author of a unique exploration into digital technologies entitled <emphasis>Code: The Hidden Language of Computer Hardware and Software</emphasis> (Microsoft Press). His web site is <ulink url="http://www.charlespetzold.com"/>.</para><para><emphasis role="strong">T. V. Raman</emphasis> specializes in web technologies and auditory user interfaces. In the early 1990s, he introduced the notion of audio formatting in his Ph.D. thesis entitled <emphasis>AsTeR: Audio System For Technical Readings</emphasis>, concerning a system that produced high-quality aural renderings of technical documents. Emacspeak is the result of applying these ideas to the broader domain of computer user interfaces. Raman is now a Research Scientist at Google, where he focuses on web applications.</para><para><emphasis role="strong">Alberto Savoia</emphasis> is co-founder and CTO of Agitar Software. Before Agitar, he was Senior Director of Engineering at Google; prior to that he was the Director of Software Research at Sun Microsystems Laboratories. Alberto's passion and main body of work and research is in the area of software development technology—in particular, tools and technology to help programmers test and verify their own code during the design and development phase.</para><para><emphasis role="strong">Douglas C. Schmidt</emphasis> is a Full Professor in the Electrical Engineering and Computer Science (EECS) Department, Associate Chair of the Computer Science and Engineering program, and a Senior Research Scientist at the Institute for Software Integrated Systems (ISIS) at Vanderbilt University in Tennessee. He is an expert on distributed computing patterns and middleware frameworks and has published more than 350 technical papers and 9 books that cover a range of topics including high-performance communication software systems, parallel processing for high-speed networking protocols, real-time distributed object computing, object-oriented patterns for concurrent and distributed systems, and model-driven development tools. In addition to his academic research, Dr. Schmidt is CTO for PrismTechnologies, and he has over 15 years of experience leading the development of widely used, open source middleware platforms that contain a rich set of components and domain-specific languages that implement key patterns for high-performance distributed systems. Dr. Schmidt received his Ph.D. in Computer Science from the University of California Irvine in 1994.</para><para><emphasis role="strong">Christopher Seiwald</emphasis> is the author of Perforce (a software configuration management system), Jam (a build tool), and "The Seven Pillars of Pretty Code" (a paper from which <xref linkend="code_in_motion"/>, <emphasis>Code in Motion</emphasis>, draws ideas). Prior to founding Perforce, he managed the network development group at Ingres Corporation, where he toiled for years to make asynchronous networking code look palatable. He is currently the CEO of Perforce Software, and still has his hand in coding.</para><para><emphasis role="strong">Diomidis Spinellis</emphasis> is an Associate Professor at the Department of Management Science and Technology at the Athens University of Economics and Business, Greece. His research interests include software engineering tools, programming languages, and computer security. He holds an M.Eng. in Software Engineering and a Ph.D. in Computer Science, both from Imperial College London. He has published more than 100 technical papers in the areas of software engineering, information security, and ubiquitous computing. He has also written the two <emphasis>Open Source Perspective books: Code Reading</emphasis> (Software Development Productivity Award 2004), and <emphasis>Code Quality</emphasis> (both Addison-Wesley). He is a member of the IEEE Software editorial board, authoring the regular "Tools of the Trade" column. Diomidis is a FreeBSD committer and the author of a number of open source software packages, libraries, and tools.</para><para><emphasis role="strong">Lincoln Stein</emphasis> is an M.D./Ph.D. who works on biological data integration and visualization. After his training at Harvard Medical School, he worked at the Whitehead Institute/ MIT Center for Genome Research, where he developed the databases used for the mouse and human genome maps. At Cold Spring Harbor he works on a variety of genome-scale databases including WormBase, the database of the C. elegans genome; Gramene, a comparative genome-mapping database for rice and other monocots; the International Hap-Map Project Database; and a human biological pathways database called Reactome. Lincoln is also author of the books <emphasis>How to Set Up and Maintain a Web Site</emphasis> (Addison-Wesley), <emphasis>Network Programming in Perl</emphasis> (Addison-Wesley), <emphasis>Official Guide to Programming with CGI.pm</emphasis> (Wiley), and <emphasis>Writing Apache Modules with Perl and C</emphasis> (O'Reilly).</para><para><emphasis role="strong">Nevin Thompson</emphasis> translated Yukihiro Matsumoto's <xref linkend="treating_code_as_an_essay"/>, <emphasis>Treating Code As an Essay</emphasis>, from the Japanese. His clients include Japan's largest television network, as well as Technorati Japan and Creative Commons.</para><para><emphasis role="strong">Henry S. Warren</emphasis>, Jr. has had a 45-year career with IBM, spanning from the IBM 704 to the PowerPC. He has worked on various military command and control systems, and on the SETL project under Jack Schwartz at New York University. Since 1973, he has been with IBM's Research Division, focusing on compilers and computer architectures. Hank currently works on the Blue Gene petaflop computer project. He received his Ph.D. in computer science from the Courant Institute at New York University. He is the author of <emphasis>Hacker's Delight</emphasis> (Addison-Wesley).</para><para><emphasis role="strong">Laura Wingerd</emphasis> formed her early opinions of software configuration management during a decade of wrangling builds and source code for the Sybase and Ingres database products. She joined Perforce Software in its first year and has since acquired quite a bit of SCM expertise from the very Perforce customers she purports to advise. She is the author of Practical Perforce (O'Reilly) and a number of SCM-related whitepapers; <emphasis>The Flow of Change</emphasis>, a Google Tech Talk, marks her video debut. Laura is currently Vice President of Product Technology at Perforce Software, dividing her time between promoting sound SCM practices and investigating new and better ways to put Perforce to use.</para><para><emphasis role="strong">Greg Wilson</emphasis> holds a Ph.D. in Computer Science from the University of Edinburgh and has worked on high-performance scientific computing, data visualization, and computer security. He is now an adjunct professor in Computer Science at the University of Toronto, and a contributing editor with <emphasis>Dr. Dobb's Journal</emphasis>.</para><para><emphasis role="strong">Andreas Zeller</emphasis> graduated from TU Darmstadt in 1991 and received a Ph.D. in Computer Science in 1997 from TU Braunschweig in Germany. Since 2001, he has been a Computer Science professor at Saarland University in Germany. Zeller researches large programs and their history, and he has developed a number of methods to determine the causes of program failures in open source programs, as well as in industrial contexts at IBM, Microsoft, SAP, and others. His book <emphasis>Why Programs Fail: A Guide to Systematic Debugging</emphasis> (Morgan Kaufmann) received the Software Development Magazine productivity award in 2006.</para></colophon><colophon id="colophon"><title>COLOPHON</title><para>The cover image is from <ulink url="http://www.clipart.com">www.clipart.com</ulink>. The cover fonts are Akzidenz Grotesk and Orator.</para><para>The text font is Adobe's Meridien; the heading font is ITC Bailey.</para></colophon></book>
